{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implements an RNN on a synthetic data set, following the architecture \n",
    "described in \"Deep Knowledge Tracing\" by Chris Piech et al.\n",
    "The RNN implementation is based on min-char-rnn.py by Andrej Karpathy (@karpathy).\n",
    "BSD License\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "synthetic_data_set = \"syntheticDetailed/naive_c5_q50_s4000_v0.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 0 0 1 1 0 1 1 1 0 0 1 1 1 0 1 1 1 1 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 0\n",
      "  0 1 1 0 1 1 0 1 0 1 1 0 1]\n",
      " [1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
      "  1 0 0 0 1 0 1 0 0 1 0 0 0]\n",
      " [0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1 1 0 0 1\n",
      "  1 1 1 0 0 1 1 1 0 0 1 1 1]\n",
      " [0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 1 0 0 1 1\n",
      "  0 1 0 0 1 1 1 1 0 0 1 1 1]\n",
      " [0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1\n",
      "  1 1 1 0 0 0 1 0 1 1 1 1 1]\n",
      " [0 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1\n",
      "  1 1 0 0 0 0 1 0 0 0 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 1 1 1 0 0 1 1 1 0 0 1 1 0 1 1 0 1\n",
      "  1 1 1 0 0 1 1 1 1 1 1 1 1]\n",
      " [0 1 0 0 0 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 1 1 0 0 1 1 0 0 1 0 1 1 0 0\n",
      "  1 0 1 0 0 0 0 1 1 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 1\n",
      "  1 0 1 0 0 0 1 0 1 1 0 1 0]\n",
      " [0 0 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1\n",
      "  1 0 1 1 1 1 0 1 1 1 1 0 0]]\n",
      "(250, 50)\n",
      "(250, 50)\n",
      "Vectorization...\n",
      "Vectorization done!\n"
     ]
    }
   ],
   "source": [
    "# Read in the data set\n",
    "# This function can be moved to utils.py\n",
    "data_array = np.array(list(csv.reader(open(synthetic_data_set,\"rb\"),delimiter=','))).astype('int')\n",
    "num_samples = data_array.shape[0]\n",
    "num_problems = data_array.shape[1]\n",
    "\n",
    "# time steps is number of problems - 1 because we cannot predict on the last problem.\n",
    "num_timesteps = num_problems - 1 \n",
    "# Split data into train and test (half and half)\n",
    "train = data_array[0:num_samples/2,:]\n",
    "test = data_array[num_samples/2:num_samples,:]\n",
    "\n",
    "num_train = train.shape[0]\n",
    "num_test = test.shape[0]\n",
    "\n",
    "\n",
    "print('Vectorization...')\n",
    "X_train = np.zeros((num_train, num_timesteps, num_problems * 2), dtype=np.bool)\n",
    "y_train = np.zeros((num_train, num_timesteps), dtype=np.int)\n",
    "\n",
    "# Create 3-dimensional input tensor with one-hot encodings for each sample\n",
    "# the dimension of each vector for a student i and time t is 2 * num_problems\n",
    "# where the first half corresponds to the correctly answered problems and the\n",
    "# second half to the incorrectly answered ones.\n",
    "for i in xrange(num_train):\n",
    "    \n",
    "    # for the first time step. Done separately so we can populate the output \n",
    "    # tensor at the same time, which is shifted back by 1.\n",
    "\n",
    "    for t in xrange(0,num_timesteps):\n",
    "        p = t # since timestep t corresponds to problem p where t=p\n",
    "        if train[i,p] == 1:\n",
    "            X_train[i, t, p] = 1 \n",
    "        else:\n",
    "            X_train[i, t, num_problems + p] = 1\n",
    "        # this is a special case for the synthetic data set, where the next problem \n",
    "        # is just the current problem index + 1\n",
    "        y_train[i,t] = p + 1\n",
    "correctness = train\n",
    "\n",
    "print (\"Vectorization done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "hidden_size = 200 # size of hidden layer of neurons\n",
    "learning_rate = 1e-1\n",
    "epochs = 20\n",
    "\n",
    "# model parameters\n",
    "Wxh = np.random.randn(hidden_size, num_problems * 2)*0.01 # input to hidden\n",
    "Whh = np.random.randn(hidden_size, hidden_size)*0.01 # hidden to hidden\n",
    "Why = np.random.randn(num_problems, hidden_size)*0.01 # hidden to output\n",
    "bh = np.zeros((hidden_size, 1)) # hidden bias\n",
    "by = np.zeros((num_problems, 1)) # output bias\n",
    "\n",
    "def lossFun(inputs, targets, correctness, hprev):\n",
    "    \"\"\"\n",
    "    inputs,targets are both list of integers.\n",
    "    hprev is Hx1 array of initial hidden state\n",
    "    returns the loss, gradients on model parameters, and last hidden state\n",
    "    \"\"\"\n",
    "    xs, hs, ys, ps, ps_denom = {}, {}, {}, {}, {}\n",
    "    hs[-1] = np.copy(hprev)\n",
    "    loss = 0\n",
    "    # forward pass\n",
    "    for t in xrange(len(inputs)):\n",
    "        xs[t] = inputs[t,:].reshape((num_problems * 2, 1))\n",
    "        hs[t] = np.tanh(np.dot(Wxh, xs[t]) + np.dot(Whh, hs[t-1]) + bh) # hidden state\n",
    "        ys[t] = np.dot(Why, hs[t]) + by # unnormalized log probabilities for next chars\n",
    "        ps_denom[t] = np.sum(np.exp(ys[t]))\n",
    "        ps[t] = np.exp(ys[t]) / ps_denom[t] # probabilities for next chars\n",
    "\n",
    "        # softmax (cross-entropy loss)\n",
    "        if correctness[targets[t]] == 1:\n",
    "            loss += -np.log(ps[t][targets[t],0]) \n",
    "        else:\n",
    "            loss += -np.log(1-ps[t][targets[t],0]) \n",
    "        # backward pass: compute gradients going backwards\n",
    "        dWxh, dWhh, dWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
    "        dbh, dby = np.zeros_like(bh), np.zeros_like(by)\n",
    "        dhnext = np.zeros_like(hs[0])\n",
    "\n",
    "\n",
    "    for t in reversed(xrange(len(inputs))):\n",
    "        dy = np.copy(ps[t])\n",
    "        if correctness[targets[t]] == 1:\n",
    "            dy[targets[t]] -= 1 # backprop into y\n",
    "        else:\n",
    "            for p in xrange(num_problems):\n",
    "                if p != targets[t]:\n",
    "                    dy[p] -= np.exp(ys[t][p]) / (ps_denom[t] - np.exp(ys[t][targets[t]]))\n",
    "\n",
    "\n",
    "\n",
    "        dWhy += np.dot(dy, hs[t].T)\n",
    "        dby += dy\n",
    "        dh = np.dot(Why.T, dy) + dhnext # backprop into h\n",
    "        dhraw = (1 - hs[t] * hs[t]) * dh # backprop through tanh nonlinearity\n",
    "        dbh += dhraw\n",
    "        dWxh += np.dot(dhraw, xs[t].T)\n",
    "        dWhh += np.dot(dhraw, hs[t-1].T)\n",
    "        dhnext = np.dot(Whh.T, dhraw)\n",
    "        for dparam in [dWxh, dWhh, dWhy, dbh, dby]:\n",
    "            np.clip(dparam, -5, 5, out=dparam) # clip to mitigate exploding gradients\n",
    "    return loss, dWxh, dWhh, dWhy, dbh, dby, hs[len(inputs)-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(ps, targets, correctness):\n",
    "    \"\"\"\n",
    "    Computes the accuracy using the predictions at each time step.\n",
    "    For each t, if probability of next problem is > 0.5 for correct, or <= 0.5 \n",
    "    for incorrect, then count this as correct prediction.\n",
    "    \"\"\"\n",
    "    num_correct = 0\n",
    "    for t in xrange(num_timesteps):\n",
    "        predicted_prob = ps[t][targets[t],0] \n",
    "        if (predicted_prob >= 0.5 and correctness[targets[t]] == 1) or (predicted_prob < 0.5 and correctness[targets[t]] == 0):\n",
    "            num_correct += 1\n",
    "    accuracy = num_correct / float(num_timesteps)\n",
    "    return accuracy\n",
    "\n",
    "def forward_pass(inputs):\n",
    "    xs, hs, ys, ps, ps_denom = {}, {}, {}, {}, {}\n",
    "    hs[-1] = np.copy(hprev)\n",
    "    for t in xrange(len(inputs)):\n",
    "        xs[t] = inputs[t,:].reshape((num_problems * 2, 1))\n",
    "        hs[t] = np.tanh(np.dot(Wxh, xs[t]) + np.dot(Whh, hs[t-1]) + bh) # hidden state\n",
    "        ys[t] = np.dot(Why, hs[t]) + by # unnormalized log probabilities for next chars\n",
    "        ps_denom[t] = np.sum(np.exp(ys[t]))\n",
    "        ps[t] = np.exp(ys[t]) / ps_denom[t] # probabilities for next chars\n",
    "    return ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, iter 0, loss: 171.846600, acc: 0.346939\n",
      "epoch 0, iter 1, loss: 132.552933, acc: 0.795918\n",
      "epoch 0, iter 2, loss: 182.373403, acc: 0.306122\n",
      "epoch 0, iter 3, loss: 214.434294, acc: 0.530612\n",
      "epoch 0, iter 4, loss: 304.703716, acc: 0.265306\n",
      "epoch 0, iter 5, loss: 340.633408, acc: 0.408163\n",
      "epoch 0, iter 6, loss: 414.179585, acc: 0.244898\n",
      "epoch 0, iter 7, loss: 382.005165, acc: 0.510204\n",
      "epoch 0, iter 8, loss: 349.412870, acc: 0.673469\n",
      "epoch 0, iter 9, loss: 353.380815, acc: 0.244898\n",
      "epoch 0, iter 10, loss: 320.405270, acc: 0.408163\n",
      "epoch 0, iter 11, loss: 291.419726, acc: 0.653061\n",
      "epoch 0, iter 12, loss: 343.207638, acc: 0.224490\n",
      "epoch 0, iter 13, loss: 314.977223, acc: 0.346939\n",
      "epoch 0, iter 14, loss: 309.986956, acc: 0.306122\n",
      "epoch 0, iter 15, loss: 337.404591, acc: 0.122449\n",
      "epoch 0, iter 16, loss: 288.674526, acc: 0.571429\n",
      "epoch 0, iter 17, loss: 312.516664, acc: 0.224490\n",
      "epoch 0, iter 18, loss: 253.486095, acc: 0.734694\n",
      "epoch 0, iter 19, loss: 301.012876, acc: 0.040816\n",
      "epoch 0, iter 20, loss: 309.611977, acc: 0.102041\n",
      "epoch 0, iter 21, loss: 278.812583, acc: 0.326531\n",
      "epoch 0, iter 22, loss: 286.783083, acc: 0.204082\n",
      "epoch 0, iter 23, loss: 249.076870, acc: 0.510204\n",
      "epoch 0, iter 24, loss: 226.871358, acc: 0.408163\n",
      "epoch 0, iter 25, loss: 201.536580, acc: 0.571429\n",
      "epoch 0, iter 26, loss: 193.321676, acc: 0.448980\n",
      "epoch 0, iter 27, loss: 198.985549, acc: 0.387755\n",
      "epoch 0, iter 28, loss: 202.962446, acc: 0.306122\n",
      "epoch 0, iter 29, loss: 213.042566, acc: 0.204082\n",
      "epoch 0, iter 30, loss: 190.581283, acc: 0.489796\n",
      "epoch 0, iter 31, loss: 167.983133, acc: 0.571429\n",
      "epoch 0, iter 32, loss: 165.376951, acc: 0.408163\n",
      "epoch 0, iter 33, loss: 182.663467, acc: 0.183673\n",
      "epoch 0, iter 34, loss: 179.385442, acc: 0.387755\n",
      "epoch 0, iter 35, loss: 155.010405, acc: 0.571429\n",
      "epoch 0, iter 36, loss: 147.652929, acc: 0.469388\n",
      "epoch 0, iter 37, loss: 166.721710, acc: 0.163265\n",
      "epoch 0, iter 38, loss: 174.295652, acc: 0.265306\n",
      "epoch 0, iter 39, loss: 152.328783, acc: 0.591837\n",
      "epoch 0, iter 40, loss: 152.415965, acc: 0.448980\n",
      "epoch 0, iter 41, loss: 165.491005, acc: 0.285714\n",
      "epoch 0, iter 42, loss: 137.674730, acc: 0.693878\n",
      "epoch 0, iter 43, loss: 162.379354, acc: 0.142857\n",
      "epoch 0, iter 44, loss: 182.853718, acc: 0.122449\n",
      "epoch 0, iter 45, loss: 164.586169, acc: 0.489796\n",
      "epoch 0, iter 46, loss: 147.798976, acc: 0.530612\n",
      "epoch 0, iter 47, loss: 145.724986, acc: 0.387755\n",
      "epoch 0, iter 48, loss: 149.215881, acc: 0.367347\n",
      "epoch 0, iter 49, loss: 155.878971, acc: 0.244898\n",
      "epoch 0, iter 50, loss: 155.919572, acc: 0.306122\n",
      "epoch 0, iter 51, loss: 149.846122, acc: 0.367347\n",
      "epoch 0, iter 52, loss: 137.245356, acc: 0.469388\n",
      "epoch 0, iter 53, loss: 138.658598, acc: 0.408163\n",
      "epoch 0, iter 54, loss: 153.298408, acc: 0.244898\n",
      "epoch 0, iter 55, loss: 157.303074, acc: 0.224490\n",
      "epoch 0, iter 56, loss: 163.075541, acc: 0.204082\n",
      "epoch 0, iter 57, loss: 168.888638, acc: 0.204082\n",
      "epoch 0, iter 58, loss: 146.379945, acc: 0.591837\n",
      "epoch 0, iter 59, loss: 158.091021, acc: 0.285714\n",
      "epoch 0, iter 60, loss: 155.956276, acc: 0.346939\n",
      "epoch 0, iter 61, loss: 172.243420, acc: 0.142857\n",
      "epoch 0, iter 62, loss: 157.503893, acc: 0.387755\n",
      "epoch 0, iter 63, loss: 158.519307, acc: 0.265306\n",
      "epoch 0, iter 64, loss: 136.062952, acc: 0.612245\n",
      "epoch 0, iter 65, loss: 130.519371, acc: 0.448980\n",
      "epoch 0, iter 66, loss: 143.175356, acc: 0.204082\n",
      "epoch 0, iter 67, loss: 126.478763, acc: 0.571429\n",
      "epoch 0, iter 68, loss: 146.130652, acc: 0.163265\n",
      "epoch 0, iter 69, loss: 159.601241, acc: 0.122449\n",
      "epoch 0, iter 70, loss: 152.818450, acc: 0.346939\n",
      "epoch 0, iter 71, loss: 147.667341, acc: 0.387755\n",
      "epoch 0, iter 72, loss: 142.675101, acc: 0.367347\n",
      "epoch 0, iter 73, loss: 148.090115, acc: 0.224490\n",
      "epoch 0, iter 74, loss: 134.019843, acc: 0.469388\n",
      "epoch 0, iter 75, loss: 139.379434, acc: 0.265306\n",
      "epoch 0, iter 76, loss: 139.417688, acc: 0.346939\n",
      "epoch 0, iter 77, loss: 138.980212, acc: 0.367347\n",
      "epoch 0, iter 78, loss: 135.612714, acc: 0.408163\n",
      "epoch 0, iter 79, loss: 133.306789, acc: 0.408163\n",
      "epoch 0, iter 80, loss: 156.844598, acc: 0.061224\n",
      "epoch 0, iter 81, loss: 153.508464, acc: 0.326531\n",
      "epoch 0, iter 82, loss: 145.609126, acc: 0.387755\n",
      "epoch 0, iter 83, loss: 150.534424, acc: 0.306122\n",
      "epoch 0, iter 84, loss: 162.411416, acc: 0.122449\n",
      "epoch 0, iter 85, loss: 169.346565, acc: 0.102041\n",
      "epoch 0, iter 86, loss: 146.274924, acc: 0.510204\n",
      "epoch 0, iter 87, loss: 130.827835, acc: 0.571429\n",
      "epoch 0, iter 88, loss: 138.585531, acc: 0.326531\n",
      "epoch 0, iter 89, loss: 132.577213, acc: 0.387755\n",
      "epoch 0, iter 90, loss: 123.234431, acc: 0.510204\n",
      "epoch 0, iter 91, loss: 137.551266, acc: 0.285714\n",
      "epoch 0, iter 92, loss: 123.288539, acc: 0.591837\n",
      "epoch 0, iter 93, loss: 108.648797, acc: 0.632653\n",
      "epoch 0, iter 94, loss: 119.990118, acc: 0.346939\n",
      "epoch 0, iter 95, loss: 145.301449, acc: 0.040816\n",
      "epoch 0, iter 96, loss: 132.690611, acc: 0.489796\n",
      "epoch 0, iter 97, loss: 138.881263, acc: 0.326531\n",
      "epoch 0, iter 98, loss: 131.147862, acc: 0.469388\n",
      "epoch 0, iter 99, loss: 140.262024, acc: 0.244898\n",
      "epoch 0, iter 100, loss: 126.448134, acc: 0.612245\n",
      "epoch 0, iter 101, loss: 125.759829, acc: 0.448980\n",
      "epoch 0, iter 102, loss: 139.391977, acc: 0.183673\n",
      "epoch 0, iter 103, loss: 144.579265, acc: 0.265306\n",
      "epoch 0, iter 104, loss: 133.267796, acc: 0.469388\n",
      "epoch 0, iter 105, loss: 138.923039, acc: 0.285714\n",
      "epoch 0, iter 106, loss: 148.336381, acc: 0.204082\n",
      "epoch 0, iter 107, loss: 155.993254, acc: 0.163265\n",
      "epoch 0, iter 108, loss: 136.404635, acc: 0.530612\n",
      "epoch 0, iter 109, loss: 123.532032, acc: 0.551020\n",
      "epoch 0, iter 110, loss: 116.784238, acc: 0.489796\n",
      "epoch 0, iter 111, loss: 110.431723, acc: 0.591837\n",
      "epoch 0, iter 112, loss: 121.172311, acc: 0.306122\n",
      "epoch 0, iter 113, loss: 109.136599, acc: 0.653061\n",
      "epoch 0, iter 114, loss: 106.408098, acc: 0.530612\n",
      "epoch 0, iter 115, loss: 117.358174, acc: 0.326531\n",
      "epoch 0, iter 116, loss: 107.559796, acc: 0.612245\n",
      "epoch 0, iter 117, loss: 111.422630, acc: 0.408163\n",
      "epoch 0, iter 118, loss: 109.168642, acc: 0.530612\n",
      "epoch 0, iter 119, loss: 114.145142, acc: 0.387755\n",
      "epoch 0, iter 120, loss: 119.570062, acc: 0.387755\n",
      "epoch 0, iter 121, loss: 134.453893, acc: 0.204082\n",
      "epoch 0, iter 122, loss: 110.953372, acc: 0.714286\n",
      "epoch 0, iter 123, loss: 120.429056, acc: 0.285714\n",
      "epoch 0, iter 124, loss: 110.302972, acc: 0.571429\n",
      "epoch 0, iter 125, loss: 116.482158, acc: 0.387755\n",
      "epoch 0, iter 126, loss: 136.972438, acc: 0.204082\n",
      "epoch 0, iter 127, loss: 133.623507, acc: 0.469388\n",
      "epoch 0, iter 128, loss: 137.113506, acc: 0.326531\n",
      "epoch 0, iter 129, loss: 137.287395, acc: 0.326531\n",
      "epoch 0, iter 130, loss: 153.330524, acc: 0.102041\n",
      "epoch 0, iter 131, loss: 145.121114, acc: 0.367347\n",
      "epoch 0, iter 132, loss: 150.841482, acc: 0.224490\n",
      "epoch 0, iter 133, loss: 150.821050, acc: 0.265306\n",
      "epoch 0, iter 134, loss: 124.952135, acc: 0.693878\n",
      "epoch 0, iter 135, loss: 122.813419, acc: 0.448980\n",
      "epoch 0, iter 136, loss: 94.598237, acc: 0.857143\n",
      "epoch 0, iter 137, loss: 102.423175, acc: 0.448980\n",
      "epoch 0, iter 138, loss: 112.009516, acc: 0.346939\n",
      "epoch 0, iter 139, loss: 116.089324, acc: 0.346939\n",
      "epoch 0, iter 140, loss: 114.474464, acc: 0.469388\n",
      "epoch 0, iter 141, loss: 141.502904, acc: 0.081633\n",
      "epoch 0, iter 142, loss: 126.102377, acc: 0.551020\n",
      "epoch 0, iter 143, loss: 134.506714, acc: 0.306122\n",
      "epoch 0, iter 144, loss: 129.636170, acc: 0.428571\n",
      "epoch 0, iter 145, loss: 152.760366, acc: 0.040816\n",
      "epoch 0, iter 146, loss: 147.871790, acc: 0.306122\n",
      "epoch 0, iter 147, loss: 145.747136, acc: 0.326531\n",
      "epoch 0, iter 148, loss: 136.425804, acc: 0.408163\n",
      "epoch 0, iter 149, loss: 153.106773, acc: 0.102041\n",
      "epoch 0, iter 150, loss: 145.478077, acc: 0.346939\n",
      "epoch 0, iter 151, loss: 132.750356, acc: 0.469388\n",
      "epoch 0, iter 152, loss: 135.866584, acc: 0.306122\n",
      "epoch 0, iter 153, loss: 127.640350, acc: 0.489796\n",
      "epoch 0, iter 154, loss: 119.374658, acc: 0.510204\n",
      "epoch 0, iter 155, loss: 129.151932, acc: 0.285714\n",
      "epoch 0, iter 156, loss: 117.825017, acc: 0.530612\n",
      "epoch 0, iter 157, loss: 126.228461, acc: 0.326531\n",
      "epoch 0, iter 158, loss: 140.543859, acc: 0.163265\n",
      "epoch 0, iter 159, loss: 125.769539, acc: 0.530612\n",
      "epoch 0, iter 160, loss: 122.596851, acc: 0.530612\n",
      "epoch 0, iter 161, loss: 128.997793, acc: 0.285714\n",
      "epoch 0, iter 162, loss: 129.585656, acc: 0.367347\n",
      "epoch 0, iter 163, loss: 131.398232, acc: 0.346939\n",
      "epoch 0, iter 164, loss: 125.631861, acc: 0.510204\n",
      "epoch 0, iter 165, loss: 139.052082, acc: 0.224490\n",
      "epoch 0, iter 166, loss: 131.170205, acc: 0.448980\n",
      "epoch 0, iter 167, loss: 118.097691, acc: 0.612245\n",
      "epoch 0, iter 168, loss: 114.824465, acc: 0.489796\n",
      "epoch 0, iter 169, loss: 103.127890, acc: 0.612245\n",
      "epoch 0, iter 170, loss: 114.386187, acc: 0.387755\n",
      "epoch 0, iter 171, loss: 121.518454, acc: 0.306122\n",
      "epoch 0, iter 172, loss: 120.137421, acc: 0.428571\n",
      "epoch 0, iter 173, loss: 129.238336, acc: 0.265306\n",
      "epoch 0, iter 174, loss: 127.880385, acc: 0.387755\n",
      "epoch 0, iter 175, loss: 139.590228, acc: 0.204082\n",
      "epoch 0, iter 176, loss: 142.216585, acc: 0.244898\n",
      "epoch 0, iter 177, loss: 139.784843, acc: 0.306122\n",
      "epoch 0, iter 178, loss: 125.925311, acc: 0.489796\n",
      "epoch 0, iter 179, loss: 137.610338, acc: 0.224490\n",
      "epoch 0, iter 180, loss: 146.227060, acc: 0.204082\n",
      "epoch 0, iter 181, loss: 147.182885, acc: 0.306122\n",
      "epoch 0, iter 182, loss: 144.664479, acc: 0.346939\n",
      "epoch 0, iter 183, loss: 124.003786, acc: 0.653061\n",
      "epoch 0, iter 184, loss: 121.385371, acc: 0.428571\n",
      "epoch 0, iter 185, loss: 119.464994, acc: 0.448980\n",
      "epoch 0, iter 186, loss: 137.200812, acc: 0.163265\n",
      "epoch 0, iter 187, loss: 128.575970, acc: 0.428571\n",
      "epoch 0, iter 188, loss: 105.393886, acc: 0.755102\n",
      "epoch 0, iter 189, loss: 102.514392, acc: 0.530612\n",
      "epoch 0, iter 190, loss: 97.586579, acc: 0.591837\n",
      "epoch 0, iter 191, loss: 107.677244, acc: 0.346939\n",
      "epoch 0, iter 192, loss: 104.720389, acc: 0.489796\n",
      "epoch 0, iter 193, loss: 107.702217, acc: 0.489796\n",
      "epoch 0, iter 194, loss: 125.492566, acc: 0.204082\n",
      "epoch 0, iter 195, loss: 116.328812, acc: 0.510204\n",
      "epoch 0, iter 196, loss: 128.166380, acc: 0.244898\n",
      "epoch 0, iter 197, loss: 124.888102, acc: 0.408163\n",
      "epoch 0, iter 198, loss: 136.532481, acc: 0.265306\n",
      "epoch 0, iter 199, loss: 131.008032, acc: 0.408163\n",
      "epoch 0, iter 200, loss: 118.180463, acc: 0.551020\n",
      "epoch 0, iter 201, loss: 138.668468, acc: 0.142857\n",
      "epoch 0, iter 202, loss: 139.164728, acc: 0.326531\n",
      "epoch 0, iter 203, loss: 118.175394, acc: 0.673469\n",
      "epoch 0, iter 204, loss: 110.231348, acc: 0.551020\n",
      "epoch 0, iter 205, loss: 112.429261, acc: 0.448980\n",
      "epoch 0, iter 206, loss: 126.424294, acc: 0.224490\n",
      "epoch 0, iter 207, loss: 122.989425, acc: 0.408163\n",
      "epoch 0, iter 208, loss: 138.084279, acc: 0.163265\n",
      "epoch 0, iter 209, loss: 140.648412, acc: 0.224490\n",
      "epoch 0, iter 210, loss: 127.627185, acc: 0.489796\n",
      "epoch 0, iter 211, loss: 149.389579, acc: 0.081633\n",
      "epoch 0, iter 212, loss: 128.275822, acc: 0.632653\n",
      "epoch 0, iter 213, loss: 142.386626, acc: 0.163265\n",
      "epoch 0, iter 214, loss: 147.320342, acc: 0.224490\n",
      "epoch 0, iter 215, loss: 128.257674, acc: 0.571429\n",
      "epoch 0, iter 216, loss: 127.906278, acc: 0.367347\n",
      "epoch 0, iter 217, loss: 114.718882, acc: 0.571429\n",
      "epoch 0, iter 218, loss: 117.927030, acc: 0.367347\n",
      "epoch 0, iter 219, loss: 134.275762, acc: 0.142857\n",
      "epoch 0, iter 220, loss: 114.711613, acc: 0.653061\n",
      "epoch 0, iter 221, loss: 128.207705, acc: 0.224490\n",
      "epoch 0, iter 222, loss: 124.951354, acc: 0.428571\n",
      "epoch 0, iter 223, loss: 134.138218, acc: 0.244898\n",
      "epoch 0, iter 224, loss: 128.717536, acc: 0.428571\n",
      "epoch 0, iter 225, loss: 133.011129, acc: 0.326531\n",
      "epoch 0, iter 226, loss: 134.373223, acc: 0.326531\n",
      "epoch 0, iter 227, loss: 134.350378, acc: 0.346939\n",
      "epoch 0, iter 228, loss: 127.559789, acc: 0.428571\n",
      "epoch 0, iter 229, loss: 151.123053, acc: 0.020408\n",
      "epoch 0, iter 230, loss: 140.888887, acc: 0.408163\n",
      "epoch 0, iter 231, loss: 144.868493, acc: 0.244898\n",
      "epoch 0, iter 232, loss: 131.901334, acc: 0.448980\n",
      "epoch 0, iter 233, loss: 131.478612, acc: 0.387755\n",
      "epoch 0, iter 234, loss: 146.360663, acc: 0.081633\n",
      "epoch 0, iter 235, loss: 136.102259, acc: 0.387755\n",
      "epoch 0, iter 236, loss: 136.555198, acc: 0.265306\n",
      "epoch 0, iter 237, loss: 128.526105, acc: 0.510204\n",
      "epoch 0, iter 238, loss: 118.353431, acc: 0.530612\n",
      "epoch 0, iter 239, loss: 114.648794, acc: 0.489796\n",
      "epoch 0, iter 240, loss: 123.800977, acc: 0.265306\n",
      "epoch 0, iter 241, loss: 125.972040, acc: 0.346939\n",
      "epoch 0, iter 242, loss: 116.725167, acc: 0.510204\n",
      "epoch 0, iter 243, loss: 112.815493, acc: 0.469388\n",
      "epoch 0, iter 244, loss: 100.876877, acc: 0.591837\n",
      "epoch 0, iter 245, loss: 102.665942, acc: 0.469388\n",
      "epoch 0, iter 246, loss: 102.363585, acc: 0.510204\n",
      "epoch 0, iter 247, loss: 90.461903, acc: 0.673469\n",
      "epoch 0, iter 248, loss: 112.885758, acc: 0.244898\n",
      "epoch 0, iter 249, loss: 103.643777, acc: 0.612245\n",
      "epoch 0, acc: 0.380245\n",
      "epoch 1, iter 0, loss: 114.551124, acc: 0.346939\n",
      "epoch 1, iter 1, loss: 92.179273, acc: 0.795918\n",
      "epoch 1, iter 2, loss: 109.859297, acc: 0.306122\n",
      "epoch 1, iter 3, loss: 103.419965, acc: 0.530612\n",
      "epoch 1, iter 4, loss: 119.374022, acc: 0.265306\n",
      "epoch 1, iter 5, loss: 119.430212, acc: 0.367347\n",
      "epoch 1, iter 6, loss: 129.595708, acc: 0.244898\n",
      "epoch 1, iter 7, loss: 121.937761, acc: 0.489796\n",
      "epoch 1, iter 8, loss: 104.115639, acc: 0.653061\n",
      "epoch 1, iter 9, loss: 121.187845, acc: 0.244898\n",
      "epoch 1, iter 10, loss: 124.711114, acc: 0.387755\n",
      "epoch 1, iter 11, loss: 109.743537, acc: 0.632653\n",
      "epoch 1, iter 12, loss: 124.144224, acc: 0.224490\n",
      "epoch 1, iter 13, loss: 126.400119, acc: 0.346939\n",
      "epoch 1, iter 14, loss: 131.459157, acc: 0.306122\n",
      "epoch 1, iter 15, loss: 147.774854, acc: 0.102041\n",
      "epoch 1, iter 16, loss: 127.391645, acc: 0.571429\n",
      "epoch 1, iter 17, loss: 134.111702, acc: 0.224490\n",
      "epoch 1, iter 18, loss: 109.657365, acc: 0.734694\n",
      "epoch 1, iter 19, loss: 134.524512, acc: 0.040816\n",
      "epoch 1, iter 20, loss: 145.718510, acc: 0.102041\n",
      "epoch 1, iter 21, loss: 138.513928, acc: 0.326531\n",
      "epoch 1, iter 22, loss: 142.346903, acc: 0.204082\n",
      "epoch 1, iter 23, loss: 127.438461, acc: 0.510204\n",
      "epoch 1, iter 24, loss: 122.548801, acc: 0.408163\n",
      "epoch 1, iter 25, loss: 110.826312, acc: 0.571429\n",
      "epoch 1, iter 26, loss: 109.320511, acc: 0.448980\n",
      "epoch 1, iter 27, loss: 112.863981, acc: 0.387755\n",
      "epoch 1, iter 28, loss: 119.519072, acc: 0.306122\n",
      "epoch 1, iter 29, loss: 132.587993, acc: 0.204082\n",
      "epoch 1, iter 30, loss: 124.968309, acc: 0.489796\n",
      "epoch 1, iter 31, loss: 115.275232, acc: 0.571429\n",
      "epoch 1, iter 32, loss: 117.423078, acc: 0.408163\n",
      "epoch 1, iter 33, loss: 130.573413, acc: 0.183673\n",
      "epoch 1, iter 34, loss: 128.583638, acc: 0.387755\n",
      "epoch 1, iter 35, loss: 113.210424, acc: 0.571429\n",
      "epoch 1, iter 36, loss: 109.839036, acc: 0.469388\n",
      "epoch 1, iter 37, loss: 124.955636, acc: 0.163265\n",
      "epoch 1, iter 38, loss: 129.307574, acc: 0.265306\n",
      "epoch 1, iter 39, loss: 114.192717, acc: 0.591837\n",
      "epoch 1, iter 40, loss: 114.132778, acc: 0.448980\n",
      "epoch 1, iter 41, loss: 121.860304, acc: 0.285714\n",
      "epoch 1, iter 42, loss: 102.904984, acc: 0.693878\n",
      "epoch 1, iter 43, loss: 122.024079, acc: 0.142857\n",
      "epoch 1, iter 44, loss: 134.670487, acc: 0.122449\n",
      "epoch 1, iter 45, loss: 121.766787, acc: 0.489796\n",
      "epoch 1, iter 46, loss: 110.706564, acc: 0.530612\n",
      "epoch 1, iter 47, loss: 110.458004, acc: 0.387755\n",
      "epoch 1, iter 48, loss: 114.969079, acc: 0.367347\n",
      "epoch 1, iter 49, loss: 123.121736, acc: 0.244898\n",
      "epoch 1, iter 50, loss: 125.905931, acc: 0.306122\n",
      "epoch 1, iter 51, loss: 124.190013, acc: 0.367347\n",
      "epoch 1, iter 52, loss: 115.042219, acc: 0.469388\n",
      "epoch 1, iter 53, loss: 115.251195, acc: 0.408163\n",
      "epoch 1, iter 54, loss: 124.706046, acc: 0.244898\n",
      "epoch 1, iter 55, loss: 131.155621, acc: 0.224490\n",
      "epoch 1, iter 56, loss: 141.888520, acc: 0.204082\n",
      "epoch 1, iter 57, loss: 141.763568, acc: 0.204082\n",
      "epoch 1, iter 58, loss: 120.321179, acc: 0.591837\n",
      "epoch 1, iter 59, loss: 127.730984, acc: 0.285714\n",
      "epoch 1, iter 60, loss: 127.370213, acc: 0.346939\n",
      "epoch 1, iter 61, loss: 139.730319, acc: 0.142857\n",
      "epoch 1, iter 62, loss: 132.212372, acc: 0.387755\n",
      "epoch 1, iter 63, loss: 136.183100, acc: 0.265306\n",
      "epoch 1, iter 64, loss: 117.722273, acc: 0.612245\n",
      "epoch 1, iter 65, loss: 113.308308, acc: 0.448980\n",
      "epoch 1, iter 66, loss: 123.413622, acc: 0.204082\n",
      "epoch 1, iter 67, loss: 111.763631, acc: 0.571429\n",
      "epoch 1, iter 68, loss: 127.617289, acc: 0.163265\n",
      "epoch 1, iter 69, loss: 138.403173, acc: 0.122449\n",
      "epoch 1, iter 70, loss: 131.881461, acc: 0.346939\n",
      "epoch 1, iter 71, loss: 128.262432, acc: 0.387755\n",
      "epoch 1, iter 72, loss: 125.205471, acc: 0.367347\n",
      "epoch 1, iter 73, loss: 130.817494, acc: 0.224490\n",
      "epoch 1, iter 74, loss: 120.966685, acc: 0.469388\n",
      "epoch 1, iter 75, loss: 127.182297, acc: 0.265306\n",
      "epoch 1, iter 76, loss: 128.553152, acc: 0.346939\n",
      "epoch 1, iter 77, loss: 127.772027, acc: 0.367347\n",
      "epoch 1, iter 78, loss: 123.299224, acc: 0.408163\n",
      "epoch 1, iter 79, loss: 119.808502, acc: 0.408163\n",
      "epoch 1, iter 80, loss: 137.963389, acc: 0.061224\n",
      "epoch 1, iter 81, loss: 135.031573, acc: 0.326531\n",
      "epoch 1, iter 82, loss: 128.883558, acc: 0.387755\n",
      "epoch 1, iter 83, loss: 130.351709, acc: 0.306122\n",
      "epoch 1, iter 84, loss: 139.376299, acc: 0.122449\n",
      "epoch 1, iter 85, loss: 146.036714, acc: 0.102041\n",
      "epoch 1, iter 86, loss: 128.694333, acc: 0.510204\n",
      "epoch 1, iter 87, loss: 114.346988, acc: 0.571429\n",
      "epoch 1, iter 88, loss: 120.105222, acc: 0.326531\n",
      "epoch 1, iter 89, loss: 115.695921, acc: 0.387755\n",
      "epoch 1, iter 90, loss: 111.608887, acc: 0.510204\n",
      "epoch 1, iter 91, loss: 125.472917, acc: 0.285714\n",
      "epoch 1, iter 92, loss: 112.594025, acc: 0.591837\n",
      "epoch 1, iter 93, loss: 98.177138, acc: 0.632653\n",
      "epoch 1, iter 94, loss: 105.195084, acc: 0.346939\n",
      "epoch 1, iter 95, loss: 125.166766, acc: 0.040816\n",
      "epoch 1, iter 96, loss: 113.621483, acc: 0.489796\n",
      "epoch 1, iter 97, loss: 117.523406, acc: 0.326531\n",
      "epoch 1, iter 98, loss: 110.179615, acc: 0.469388\n",
      "epoch 1, iter 99, loss: 118.411464, acc: 0.244898\n",
      "epoch 1, iter 100, loss: 106.467707, acc: 0.612245\n",
      "epoch 1, iter 101, loss: 105.541569, acc: 0.448980\n",
      "epoch 1, iter 102, loss: 118.005259, acc: 0.183673\n",
      "epoch 1, iter 103, loss: 123.925798, acc: 0.265306\n",
      "epoch 1, iter 104, loss: 114.333437, acc: 0.469388\n",
      "epoch 1, iter 105, loss: 119.142095, acc: 0.285714\n",
      "epoch 1, iter 106, loss: 127.612970, acc: 0.204082\n",
      "epoch 1, iter 107, loss: 134.030560, acc: 0.163265\n",
      "epoch 1, iter 108, loss: 118.004169, acc: 0.530612\n",
      "epoch 1, iter 109, loss: 106.829218, acc: 0.551020\n",
      "epoch 1, iter 110, loss: 100.321665, acc: 0.489796\n",
      "epoch 1, iter 111, loss: 94.844903, acc: 0.591837\n",
      "epoch 1, iter 112, loss: 103.299045, acc: 0.306122\n",
      "epoch 1, iter 113, loss: 92.256627, acc: 0.653061\n",
      "epoch 1, iter 114, loss: 89.067310, acc: 0.530612\n",
      "epoch 1, iter 115, loss: 98.223400, acc: 0.326531\n",
      "epoch 1, iter 116, loss: 90.235589, acc: 0.612245\n",
      "epoch 1, iter 117, loss: 92.958302, acc: 0.408163\n",
      "epoch 1, iter 118, loss: 91.599656, acc: 0.530612\n",
      "epoch 1, iter 119, loss: 94.903558, acc: 0.387755\n",
      "epoch 1, iter 120, loss: 100.700314, acc: 0.387755\n",
      "epoch 1, iter 121, loss: 113.803619, acc: 0.204082\n",
      "epoch 1, iter 122, loss: 95.227695, acc: 0.714286\n",
      "epoch 1, iter 123, loss: 102.781594, acc: 0.285714\n",
      "epoch 1, iter 124, loss: 94.696347, acc: 0.571429\n",
      "epoch 1, iter 125, loss: 98.896842, acc: 0.387755\n",
      "epoch 1, iter 126, loss: 113.007202, acc: 0.204082\n",
      "epoch 1, iter 127, loss: 113.051343, acc: 0.469388\n",
      "epoch 1, iter 128, loss: 119.088462, acc: 0.326531\n",
      "epoch 1, iter 129, loss: 121.086364, acc: 0.326531\n",
      "epoch 1, iter 130, loss: 133.932702, acc: 0.102041\n",
      "epoch 1, iter 131, loss: 125.366712, acc: 0.367347\n",
      "epoch 1, iter 132, loss: 128.701197, acc: 0.224490\n",
      "epoch 1, iter 133, loss: 128.140416, acc: 0.265306\n",
      "epoch 1, iter 134, loss: 106.938217, acc: 0.693878\n",
      "epoch 1, iter 135, loss: 103.125459, acc: 0.448980\n",
      "epoch 1, iter 136, loss: 79.181562, acc: 0.857143\n",
      "epoch 1, iter 137, loss: 85.121357, acc: 0.448980\n",
      "epoch 1, iter 138, loss: 92.305815, acc: 0.346939\n",
      "epoch 1, iter 139, loss: 96.868375, acc: 0.346939\n",
      "epoch 1, iter 140, loss: 94.893771, acc: 0.469388\n",
      "epoch 1, iter 141, loss: 117.176636, acc: 0.081633\n",
      "epoch 1, iter 142, loss: 109.653684, acc: 0.551020\n",
      "epoch 1, iter 143, loss: 115.231076, acc: 0.306122\n",
      "epoch 1, iter 144, loss: 110.328126, acc: 0.428571\n",
      "epoch 1, iter 145, loss: 126.569504, acc: 0.040816\n",
      "epoch 1, iter 146, loss: 123.452711, acc: 0.306122\n",
      "epoch 1, iter 147, loss: 121.972025, acc: 0.326531\n",
      "epoch 1, iter 148, loss: 114.550508, acc: 0.408163\n",
      "epoch 1, iter 149, loss: 126.031168, acc: 0.102041\n",
      "epoch 1, iter 150, loss: 120.970683, acc: 0.346939\n",
      "epoch 1, iter 151, loss: 112.634146, acc: 0.469388\n",
      "epoch 1, iter 152, loss: 114.479548, acc: 0.306122\n",
      "epoch 1, iter 153, loss: 107.344610, acc: 0.489796\n",
      "epoch 1, iter 154, loss: 99.956175, acc: 0.510204\n",
      "epoch 1, iter 155, loss: 107.304126, acc: 0.285714\n",
      "epoch 1, iter 156, loss: 97.441671, acc: 0.530612\n",
      "epoch 1, iter 157, loss: 102.864233, acc: 0.326531\n",
      "epoch 1, iter 158, loss: 114.707372, acc: 0.163265\n",
      "epoch 1, iter 159, loss: 105.659565, acc: 0.530612\n",
      "epoch 1, iter 160, loss: 102.852277, acc: 0.530612\n",
      "epoch 1, iter 161, loss: 108.289441, acc: 0.285714\n",
      "epoch 1, iter 162, loss: 108.485773, acc: 0.367347\n",
      "epoch 1, iter 163, loss: 108.715275, acc: 0.346939\n",
      "epoch 1, iter 164, loss: 101.553003, acc: 0.510204\n",
      "epoch 1, iter 165, loss: 111.153569, acc: 0.224490\n",
      "epoch 1, iter 166, loss: 103.760603, acc: 0.448980\n",
      "epoch 1, iter 167, loss: 93.875710, acc: 0.612245\n",
      "epoch 1, iter 168, loss: 90.862959, acc: 0.489796\n",
      "epoch 1, iter 169, loss: 81.618609, acc: 0.612245\n",
      "epoch 1, iter 170, loss: 91.048765, acc: 0.387755\n",
      "epoch 1, iter 171, loss: 97.671150, acc: 0.306122\n",
      "epoch 1, iter 172, loss: 96.828492, acc: 0.428571\n",
      "epoch 1, iter 173, loss: 106.703944, acc: 0.265306\n",
      "epoch 1, iter 174, loss: 108.171833, acc: 0.387755\n",
      "epoch 1, iter 175, loss: 117.444864, acc: 0.204082\n",
      "epoch 1, iter 176, loss: 119.620002, acc: 0.244898\n",
      "epoch 1, iter 177, loss: 117.953113, acc: 0.306122\n",
      "epoch 1, iter 178, loss: 107.759703, acc: 0.489796\n",
      "epoch 1, iter 179, loss: 114.792277, acc: 0.224490\n",
      "epoch 1, iter 180, loss: 121.038113, acc: 0.204082\n",
      "epoch 1, iter 181, loss: 122.873071, acc: 0.306122\n",
      "epoch 1, iter 182, loss: 120.503870, acc: 0.346939\n",
      "epoch 1, iter 183, loss: 102.678124, acc: 0.653061\n",
      "epoch 1, iter 184, loss: 99.518384, acc: 0.428571\n",
      "epoch 1, iter 185, loss: 96.273310, acc: 0.448980\n",
      "epoch 1, iter 186, loss: 108.727441, acc: 0.163265\n",
      "epoch 1, iter 187, loss: 103.275349, acc: 0.428571\n",
      "epoch 1, iter 188, loss: 84.935023, acc: 0.755102\n",
      "epoch 1, iter 189, loss: 81.972993, acc: 0.530612\n",
      "epoch 1, iter 190, loss: 78.693476, acc: 0.591837\n",
      "epoch 1, iter 191, loss: 86.319755, acc: 0.346939\n",
      "epoch 1, iter 192, loss: 83.403743, acc: 0.489796\n",
      "epoch 1, iter 193, loss: 87.121903, acc: 0.489796\n",
      "epoch 1, iter 194, loss: 101.907811, acc: 0.204082\n",
      "epoch 1, iter 195, loss: 94.896060, acc: 0.510204\n",
      "epoch 1, iter 196, loss: 102.948646, acc: 0.244898\n",
      "epoch 1, iter 197, loss: 99.410087, acc: 0.408163\n",
      "epoch 1, iter 198, loss: 106.970659, acc: 0.265306\n",
      "epoch 1, iter 199, loss: 102.881510, acc: 0.408163\n",
      "epoch 1, iter 200, loss: 93.728480, acc: 0.551020\n",
      "epoch 1, iter 201, loss: 109.943150, acc: 0.142857\n",
      "epoch 1, iter 202, loss: 110.421176, acc: 0.326531\n",
      "epoch 1, iter 203, loss: 93.644740, acc: 0.673469\n",
      "epoch 1, iter 204, loss: 86.059249, acc: 0.551020\n",
      "epoch 1, iter 205, loss: 89.479880, acc: 0.448980\n",
      "epoch 1, iter 206, loss: 100.057152, acc: 0.224490\n",
      "epoch 1, iter 207, loss: 97.666485, acc: 0.408163\n",
      "epoch 1, iter 208, loss: 113.460499, acc: 0.163265\n",
      "epoch 1, iter 209, loss: 119.055744, acc: 0.224490\n",
      "epoch 1, iter 210, loss: 109.528145, acc: 0.489796\n",
      "epoch 1, iter 211, loss: 125.007723, acc: 0.081633\n",
      "epoch 1, iter 212, loss: 106.252960, acc: 0.632653\n",
      "epoch 1, iter 213, loss: 115.370335, acc: 0.163265\n",
      "epoch 1, iter 214, loss: 117.203904, acc: 0.224490\n",
      "epoch 1, iter 215, loss: 102.349255, acc: 0.571429\n",
      "epoch 1, iter 216, loss: 101.976237, acc: 0.367347\n",
      "epoch 1, iter 217, loss: 91.722586, acc: 0.571429\n",
      "epoch 1, iter 218, loss: 93.560463, acc: 0.367347\n",
      "epoch 1, iter 219, loss: 105.401555, acc: 0.142857\n",
      "epoch 1, iter 220, loss: 91.187869, acc: 0.653061\n",
      "epoch 1, iter 221, loss: 101.175456, acc: 0.224490\n",
      "epoch 1, iter 222, loss: 97.588585, acc: 0.428571\n",
      "epoch 1, iter 223, loss: 103.924104, acc: 0.244898\n",
      "epoch 1, iter 224, loss: 102.087996, acc: 0.428571\n",
      "epoch 1, iter 225, loss: 104.275129, acc: 0.326531\n",
      "epoch 1, iter 226, loss: 105.187284, acc: 0.326531\n",
      "epoch 1, iter 227, loss: 104.329466, acc: 0.346939\n",
      "epoch 1, iter 228, loss: 100.087378, acc: 0.428571\n",
      "epoch 1, iter 229, loss: 116.020329, acc: 0.020408\n",
      "epoch 1, iter 230, loss: 107.207158, acc: 0.408163\n",
      "epoch 1, iter 231, loss: 109.670657, acc: 0.244898\n",
      "epoch 1, iter 232, loss: 102.202710, acc: 0.448980\n",
      "epoch 1, iter 233, loss: 102.531342, acc: 0.387755\n",
      "epoch 1, iter 234, loss: 115.860819, acc: 0.081633\n",
      "epoch 1, iter 235, loss: 108.403500, acc: 0.387755\n",
      "epoch 1, iter 236, loss: 107.726420, acc: 0.265306\n",
      "epoch 1, iter 237, loss: 100.939881, acc: 0.510204\n",
      "epoch 1, iter 238, loss: 92.712886, acc: 0.530612\n",
      "epoch 1, iter 239, loss: 88.852747, acc: 0.489796\n",
      "epoch 1, iter 240, loss: 94.772274, acc: 0.265306\n",
      "epoch 1, iter 241, loss: 95.118904, acc: 0.346939\n",
      "epoch 1, iter 242, loss: 89.189357, acc: 0.510204\n",
      "epoch 1, iter 243, loss: 86.045995, acc: 0.469388\n",
      "epoch 1, iter 244, loss: 76.918248, acc: 0.591837\n",
      "epoch 1, iter 245, loss: 78.186685, acc: 0.469388\n",
      "epoch 1, iter 246, loss: 78.398307, acc: 0.510204\n",
      "epoch 1, iter 247, loss: 69.330119, acc: 0.673469\n",
      "epoch 1, iter 248, loss: 86.253789, acc: 0.244898\n",
      "epoch 1, iter 249, loss: 79.126725, acc: 0.612245\n",
      "epoch 1, acc: 0.379673\n",
      "epoch 2, iter 0, loss: 85.978149, acc: 0.346939\n",
      "epoch 2, iter 1, loss: 70.120355, acc: 0.795918\n",
      "epoch 2, iter 2, loss: 83.522689, acc: 0.306122\n",
      "epoch 2, iter 3, loss: 80.760255, acc: 0.530612\n",
      "epoch 2, iter 4, loss: 91.553724, acc: 0.265306\n",
      "epoch 2, iter 5, loss: 90.522922, acc: 0.367347\n",
      "epoch 2, iter 6, loss: 97.083688, acc: 0.244898\n",
      "epoch 2, iter 7, loss: 92.889770, acc: 0.489796\n",
      "epoch 2, iter 8, loss: 80.130140, acc: 0.653061\n",
      "epoch 2, iter 9, loss: 92.868209, acc: 0.244898\n",
      "epoch 2, iter 10, loss: 94.863057, acc: 0.387755\n",
      "epoch 2, iter 11, loss: 85.206339, acc: 0.632653\n",
      "epoch 2, iter 12, loss: 95.263724, acc: 0.224490\n",
      "epoch 2, iter 13, loss: 95.263049, acc: 0.346939\n",
      "epoch 2, iter 14, loss: 97.779419, acc: 0.306122\n",
      "epoch 2, iter 15, loss: 107.700687, acc: 0.102041\n",
      "epoch 2, iter 16, loss: 93.212730, acc: 0.571429\n",
      "epoch 2, iter 17, loss: 98.508034, acc: 0.224490\n",
      "epoch 2, iter 18, loss: 81.222668, acc: 0.734694\n",
      "epoch 2, iter 19, loss: 100.488938, acc: 0.040816\n",
      "epoch 2, iter 20, loss: 107.741411, acc: 0.102041\n",
      "epoch 2, iter 21, loss: 103.903808, acc: 0.326531\n",
      "epoch 2, iter 22, loss: 109.194472, acc: 0.204082\n",
      "epoch 2, iter 23, loss: 98.544150, acc: 0.510204\n",
      "epoch 2, iter 24, loss: 94.174813, acc: 0.408163\n",
      "epoch 2, iter 25, loss: 84.580603, acc: 0.571429\n",
      "epoch 2, iter 26, loss: 82.528349, acc: 0.448980\n",
      "epoch 2, iter 27, loss: 84.759774, acc: 0.387755\n",
      "epoch 2, iter 28, loss: 89.753933, acc: 0.306122\n",
      "epoch 2, iter 29, loss: 99.179820, acc: 0.204082\n",
      "epoch 2, iter 30, loss: 93.503967, acc: 0.489796\n",
      "epoch 2, iter 31, loss: 85.699052, acc: 0.571429\n",
      "epoch 2, iter 32, loss: 84.362552, acc: 0.408163\n",
      "epoch 2, iter 33, loss: 92.285171, acc: 0.183673\n",
      "epoch 2, iter 34, loss: 91.034470, acc: 0.387755\n",
      "epoch 2, iter 35, loss: 81.734229, acc: 0.571429\n",
      "epoch 2, iter 36, loss: 79.419768, acc: 0.469388\n",
      "epoch 2, iter 37, loss: 90.128833, acc: 0.163265\n",
      "epoch 2, iter 38, loss: 93.848329, acc: 0.265306\n",
      "epoch 2, iter 39, loss: 82.719501, acc: 0.591837\n",
      "epoch 2, iter 40, loss: 83.873544, acc: 0.448980\n",
      "epoch 2, iter 41, loss: 90.671552, acc: 0.285714\n",
      "epoch 2, iter 42, loss: 77.881958, acc: 0.693878\n",
      "epoch 2, iter 43, loss: 89.554486, acc: 0.142857\n",
      "epoch 2, iter 44, loss: 100.162361, acc: 0.122449\n",
      "epoch 2, iter 45, loss: 92.062046, acc: 0.489796\n",
      "epoch 2, iter 46, loss: 83.344595, acc: 0.530612\n",
      "epoch 2, iter 47, loss: 82.024296, acc: 0.387755\n",
      "epoch 2, iter 48, loss: 85.088670, acc: 0.367347\n",
      "epoch 2, iter 49, loss: 90.195436, acc: 0.244898\n",
      "epoch 2, iter 50, loss: 93.289046, acc: 0.306122\n",
      "epoch 2, iter 51, loss: 92.775591, acc: 0.367347\n",
      "epoch 2, iter 52, loss: 86.589977, acc: 0.469388\n",
      "epoch 2, iter 53, loss: 85.984615, acc: 0.408163\n",
      "epoch 2, iter 54, loss: 92.910061, acc: 0.244898\n",
      "epoch 2, iter 55, loss: 95.946097, acc: 0.224490\n",
      "epoch 2, iter 56, loss: 99.490003, acc: 0.204082\n",
      "epoch 2, iter 57, loss: 103.936236, acc: 0.204082\n",
      "epoch 2, iter 58, loss: 89.177976, acc: 0.591837\n",
      "epoch 2, iter 59, loss: 92.532152, acc: 0.285714\n",
      "epoch 2, iter 60, loss: 89.687071, acc: 0.346939\n",
      "epoch 2, iter 61, loss: 99.015788, acc: 0.142857\n",
      "epoch 2, iter 62, loss: 93.495323, acc: 0.387755\n",
      "epoch 2, iter 63, loss: 97.970240, acc: 0.265306\n",
      "epoch 2, iter 64, loss: 84.376274, acc: 0.612245\n",
      "epoch 2, iter 65, loss: 80.055065, acc: 0.448980\n",
      "epoch 2, iter 66, loss: 85.625050, acc: 0.204082\n",
      "epoch 2, iter 67, loss: 76.942096, acc: 0.571429\n",
      "epoch 2, iter 68, loss: 87.128571, acc: 0.163265\n",
      "epoch 2, iter 69, loss: 94.314922, acc: 0.122449\n",
      "epoch 2, iter 70, loss: 89.933043, acc: 0.346939\n",
      "epoch 2, iter 71, loss: 86.702828, acc: 0.387755\n",
      "epoch 2, iter 72, loss: 83.581853, acc: 0.367347\n",
      "epoch 2, iter 73, loss: 88.690891, acc: 0.224490\n",
      "epoch 2, iter 74, loss: 82.709220, acc: 0.469388\n",
      "epoch 2, iter 75, loss: 85.399705, acc: 0.265306\n",
      "epoch 2, iter 76, loss: 85.456407, acc: 0.346939\n",
      "epoch 2, iter 77, loss: 84.171536, acc: 0.367347\n",
      "epoch 2, iter 78, loss: 81.653377, acc: 0.408163\n",
      "epoch 2, iter 79, loss: 80.097452, acc: 0.408163\n",
      "epoch 2, iter 80, loss: 92.131185, acc: 0.061224\n",
      "epoch 2, iter 81, loss: 91.563131, acc: 0.326531\n",
      "epoch 2, iter 82, loss: 86.535663, acc: 0.387755\n",
      "epoch 2, iter 83, loss: 90.723247, acc: 0.306122\n",
      "epoch 2, iter 84, loss: 95.235164, acc: 0.122449\n",
      "epoch 2, iter 85, loss: 97.039366, acc: 0.102041\n",
      "epoch 2, iter 86, loss: 85.078058, acc: 0.510204\n",
      "epoch 2, iter 87, loss: 76.203519, acc: 0.571429\n",
      "epoch 2, iter 88, loss: 78.839451, acc: 0.326531\n",
      "epoch 2, iter 89, loss: 74.913939, acc: 0.387755\n",
      "epoch 2, iter 90, loss: 70.132074, acc: 0.510204\n",
      "epoch 2, iter 91, loss: 76.369635, acc: 0.285714\n",
      "epoch 2, iter 92, loss: 68.115256, acc: 0.591837\n",
      "epoch 2, iter 93, loss: 61.762694, acc: 0.632653\n",
      "epoch 2, iter 94, loss: 66.822091, acc: 0.346939\n",
      "epoch 2, iter 95, loss: 80.036036, acc: 0.040816\n",
      "epoch 2, iter 96, loss: 74.562284, acc: 0.489796\n",
      "epoch 2, iter 97, loss: 75.978334, acc: 0.326531\n",
      "epoch 2, iter 98, loss: 71.226132, acc: 0.469388\n",
      "epoch 2, iter 99, loss: 74.491774, acc: 0.244898\n",
      "epoch 2, iter 100, loss: 69.808875, acc: 0.612245\n",
      "epoch 2, iter 101, loss: 68.243398, acc: 0.448980\n",
      "epoch 2, iter 102, loss: 73.801193, acc: 0.183673\n",
      "epoch 2, iter 103, loss: 76.297191, acc: 0.265306\n",
      "epoch 2, iter 104, loss: 72.198399, acc: 0.469388\n",
      "epoch 2, iter 105, loss: 74.493025, acc: 0.285714\n",
      "epoch 2, iter 106, loss: 79.165834, acc: 0.204082\n",
      "epoch 2, iter 107, loss: 83.178658, acc: 0.163265\n",
      "epoch 2, iter 108, loss: 74.384402, acc: 0.530612\n",
      "epoch 2, iter 109, loss: 66.536823, acc: 0.551020\n",
      "epoch 2, iter 110, loss: 61.654968, acc: 0.489796\n",
      "epoch 2, iter 111, loss: 59.612342, acc: 0.591837\n",
      "epoch 2, iter 112, loss: 63.770986, acc: 0.306122\n",
      "epoch 2, iter 113, loss: 59.550960, acc: 0.653061\n",
      "epoch 2, iter 114, loss: 56.983366, acc: 0.530612\n",
      "epoch 2, iter 115, loss: 61.847107, acc: 0.326531\n",
      "epoch 2, iter 116, loss: 56.233406, acc: 0.612245\n",
      "epoch 2, iter 117, loss: 56.421159, acc: 0.408163\n",
      "epoch 2, iter 118, loss: 57.416884, acc: 0.551020\n",
      "epoch 2, iter 119, loss: 57.564371, acc: 0.387755\n",
      "epoch 2, iter 120, loss: 61.768783, acc: 0.387755\n",
      "epoch 2, iter 121, loss: 68.975244, acc: 0.204082\n",
      "epoch 2, iter 122, loss: 58.040441, acc: 0.734694\n",
      "epoch 2, iter 123, loss: 62.104090, acc: 0.285714\n",
      "epoch 2, iter 124, loss: 57.678402, acc: 0.571429\n",
      "epoch 2, iter 125, loss: 60.070366, acc: 0.387755\n",
      "epoch 2, iter 126, loss: 68.098100, acc: 0.224490\n",
      "epoch 2, iter 127, loss: 68.962832, acc: 0.469388\n",
      "epoch 2, iter 128, loss: 70.246731, acc: 0.326531\n",
      "epoch 2, iter 129, loss: 70.776296, acc: 0.326531\n",
      "epoch 2, iter 130, loss: 77.705843, acc: 0.102041\n",
      "epoch 2, iter 131, loss: 72.448065, acc: 0.367347\n",
      "epoch 2, iter 132, loss: 75.378431, acc: 0.224490\n",
      "epoch 2, iter 133, loss: 74.809308, acc: 0.265306\n",
      "epoch 2, iter 134, loss: 63.535689, acc: 0.693878\n",
      "epoch 2, iter 135, loss: 61.974735, acc: 0.469388\n",
      "epoch 2, iter 136, loss: 49.107499, acc: 0.918367\n",
      "epoch 2, iter 137, loss: 51.969606, acc: 0.448980\n",
      "epoch 2, iter 138, loss: 55.144468, acc: 0.346939\n",
      "epoch 2, iter 139, loss: 56.665584, acc: 0.346939\n",
      "epoch 2, iter 140, loss: 55.573202, acc: 0.469388\n",
      "epoch 2, iter 141, loss: 66.304428, acc: 0.081633\n",
      "epoch 2, iter 142, loss: 59.139402, acc: 0.551020\n",
      "epoch 2, iter 143, loss: 62.942476, acc: 0.306122\n",
      "epoch 2, iter 144, loss: 62.394674, acc: 0.448980\n",
      "epoch 2, iter 145, loss: 72.539402, acc: 0.040816\n",
      "epoch 2, iter 146, loss: 72.651654, acc: 0.306122\n",
      "epoch 2, iter 147, loss: 72.389456, acc: 0.326531\n",
      "epoch 2, iter 148, loss: 69.934197, acc: 0.428571\n",
      "epoch 2, iter 149, loss: 76.875833, acc: 0.102041\n",
      "epoch 2, iter 150, loss: 76.960079, acc: 0.346939\n",
      "epoch 2, iter 151, loss: 70.493125, acc: 0.510204\n",
      "epoch 2, iter 152, loss: 68.745246, acc: 0.326531\n",
      "epoch 2, iter 153, loss: 64.520410, acc: 0.510204\n",
      "epoch 2, iter 154, loss: 58.961847, acc: 0.530612\n",
      "epoch 2, iter 155, loss: 62.097952, acc: 0.306122\n",
      "epoch 2, iter 156, loss: 55.112365, acc: 0.571429\n",
      "epoch 2, iter 157, loss: 57.075113, acc: 0.346939\n",
      "epoch 2, iter 158, loss: 62.404671, acc: 0.163265\n",
      "epoch 2, iter 159, loss: 58.358581, acc: 0.530612\n",
      "epoch 2, iter 160, loss: 57.224649, acc: 0.551020\n",
      "epoch 2, iter 161, loss: 59.068501, acc: 0.285714\n",
      "epoch 2, iter 162, loss: 57.899399, acc: 0.408163\n",
      "epoch 2, iter 163, loss: 57.759406, acc: 0.367347\n",
      "epoch 2, iter 164, loss: 54.410517, acc: 0.551020\n",
      "epoch 2, iter 165, loss: 58.936591, acc: 0.244898\n",
      "epoch 2, iter 166, loss: 55.130444, acc: 0.489796\n",
      "epoch 2, iter 167, loss: 51.811866, acc: 0.714286\n",
      "epoch 2, iter 168, loss: 49.947168, acc: 0.612245\n",
      "epoch 2, iter 169, loss: 44.639012, acc: 0.693878\n",
      "epoch 2, iter 170, loss: 50.687512, acc: 0.428571\n",
      "epoch 2, iter 171, loss: 54.267272, acc: 0.346939\n",
      "epoch 2, iter 172, loss: 53.543437, acc: 0.428571\n",
      "epoch 2, iter 173, loss: 57.328702, acc: 0.306122\n",
      "epoch 2, iter 174, loss: 58.245104, acc: 0.428571\n",
      "epoch 2, iter 175, loss: 62.611047, acc: 0.224490\n",
      "epoch 2, iter 176, loss: 64.528654, acc: 0.265306\n",
      "epoch 2, iter 177, loss: 63.414460, acc: 0.306122\n",
      "epoch 2, iter 178, loss: 58.359732, acc: 0.510204\n",
      "epoch 2, iter 179, loss: 61.400216, acc: 0.265306\n",
      "epoch 2, iter 180, loss: 63.067626, acc: 0.265306\n",
      "epoch 2, iter 181, loss: 64.085723, acc: 0.326531\n",
      "epoch 2, iter 182, loss: 62.925434, acc: 0.408163\n",
      "epoch 2, iter 183, loss: 55.194101, acc: 0.734694\n",
      "epoch 2, iter 184, loss: 53.744900, acc: 0.428571\n",
      "epoch 2, iter 185, loss: 51.593608, acc: 0.530612\n",
      "epoch 2, iter 186, loss: 56.787833, acc: 0.204082\n",
      "epoch 2, iter 187, loss: 54.032911, acc: 0.510204\n",
      "epoch 2, iter 188, loss: 47.120353, acc: 0.816327\n",
      "epoch 2, iter 189, loss: 45.520067, acc: 0.591837\n",
      "epoch 2, iter 190, loss: 44.651207, acc: 0.673469\n",
      "epoch 2, iter 191, loss: 45.690478, acc: 0.448980\n",
      "epoch 2, iter 192, loss: 43.393026, acc: 0.591837\n",
      "epoch 2, iter 193, loss: 47.237926, acc: 0.591837\n",
      "epoch 2, iter 194, loss: 53.635790, acc: 0.204082\n",
      "epoch 2, iter 195, loss: 51.123395, acc: 0.530612\n",
      "epoch 2, iter 196, loss: 52.716156, acc: 0.285714\n",
      "epoch 2, iter 197, loss: 50.495031, acc: 0.469388\n",
      "epoch 2, iter 198, loss: 53.786815, acc: 0.367347\n",
      "epoch 2, iter 199, loss: 52.453245, acc: 0.448980\n",
      "epoch 2, iter 200, loss: 47.977503, acc: 0.653061\n",
      "epoch 2, iter 201, loss: 56.686947, acc: 0.183673\n",
      "epoch 2, iter 202, loss: 57.695533, acc: 0.408163\n",
      "epoch 2, iter 203, loss: 51.541045, acc: 0.714286\n",
      "epoch 2, iter 204, loss: 46.522919, acc: 0.673469\n",
      "epoch 2, iter 205, loss: 49.022847, acc: 0.469388\n",
      "epoch 2, iter 206, loss: 52.751605, acc: 0.326531\n",
      "epoch 2, iter 207, loss: 50.475338, acc: 0.489796\n",
      "epoch 2, iter 208, loss: 57.094672, acc: 0.204082\n",
      "epoch 2, iter 209, loss: 62.418637, acc: 0.265306\n",
      "epoch 2, iter 210, loss: 56.497481, acc: 0.612245\n",
      "epoch 2, iter 211, loss: 62.141640, acc: 0.163265\n",
      "epoch 2, iter 212, loss: 54.627585, acc: 0.755102\n",
      "epoch 2, iter 213, loss: 57.080522, acc: 0.285714\n",
      "epoch 2, iter 214, loss: 57.219793, acc: 0.285714\n",
      "epoch 2, iter 215, loss: 51.936656, acc: 0.673469\n",
      "epoch 2, iter 216, loss: 51.565506, acc: 0.489796\n",
      "epoch 2, iter 217, loss: 47.961101, acc: 0.714286\n",
      "epoch 2, iter 218, loss: 47.325889, acc: 0.530612\n",
      "epoch 2, iter 219, loss: 50.321510, acc: 0.285714\n",
      "epoch 2, iter 220, loss: 45.195234, acc: 0.816327\n",
      "epoch 2, iter 221, loss: 48.224428, acc: 0.326531\n",
      "epoch 2, iter 222, loss: 48.637314, acc: 0.530612\n",
      "epoch 2, iter 223, loss: 49.992085, acc: 0.367347\n",
      "epoch 2, iter 224, loss: 48.987857, acc: 0.591837\n",
      "epoch 2, iter 225, loss: 51.685455, acc: 0.367347\n",
      "epoch 2, iter 226, loss: 52.664258, acc: 0.448980\n",
      "epoch 2, iter 227, loss: 49.964091, acc: 0.530612\n",
      "epoch 2, iter 228, loss: 47.331189, acc: 0.591837\n",
      "epoch 2, iter 229, loss: 53.292019, acc: 0.163265\n",
      "epoch 2, iter 230, loss: 49.597031, acc: 0.612245\n",
      "epoch 2, iter 231, loss: 49.860317, acc: 0.387755\n",
      "epoch 2, iter 232, loss: 47.517429, acc: 0.612245\n",
      "epoch 2, iter 233, loss: 49.443893, acc: 0.551020\n",
      "epoch 2, iter 234, loss: 53.449995, acc: 0.163265\n",
      "epoch 2, iter 235, loss: 51.450346, acc: 0.530612\n",
      "epoch 2, iter 236, loss: 49.336904, acc: 0.367347\n",
      "epoch 2, iter 237, loss: 49.907974, acc: 0.632653\n",
      "epoch 2, iter 238, loss: 46.831709, acc: 0.714286\n",
      "epoch 2, iter 239, loss: 45.166572, acc: 0.653061\n",
      "epoch 2, iter 240, loss: 45.752083, acc: 0.469388\n",
      "epoch 2, iter 241, loss: 44.866010, acc: 0.591837\n",
      "epoch 2, iter 242, loss: 42.523626, acc: 0.734694\n",
      "epoch 2, iter 243, loss: 40.619259, acc: 0.673469\n",
      "epoch 2, iter 244, loss: 36.996245, acc: 0.877551\n",
      "epoch 2, iter 245, loss: 38.435816, acc: 0.673469\n",
      "epoch 2, iter 246, loss: 40.860654, acc: 0.693878\n",
      "epoch 2, iter 247, loss: 37.241403, acc: 0.877551\n",
      "epoch 2, iter 248, loss: 45.403832, acc: 0.469388\n",
      "epoch 2, iter 249, loss: 43.007446, acc: 0.795918\n",
      "epoch 2, acc: 0.416163\n",
      "epoch 3, iter 0, loss: 47.191057, acc: 0.387755\n",
      "epoch 3, iter 1, loss: 40.199867, acc: 0.918367\n",
      "epoch 3, iter 2, loss: 47.630724, acc: 0.346939\n",
      "epoch 3, iter 3, loss: 46.567674, acc: 0.714286\n",
      "epoch 3, iter 4, loss: 48.233912, acc: 0.510204\n",
      "epoch 3, iter 5, loss: 45.145023, acc: 0.653061\n",
      "epoch 3, iter 6, loss: 46.577806, acc: 0.387755\n",
      "epoch 3, iter 7, loss: 44.612493, acc: 0.775510\n",
      "epoch 3, iter 8, loss: 39.423884, acc: 0.857143\n",
      "epoch 3, iter 9, loss: 45.252884, acc: 0.469388\n",
      "epoch 3, iter 10, loss: 44.895633, acc: 0.551020\n",
      "epoch 3, iter 11, loss: 42.421840, acc: 0.734694\n",
      "epoch 3, iter 12, loss: 46.423160, acc: 0.367347\n",
      "epoch 3, iter 13, loss: 46.112339, acc: 0.551020\n",
      "epoch 3, iter 14, loss: 46.380417, acc: 0.510204\n",
      "epoch 3, iter 15, loss: 49.159081, acc: 0.244898\n",
      "epoch 3, iter 16, loss: 43.606508, acc: 0.836735\n",
      "epoch 3, iter 17, loss: 44.704827, acc: 0.489796\n",
      "epoch 3, iter 18, loss: 39.942259, acc: 0.897959\n",
      "epoch 3, iter 19, loss: 47.418261, acc: 0.142857\n",
      "epoch 3, iter 20, loss: 54.021842, acc: 0.224490\n",
      "epoch 3, iter 21, loss: 52.307624, acc: 0.408163\n",
      "epoch 3, iter 22, loss: 52.270541, acc: 0.428571\n",
      "epoch 3, iter 23, loss: 49.279023, acc: 0.795918\n",
      "epoch 3, iter 24, loss: 46.050143, acc: 0.755102\n",
      "epoch 3, iter 25, loss: 43.068029, acc: 0.816327\n",
      "epoch 3, iter 26, loss: 42.290928, acc: 0.734694\n",
      "epoch 3, iter 27, loss: 42.987798, acc: 0.673469\n",
      "epoch 3, iter 28, loss: 43.994613, acc: 0.591837\n",
      "epoch 3, iter 29, loss: 43.979912, acc: 0.530612\n",
      "epoch 3, iter 30, loss: 42.221613, acc: 0.775510\n",
      "epoch 3, iter 31, loss: 42.731987, acc: 0.775510\n",
      "epoch 3, iter 32, loss: 41.628933, acc: 0.673469\n",
      "epoch 3, iter 33, loss: 42.740968, acc: 0.530612\n",
      "epoch 3, iter 34, loss: 41.949872, acc: 0.775510\n",
      "epoch 3, iter 35, loss: 39.568516, acc: 0.836735\n",
      "epoch 3, iter 36, loss: 39.328507, acc: 0.734694\n",
      "epoch 3, iter 37, loss: 41.376673, acc: 0.469388\n",
      "epoch 3, iter 38, loss: 43.377791, acc: 0.469388\n",
      "epoch 3, iter 39, loss: 39.612407, acc: 0.897959\n",
      "epoch 3, iter 40, loss: 41.342925, acc: 0.693878\n",
      "epoch 3, iter 41, loss: 42.813102, acc: 0.571429\n",
      "epoch 3, iter 42, loss: 39.582705, acc: 0.857143\n",
      "epoch 3, iter 43, loss: 42.785699, acc: 0.408163\n",
      "epoch 3, iter 44, loss: 44.137805, acc: 0.367347\n",
      "epoch 3, iter 45, loss: 41.985137, acc: 0.795918\n",
      "epoch 3, iter 46, loss: 39.321775, acc: 0.816327\n",
      "epoch 3, iter 47, loss: 38.505797, acc: 0.714286\n",
      "epoch 3, iter 48, loss: 41.269255, acc: 0.693878\n",
      "epoch 3, iter 49, loss: 42.119422, acc: 0.591837\n",
      "epoch 3, iter 50, loss: 42.809301, acc: 0.632653\n",
      "epoch 3, iter 51, loss: 42.992676, acc: 0.612245\n",
      "epoch 3, iter 52, loss: 39.690854, acc: 0.816327\n",
      "epoch 3, iter 53, loss: 40.137712, acc: 0.693878\n",
      "epoch 3, iter 54, loss: 42.462135, acc: 0.530612\n",
      "epoch 3, iter 55, loss: 42.762992, acc: 0.530612\n",
      "epoch 3, iter 56, loss: 43.212714, acc: 0.571429\n",
      "epoch 3, iter 57, loss: 43.139536, acc: 0.448980\n",
      "epoch 3, iter 58, loss: 39.805634, acc: 0.918367\n",
      "epoch 3, iter 59, loss: 41.392813, acc: 0.632653\n",
      "epoch 3, iter 60, loss: 39.398467, acc: 0.816327\n",
      "epoch 3, iter 61, loss: 42.955692, acc: 0.510204\n",
      "epoch 3, iter 62, loss: 39.730383, acc: 0.775510\n",
      "epoch 3, iter 63, loss: 39.575673, acc: 0.653061\n",
      "epoch 3, iter 64, loss: 37.328865, acc: 0.897959\n",
      "epoch 3, iter 65, loss: 35.045703, acc: 0.877551\n",
      "epoch 3, iter 66, loss: 35.720302, acc: 0.693878\n",
      "epoch 3, iter 67, loss: 35.021342, acc: 0.836735\n",
      "epoch 3, iter 68, loss: 38.513006, acc: 0.571429\n",
      "epoch 3, iter 69, loss: 39.718860, acc: 0.591837\n",
      "epoch 3, iter 70, loss: 37.622181, acc: 0.857143\n",
      "epoch 3, iter 71, loss: 39.013498, acc: 0.693878\n",
      "epoch 3, iter 72, loss: 36.852555, acc: 0.836735\n",
      "epoch 3, iter 73, loss: 36.582530, acc: 0.755102\n",
      "epoch 3, iter 74, loss: 33.698417, acc: 0.938776\n",
      "epoch 3, iter 75, loss: 34.096867, acc: 0.816327\n",
      "epoch 3, iter 76, loss: 36.456858, acc: 0.734694\n",
      "epoch 3, iter 77, loss: 38.681893, acc: 0.612245\n",
      "epoch 3, iter 78, loss: 38.470023, acc: 0.795918\n",
      "epoch 3, iter 79, loss: 37.375130, acc: 0.836735\n",
      "epoch 3, iter 80, loss: 39.998589, acc: 0.591837\n",
      "epoch 3, iter 81, loss: 39.804012, acc: 0.755102\n",
      "epoch 3, iter 82, loss: 38.353248, acc: 0.734694\n",
      "epoch 3, iter 83, loss: 41.250323, acc: 0.510204\n",
      "epoch 3, iter 84, loss: 41.111348, acc: 0.632653\n",
      "epoch 3, iter 85, loss: 40.474617, acc: 0.693878\n",
      "epoch 3, iter 86, loss: 38.699303, acc: 0.795918\n",
      "epoch 3, iter 87, loss: 37.904231, acc: 0.877551\n",
      "epoch 3, iter 88, loss: 39.507202, acc: 0.816327\n",
      "epoch 3, iter 89, loss: 36.854270, acc: 0.938776\n",
      "epoch 3, iter 90, loss: 36.623332, acc: 0.755102\n",
      "epoch 3, iter 91, loss: 39.056433, acc: 0.673469\n",
      "epoch 3, iter 92, loss: 37.232656, acc: 0.857143\n",
      "epoch 3, iter 93, loss: 36.213224, acc: 0.755102\n",
      "epoch 3, iter 94, loss: 36.936725, acc: 0.734694\n",
      "epoch 3, iter 95, loss: 39.563490, acc: 0.448980\n",
      "epoch 3, iter 96, loss: 36.937861, acc: 0.938776\n",
      "epoch 3, iter 97, loss: 38.031692, acc: 0.714286\n",
      "epoch 3, iter 98, loss: 36.169835, acc: 0.857143\n",
      "epoch 3, iter 99, loss: 35.757877, acc: 0.816327\n",
      "epoch 3, iter 100, loss: 39.047386, acc: 0.755102\n",
      "epoch 3, iter 101, loss: 38.207509, acc: 0.857143\n",
      "epoch 3, iter 102, loss: 37.664896, acc: 0.653061\n",
      "epoch 3, iter 103, loss: 37.194353, acc: 0.795918\n",
      "epoch 3, iter 104, loss: 36.935901, acc: 0.795918\n",
      "epoch 3, iter 105, loss: 36.304058, acc: 0.816327\n",
      "epoch 3, iter 106, loss: 38.244286, acc: 0.714286\n",
      "epoch 3, iter 107, loss: 37.111902, acc: 0.673469\n",
      "epoch 3, iter 108, loss: 35.916225, acc: 0.857143\n",
      "epoch 3, iter 109, loss: 34.826850, acc: 0.877551\n",
      "epoch 3, iter 110, loss: 33.463282, acc: 0.836735\n",
      "epoch 3, iter 111, loss: 36.304040, acc: 0.673469\n",
      "epoch 3, iter 112, loss: 36.060810, acc: 0.775510\n",
      "epoch 3, iter 113, loss: 37.637390, acc: 0.775510\n",
      "epoch 3, iter 114, loss: 35.359380, acc: 0.857143\n",
      "epoch 3, iter 115, loss: 36.659332, acc: 0.612245\n",
      "epoch 3, iter 116, loss: 36.232370, acc: 0.795918\n",
      "epoch 3, iter 117, loss: 34.437426, acc: 0.877551\n",
      "epoch 3, iter 118, loss: 37.482700, acc: 0.591837\n",
      "epoch 3, iter 119, loss: 34.517076, acc: 0.918367\n",
      "epoch 3, iter 120, loss: 36.958885, acc: 0.714286\n",
      "epoch 3, iter 121, loss: 37.509099, acc: 0.693878\n",
      "epoch 3, iter 122, loss: 34.698304, acc: 0.959184\n",
      "epoch 3, iter 123, loss: 35.596813, acc: 0.714286\n",
      "epoch 3, iter 124, loss: 35.790779, acc: 0.816327\n",
      "epoch 3, iter 125, loss: 36.499973, acc: 0.714286\n",
      "epoch 3, iter 126, loss: 38.043270, acc: 0.714286\n",
      "epoch 3, iter 127, loss: 40.685791, acc: 0.632653\n",
      "epoch 3, iter 128, loss: 39.400952, acc: 0.775510\n",
      "epoch 3, iter 129, loss: 37.584498, acc: 0.836735\n",
      "epoch 3, iter 130, loss: 38.353162, acc: 0.571429\n",
      "epoch 3, iter 131, loss: 36.413265, acc: 0.897959\n",
      "epoch 3, iter 132, loss: 37.546546, acc: 0.632653\n",
      "epoch 3, iter 133, loss: 36.531251, acc: 0.816327\n",
      "epoch 3, iter 134, loss: 36.591619, acc: 0.755102\n",
      "epoch 3, iter 135, loss: 37.011844, acc: 0.877551\n",
      "epoch 3, iter 136, loss: 33.765842, acc: 0.938776\n",
      "epoch 3, iter 137, loss: 35.970373, acc: 0.795918\n",
      "epoch 3, iter 138, loss: 37.004032, acc: 0.795918\n",
      "epoch 3, iter 139, loss: 35.823066, acc: 0.857143\n",
      "epoch 3, iter 140, loss: 34.889311, acc: 0.857143\n",
      "epoch 3, iter 141, loss: 37.525857, acc: 0.612245\n",
      "epoch 3, iter 142, loss: 35.706264, acc: 0.897959\n",
      "epoch 3, iter 143, loss: 36.352596, acc: 0.755102\n",
      "epoch 3, iter 144, loss: 34.921477, acc: 0.857143\n",
      "epoch 3, iter 145, loss: 36.706684, acc: 0.612245\n",
      "epoch 3, iter 146, loss: 35.151356, acc: 0.857143\n",
      "epoch 3, iter 147, loss: 35.514923, acc: 0.714286\n",
      "epoch 3, iter 148, loss: 34.019555, acc: 0.897959\n",
      "epoch 3, iter 149, loss: 34.880761, acc: 0.653061\n",
      "epoch 3, iter 150, loss: 34.461125, acc: 0.857143\n",
      "epoch 3, iter 151, loss: 33.554639, acc: 0.877551\n",
      "epoch 3, iter 152, loss: 33.640965, acc: 0.795918\n",
      "epoch 3, iter 153, loss: 34.806183, acc: 0.734694\n",
      "epoch 3, iter 154, loss: 34.197379, acc: 0.836735\n",
      "epoch 3, iter 155, loss: 36.230929, acc: 0.734694\n",
      "epoch 3, iter 156, loss: 33.364486, acc: 0.959184\n",
      "epoch 3, iter 157, loss: 34.277860, acc: 0.755102\n",
      "epoch 3, iter 158, loss: 34.643435, acc: 0.775510\n",
      "epoch 3, iter 159, loss: 36.178527, acc: 0.714286\n",
      "epoch 3, iter 160, loss: 37.593547, acc: 0.857143\n",
      "epoch 3, iter 161, loss: 36.619498, acc: 0.836735\n",
      "epoch 3, iter 162, loss: 36.342915, acc: 0.918367\n",
      "epoch 3, iter 163, loss: 35.296514, acc: 0.836735\n",
      "epoch 3, iter 164, loss: 35.664385, acc: 0.836735\n",
      "epoch 3, iter 165, loss: 35.676638, acc: 0.836735\n",
      "epoch 3, iter 166, loss: 34.239971, acc: 0.857143\n",
      "epoch 3, iter 167, loss: 35.340650, acc: 0.775510\n",
      "epoch 3, iter 168, loss: 34.450993, acc: 0.897959\n",
      "epoch 3, iter 169, loss: 32.550843, acc: 0.877551\n",
      "epoch 3, iter 170, loss: 37.021711, acc: 0.755102\n",
      "epoch 3, iter 171, loss: 37.677737, acc: 0.795918\n",
      "epoch 3, iter 172, loss: 37.256645, acc: 0.857143\n",
      "epoch 3, iter 173, loss: 36.426477, acc: 0.714286\n",
      "epoch 3, iter 174, loss: 36.525469, acc: 0.877551\n",
      "epoch 3, iter 175, loss: 36.696839, acc: 0.795918\n",
      "epoch 3, iter 176, loss: 34.840115, acc: 0.857143\n",
      "epoch 3, iter 177, loss: 33.969853, acc: 0.836735\n",
      "epoch 3, iter 178, loss: 33.344226, acc: 0.836735\n",
      "epoch 3, iter 179, loss: 34.716149, acc: 0.836735\n",
      "epoch 3, iter 180, loss: 34.971569, acc: 0.734694\n",
      "epoch 3, iter 181, loss: 37.019198, acc: 0.775510\n",
      "epoch 3, iter 182, loss: 36.988904, acc: 0.795918\n",
      "epoch 3, iter 183, loss: 37.461062, acc: 0.857143\n",
      "epoch 3, iter 184, loss: 35.912060, acc: 0.857143\n",
      "epoch 3, iter 185, loss: 34.761772, acc: 0.918367\n",
      "epoch 3, iter 186, loss: 35.502759, acc: 0.816327\n",
      "epoch 3, iter 187, loss: 35.697922, acc: 0.897959\n",
      "epoch 3, iter 188, loss: 36.081449, acc: 0.755102\n",
      "epoch 3, iter 189, loss: 36.058580, acc: 0.836735\n",
      "epoch 3, iter 190, loss: 36.696626, acc: 0.734694\n",
      "epoch 3, iter 191, loss: 36.161883, acc: 0.877551\n",
      "epoch 3, iter 192, loss: 33.880700, acc: 0.897959\n",
      "epoch 3, iter 193, loss: 37.626196, acc: 0.795918\n",
      "epoch 3, iter 194, loss: 39.577910, acc: 0.673469\n",
      "epoch 3, iter 195, loss: 38.170851, acc: 0.836735\n",
      "epoch 3, iter 196, loss: 36.619086, acc: 0.836735\n",
      "epoch 3, iter 197, loss: 35.182657, acc: 0.877551\n",
      "epoch 3, iter 198, loss: 36.492369, acc: 0.795918\n",
      "epoch 3, iter 199, loss: 35.612347, acc: 0.857143\n",
      "epoch 3, iter 200, loss: 34.281526, acc: 0.897959\n",
      "epoch 3, iter 201, loss: 39.250940, acc: 0.693878\n",
      "epoch 3, iter 202, loss: 38.743687, acc: 0.775510\n",
      "epoch 3, iter 203, loss: 38.157492, acc: 0.836735\n",
      "epoch 3, iter 204, loss: 35.643210, acc: 0.877551\n",
      "epoch 3, iter 205, loss: 38.514365, acc: 0.734694\n",
      "epoch 3, iter 206, loss: 38.670375, acc: 0.775510\n",
      "epoch 3, iter 207, loss: 36.265251, acc: 0.836735\n",
      "epoch 3, iter 208, loss: 36.692998, acc: 0.755102\n",
      "epoch 3, iter 209, loss: 35.578697, acc: 0.816327\n",
      "epoch 3, iter 210, loss: 34.215290, acc: 0.918367\n",
      "epoch 3, iter 211, loss: 36.251439, acc: 0.755102\n",
      "epoch 3, iter 212, loss: 36.219621, acc: 0.816327\n",
      "epoch 3, iter 213, loss: 36.464087, acc: 0.857143\n",
      "epoch 3, iter 214, loss: 35.411982, acc: 0.857143\n",
      "epoch 3, iter 215, loss: 35.758022, acc: 0.857143\n",
      "epoch 3, iter 216, loss: 35.535643, acc: 0.775510\n",
      "epoch 3, iter 217, loss: 36.071691, acc: 0.836735\n",
      "epoch 3, iter 218, loss: 35.740187, acc: 0.918367\n",
      "epoch 3, iter 219, loss: 34.921893, acc: 0.816327\n",
      "epoch 3, iter 220, loss: 35.214177, acc: 0.775510\n",
      "epoch 3, iter 221, loss: 35.049720, acc: 0.857143\n",
      "epoch 3, iter 222, loss: 36.686569, acc: 0.795918\n",
      "epoch 3, iter 223, loss: 35.089699, acc: 0.816327\n",
      "epoch 3, iter 224, loss: 35.360849, acc: 0.877551\n",
      "epoch 3, iter 225, loss: 36.114247, acc: 0.857143\n",
      "epoch 3, iter 226, loss: 36.479869, acc: 0.795918\n",
      "epoch 3, iter 227, loss: 34.526742, acc: 0.897959\n",
      "epoch 3, iter 228, loss: 33.872210, acc: 0.816327\n",
      "epoch 3, iter 229, loss: 34.212529, acc: 0.673469\n",
      "epoch 3, iter 230, loss: 33.450805, acc: 0.959184\n",
      "epoch 3, iter 231, loss: 32.656955, acc: 0.857143\n",
      "epoch 3, iter 232, loss: 32.091394, acc: 0.918367\n",
      "epoch 3, iter 233, loss: 34.664598, acc: 0.775510\n",
      "epoch 3, iter 234, loss: 34.729579, acc: 0.693878\n",
      "epoch 3, iter 235, loss: 34.820262, acc: 0.836735\n",
      "epoch 3, iter 236, loss: 31.828761, acc: 0.979592\n",
      "epoch 3, iter 237, loss: 36.120950, acc: 0.653061\n",
      "epoch 3, iter 238, loss: 36.437200, acc: 0.795918\n",
      "epoch 3, iter 239, loss: 36.145262, acc: 0.836735\n",
      "epoch 3, iter 240, loss: 35.432027, acc: 0.918367\n",
      "epoch 3, iter 241, loss: 34.283833, acc: 0.918367\n",
      "epoch 3, iter 242, loss: 33.975110, acc: 0.877551\n",
      "epoch 3, iter 243, loss: 32.723471, acc: 0.897959\n",
      "epoch 3, iter 244, loss: 31.471987, acc: 0.897959\n",
      "epoch 3, iter 245, loss: 32.496374, acc: 0.816327\n",
      "epoch 3, iter 246, loss: 36.095918, acc: 0.775510\n",
      "epoch 3, iter 247, loss: 34.949332, acc: 0.836735\n",
      "epoch 3, iter 248, loss: 39.190863, acc: 0.693878\n",
      "epoch 3, iter 249, loss: 38.965032, acc: 0.795918\n",
      "epoch 3, acc: 0.753388\n",
      "epoch 4, iter 0, loss: 41.123065, acc: 0.734694\n",
      "epoch 4, iter 1, loss: 38.981875, acc: 0.938776\n",
      "epoch 4, iter 2, loss: 45.028984, acc: 0.571429\n",
      "epoch 4, iter 3, loss: 42.220173, acc: 0.836735\n",
      "epoch 4, iter 4, loss: 40.772941, acc: 0.897959\n",
      "epoch 4, iter 5, loss: 37.022239, acc: 0.877551\n",
      "epoch 4, iter 6, loss: 36.284338, acc: 0.816327\n",
      "epoch 4, iter 7, loss: 36.473180, acc: 0.816327\n",
      "epoch 4, iter 8, loss: 34.458957, acc: 0.857143\n",
      "epoch 4, iter 9, loss: 37.716772, acc: 0.714286\n",
      "epoch 4, iter 10, loss: 37.307631, acc: 0.795918\n",
      "epoch 4, iter 11, loss: 37.492592, acc: 0.816327\n",
      "epoch 4, iter 12, loss: 38.514282, acc: 0.816327\n",
      "epoch 4, iter 13, loss: 37.082207, acc: 0.938776\n",
      "epoch 4, iter 14, loss: 35.871291, acc: 0.816327\n",
      "epoch 4, iter 15, loss: 34.475801, acc: 0.836735\n",
      "epoch 4, iter 16, loss: 33.504527, acc: 0.918367\n",
      "epoch 4, iter 17, loss: 32.673013, acc: 0.836735\n",
      "epoch 4, iter 18, loss: 34.220127, acc: 0.775510\n",
      "epoch 4, iter 19, loss: 36.210158, acc: 0.489796\n",
      "epoch 4, iter 20, loss: 36.073038, acc: 0.673469\n",
      "epoch 4, iter 21, loss: 33.892752, acc: 0.877551\n",
      "epoch 4, iter 22, loss: 32.018897, acc: 0.897959\n",
      "epoch 4, iter 23, loss: 33.034841, acc: 0.795918\n",
      "epoch 4, iter 24, loss: 32.294832, acc: 0.897959\n",
      "epoch 4, iter 25, loss: 33.155395, acc: 0.816327\n",
      "epoch 4, iter 26, loss: 34.448474, acc: 0.857143\n",
      "epoch 4, iter 27, loss: 34.950770, acc: 0.816327\n",
      "epoch 4, iter 28, loss: 33.712104, acc: 0.775510\n",
      "epoch 4, iter 29, loss: 32.426733, acc: 0.897959\n",
      "epoch 4, iter 30, loss: 33.912740, acc: 0.816327\n",
      "epoch 4, iter 31, loss: 36.999952, acc: 0.734694\n",
      "epoch 4, iter 32, loss: 35.548334, acc: 0.836735\n",
      "epoch 4, iter 33, loss: 34.640853, acc: 0.795918\n",
      "epoch 4, iter 34, loss: 34.704357, acc: 0.816327\n",
      "epoch 4, iter 35, loss: 34.772019, acc: 0.755102\n",
      "epoch 4, iter 36, loss: 35.152096, acc: 0.877551\n",
      "epoch 4, iter 37, loss: 34.070629, acc: 0.836735\n",
      "epoch 4, iter 38, loss: 34.921922, acc: 0.755102\n",
      "epoch 4, iter 39, loss: 34.342654, acc: 0.877551\n",
      "epoch 4, iter 40, loss: 36.306650, acc: 0.775510\n",
      "epoch 4, iter 41, loss: 36.147193, acc: 0.857143\n",
      "epoch 4, iter 42, loss: 36.938001, acc: 0.795918\n",
      "epoch 4, iter 43, loss: 35.882752, acc: 0.897959\n",
      "epoch 4, iter 44, loss: 33.680137, acc: 0.877551\n",
      "epoch 4, iter 45, loss: 33.698621, acc: 0.857143\n",
      "epoch 4, iter 46, loss: 33.451891, acc: 0.857143\n",
      "epoch 4, iter 47, loss: 32.450590, acc: 0.836735\n",
      "epoch 4, iter 48, loss: 34.690476, acc: 0.775510\n",
      "epoch 4, iter 49, loss: 34.138815, acc: 0.897959\n",
      "epoch 4, iter 50, loss: 34.731358, acc: 0.816327\n",
      "epoch 4, iter 51, loss: 35.700519, acc: 0.795918\n",
      "epoch 4, iter 52, loss: 34.316925, acc: 0.918367\n",
      "epoch 4, iter 53, loss: 34.981939, acc: 0.795918\n",
      "epoch 4, iter 54, loss: 35.547388, acc: 0.734694\n",
      "epoch 4, iter 55, loss: 34.640559, acc: 0.918367\n",
      "epoch 4, iter 56, loss: 34.092940, acc: 0.836735\n",
      "epoch 4, iter 57, loss: 32.959394, acc: 0.816327\n",
      "epoch 4, iter 58, loss: 33.299767, acc: 0.897959\n",
      "epoch 4, iter 59, loss: 33.968056, acc: 0.877551\n",
      "epoch 4, iter 60, loss: 32.139397, acc: 0.959184\n",
      "epoch 4, iter 61, loss: 34.644273, acc: 0.714286\n",
      "epoch 4, iter 62, loss: 33.173198, acc: 0.938776\n",
      "epoch 4, iter 63, loss: 32.144207, acc: 0.877551\n",
      "epoch 4, iter 64, loss: 33.229253, acc: 0.693878\n",
      "epoch 4, iter 65, loss: 31.365838, acc: 0.918367\n",
      "epoch 4, iter 66, loss: 30.005351, acc: 0.918367\n",
      "epoch 4, iter 67, loss: 31.645251, acc: 0.775510\n",
      "epoch 4, iter 68, loss: 32.098390, acc: 0.795918\n",
      "epoch 4, iter 69, loss: 31.558849, acc: 0.836735\n",
      "epoch 4, iter 70, loss: 30.240314, acc: 0.918367\n",
      "epoch 4, iter 71, loss: 32.685917, acc: 0.836735\n",
      "epoch 4, iter 72, loss: 31.368059, acc: 0.938776\n",
      "epoch 4, iter 73, loss: 29.846487, acc: 0.897959\n",
      "epoch 4, iter 74, loss: 28.548678, acc: 0.897959\n",
      "epoch 4, iter 75, loss: 27.892715, acc: 0.897959\n",
      "epoch 4, iter 76, loss: 30.866257, acc: 0.714286\n",
      "epoch 4, iter 77, loss: 33.371863, acc: 0.755102\n",
      "epoch 4, iter 78, loss: 33.760504, acc: 0.897959\n",
      "epoch 4, iter 79, loss: 32.879493, acc: 0.897959\n",
      "epoch 4, iter 80, loss: 32.735069, acc: 0.836735\n",
      "epoch 4, iter 81, loss: 33.296228, acc: 0.836735\n",
      "epoch 4, iter 82, loss: 32.047499, acc: 0.897959\n",
      "epoch 4, iter 83, loss: 34.403251, acc: 0.714286\n",
      "epoch 4, iter 84, loss: 32.372148, acc: 0.938776\n",
      "epoch 4, iter 85, loss: 30.455948, acc: 0.918367\n",
      "epoch 4, iter 86, loss: 32.347475, acc: 0.755102\n",
      "epoch 4, iter 87, loss: 35.073393, acc: 0.836735\n",
      "epoch 4, iter 88, loss: 35.083389, acc: 0.857143\n",
      "epoch 4, iter 89, loss: 33.112409, acc: 0.938776\n",
      "epoch 4, iter 90, loss: 34.422103, acc: 0.734694\n",
      "epoch 4, iter 91, loss: 36.248451, acc: 0.734694\n",
      "epoch 4, iter 92, loss: 36.174968, acc: 0.836735\n",
      "epoch 4, iter 93, loss: 36.175005, acc: 0.795918\n",
      "epoch 4, iter 94, loss: 37.373643, acc: 0.836735\n",
      "epoch 4, iter 95, loss: 36.171620, acc: 0.877551\n",
      "epoch 4, iter 96, loss: 34.608502, acc: 0.938776\n",
      "epoch 4, iter 97, loss: 34.787879, acc: 0.836735\n",
      "epoch 4, iter 98, loss: 33.356311, acc: 0.857143\n",
      "epoch 4, iter 99, loss: 32.019875, acc: 0.918367\n",
      "epoch 4, iter 100, loss: 37.197139, acc: 0.632653\n",
      "epoch 4, iter 101, loss: 35.850677, acc: 0.897959\n",
      "epoch 4, iter 102, loss: 33.794547, acc: 0.877551\n",
      "epoch 4, iter 103, loss: 32.613409, acc: 0.938776\n",
      "epoch 4, iter 104, loss: 33.095605, acc: 0.816327\n",
      "epoch 4, iter 105, loss: 32.245655, acc: 0.877551\n",
      "epoch 4, iter 106, loss: 32.550494, acc: 0.795918\n",
      "epoch 4, iter 107, loss: 30.197863, acc: 0.918367\n",
      "epoch 4, iter 108, loss: 31.798958, acc: 0.734694\n",
      "epoch 4, iter 109, loss: 32.550998, acc: 0.795918\n",
      "epoch 4, iter 110, loss: 31.898871, acc: 0.857143\n",
      "epoch 4, iter 111, loss: 35.743958, acc: 0.714286\n",
      "epoch 4, iter 112, loss: 35.508499, acc: 0.918367\n",
      "epoch 4, iter 113, loss: 38.121916, acc: 0.693878\n",
      "epoch 4, iter 114, loss: 36.179255, acc: 0.897959\n",
      "epoch 4, iter 115, loss: 35.605482, acc: 0.857143\n",
      "epoch 4, iter 116, loss: 36.461563, acc: 0.734694\n",
      "epoch 4, iter 117, loss: 33.876322, acc: 0.897959\n",
      "epoch 4, iter 118, loss: 36.809828, acc: 0.734694\n",
      "epoch 4, iter 119, loss: 33.667649, acc: 0.959184\n",
      "epoch 4, iter 120, loss: 35.593855, acc: 0.693878\n",
      "epoch 4, iter 121, loss: 34.318353, acc: 0.836735\n",
      "epoch 4, iter 122, loss: 33.896969, acc: 0.836735\n",
      "epoch 4, iter 123, loss: 33.316062, acc: 0.816327\n",
      "epoch 4, iter 124, loss: 33.996548, acc: 0.816327\n",
      "epoch 4, iter 125, loss: 35.150125, acc: 0.857143\n",
      "epoch 4, iter 126, loss: 34.898484, acc: 0.836735\n",
      "epoch 4, iter 127, loss: 38.395120, acc: 0.632653\n",
      "epoch 4, iter 128, loss: 36.190259, acc: 0.938776\n",
      "epoch 4, iter 129, loss: 34.509630, acc: 0.897959\n",
      "epoch 4, iter 130, loss: 33.407198, acc: 0.897959\n",
      "epoch 4, iter 131, loss: 32.484000, acc: 0.877551\n",
      "epoch 4, iter 132, loss: 33.220842, acc: 0.836735\n",
      "epoch 4, iter 133, loss: 31.294310, acc: 0.938776\n",
      "epoch 4, iter 134, loss: 34.360068, acc: 0.653061\n",
      "epoch 4, iter 135, loss: 35.481860, acc: 0.836735\n",
      "epoch 4, iter 136, loss: 34.242142, acc: 0.877551\n",
      "epoch 4, iter 137, loss: 35.593780, acc: 0.877551\n",
      "epoch 4, iter 138, loss: 36.400948, acc: 0.816327\n",
      "epoch 4, iter 139, loss: 35.180930, acc: 0.857143\n",
      "epoch 4, iter 140, loss: 34.385051, acc: 0.857143\n",
      "epoch 4, iter 141, loss: 34.319810, acc: 0.836735\n",
      "epoch 4, iter 142, loss: 34.043822, acc: 0.836735\n",
      "epoch 4, iter 143, loss: 33.638049, acc: 0.836735\n",
      "epoch 4, iter 144, loss: 33.292882, acc: 0.795918\n",
      "epoch 4, iter 145, loss: 32.807271, acc: 0.877551\n",
      "epoch 4, iter 146, loss: 31.684028, acc: 0.918367\n",
      "epoch 4, iter 147, loss: 32.080891, acc: 0.795918\n",
      "epoch 4, iter 148, loss: 31.488419, acc: 0.918367\n",
      "epoch 4, iter 149, loss: 30.690810, acc: 0.877551\n",
      "epoch 4, iter 150, loss: 30.743710, acc: 0.897959\n",
      "epoch 4, iter 151, loss: 30.472978, acc: 0.877551\n",
      "epoch 4, iter 152, loss: 31.579585, acc: 0.897959\n",
      "epoch 4, iter 153, loss: 32.911203, acc: 0.775510\n",
      "epoch 4, iter 154, loss: 33.119768, acc: 0.836735\n",
      "epoch 4, iter 155, loss: 33.896461, acc: 0.816327\n",
      "epoch 4, iter 156, loss: 31.929806, acc: 0.938776\n",
      "epoch 4, iter 157, loss: 32.925224, acc: 0.857143\n",
      "epoch 4, iter 158, loss: 31.794779, acc: 0.897959\n",
      "epoch 4, iter 159, loss: 34.846249, acc: 0.755102\n",
      "epoch 4, iter 160, loss: 36.808708, acc: 0.795918\n",
      "epoch 4, iter 161, loss: 35.461268, acc: 0.857143\n",
      "epoch 4, iter 162, loss: 34.913580, acc: 0.857143\n",
      "epoch 4, iter 163, loss: 33.925942, acc: 0.877551\n",
      "epoch 4, iter 164, loss: 34.925279, acc: 0.775510\n",
      "epoch 4, iter 165, loss: 33.453501, acc: 0.938776\n",
      "epoch 4, iter 166, loss: 32.582164, acc: 0.836735\n",
      "epoch 4, iter 167, loss: 34.881234, acc: 0.734694\n",
      "epoch 4, iter 168, loss: 33.350792, acc: 0.897959\n",
      "epoch 4, iter 169, loss: 32.289288, acc: 0.877551\n",
      "epoch 4, iter 170, loss: 37.528206, acc: 0.714286\n",
      "epoch 4, iter 171, loss: 38.773591, acc: 0.734694\n",
      "epoch 4, iter 172, loss: 38.060192, acc: 0.795918\n",
      "epoch 4, iter 173, loss: 35.947383, acc: 0.836735\n",
      "epoch 4, iter 174, loss: 35.796391, acc: 0.836735\n",
      "epoch 4, iter 175, loss: 34.408967, acc: 0.836735\n",
      "epoch 4, iter 176, loss: 32.564251, acc: 0.918367\n",
      "epoch 4, iter 177, loss: 31.894117, acc: 0.836735\n",
      "epoch 4, iter 178, loss: 31.911172, acc: 0.816327\n",
      "epoch 4, iter 179, loss: 32.048034, acc: 0.857143\n",
      "epoch 4, iter 180, loss: 31.262705, acc: 0.836735\n",
      "epoch 4, iter 181, loss: 33.564243, acc: 0.734694\n",
      "epoch 4, iter 182, loss: 33.251389, acc: 0.816327\n",
      "epoch 4, iter 183, loss: 35.843831, acc: 0.693878\n",
      "epoch 4, iter 184, loss: 34.750137, acc: 0.857143\n",
      "epoch 4, iter 185, loss: 34.270288, acc: 0.857143\n",
      "epoch 4, iter 186, loss: 34.492721, acc: 0.897959\n",
      "epoch 4, iter 187, loss: 35.340919, acc: 0.755102\n",
      "epoch 4, iter 188, loss: 37.519920, acc: 0.775510\n",
      "epoch 4, iter 189, loss: 36.323919, acc: 0.836735\n",
      "epoch 4, iter 190, loss: 36.606603, acc: 0.795918\n",
      "epoch 4, iter 191, loss: 35.027016, acc: 0.959184\n",
      "epoch 4, iter 192, loss: 33.238473, acc: 0.857143\n",
      "epoch 4, iter 193, loss: 36.591024, acc: 0.714286\n",
      "epoch 4, iter 194, loss: 36.826581, acc: 0.795918\n",
      "epoch 4, iter 195, loss: 36.294932, acc: 0.816327\n",
      "epoch 4, iter 196, loss: 33.944114, acc: 0.938776\n",
      "epoch 4, iter 197, loss: 33.248934, acc: 0.795918\n",
      "epoch 4, iter 198, loss: 34.042272, acc: 0.775510\n",
      "epoch 4, iter 199, loss: 33.434173, acc: 0.877551\n",
      "epoch 4, iter 200, loss: 32.778112, acc: 0.836735\n",
      "epoch 4, iter 201, loss: 36.516539, acc: 0.775510\n",
      "epoch 4, iter 202, loss: 35.491357, acc: 0.836735\n",
      "epoch 4, iter 203, loss: 37.059112, acc: 0.836735\n",
      "epoch 4, iter 204, loss: 35.041109, acc: 0.857143\n",
      "epoch 4, iter 205, loss: 38.658169, acc: 0.734694\n",
      "epoch 4, iter 206, loss: 37.745217, acc: 0.795918\n",
      "epoch 4, iter 207, loss: 35.481063, acc: 0.857143\n",
      "epoch 4, iter 208, loss: 34.856849, acc: 0.795918\n",
      "epoch 4, iter 209, loss: 32.859833, acc: 0.918367\n",
      "epoch 4, iter 210, loss: 32.536523, acc: 0.877551\n",
      "epoch 4, iter 211, loss: 33.122776, acc: 0.836735\n",
      "epoch 4, iter 212, loss: 34.746089, acc: 0.693878\n",
      "epoch 4, iter 213, loss: 33.763930, acc: 0.836735\n",
      "epoch 4, iter 214, loss: 32.369154, acc: 0.897959\n",
      "epoch 4, iter 215, loss: 33.451984, acc: 0.877551\n",
      "epoch 4, iter 216, loss: 33.194214, acc: 0.816327\n",
      "epoch 4, iter 217, loss: 35.444166, acc: 0.755102\n",
      "epoch 4, iter 218, loss: 34.620266, acc: 0.918367\n",
      "epoch 4, iter 219, loss: 33.103501, acc: 0.959184\n",
      "epoch 4, iter 220, loss: 34.651864, acc: 0.693878\n",
      "epoch 4, iter 221, loss: 33.731955, acc: 0.877551\n",
      "epoch 4, iter 222, loss: 35.558714, acc: 0.734694\n",
      "epoch 4, iter 223, loss: 33.078502, acc: 0.918367\n",
      "epoch 4, iter 224, loss: 33.601978, acc: 0.877551\n",
      "epoch 4, iter 225, loss: 34.174686, acc: 0.877551\n",
      "epoch 4, iter 226, loss: 34.572714, acc: 0.816327\n",
      "epoch 4, iter 227, loss: 32.795728, acc: 0.918367\n",
      "epoch 4, iter 228, loss: 32.675659, acc: 0.857143\n",
      "epoch 4, iter 229, loss: 31.308570, acc: 0.836735\n",
      "epoch 4, iter 230, loss: 31.299505, acc: 0.877551\n",
      "epoch 4, iter 231, loss: 30.137863, acc: 0.918367\n",
      "epoch 4, iter 232, loss: 30.678777, acc: 0.857143\n",
      "epoch 4, iter 233, loss: 33.150595, acc: 0.734694\n",
      "epoch 4, iter 234, loss: 31.886428, acc: 0.918367\n",
      "epoch 4, iter 235, loss: 32.162800, acc: 0.816327\n",
      "epoch 4, iter 236, loss: 29.524707, acc: 1.000000\n",
      "epoch 4, iter 237, loss: 34.213986, acc: 0.693878\n",
      "epoch 4, iter 238, loss: 35.609230, acc: 0.795918\n",
      "epoch 4, iter 239, loss: 35.020715, acc: 0.836735\n",
      "epoch 4, iter 240, loss: 34.597793, acc: 0.938776\n",
      "epoch 4, iter 241, loss: 32.889605, acc: 0.918367\n",
      "epoch 4, iter 242, loss: 32.688184, acc: 0.795918\n",
      "epoch 4, iter 243, loss: 33.227917, acc: 0.857143\n",
      "epoch 4, iter 244, loss: 32.174826, acc: 0.816327\n",
      "epoch 4, iter 245, loss: 33.418765, acc: 0.836735\n",
      "epoch 4, iter 246, loss: 35.999417, acc: 0.816327\n",
      "epoch 4, iter 247, loss: 35.448073, acc: 0.816327\n",
      "epoch 4, iter 248, loss: 39.028623, acc: 0.734694\n",
      "epoch 4, iter 249, loss: 38.799617, acc: 0.836735\n",
      "epoch 4, acc: 0.834286\n",
      "epoch 5, iter 0, loss: 40.430228, acc: 0.693878\n",
      "epoch 5, iter 1, loss: 39.214626, acc: 0.816327\n",
      "epoch 5, iter 2, loss: 40.500484, acc: 0.734694\n",
      "epoch 5, iter 3, loss: 38.633543, acc: 0.857143\n",
      "epoch 5, iter 4, loss: 37.824346, acc: 0.857143\n",
      "epoch 5, iter 5, loss: 34.934496, acc: 0.918367\n",
      "epoch 5, iter 6, loss: 33.609101, acc: 0.897959\n",
      "epoch 5, iter 7, loss: 34.561648, acc: 0.755102\n",
      "epoch 5, iter 8, loss: 34.122490, acc: 0.775510\n",
      "epoch 5, iter 9, loss: 35.818990, acc: 0.816327\n",
      "epoch 5, iter 10, loss: 34.858802, acc: 0.816327\n",
      "epoch 5, iter 11, loss: 36.122690, acc: 0.714286\n",
      "epoch 5, iter 12, loss: 35.408200, acc: 0.897959\n",
      "epoch 5, iter 13, loss: 34.156667, acc: 0.897959\n",
      "epoch 5, iter 14, loss: 33.286360, acc: 0.897959\n",
      "epoch 5, iter 15, loss: 32.026660, acc: 0.938776\n",
      "epoch 5, iter 16, loss: 32.192197, acc: 0.836735\n",
      "epoch 5, iter 17, loss: 31.119068, acc: 0.877551\n",
      "epoch 5, iter 18, loss: 34.121052, acc: 0.734694\n",
      "epoch 5, iter 19, loss: 34.282947, acc: 0.734694\n",
      "epoch 5, iter 20, loss: 32.258513, acc: 0.918367\n",
      "epoch 5, iter 21, loss: 30.277997, acc: 0.918367\n",
      "epoch 5, iter 22, loss: 28.610979, acc: 0.918367\n",
      "epoch 5, iter 23, loss: 31.154714, acc: 0.755102\n",
      "epoch 5, iter 24, loss: 30.455829, acc: 0.857143\n",
      "epoch 5, iter 25, loss: 32.233689, acc: 0.775510\n",
      "epoch 5, iter 26, loss: 34.070376, acc: 0.836735\n",
      "epoch 5, iter 27, loss: 34.536214, acc: 0.734694\n",
      "epoch 5, iter 28, loss: 32.693509, acc: 0.897959\n",
      "epoch 5, iter 29, loss: 30.640011, acc: 0.897959\n",
      "epoch 5, iter 30, loss: 32.650775, acc: 0.693878\n",
      "epoch 5, iter 31, loss: 36.481415, acc: 0.693878\n",
      "epoch 5, iter 32, loss: 34.713804, acc: 0.877551\n",
      "epoch 5, iter 33, loss: 32.926009, acc: 0.857143\n",
      "epoch 5, iter 34, loss: 33.266268, acc: 0.775510\n",
      "epoch 5, iter 35, loss: 34.351525, acc: 0.755102\n",
      "epoch 5, iter 36, loss: 34.572206, acc: 0.857143\n",
      "epoch 5, iter 37, loss: 32.879966, acc: 0.877551\n",
      "epoch 5, iter 38, loss: 33.671164, acc: 0.795918\n",
      "epoch 5, iter 39, loss: 33.453566, acc: 0.836735\n",
      "epoch 5, iter 40, loss: 35.310891, acc: 0.795918\n",
      "epoch 5, iter 41, loss: 34.682717, acc: 0.918367\n",
      "epoch 5, iter 42, loss: 36.971007, acc: 0.755102\n",
      "epoch 5, iter 43, loss: 34.688618, acc: 0.938776\n",
      "epoch 5, iter 44, loss: 31.720743, acc: 0.897959\n",
      "epoch 5, iter 45, loss: 32.457205, acc: 0.836735\n",
      "epoch 5, iter 46, loss: 32.847415, acc: 0.816327\n",
      "epoch 5, iter 47, loss: 32.024337, acc: 0.857143\n",
      "epoch 5, iter 48, loss: 33.686975, acc: 0.816327\n",
      "epoch 5, iter 49, loss: 33.144106, acc: 0.877551\n",
      "epoch 5, iter 50, loss: 33.570808, acc: 0.836735\n",
      "epoch 5, iter 51, loss: 34.691884, acc: 0.775510\n",
      "epoch 5, iter 52, loss: 33.864954, acc: 0.897959\n",
      "epoch 5, iter 53, loss: 34.586003, acc: 0.816327\n",
      "epoch 5, iter 54, loss: 34.427319, acc: 0.775510\n",
      "epoch 5, iter 55, loss: 33.579660, acc: 0.897959\n",
      "epoch 5, iter 56, loss: 32.684847, acc: 0.857143\n",
      "epoch 5, iter 57, loss: 31.246511, acc: 0.857143\n",
      "epoch 5, iter 58, loss: 32.381933, acc: 0.816327\n",
      "epoch 5, iter 59, loss: 32.520362, acc: 0.816327\n",
      "epoch 5, iter 60, loss: 30.811894, acc: 1.000000\n",
      "epoch 5, iter 61, loss: 32.560417, acc: 0.836735\n",
      "epoch 5, iter 62, loss: 31.376184, acc: 0.918367\n",
      "epoch 5, iter 63, loss: 30.406805, acc: 0.938776\n",
      "epoch 5, iter 64, loss: 32.711750, acc: 0.612245\n",
      "epoch 5, iter 65, loss: 31.212688, acc: 0.877551\n",
      "epoch 5, iter 66, loss: 29.372550, acc: 0.918367\n",
      "epoch 5, iter 67, loss: 31.640902, acc: 0.755102\n",
      "epoch 5, iter 68, loss: 31.055469, acc: 0.857143\n",
      "epoch 5, iter 69, loss: 29.735612, acc: 0.897959\n",
      "epoch 5, iter 70, loss: 28.962303, acc: 0.877551\n",
      "epoch 5, iter 71, loss: 31.854819, acc: 0.795918\n",
      "epoch 5, iter 72, loss: 30.436122, acc: 0.918367\n",
      "epoch 5, iter 73, loss: 28.400606, acc: 0.918367\n",
      "epoch 5, iter 74, loss: 27.506616, acc: 0.857143\n",
      "epoch 5, iter 75, loss: 26.696542, acc: 0.918367\n",
      "epoch 5, iter 76, loss: 29.709119, acc: 0.693878\n",
      "epoch 5, iter 77, loss: 32.571399, acc: 0.775510\n",
      "epoch 5, iter 78, loss: 33.224961, acc: 0.836735\n",
      "epoch 5, iter 79, loss: 31.993142, acc: 0.897959\n",
      "epoch 5, iter 80, loss: 31.340891, acc: 0.857143\n",
      "epoch 5, iter 81, loss: 31.919653, acc: 0.795918\n",
      "epoch 5, iter 82, loss: 31.129073, acc: 0.857143\n",
      "epoch 5, iter 83, loss: 33.246248, acc: 0.734694\n",
      "epoch 5, iter 84, loss: 30.991944, acc: 0.897959\n",
      "epoch 5, iter 85, loss: 28.843267, acc: 0.918367\n",
      "epoch 5, iter 86, loss: 31.332023, acc: 0.673469\n",
      "epoch 5, iter 87, loss: 34.047699, acc: 0.714286\n",
      "epoch 5, iter 88, loss: 33.815577, acc: 0.857143\n",
      "epoch 5, iter 89, loss: 32.275350, acc: 0.857143\n",
      "epoch 5, iter 90, loss: 33.828941, acc: 0.734694\n",
      "epoch 5, iter 91, loss: 34.773791, acc: 0.795918\n",
      "epoch 5, iter 92, loss: 35.554446, acc: 0.775510\n",
      "epoch 5, iter 93, loss: 36.018214, acc: 0.795918\n",
      "epoch 5, iter 94, loss: 34.757381, acc: 0.877551\n",
      "epoch 5, iter 95, loss: 33.052224, acc: 0.938776\n",
      "epoch 5, iter 96, loss: 32.851460, acc: 0.836735\n",
      "epoch 5, iter 97, loss: 33.038204, acc: 0.857143\n",
      "epoch 5, iter 98, loss: 32.130402, acc: 0.836735\n",
      "epoch 5, iter 99, loss: 30.788813, acc: 0.918367\n",
      "epoch 5, iter 100, loss: 36.122515, acc: 0.591837\n",
      "epoch 5, iter 101, loss: 35.034154, acc: 0.836735\n",
      "epoch 5, iter 102, loss: 32.481573, acc: 0.897959\n",
      "epoch 5, iter 103, loss: 31.602026, acc: 0.918367\n",
      "epoch 5, iter 104, loss: 32.470904, acc: 0.795918\n",
      "epoch 5, iter 105, loss: 31.806137, acc: 0.857143\n",
      "epoch 5, iter 106, loss: 31.791245, acc: 0.816327\n",
      "epoch 5, iter 107, loss: 29.166710, acc: 0.938776\n",
      "epoch 5, iter 108, loss: 31.322536, acc: 0.714286\n",
      "epoch 5, iter 109, loss: 32.472195, acc: 0.755102\n",
      "epoch 5, iter 110, loss: 31.763627, acc: 0.857143\n",
      "epoch 5, iter 111, loss: 36.025593, acc: 0.632653\n",
      "epoch 5, iter 112, loss: 35.471155, acc: 0.857143\n",
      "epoch 5, iter 113, loss: 38.301795, acc: 0.693878\n",
      "epoch 5, iter 114, loss: 36.216702, acc: 0.897959\n",
      "epoch 5, iter 115, loss: 36.482491, acc: 0.897959\n",
      "epoch 5, iter 116, loss: 37.400714, acc: 0.775510\n",
      "epoch 5, iter 117, loss: 33.963748, acc: 0.897959\n",
      "epoch 5, iter 118, loss: 36.819616, acc: 0.714286\n",
      "epoch 5, iter 119, loss: 33.633090, acc: 0.938776\n",
      "epoch 5, iter 120, loss: 35.789990, acc: 0.693878\n",
      "epoch 5, iter 121, loss: 33.658982, acc: 0.857143\n",
      "epoch 5, iter 122, loss: 33.508208, acc: 0.836735\n",
      "epoch 5, iter 123, loss: 32.877756, acc: 0.897959\n",
      "epoch 5, iter 124, loss: 33.504576, acc: 0.836735\n",
      "epoch 5, iter 125, loss: 34.229683, acc: 0.857143\n",
      "epoch 5, iter 126, loss: 33.966688, acc: 0.897959\n",
      "epoch 5, iter 127, loss: 37.165959, acc: 0.673469\n",
      "epoch 5, iter 128, loss: 34.933337, acc: 0.959184\n",
      "epoch 5, iter 129, loss: 33.679823, acc: 0.897959\n",
      "epoch 5, iter 130, loss: 32.334705, acc: 0.918367\n",
      "epoch 5, iter 131, loss: 31.341648, acc: 0.877551\n",
      "epoch 5, iter 132, loss: 31.420974, acc: 0.836735\n",
      "epoch 5, iter 133, loss: 29.755693, acc: 0.918367\n",
      "epoch 5, iter 134, loss: 33.324326, acc: 0.612245\n",
      "epoch 5, iter 135, loss: 34.831347, acc: 0.795918\n",
      "epoch 5, iter 136, loss: 34.088000, acc: 0.836735\n",
      "epoch 5, iter 137, loss: 36.172174, acc: 0.918367\n",
      "epoch 5, iter 138, loss: 35.921629, acc: 0.857143\n",
      "epoch 5, iter 139, loss: 34.570469, acc: 0.857143\n",
      "epoch 5, iter 140, loss: 34.253145, acc: 0.816327\n",
      "epoch 5, iter 141, loss: 33.203807, acc: 0.816327\n",
      "epoch 5, iter 142, loss: 33.500713, acc: 0.795918\n",
      "epoch 5, iter 143, loss: 32.578659, acc: 0.877551\n",
      "epoch 5, iter 144, loss: 32.746267, acc: 0.755102\n",
      "epoch 5, iter 145, loss: 31.658779, acc: 0.918367\n",
      "epoch 5, iter 146, loss: 30.632600, acc: 0.857143\n",
      "epoch 5, iter 147, loss: 30.934293, acc: 0.816327\n",
      "epoch 5, iter 148, loss: 30.723307, acc: 0.938776\n",
      "epoch 5, iter 149, loss: 29.295578, acc: 0.938776\n",
      "epoch 5, iter 150, loss: 29.956320, acc: 0.857143\n",
      "epoch 5, iter 151, loss: 30.018685, acc: 0.877551\n",
      "epoch 5, iter 152, loss: 30.667842, acc: 0.836735\n",
      "epoch 5, iter 153, loss: 32.582080, acc: 0.693878\n",
      "epoch 5, iter 154, loss: 33.649179, acc: 0.734694\n",
      "epoch 5, iter 155, loss: 33.479240, acc: 0.836735\n",
      "epoch 5, iter 156, loss: 31.884433, acc: 0.857143\n",
      "epoch 5, iter 157, loss: 32.083746, acc: 0.836735\n",
      "epoch 5, iter 158, loss: 30.627835, acc: 0.897959\n",
      "epoch 5, iter 159, loss: 34.507581, acc: 0.755102\n",
      "epoch 5, iter 160, loss: 36.050266, acc: 0.653061\n",
      "epoch 5, iter 161, loss: 34.515316, acc: 0.775510\n",
      "epoch 5, iter 162, loss: 33.979203, acc: 0.836735\n",
      "epoch 5, iter 163, loss: 33.000177, acc: 0.877551\n",
      "epoch 5, iter 164, loss: 34.372301, acc: 0.714286\n",
      "epoch 5, iter 165, loss: 32.795254, acc: 0.918367\n",
      "epoch 5, iter 166, loss: 31.835971, acc: 0.857143\n",
      "epoch 5, iter 167, loss: 33.837549, acc: 0.734694\n",
      "epoch 5, iter 168, loss: 32.331701, acc: 0.857143\n",
      "epoch 5, iter 169, loss: 31.535997, acc: 0.836735\n",
      "epoch 5, iter 170, loss: 36.496871, acc: 0.775510\n",
      "epoch 5, iter 171, loss: 36.388363, acc: 0.816327\n",
      "epoch 5, iter 172, loss: 36.088670, acc: 0.816327\n",
      "epoch 5, iter 173, loss: 34.449676, acc: 0.816327\n",
      "epoch 5, iter 174, loss: 34.958398, acc: 0.795918\n",
      "epoch 5, iter 175, loss: 33.363034, acc: 0.857143\n",
      "epoch 5, iter 176, loss: 31.650717, acc: 0.857143\n",
      "epoch 5, iter 177, loss: 30.656984, acc: 0.857143\n",
      "epoch 5, iter 178, loss: 31.064327, acc: 0.775510\n",
      "epoch 5, iter 179, loss: 30.727768, acc: 0.857143\n",
      "epoch 5, iter 180, loss: 29.959264, acc: 0.857143\n",
      "epoch 5, iter 181, loss: 32.593122, acc: 0.734694\n",
      "epoch 5, iter 182, loss: 32.301443, acc: 0.816327\n",
      "epoch 5, iter 183, loss: 35.440437, acc: 0.653061\n",
      "epoch 5, iter 184, loss: 34.335087, acc: 0.836735\n",
      "epoch 5, iter 185, loss: 34.550146, acc: 0.857143\n",
      "epoch 5, iter 186, loss: 33.562461, acc: 0.938776\n",
      "epoch 5, iter 187, loss: 34.916346, acc: 0.714286\n",
      "epoch 5, iter 188, loss: 37.857935, acc: 0.795918\n",
      "epoch 5, iter 189, loss: 38.057250, acc: 0.816327\n",
      "epoch 5, iter 190, loss: 37.772587, acc: 0.775510\n",
      "epoch 5, iter 191, loss: 36.023008, acc: 0.959184\n",
      "epoch 5, iter 192, loss: 34.059622, acc: 0.836735\n",
      "epoch 5, iter 193, loss: 36.694087, acc: 0.775510\n",
      "epoch 5, iter 194, loss: 36.412513, acc: 0.775510\n",
      "epoch 5, iter 195, loss: 35.683427, acc: 0.816327\n",
      "epoch 5, iter 196, loss: 33.493244, acc: 0.897959\n",
      "epoch 5, iter 197, loss: 32.785405, acc: 0.795918\n",
      "epoch 5, iter 198, loss: 33.640725, acc: 0.775510\n",
      "epoch 5, iter 199, loss: 33.058687, acc: 0.857143\n",
      "epoch 5, iter 200, loss: 32.295960, acc: 0.857143\n",
      "epoch 5, iter 201, loss: 35.668590, acc: 0.857143\n",
      "epoch 5, iter 202, loss: 34.459233, acc: 0.857143\n",
      "epoch 5, iter 203, loss: 36.396195, acc: 0.714286\n",
      "epoch 5, iter 204, loss: 35.089562, acc: 0.816327\n",
      "epoch 5, iter 205, loss: 38.757655, acc: 0.673469\n",
      "epoch 5, iter 206, loss: 37.966156, acc: 0.836735\n",
      "epoch 5, iter 207, loss: 35.618756, acc: 0.857143\n",
      "epoch 5, iter 208, loss: 34.038598, acc: 0.795918\n",
      "epoch 5, iter 209, loss: 32.369958, acc: 0.938776\n",
      "epoch 5, iter 210, loss: 32.587090, acc: 0.795918\n",
      "epoch 5, iter 211, loss: 32.000203, acc: 0.816327\n",
      "epoch 5, iter 212, loss: 33.925942, acc: 0.693878\n",
      "epoch 5, iter 213, loss: 32.458579, acc: 0.836735\n",
      "epoch 5, iter 214, loss: 30.694716, acc: 0.877551\n",
      "epoch 5, iter 215, loss: 32.509630, acc: 0.775510\n",
      "epoch 5, iter 216, loss: 32.242801, acc: 0.816327\n",
      "epoch 5, iter 217, loss: 34.653089, acc: 0.775510\n",
      "epoch 5, iter 218, loss: 33.395070, acc: 0.897959\n",
      "epoch 5, iter 219, loss: 31.868751, acc: 0.918367\n",
      "epoch 5, iter 220, loss: 33.782201, acc: 0.734694\n",
      "epoch 5, iter 221, loss: 32.870220, acc: 0.877551\n",
      "epoch 5, iter 222, loss: 34.879331, acc: 0.775510\n",
      "epoch 5, iter 223, loss: 32.199945, acc: 0.959184\n",
      "epoch 5, iter 224, loss: 32.752809, acc: 0.836735\n",
      "epoch 5, iter 225, loss: 33.432843, acc: 0.857143\n",
      "epoch 5, iter 226, loss: 34.043063, acc: 0.795918\n",
      "epoch 5, iter 227, loss: 32.378585, acc: 0.897959\n",
      "epoch 5, iter 228, loss: 32.449853, acc: 0.857143\n",
      "epoch 5, iter 229, loss: 30.314379, acc: 0.836735\n",
      "epoch 5, iter 230, loss: 30.602889, acc: 0.857143\n",
      "epoch 5, iter 231, loss: 29.422655, acc: 0.897959\n",
      "epoch 5, iter 232, loss: 30.303914, acc: 0.816327\n",
      "epoch 5, iter 233, loss: 32.668724, acc: 0.734694\n",
      "epoch 5, iter 234, loss: 31.059255, acc: 0.918367\n",
      "epoch 5, iter 235, loss: 31.434768, acc: 0.775510\n",
      "epoch 5, iter 236, loss: 28.937263, acc: 0.959184\n",
      "epoch 5, iter 237, loss: 33.298245, acc: 0.693878\n",
      "epoch 5, iter 238, loss: 35.527659, acc: 0.775510\n",
      "epoch 5, iter 239, loss: 35.274008, acc: 0.775510\n",
      "epoch 5, iter 240, loss: 34.073685, acc: 0.897959\n",
      "epoch 5, iter 241, loss: 32.764955, acc: 0.836735\n",
      "epoch 5, iter 242, loss: 33.170466, acc: 0.816327\n",
      "epoch 5, iter 243, loss: 32.099050, acc: 0.857143\n",
      "epoch 5, iter 244, loss: 31.538264, acc: 0.795918\n",
      "epoch 5, iter 245, loss: 31.902192, acc: 0.734694\n",
      "epoch 5, iter 246, loss: 35.436143, acc: 0.714286\n",
      "epoch 5, iter 247, loss: 35.451515, acc: 0.836735\n",
      "epoch 5, iter 248, loss: 39.533942, acc: 0.714286\n",
      "epoch 5, iter 249, loss: 39.218123, acc: 0.775510\n",
      "epoch 5, acc: 0.827673\n",
      "epoch 6, iter 0, loss: 40.104728, acc: 0.714286\n",
      "epoch 6, iter 1, loss: 39.310520, acc: 0.795918\n",
      "epoch 6, iter 2, loss: 40.077814, acc: 0.734694\n",
      "epoch 6, iter 3, loss: 38.012232, acc: 0.857143\n",
      "epoch 6, iter 4, loss: 36.899607, acc: 0.816327\n",
      "epoch 6, iter 5, loss: 34.075639, acc: 0.857143\n",
      "epoch 6, iter 6, loss: 33.029803, acc: 0.897959\n",
      "epoch 6, iter 7, loss: 34.393015, acc: 0.734694\n",
      "epoch 6, iter 8, loss: 34.068376, acc: 0.775510\n",
      "epoch 6, iter 9, loss: 34.707759, acc: 0.795918\n",
      "epoch 6, iter 10, loss: 34.085069, acc: 0.775510\n",
      "epoch 6, iter 11, loss: 35.276986, acc: 0.714286\n",
      "epoch 6, iter 12, loss: 34.000645, acc: 0.877551\n",
      "epoch 6, iter 13, loss: 32.789254, acc: 0.857143\n",
      "epoch 6, iter 14, loss: 31.997971, acc: 0.857143\n",
      "epoch 6, iter 15, loss: 30.561604, acc: 0.938776\n",
      "epoch 6, iter 16, loss: 31.344023, acc: 0.836735\n",
      "epoch 6, iter 17, loss: 30.349525, acc: 0.897959\n",
      "epoch 6, iter 18, loss: 34.068425, acc: 0.693878\n",
      "epoch 6, iter 19, loss: 33.013297, acc: 0.938776\n",
      "epoch 6, iter 20, loss: 30.034201, acc: 0.938776\n",
      "epoch 6, iter 21, loss: 28.850514, acc: 0.897959\n",
      "epoch 6, iter 22, loss: 27.538489, acc: 0.877551\n",
      "epoch 6, iter 23, loss: 30.835592, acc: 0.755102\n",
      "epoch 6, iter 24, loss: 30.232120, acc: 0.836735\n",
      "epoch 6, iter 25, loss: 32.136804, acc: 0.734694\n",
      "epoch 6, iter 26, loss: 33.781874, acc: 0.816327\n",
      "epoch 6, iter 27, loss: 34.089555, acc: 0.795918\n",
      "epoch 6, iter 28, loss: 32.594471, acc: 0.877551\n",
      "epoch 6, iter 29, loss: 30.278869, acc: 0.857143\n",
      "epoch 6, iter 30, loss: 32.441219, acc: 0.693878\n",
      "epoch 6, iter 31, loss: 36.574011, acc: 0.673469\n",
      "epoch 6, iter 32, loss: 34.580400, acc: 0.857143\n",
      "epoch 6, iter 33, loss: 32.721651, acc: 0.836735\n",
      "epoch 6, iter 34, loss: 32.985122, acc: 0.755102\n",
      "epoch 6, iter 35, loss: 34.320737, acc: 0.755102\n",
      "epoch 6, iter 36, loss: 34.365616, acc: 0.857143\n",
      "epoch 6, iter 37, loss: 31.917472, acc: 0.877551\n",
      "epoch 6, iter 38, loss: 33.239807, acc: 0.795918\n",
      "epoch 6, iter 39, loss: 32.939212, acc: 0.816327\n",
      "epoch 6, iter 40, loss: 34.978065, acc: 0.755102\n",
      "epoch 6, iter 41, loss: 33.780152, acc: 0.877551\n",
      "epoch 6, iter 42, loss: 36.290682, acc: 0.673469\n",
      "epoch 6, iter 43, loss: 35.328152, acc: 0.918367\n",
      "epoch 6, iter 44, loss: 32.398672, acc: 0.918367\n",
      "epoch 6, iter 45, loss: 32.817925, acc: 0.795918\n",
      "epoch 6, iter 46, loss: 33.068212, acc: 0.836735\n",
      "epoch 6, iter 47, loss: 32.189409, acc: 0.836735\n",
      "epoch 6, iter 48, loss: 33.182031, acc: 0.775510\n",
      "epoch 6, iter 49, loss: 32.486721, acc: 0.877551\n",
      "epoch 6, iter 50, loss: 32.899482, acc: 0.795918\n",
      "epoch 6, iter 51, loss: 34.300659, acc: 0.734694\n",
      "epoch 6, iter 52, loss: 33.539836, acc: 0.877551\n",
      "epoch 6, iter 53, loss: 34.156326, acc: 0.775510\n",
      "epoch 6, iter 54, loss: 33.887569, acc: 0.795918\n",
      "epoch 6, iter 55, loss: 33.021529, acc: 0.897959\n",
      "epoch 6, iter 56, loss: 31.954850, acc: 0.857143\n",
      "epoch 6, iter 57, loss: 30.502712, acc: 0.857143\n",
      "epoch 6, iter 58, loss: 31.952989, acc: 0.775510\n",
      "epoch 6, iter 59, loss: 31.720030, acc: 0.836735\n",
      "epoch 6, iter 60, loss: 30.347750, acc: 0.938776\n",
      "epoch 6, iter 61, loss: 32.673917, acc: 0.836735\n",
      "epoch 6, iter 62, loss: 31.461412, acc: 0.897959\n",
      "epoch 6, iter 63, loss: 30.090261, acc: 0.877551\n",
      "epoch 6, iter 64, loss: 32.521642, acc: 0.693878\n",
      "epoch 6, iter 65, loss: 31.029786, acc: 0.897959\n",
      "epoch 6, iter 66, loss: 29.576228, acc: 0.918367\n",
      "epoch 6, iter 67, loss: 31.916200, acc: 0.755102\n",
      "epoch 6, iter 68, loss: 30.827850, acc: 0.816327\n",
      "epoch 6, iter 69, loss: 28.910163, acc: 0.897959\n",
      "epoch 6, iter 70, loss: 28.300338, acc: 0.857143\n",
      "epoch 6, iter 71, loss: 30.896072, acc: 0.795918\n",
      "epoch 6, iter 72, loss: 29.784472, acc: 0.877551\n",
      "epoch 6, iter 73, loss: 27.732140, acc: 0.938776\n",
      "epoch 6, iter 74, loss: 26.854938, acc: 0.857143\n",
      "epoch 6, iter 75, loss: 26.083749, acc: 0.877551\n",
      "epoch 6, iter 76, loss: 28.962656, acc: 0.734694\n",
      "epoch 6, iter 77, loss: 31.980336, acc: 0.673469\n",
      "epoch 6, iter 78, loss: 32.875545, acc: 0.795918\n",
      "epoch 6, iter 79, loss: 31.475102, acc: 0.877551\n",
      "epoch 6, iter 80, loss: 30.142317, acc: 0.897959\n",
      "epoch 6, iter 81, loss: 31.001545, acc: 0.795918\n",
      "epoch 6, iter 82, loss: 30.406180, acc: 0.795918\n",
      "epoch 6, iter 83, loss: 32.547765, acc: 0.755102\n",
      "epoch 6, iter 84, loss: 30.323466, acc: 0.897959\n",
      "epoch 6, iter 85, loss: 28.257986, acc: 0.918367\n",
      "epoch 6, iter 86, loss: 30.870275, acc: 0.693878\n",
      "epoch 6, iter 87, loss: 33.680755, acc: 0.714286\n",
      "epoch 6, iter 88, loss: 32.967660, acc: 0.816327\n",
      "epoch 6, iter 89, loss: 32.046278, acc: 0.857143\n",
      "epoch 6, iter 90, loss: 33.414133, acc: 0.755102\n",
      "epoch 6, iter 91, loss: 34.381028, acc: 0.836735\n",
      "epoch 6, iter 92, loss: 35.513765, acc: 0.775510\n",
      "epoch 6, iter 93, loss: 35.934133, acc: 0.755102\n",
      "epoch 6, iter 94, loss: 34.660525, acc: 0.897959\n",
      "epoch 6, iter 95, loss: 32.474999, acc: 0.938776\n",
      "epoch 6, iter 96, loss: 32.490675, acc: 0.795918\n",
      "epoch 6, iter 97, loss: 32.595848, acc: 0.836735\n",
      "epoch 6, iter 98, loss: 32.050940, acc: 0.816327\n",
      "epoch 6, iter 99, loss: 30.557494, acc: 0.897959\n",
      "epoch 6, iter 100, loss: 35.597245, acc: 0.551020\n",
      "epoch 6, iter 101, loss: 34.378024, acc: 0.816327\n",
      "epoch 6, iter 102, loss: 32.019447, acc: 0.938776\n",
      "epoch 6, iter 103, loss: 31.057414, acc: 0.918367\n",
      "epoch 6, iter 104, loss: 32.029359, acc: 0.755102\n",
      "epoch 6, iter 105, loss: 31.448850, acc: 0.836735\n",
      "epoch 6, iter 106, loss: 31.089262, acc: 0.816327\n",
      "epoch 6, iter 107, loss: 28.411825, acc: 0.938776\n",
      "epoch 6, iter 108, loss: 30.564413, acc: 0.734694\n",
      "epoch 6, iter 109, loss: 32.002960, acc: 0.673469\n",
      "epoch 6, iter 110, loss: 31.464366, acc: 0.816327\n",
      "epoch 6, iter 111, loss: 35.808225, acc: 0.632653\n",
      "epoch 6, iter 112, loss: 35.497248, acc: 0.897959\n",
      "epoch 6, iter 113, loss: 38.094853, acc: 0.653061\n",
      "epoch 6, iter 114, loss: 35.629545, acc: 0.857143\n",
      "epoch 6, iter 115, loss: 36.103923, acc: 0.897959\n",
      "epoch 6, iter 116, loss: 38.039668, acc: 0.714286\n",
      "epoch 6, iter 117, loss: 34.591686, acc: 0.897959\n",
      "epoch 6, iter 118, loss: 36.673271, acc: 0.673469\n",
      "epoch 6, iter 119, loss: 33.361544, acc: 0.938776\n",
      "epoch 6, iter 120, loss: 34.840349, acc: 0.693878\n",
      "epoch 6, iter 121, loss: 32.836036, acc: 0.836735\n",
      "epoch 6, iter 122, loss: 32.891952, acc: 0.775510\n",
      "epoch 6, iter 123, loss: 31.991551, acc: 0.897959\n",
      "epoch 6, iter 124, loss: 32.874902, acc: 0.836735\n",
      "epoch 6, iter 125, loss: 34.387003, acc: 0.775510\n",
      "epoch 6, iter 126, loss: 33.292462, acc: 0.918367\n",
      "epoch 6, iter 127, loss: 37.433499, acc: 0.591837\n",
      "epoch 6, iter 128, loss: 34.619575, acc: 0.918367\n",
      "epoch 6, iter 129, loss: 33.490261, acc: 0.877551\n",
      "epoch 6, iter 130, loss: 31.692370, acc: 0.918367\n",
      "epoch 6, iter 131, loss: 31.018941, acc: 0.836735\n",
      "epoch 6, iter 132, loss: 31.112493, acc: 0.816327\n",
      "epoch 6, iter 133, loss: 29.337881, acc: 0.918367\n",
      "epoch 6, iter 134, loss: 33.084748, acc: 0.591837\n",
      "epoch 6, iter 135, loss: 34.672593, acc: 0.755102\n",
      "epoch 6, iter 136, loss: 34.537628, acc: 0.795918\n",
      "epoch 6, iter 137, loss: 34.950172, acc: 0.959184\n",
      "epoch 6, iter 138, loss: 34.623567, acc: 0.877551\n",
      "epoch 6, iter 139, loss: 33.600163, acc: 0.897959\n",
      "epoch 6, iter 140, loss: 33.852080, acc: 0.836735\n",
      "epoch 6, iter 141, loss: 32.539836, acc: 0.857143\n",
      "epoch 6, iter 142, loss: 33.101441, acc: 0.775510\n",
      "epoch 6, iter 143, loss: 31.952226, acc: 0.877551\n",
      "epoch 6, iter 144, loss: 32.469379, acc: 0.714286\n",
      "epoch 6, iter 145, loss: 31.385527, acc: 0.918367\n",
      "epoch 6, iter 146, loss: 30.539424, acc: 0.836735\n",
      "epoch 6, iter 147, loss: 30.695203, acc: 0.816327\n",
      "epoch 6, iter 148, loss: 30.432123, acc: 0.897959\n",
      "epoch 6, iter 149, loss: 28.906863, acc: 0.938776\n",
      "epoch 6, iter 150, loss: 29.695522, acc: 0.816327\n",
      "epoch 6, iter 151, loss: 29.795679, acc: 0.857143\n",
      "epoch 6, iter 152, loss: 30.041340, acc: 0.836735\n",
      "epoch 6, iter 153, loss: 32.215655, acc: 0.673469\n",
      "epoch 6, iter 154, loss: 33.343728, acc: 0.714286\n",
      "epoch 6, iter 155, loss: 32.868898, acc: 0.816327\n",
      "epoch 6, iter 156, loss: 31.334893, acc: 0.816327\n",
      "epoch 6, iter 157, loss: 32.061233, acc: 0.795918\n",
      "epoch 6, iter 158, loss: 30.554693, acc: 0.897959\n",
      "epoch 6, iter 159, loss: 34.123744, acc: 0.755102\n",
      "epoch 6, iter 160, loss: 35.549022, acc: 0.755102\n",
      "epoch 6, iter 161, loss: 33.687777, acc: 0.836735\n",
      "epoch 6, iter 162, loss: 33.301213, acc: 0.816327\n",
      "epoch 6, iter 163, loss: 32.787294, acc: 0.877551\n",
      "epoch 6, iter 164, loss: 33.954365, acc: 0.755102\n",
      "epoch 6, iter 165, loss: 32.760476, acc: 0.877551\n",
      "epoch 6, iter 166, loss: 31.756507, acc: 0.836735\n",
      "epoch 6, iter 167, loss: 33.489151, acc: 0.755102\n",
      "epoch 6, iter 168, loss: 32.176541, acc: 0.836735\n",
      "epoch 6, iter 169, loss: 31.717233, acc: 0.775510\n",
      "epoch 6, iter 170, loss: 39.129274, acc: 0.693878\n",
      "epoch 6, iter 171, loss: 38.529642, acc: 0.795918\n",
      "epoch 6, iter 172, loss: 37.451595, acc: 0.775510\n",
      "epoch 6, iter 173, loss: 35.445724, acc: 0.795918\n",
      "epoch 6, iter 174, loss: 35.605279, acc: 0.795918\n",
      "epoch 6, iter 175, loss: 33.792748, acc: 0.857143\n",
      "epoch 6, iter 176, loss: 31.798419, acc: 0.897959\n",
      "epoch 6, iter 177, loss: 30.692488, acc: 0.877551\n",
      "epoch 6, iter 178, loss: 31.111690, acc: 0.775510\n",
      "epoch 6, iter 179, loss: 30.629886, acc: 0.816327\n",
      "epoch 6, iter 180, loss: 29.309423, acc: 0.836735\n",
      "epoch 6, iter 181, loss: 31.781218, acc: 0.734694\n",
      "epoch 6, iter 182, loss: 31.753807, acc: 0.795918\n",
      "epoch 6, iter 183, loss: 34.856665, acc: 0.653061\n",
      "epoch 6, iter 184, loss: 33.915094, acc: 0.836735\n",
      "epoch 6, iter 185, loss: 34.418743, acc: 0.795918\n",
      "epoch 6, iter 186, loss: 32.847109, acc: 0.938776\n",
      "epoch 6, iter 187, loss: 34.616961, acc: 0.714286\n",
      "epoch 6, iter 188, loss: 37.885144, acc: 0.673469\n",
      "epoch 6, iter 189, loss: 37.162369, acc: 0.857143\n",
      "epoch 6, iter 190, loss: 36.543714, acc: 0.734694\n",
      "epoch 6, iter 191, loss: 35.449144, acc: 0.938776\n",
      "epoch 6, iter 192, loss: 33.692314, acc: 0.857143\n",
      "epoch 6, iter 193, loss: 35.836940, acc: 0.755102\n",
      "epoch 6, iter 194, loss: 35.814278, acc: 0.775510\n",
      "epoch 6, iter 195, loss: 35.834313, acc: 0.795918\n",
      "epoch 6, iter 196, loss: 32.908339, acc: 0.897959\n",
      "epoch 6, iter 197, loss: 32.564759, acc: 0.775510\n",
      "epoch 6, iter 198, loss: 33.135281, acc: 0.795918\n",
      "epoch 6, iter 199, loss: 32.809755, acc: 0.775510\n",
      "epoch 6, iter 200, loss: 32.250839, acc: 0.836735\n",
      "epoch 6, iter 201, loss: 34.516833, acc: 0.836735\n",
      "epoch 6, iter 202, loss: 33.438926, acc: 0.857143\n",
      "epoch 6, iter 203, loss: 35.405509, acc: 0.755102\n",
      "epoch 6, iter 204, loss: 34.480745, acc: 0.816327\n",
      "epoch 6, iter 205, loss: 38.219741, acc: 0.714286\n",
      "epoch 6, iter 206, loss: 37.470852, acc: 0.836735\n",
      "epoch 6, iter 207, loss: 35.404998, acc: 0.857143\n",
      "epoch 6, iter 208, loss: 33.966593, acc: 0.795918\n",
      "epoch 6, iter 209, loss: 32.138199, acc: 0.918367\n",
      "epoch 6, iter 210, loss: 32.420779, acc: 0.775510\n",
      "epoch 6, iter 211, loss: 31.488505, acc: 0.816327\n",
      "epoch 6, iter 212, loss: 33.044637, acc: 0.693878\n",
      "epoch 6, iter 213, loss: 31.531296, acc: 0.857143\n",
      "epoch 6, iter 214, loss: 29.961322, acc: 0.877551\n",
      "epoch 6, iter 215, loss: 32.032927, acc: 0.775510\n",
      "epoch 6, iter 216, loss: 31.746006, acc: 0.795918\n",
      "epoch 6, iter 217, loss: 34.315029, acc: 0.775510\n",
      "epoch 6, iter 218, loss: 32.716919, acc: 0.897959\n",
      "epoch 6, iter 219, loss: 31.158178, acc: 0.897959\n",
      "epoch 6, iter 220, loss: 33.365475, acc: 0.714286\n",
      "epoch 6, iter 221, loss: 32.442974, acc: 0.836735\n",
      "epoch 6, iter 222, loss: 34.698214, acc: 0.755102\n",
      "epoch 6, iter 223, loss: 31.765480, acc: 0.938776\n",
      "epoch 6, iter 224, loss: 32.120313, acc: 0.795918\n",
      "epoch 6, iter 225, loss: 32.827161, acc: 0.816327\n",
      "epoch 6, iter 226, loss: 33.614801, acc: 0.795918\n",
      "epoch 6, iter 227, loss: 32.074203, acc: 0.857143\n",
      "epoch 6, iter 228, loss: 32.171565, acc: 0.836735\n",
      "epoch 6, iter 229, loss: 29.776078, acc: 0.857143\n",
      "epoch 6, iter 230, loss: 30.333307, acc: 0.836735\n",
      "epoch 6, iter 231, loss: 29.063019, acc: 0.897959\n",
      "epoch 6, iter 232, loss: 30.072268, acc: 0.816327\n",
      "epoch 6, iter 233, loss: 32.276052, acc: 0.714286\n",
      "epoch 6, iter 234, loss: 30.652163, acc: 0.938776\n",
      "epoch 6, iter 235, loss: 31.017300, acc: 0.795918\n",
      "epoch 6, iter 236, loss: 28.521320, acc: 0.959184\n",
      "epoch 6, iter 237, loss: 32.761362, acc: 0.653061\n",
      "epoch 6, iter 238, loss: 35.285691, acc: 0.775510\n",
      "epoch 6, iter 239, loss: 34.827328, acc: 0.816327\n",
      "epoch 6, iter 240, loss: 33.819431, acc: 0.918367\n",
      "epoch 6, iter 241, loss: 32.588214, acc: 0.857143\n",
      "epoch 6, iter 242, loss: 33.094430, acc: 0.836735\n",
      "epoch 6, iter 243, loss: 31.966319, acc: 0.857143\n",
      "epoch 6, iter 244, loss: 31.307532, acc: 0.755102\n",
      "epoch 6, iter 245, loss: 32.093347, acc: 0.795918\n",
      "epoch 6, iter 246, loss: 35.072647, acc: 0.673469\n",
      "epoch 6, iter 247, loss: 35.205809, acc: 0.816327\n",
      "epoch 6, iter 248, loss: 38.556410, acc: 0.714286\n",
      "epoch 6, iter 249, loss: 38.839228, acc: 0.693878\n",
      "epoch 6, acc: 0.816653\n",
      "epoch 7, iter 0, loss: 39.302168, acc: 0.673469\n",
      "epoch 7, iter 1, loss: 39.787906, acc: 0.693878\n",
      "epoch 7, iter 2, loss: 38.986915, acc: 0.734694\n",
      "epoch 7, iter 3, loss: 37.361136, acc: 0.836735\n",
      "epoch 7, iter 4, loss: 36.136858, acc: 0.877551\n",
      "epoch 7, iter 5, loss: 33.748999, acc: 0.897959\n",
      "epoch 7, iter 6, loss: 32.616044, acc: 0.918367\n",
      "epoch 7, iter 7, loss: 34.452330, acc: 0.632653\n",
      "epoch 7, iter 8, loss: 34.668971, acc: 0.795918\n",
      "epoch 7, iter 9, loss: 34.682323, acc: 0.795918\n",
      "epoch 7, iter 10, loss: 34.043764, acc: 0.755102\n",
      "epoch 7, iter 11, loss: 35.274967, acc: 0.632653\n",
      "epoch 7, iter 12, loss: 33.674423, acc: 0.877551\n",
      "epoch 7, iter 13, loss: 32.449496, acc: 0.816327\n",
      "epoch 7, iter 14, loss: 31.519590, acc: 0.877551\n",
      "epoch 7, iter 15, loss: 29.835827, acc: 0.959184\n",
      "epoch 7, iter 16, loss: 30.955877, acc: 0.795918\n",
      "epoch 7, iter 17, loss: 30.026460, acc: 0.857143\n",
      "epoch 7, iter 18, loss: 33.887320, acc: 0.693878\n",
      "epoch 7, iter 19, loss: 32.275985, acc: 0.918367\n",
      "epoch 7, iter 20, loss: 29.278509, acc: 0.918367\n",
      "epoch 7, iter 21, loss: 28.329871, acc: 0.877551\n",
      "epoch 7, iter 22, loss: 26.992288, acc: 0.897959\n",
      "epoch 7, iter 23, loss: 30.521596, acc: 0.693878\n",
      "epoch 7, iter 24, loss: 29.985364, acc: 0.816327\n",
      "epoch 7, iter 25, loss: 32.040824, acc: 0.734694\n",
      "epoch 7, iter 26, loss: 33.430518, acc: 0.795918\n",
      "epoch 7, iter 27, loss: 34.311802, acc: 0.734694\n",
      "epoch 7, iter 28, loss: 32.692974, acc: 0.836735\n",
      "epoch 7, iter 29, loss: 30.200043, acc: 0.857143\n",
      "epoch 7, iter 30, loss: 32.447746, acc: 0.693878\n",
      "epoch 7, iter 31, loss: 36.488144, acc: 0.673469\n",
      "epoch 7, iter 32, loss: 34.358256, acc: 0.857143\n",
      "epoch 7, iter 33, loss: 32.310079, acc: 0.857143\n",
      "epoch 7, iter 34, loss: 32.666755, acc: 0.734694\n",
      "epoch 7, iter 35, loss: 34.154195, acc: 0.775510\n",
      "epoch 7, iter 36, loss: 34.536412, acc: 0.836735\n",
      "epoch 7, iter 37, loss: 31.642064, acc: 0.877551\n",
      "epoch 7, iter 38, loss: 32.869912, acc: 0.755102\n",
      "epoch 7, iter 39, loss: 32.522279, acc: 0.795918\n",
      "epoch 7, iter 40, loss: 34.662886, acc: 0.775510\n",
      "epoch 7, iter 41, loss: 33.366639, acc: 0.857143\n",
      "epoch 7, iter 42, loss: 36.125878, acc: 0.714286\n",
      "epoch 7, iter 43, loss: 34.699994, acc: 0.938776\n",
      "epoch 7, iter 44, loss: 31.377163, acc: 0.918367\n",
      "epoch 7, iter 45, loss: 31.990501, acc: 0.775510\n",
      "epoch 7, iter 46, loss: 32.369962, acc: 0.816327\n",
      "epoch 7, iter 47, loss: 31.816436, acc: 0.836735\n",
      "epoch 7, iter 48, loss: 33.770331, acc: 0.795918\n",
      "epoch 7, iter 49, loss: 32.728962, acc: 0.897959\n",
      "epoch 7, iter 50, loss: 32.870172, acc: 0.816327\n",
      "epoch 7, iter 51, loss: 34.264926, acc: 0.734694\n",
      "epoch 7, iter 52, loss: 33.527351, acc: 0.877551\n",
      "epoch 7, iter 53, loss: 34.162285, acc: 0.775510\n",
      "epoch 7, iter 54, loss: 33.773282, acc: 0.755102\n",
      "epoch 7, iter 55, loss: 32.978312, acc: 0.857143\n",
      "epoch 7, iter 56, loss: 31.711163, acc: 0.857143\n",
      "epoch 7, iter 57, loss: 30.248552, acc: 0.877551\n",
      "epoch 7, iter 58, loss: 31.785328, acc: 0.734694\n",
      "epoch 7, iter 59, loss: 31.496265, acc: 0.816327\n",
      "epoch 7, iter 60, loss: 30.499276, acc: 0.959184\n",
      "epoch 7, iter 61, loss: 31.402351, acc: 0.836735\n",
      "epoch 7, iter 62, loss: 30.813904, acc: 0.877551\n",
      "epoch 7, iter 63, loss: 29.757733, acc: 0.897959\n",
      "epoch 7, iter 64, loss: 32.606565, acc: 0.612245\n",
      "epoch 7, iter 65, loss: 31.271764, acc: 0.836735\n",
      "epoch 7, iter 66, loss: 29.566377, acc: 0.918367\n",
      "epoch 7, iter 67, loss: 31.974599, acc: 0.734694\n",
      "epoch 7, iter 68, loss: 30.989003, acc: 0.816327\n",
      "epoch 7, iter 69, loss: 28.808081, acc: 0.897959\n",
      "epoch 7, iter 70, loss: 28.076361, acc: 0.877551\n",
      "epoch 7, iter 71, loss: 30.895518, acc: 0.795918\n",
      "epoch 7, iter 72, loss: 29.787672, acc: 0.857143\n",
      "epoch 7, iter 73, loss: 27.615518, acc: 0.938776\n",
      "epoch 7, iter 74, loss: 26.703814, acc: 0.857143\n",
      "epoch 7, iter 75, loss: 25.795774, acc: 0.877551\n",
      "epoch 7, iter 76, loss: 28.629363, acc: 0.734694\n",
      "epoch 7, iter 77, loss: 31.776480, acc: 0.653061\n",
      "epoch 7, iter 78, loss: 32.666120, acc: 0.816327\n",
      "epoch 7, iter 79, loss: 31.096946, acc: 0.877551\n",
      "epoch 7, iter 80, loss: 29.596441, acc: 0.877551\n",
      "epoch 7, iter 81, loss: 30.631354, acc: 0.795918\n",
      "epoch 7, iter 82, loss: 30.251154, acc: 0.795918\n",
      "epoch 7, iter 83, loss: 32.213243, acc: 0.755102\n",
      "epoch 7, iter 84, loss: 29.976961, acc: 0.897959\n",
      "epoch 7, iter 85, loss: 27.848895, acc: 0.897959\n",
      "epoch 7, iter 86, loss: 30.538766, acc: 0.693878\n",
      "epoch 7, iter 87, loss: 33.564014, acc: 0.673469\n",
      "epoch 7, iter 88, loss: 32.639559, acc: 0.857143\n",
      "epoch 7, iter 89, loss: 31.952272, acc: 0.857143\n",
      "epoch 7, iter 90, loss: 33.350968, acc: 0.734694\n",
      "epoch 7, iter 91, loss: 33.825894, acc: 0.816327\n",
      "epoch 7, iter 92, loss: 35.249952, acc: 0.755102\n",
      "epoch 7, iter 93, loss: 35.650924, acc: 0.734694\n",
      "epoch 7, iter 94, loss: 34.026678, acc: 0.877551\n",
      "epoch 7, iter 95, loss: 31.712341, acc: 0.938776\n",
      "epoch 7, iter 96, loss: 32.158971, acc: 0.795918\n",
      "epoch 7, iter 97, loss: 32.218573, acc: 0.816327\n",
      "epoch 7, iter 98, loss: 32.043035, acc: 0.795918\n",
      "epoch 7, iter 99, loss: 30.460505, acc: 0.897959\n",
      "epoch 7, iter 100, loss: 35.344506, acc: 0.551020\n",
      "epoch 7, iter 101, loss: 34.139816, acc: 0.775510\n",
      "epoch 7, iter 102, loss: 31.682089, acc: 0.897959\n",
      "epoch 7, iter 103, loss: 30.667427, acc: 0.918367\n",
      "epoch 7, iter 104, loss: 31.765774, acc: 0.775510\n",
      "epoch 7, iter 105, loss: 31.177963, acc: 0.836735\n",
      "epoch 7, iter 106, loss: 30.717238, acc: 0.816327\n",
      "epoch 7, iter 107, loss: 28.102731, acc: 0.938776\n",
      "epoch 7, iter 108, loss: 30.108136, acc: 0.755102\n",
      "epoch 7, iter 109, loss: 31.687424, acc: 0.653061\n",
      "epoch 7, iter 110, loss: 31.175706, acc: 0.816327\n",
      "epoch 7, iter 111, loss: 35.524844, acc: 0.612245\n",
      "epoch 7, iter 112, loss: 35.374785, acc: 0.877551\n",
      "epoch 7, iter 113, loss: 37.699139, acc: 0.632653\n",
      "epoch 7, iter 114, loss: 35.196726, acc: 0.897959\n",
      "epoch 7, iter 115, loss: 36.062841, acc: 0.795918\n",
      "epoch 7, iter 116, loss: 38.281534, acc: 0.673469\n",
      "epoch 7, iter 117, loss: 34.907339, acc: 0.897959\n",
      "epoch 7, iter 118, loss: 37.130457, acc: 0.673469\n",
      "epoch 7, iter 119, loss: 33.849917, acc: 0.918367\n",
      "epoch 7, iter 120, loss: 35.096037, acc: 0.734694\n",
      "epoch 7, iter 121, loss: 32.510973, acc: 0.836735\n",
      "epoch 7, iter 122, loss: 32.288297, acc: 0.816327\n",
      "epoch 7, iter 123, loss: 31.369702, acc: 0.897959\n",
      "epoch 7, iter 124, loss: 32.400275, acc: 0.795918\n",
      "epoch 7, iter 125, loss: 34.691985, acc: 0.714286\n",
      "epoch 7, iter 126, loss: 32.759724, acc: 0.918367\n",
      "epoch 7, iter 127, loss: 37.489704, acc: 0.612245\n",
      "epoch 7, iter 128, loss: 34.569323, acc: 0.918367\n",
      "epoch 7, iter 129, loss: 33.147545, acc: 0.857143\n",
      "epoch 7, iter 130, loss: 31.346333, acc: 0.938776\n",
      "epoch 7, iter 131, loss: 30.768449, acc: 0.816327\n",
      "epoch 7, iter 132, loss: 31.242825, acc: 0.816327\n",
      "epoch 7, iter 133, loss: 29.261947, acc: 0.938776\n",
      "epoch 7, iter 134, loss: 32.995257, acc: 0.653061\n",
      "epoch 7, iter 135, loss: 34.531232, acc: 0.755102\n",
      "epoch 7, iter 136, loss: 34.270374, acc: 0.918367\n",
      "epoch 7, iter 137, loss: 36.032565, acc: 0.816327\n",
      "epoch 7, iter 138, loss: 35.325539, acc: 0.877551\n",
      "epoch 7, iter 139, loss: 34.218122, acc: 0.877551\n",
      "epoch 7, iter 140, loss: 33.625498, acc: 0.816327\n",
      "epoch 7, iter 141, loss: 32.461056, acc: 0.816327\n",
      "epoch 7, iter 142, loss: 32.840642, acc: 0.734694\n",
      "epoch 7, iter 143, loss: 31.829892, acc: 0.877551\n",
      "epoch 7, iter 144, loss: 32.314424, acc: 0.734694\n",
      "epoch 7, iter 145, loss: 31.041188, acc: 0.918367\n",
      "epoch 7, iter 146, loss: 30.344321, acc: 0.857143\n",
      "epoch 7, iter 147, loss: 30.549400, acc: 0.816327\n",
      "epoch 7, iter 148, loss: 30.194923, acc: 0.877551\n",
      "epoch 7, iter 149, loss: 28.512200, acc: 0.938776\n",
      "epoch 7, iter 150, loss: 29.423284, acc: 0.816327\n",
      "epoch 7, iter 151, loss: 29.583212, acc: 0.836735\n",
      "epoch 7, iter 152, loss: 29.758417, acc: 0.857143\n",
      "epoch 7, iter 153, loss: 32.056792, acc: 0.714286\n",
      "epoch 7, iter 154, loss: 33.168951, acc: 0.714286\n",
      "epoch 7, iter 155, loss: 32.557207, acc: 0.795918\n",
      "epoch 7, iter 156, loss: 31.013619, acc: 0.816327\n",
      "epoch 7, iter 157, loss: 31.789505, acc: 0.775510\n",
      "epoch 7, iter 158, loss: 30.242631, acc: 0.897959\n",
      "epoch 7, iter 159, loss: 33.871703, acc: 0.693878\n",
      "epoch 7, iter 160, loss: 35.489141, acc: 0.734694\n",
      "epoch 7, iter 161, loss: 33.267438, acc: 0.836735\n",
      "epoch 7, iter 162, loss: 32.841359, acc: 0.775510\n",
      "epoch 7, iter 163, loss: 32.600084, acc: 0.816327\n",
      "epoch 7, iter 164, loss: 33.839565, acc: 0.755102\n",
      "epoch 7, iter 165, loss: 32.065803, acc: 0.938776\n",
      "epoch 7, iter 166, loss: 31.298589, acc: 0.877551\n",
      "epoch 7, iter 167, loss: 33.021997, acc: 0.775510\n",
      "epoch 7, iter 168, loss: 31.935334, acc: 0.836735\n",
      "epoch 7, iter 169, loss: 32.013270, acc: 0.775510\n",
      "epoch 7, iter 170, loss: 37.068336, acc: 0.714286\n",
      "epoch 7, iter 171, loss: 36.887777, acc: 0.795918\n",
      "epoch 7, iter 172, loss: 36.175227, acc: 0.816327\n",
      "epoch 7, iter 173, loss: 34.725645, acc: 0.816327\n",
      "epoch 7, iter 174, loss: 35.080401, acc: 0.775510\n",
      "epoch 7, iter 175, loss: 33.550276, acc: 0.877551\n",
      "epoch 7, iter 176, loss: 31.715086, acc: 0.897959\n",
      "epoch 7, iter 177, loss: 30.553283, acc: 0.897959\n",
      "epoch 7, iter 178, loss: 31.249092, acc: 0.755102\n",
      "epoch 7, iter 179, loss: 30.499641, acc: 0.816327\n",
      "epoch 7, iter 180, loss: 29.137209, acc: 0.836735\n",
      "epoch 7, iter 181, loss: 31.589393, acc: 0.734694\n",
      "epoch 7, iter 182, loss: 31.622904, acc: 0.795918\n",
      "epoch 7, iter 183, loss: 34.706858, acc: 0.632653\n",
      "epoch 7, iter 184, loss: 33.837002, acc: 0.816327\n",
      "epoch 7, iter 185, loss: 34.561602, acc: 0.734694\n",
      "epoch 7, iter 186, loss: 32.509052, acc: 0.918367\n",
      "epoch 7, iter 187, loss: 34.521882, acc: 0.693878\n",
      "epoch 7, iter 188, loss: 37.645397, acc: 0.673469\n",
      "epoch 7, iter 189, loss: 37.246940, acc: 0.755102\n",
      "epoch 7, iter 190, loss: 36.454272, acc: 0.775510\n",
      "epoch 7, iter 191, loss: 34.361983, acc: 0.938776\n",
      "epoch 7, iter 192, loss: 32.934392, acc: 0.836735\n",
      "epoch 7, iter 193, loss: 35.181085, acc: 0.734694\n",
      "epoch 7, iter 194, loss: 34.719748, acc: 0.755102\n",
      "epoch 7, iter 195, loss: 34.411148, acc: 0.795918\n",
      "epoch 7, iter 196, loss: 32.282115, acc: 0.897959\n",
      "epoch 7, iter 197, loss: 32.178119, acc: 0.755102\n",
      "epoch 7, iter 198, loss: 32.977619, acc: 0.755102\n",
      "epoch 7, iter 199, loss: 32.782871, acc: 0.795918\n",
      "epoch 7, iter 200, loss: 32.091820, acc: 0.836735\n",
      "epoch 7, iter 201, loss: 33.925413, acc: 0.857143\n",
      "epoch 7, iter 202, loss: 32.665630, acc: 0.877551\n",
      "epoch 7, iter 203, loss: 34.434552, acc: 0.734694\n",
      "epoch 7, iter 204, loss: 33.754714, acc: 0.816327\n",
      "epoch 7, iter 205, loss: 38.293032, acc: 0.632653\n",
      "epoch 7, iter 206, loss: 37.244678, acc: 0.795918\n",
      "epoch 7, iter 207, loss: 35.188408, acc: 0.857143\n",
      "epoch 7, iter 208, loss: 33.793135, acc: 0.836735\n",
      "epoch 7, iter 209, loss: 32.011904, acc: 0.938776\n",
      "epoch 7, iter 210, loss: 32.414378, acc: 0.775510\n",
      "epoch 7, iter 211, loss: 31.255621, acc: 0.795918\n",
      "epoch 7, iter 212, loss: 32.764891, acc: 0.673469\n",
      "epoch 7, iter 213, loss: 31.081146, acc: 0.836735\n",
      "epoch 7, iter 214, loss: 29.575699, acc: 0.877551\n",
      "epoch 7, iter 215, loss: 31.789214, acc: 0.714286\n",
      "epoch 7, iter 216, loss: 31.464724, acc: 0.775510\n",
      "epoch 7, iter 217, loss: 34.036090, acc: 0.775510\n",
      "epoch 7, iter 218, loss: 32.378489, acc: 0.897959\n",
      "epoch 7, iter 219, loss: 30.838598, acc: 0.918367\n",
      "epoch 7, iter 220, loss: 33.007117, acc: 0.714286\n",
      "epoch 7, iter 221, loss: 32.131694, acc: 0.816327\n",
      "epoch 7, iter 222, loss: 34.344794, acc: 0.714286\n",
      "epoch 7, iter 223, loss: 31.360369, acc: 0.918367\n",
      "epoch 7, iter 224, loss: 31.750083, acc: 0.775510\n",
      "epoch 7, iter 225, loss: 32.469164, acc: 0.795918\n",
      "epoch 7, iter 226, loss: 33.249207, acc: 0.775510\n",
      "epoch 7, iter 227, loss: 31.917433, acc: 0.836735\n",
      "epoch 7, iter 228, loss: 31.994942, acc: 0.795918\n",
      "epoch 7, iter 229, loss: 29.435828, acc: 0.857143\n",
      "epoch 7, iter 230, loss: 29.978638, acc: 0.836735\n",
      "epoch 7, iter 231, loss: 28.745124, acc: 0.897959\n",
      "epoch 7, iter 232, loss: 29.857847, acc: 0.816327\n",
      "epoch 7, iter 233, loss: 32.086250, acc: 0.734694\n",
      "epoch 7, iter 234, loss: 30.532525, acc: 0.918367\n",
      "epoch 7, iter 235, loss: 30.884529, acc: 0.775510\n",
      "epoch 7, iter 236, loss: 28.294852, acc: 0.959184\n",
      "epoch 7, iter 237, loss: 32.461823, acc: 0.612245\n",
      "epoch 7, iter 238, loss: 35.249934, acc: 0.775510\n",
      "epoch 7, iter 239, loss: 34.963354, acc: 0.816327\n",
      "epoch 7, iter 240, loss: 33.554521, acc: 0.897959\n",
      "epoch 7, iter 241, loss: 32.499199, acc: 0.877551\n",
      "epoch 7, iter 242, loss: 33.015259, acc: 0.836735\n",
      "epoch 7, iter 243, loss: 31.986280, acc: 0.857143\n",
      "epoch 7, iter 244, loss: 31.219748, acc: 0.816327\n",
      "epoch 7, iter 245, loss: 32.301408, acc: 0.775510\n",
      "epoch 7, iter 246, loss: 35.030065, acc: 0.673469\n",
      "epoch 7, iter 247, loss: 34.893468, acc: 0.795918\n",
      "epoch 7, iter 248, loss: 38.014292, acc: 0.714286\n",
      "epoch 7, iter 249, loss: 38.257782, acc: 0.673469\n",
      "epoch 7, acc: 0.808653\n",
      "epoch 8, iter 0, loss: 38.911595, acc: 0.714286\n",
      "epoch 8, iter 1, loss: 39.066462, acc: 0.775510\n",
      "epoch 8, iter 2, loss: 39.520200, acc: 0.775510\n",
      "epoch 8, iter 3, loss: 37.580027, acc: 0.877551\n",
      "epoch 8, iter 4, loss: 38.454555, acc: 0.877551\n",
      "epoch 8, iter 5, loss: 35.386902, acc: 0.877551\n",
      "epoch 8, iter 6, loss: 33.472155, acc: 0.897959\n",
      "epoch 8, iter 7, loss: 34.790944, acc: 0.693878\n",
      "epoch 8, iter 8, loss: 34.270329, acc: 0.795918\n",
      "epoch 8, iter 9, loss: 34.780712, acc: 0.795918\n",
      "epoch 8, iter 10, loss: 33.808896, acc: 0.755102\n",
      "epoch 8, iter 11, loss: 35.117146, acc: 0.653061\n",
      "epoch 8, iter 12, loss: 33.643778, acc: 0.877551\n",
      "epoch 8, iter 13, loss: 32.297729, acc: 0.836735\n",
      "epoch 8, iter 14, loss: 31.484532, acc: 0.857143\n",
      "epoch 8, iter 15, loss: 29.569978, acc: 0.979592\n",
      "epoch 8, iter 16, loss: 30.683461, acc: 0.775510\n",
      "epoch 8, iter 17, loss: 29.949146, acc: 0.857143\n",
      "epoch 8, iter 18, loss: 33.637682, acc: 0.673469\n",
      "epoch 8, iter 19, loss: 32.014294, acc: 0.918367\n",
      "epoch 8, iter 20, loss: 29.156666, acc: 0.918367\n",
      "epoch 8, iter 21, loss: 28.221002, acc: 0.857143\n",
      "epoch 8, iter 22, loss: 26.929429, acc: 0.877551\n",
      "epoch 8, iter 23, loss: 30.320315, acc: 0.714286\n",
      "epoch 8, iter 24, loss: 29.977605, acc: 0.816327\n",
      "epoch 8, iter 25, loss: 31.868626, acc: 0.714286\n",
      "epoch 8, iter 26, loss: 33.778690, acc: 0.795918\n",
      "epoch 8, iter 27, loss: 33.982056, acc: 0.734694\n",
      "epoch 8, iter 28, loss: 32.306641, acc: 0.836735\n",
      "epoch 8, iter 29, loss: 29.875277, acc: 0.877551\n",
      "epoch 8, iter 30, loss: 32.071894, acc: 0.653061\n",
      "epoch 8, iter 31, loss: 35.943374, acc: 0.673469\n",
      "epoch 8, iter 32, loss: 33.999116, acc: 0.836735\n",
      "epoch 8, iter 33, loss: 31.863348, acc: 0.857143\n",
      "epoch 8, iter 34, loss: 32.207850, acc: 0.755102\n",
      "epoch 8, iter 35, loss: 34.173387, acc: 0.714286\n",
      "epoch 8, iter 36, loss: 34.194969, acc: 0.795918\n",
      "epoch 8, iter 37, loss: 31.443722, acc: 0.897959\n",
      "epoch 8, iter 38, loss: 32.436479, acc: 0.734694\n",
      "epoch 8, iter 39, loss: 32.111227, acc: 0.816327\n",
      "epoch 8, iter 40, loss: 34.086093, acc: 0.755102\n",
      "epoch 8, iter 41, loss: 32.873641, acc: 0.877551\n",
      "epoch 8, iter 42, loss: 35.631312, acc: 0.653061\n",
      "epoch 8, iter 43, loss: 33.341567, acc: 0.938776\n",
      "epoch 8, iter 44, loss: 30.462489, acc: 0.897959\n",
      "epoch 8, iter 45, loss: 31.257207, acc: 0.755102\n",
      "epoch 8, iter 46, loss: 32.040879, acc: 0.795918\n",
      "epoch 8, iter 47, loss: 31.491208, acc: 0.836735\n",
      "epoch 8, iter 48, loss: 32.327716, acc: 0.775510\n",
      "epoch 8, iter 49, loss: 31.871581, acc: 0.877551\n",
      "epoch 8, iter 50, loss: 32.498872, acc: 0.795918\n",
      "epoch 8, iter 51, loss: 33.925918, acc: 0.734694\n",
      "epoch 8, iter 52, loss: 33.165542, acc: 0.877551\n",
      "epoch 8, iter 53, loss: 33.711127, acc: 0.775510\n",
      "epoch 8, iter 54, loss: 33.442031, acc: 0.734694\n",
      "epoch 8, iter 55, loss: 32.777293, acc: 0.877551\n",
      "epoch 8, iter 56, loss: 31.490037, acc: 0.857143\n",
      "epoch 8, iter 57, loss: 29.904368, acc: 0.877551\n",
      "epoch 8, iter 58, loss: 31.474415, acc: 0.734694\n",
      "epoch 8, iter 59, loss: 31.195527, acc: 0.816327\n",
      "epoch 8, iter 60, loss: 30.281375, acc: 0.938776\n",
      "epoch 8, iter 61, loss: 31.073228, acc: 0.857143\n",
      "epoch 8, iter 62, loss: 30.554394, acc: 0.877551\n",
      "epoch 8, iter 63, loss: 29.563362, acc: 0.918367\n",
      "epoch 8, iter 64, loss: 32.391206, acc: 0.632653\n",
      "epoch 8, iter 65, loss: 31.102560, acc: 0.816327\n",
      "epoch 8, iter 66, loss: 29.310061, acc: 0.918367\n",
      "epoch 8, iter 67, loss: 31.740110, acc: 0.714286\n",
      "epoch 8, iter 68, loss: 30.484619, acc: 0.816327\n",
      "epoch 8, iter 69, loss: 28.524346, acc: 0.897959\n",
      "epoch 8, iter 70, loss: 27.987632, acc: 0.857143\n",
      "epoch 8, iter 71, loss: 30.723255, acc: 0.775510\n",
      "epoch 8, iter 72, loss: 29.593504, acc: 0.857143\n",
      "epoch 8, iter 73, loss: 27.320750, acc: 0.938776\n",
      "epoch 8, iter 74, loss: 26.455593, acc: 0.836735\n",
      "epoch 8, iter 75, loss: 25.541930, acc: 0.897959\n",
      "epoch 8, iter 76, loss: 28.480368, acc: 0.734694\n",
      "epoch 8, iter 77, loss: 31.732129, acc: 0.673469\n",
      "epoch 8, iter 78, loss: 32.536151, acc: 0.795918\n",
      "epoch 8, iter 79, loss: 30.946158, acc: 0.877551\n",
      "epoch 8, iter 80, loss: 29.303567, acc: 0.877551\n",
      "epoch 8, iter 81, loss: 30.446536, acc: 0.755102\n",
      "epoch 8, iter 82, loss: 30.246598, acc: 0.755102\n",
      "epoch 8, iter 83, loss: 32.047243, acc: 0.755102\n",
      "epoch 8, iter 84, loss: 29.847440, acc: 0.897959\n",
      "epoch 8, iter 85, loss: 27.727675, acc: 0.877551\n",
      "epoch 8, iter 86, loss: 30.361235, acc: 0.673469\n",
      "epoch 8, iter 87, loss: 33.500379, acc: 0.673469\n",
      "epoch 8, iter 88, loss: 32.386482, acc: 0.857143\n",
      "epoch 8, iter 89, loss: 31.834924, acc: 0.816327\n",
      "epoch 8, iter 90, loss: 33.170504, acc: 0.734694\n",
      "epoch 8, iter 91, loss: 33.610934, acc: 0.816327\n",
      "epoch 8, iter 92, loss: 35.005416, acc: 0.734694\n",
      "epoch 8, iter 93, loss: 35.541802, acc: 0.673469\n",
      "epoch 8, iter 94, loss: 33.866936, acc: 0.857143\n",
      "epoch 8, iter 95, loss: 31.610400, acc: 0.938776\n",
      "epoch 8, iter 96, loss: 32.143868, acc: 0.816327\n",
      "epoch 8, iter 97, loss: 32.133770, acc: 0.816327\n",
      "epoch 8, iter 98, loss: 32.159927, acc: 0.775510\n",
      "epoch 8, iter 99, loss: 30.426695, acc: 0.897959\n",
      "epoch 8, iter 100, loss: 34.941442, acc: 0.530612\n",
      "epoch 8, iter 101, loss: 33.825741, acc: 0.775510\n",
      "epoch 8, iter 102, loss: 31.469635, acc: 0.918367\n",
      "epoch 8, iter 103, loss: 30.457143, acc: 0.897959\n",
      "epoch 8, iter 104, loss: 31.522914, acc: 0.775510\n",
      "epoch 8, iter 105, loss: 31.045113, acc: 0.857143\n",
      "epoch 8, iter 106, loss: 30.492961, acc: 0.816327\n",
      "epoch 8, iter 107, loss: 27.878312, acc: 0.938776\n",
      "epoch 8, iter 108, loss: 29.814541, acc: 0.734694\n",
      "epoch 8, iter 109, loss: 31.437937, acc: 0.673469\n",
      "epoch 8, iter 110, loss: 31.024766, acc: 0.795918\n",
      "epoch 8, iter 111, loss: 35.131239, acc: 0.612245\n",
      "epoch 8, iter 112, loss: 35.112757, acc: 0.857143\n",
      "epoch 8, iter 113, loss: 37.230714, acc: 0.673469\n",
      "epoch 8, iter 114, loss: 34.758216, acc: 0.857143\n",
      "epoch 8, iter 115, loss: 35.818210, acc: 0.714286\n",
      "epoch 8, iter 116, loss: 37.100176, acc: 0.693878\n",
      "epoch 8, iter 117, loss: 34.621086, acc: 0.918367\n",
      "epoch 8, iter 118, loss: 36.774640, acc: 0.734694\n",
      "epoch 8, iter 119, loss: 33.560292, acc: 0.918367\n",
      "epoch 8, iter 120, loss: 34.751556, acc: 0.755102\n",
      "epoch 8, iter 121, loss: 32.474521, acc: 0.857143\n",
      "epoch 8, iter 122, loss: 32.232910, acc: 0.795918\n",
      "epoch 8, iter 123, loss: 31.093991, acc: 0.897959\n",
      "epoch 8, iter 124, loss: 32.158683, acc: 0.816327\n",
      "epoch 8, iter 125, loss: 34.730127, acc: 0.693878\n",
      "epoch 8, iter 126, loss: 32.636392, acc: 0.918367\n",
      "epoch 8, iter 127, loss: 37.238659, acc: 0.551020\n",
      "epoch 8, iter 128, loss: 34.259441, acc: 0.897959\n",
      "epoch 8, iter 129, loss: 33.030874, acc: 0.836735\n",
      "epoch 8, iter 130, loss: 31.086889, acc: 0.897959\n",
      "epoch 8, iter 131, loss: 30.516964, acc: 0.795918\n",
      "epoch 8, iter 132, loss: 31.056644, acc: 0.795918\n",
      "epoch 8, iter 133, loss: 29.179175, acc: 0.918367\n",
      "epoch 8, iter 134, loss: 32.895361, acc: 0.612245\n",
      "epoch 8, iter 135, loss: 34.349759, acc: 0.734694\n",
      "epoch 8, iter 136, loss: 33.927096, acc: 0.918367\n",
      "epoch 8, iter 137, loss: 35.158527, acc: 0.795918\n",
      "epoch 8, iter 138, loss: 35.617109, acc: 0.877551\n",
      "epoch 8, iter 139, loss: 34.370465, acc: 0.836735\n",
      "epoch 8, iter 140, loss: 33.477858, acc: 0.816327\n",
      "epoch 8, iter 141, loss: 31.922533, acc: 0.816327\n",
      "epoch 8, iter 142, loss: 32.411837, acc: 0.734694\n",
      "epoch 8, iter 143, loss: 31.512895, acc: 0.897959\n",
      "epoch 8, iter 144, loss: 32.220725, acc: 0.714286\n",
      "epoch 8, iter 145, loss: 30.576323, acc: 0.918367\n",
      "epoch 8, iter 146, loss: 30.079461, acc: 0.857143\n",
      "epoch 8, iter 147, loss: 30.205330, acc: 0.836735\n",
      "epoch 8, iter 148, loss: 29.956373, acc: 0.877551\n",
      "epoch 8, iter 149, loss: 28.252558, acc: 0.938776\n",
      "epoch 8, iter 150, loss: 29.180924, acc: 0.816327\n",
      "epoch 8, iter 151, loss: 29.469317, acc: 0.836735\n",
      "epoch 8, iter 152, loss: 29.848508, acc: 0.816327\n",
      "epoch 8, iter 153, loss: 32.084702, acc: 0.714286\n",
      "epoch 8, iter 154, loss: 33.178545, acc: 0.693878\n",
      "epoch 8, iter 155, loss: 32.459605, acc: 0.795918\n",
      "epoch 8, iter 156, loss: 30.866971, acc: 0.836735\n",
      "epoch 8, iter 157, loss: 31.384306, acc: 0.816327\n",
      "epoch 8, iter 158, loss: 29.872178, acc: 0.897959\n",
      "epoch 8, iter 159, loss: 33.554430, acc: 0.693878\n",
      "epoch 8, iter 160, loss: 35.110148, acc: 0.673469\n",
      "epoch 8, iter 161, loss: 32.780865, acc: 0.857143\n",
      "epoch 8, iter 162, loss: 32.265281, acc: 0.775510\n",
      "epoch 8, iter 163, loss: 32.210517, acc: 0.836735\n",
      "epoch 8, iter 164, loss: 33.476187, acc: 0.775510\n",
      "epoch 8, iter 165, loss: 31.818134, acc: 0.918367\n",
      "epoch 8, iter 166, loss: 31.152130, acc: 0.857143\n",
      "epoch 8, iter 167, loss: 32.602774, acc: 0.775510\n",
      "epoch 8, iter 168, loss: 31.669581, acc: 0.816327\n",
      "epoch 8, iter 169, loss: 31.887185, acc: 0.755102\n",
      "epoch 8, iter 170, loss: 36.898849, acc: 0.693878\n",
      "epoch 8, iter 171, loss: 36.699750, acc: 0.755102\n",
      "epoch 8, iter 172, loss: 36.138912, acc: 0.836735\n",
      "epoch 8, iter 173, loss: 34.489229, acc: 0.775510\n",
      "epoch 8, iter 174, loss: 35.018194, acc: 0.795918\n",
      "epoch 8, iter 175, loss: 33.282056, acc: 0.877551\n",
      "epoch 8, iter 176, loss: 31.575571, acc: 0.877551\n",
      "epoch 8, iter 177, loss: 30.325509, acc: 0.897959\n",
      "epoch 8, iter 178, loss: 31.070185, acc: 0.755102\n",
      "epoch 8, iter 179, loss: 30.411649, acc: 0.775510\n",
      "epoch 8, iter 180, loss: 28.907942, acc: 0.836735\n",
      "epoch 8, iter 181, loss: 31.376839, acc: 0.734694\n",
      "epoch 8, iter 182, loss: 31.482144, acc: 0.755102\n",
      "epoch 8, iter 183, loss: 34.504608, acc: 0.632653\n",
      "epoch 8, iter 184, loss: 33.430836, acc: 0.816327\n",
      "epoch 8, iter 185, loss: 34.487625, acc: 0.714286\n",
      "epoch 8, iter 186, loss: 32.278175, acc: 0.897959\n",
      "epoch 8, iter 187, loss: 34.120924, acc: 0.714286\n",
      "epoch 8, iter 188, loss: 36.904242, acc: 0.693878\n",
      "epoch 8, iter 189, loss: 36.575403, acc: 0.775510\n",
      "epoch 8, iter 190, loss: 35.711172, acc: 0.775510\n",
      "epoch 8, iter 191, loss: 33.464830, acc: 0.938776\n",
      "epoch 8, iter 192, loss: 32.182645, acc: 0.836735\n",
      "epoch 8, iter 193, loss: 34.466965, acc: 0.734694\n",
      "epoch 8, iter 194, loss: 34.136205, acc: 0.755102\n",
      "epoch 8, iter 195, loss: 33.950293, acc: 0.775510\n",
      "epoch 8, iter 196, loss: 31.994370, acc: 0.877551\n",
      "epoch 8, iter 197, loss: 32.104965, acc: 0.755102\n",
      "epoch 8, iter 198, loss: 32.699341, acc: 0.795918\n",
      "epoch 8, iter 199, loss: 32.707624, acc: 0.795918\n",
      "epoch 8, iter 200, loss: 32.076311, acc: 0.836735\n",
      "epoch 8, iter 201, loss: 33.611774, acc: 0.857143\n",
      "epoch 8, iter 202, loss: 32.145675, acc: 0.877551\n",
      "epoch 8, iter 203, loss: 33.790386, acc: 0.755102\n",
      "epoch 8, iter 204, loss: 33.148910, acc: 0.795918\n",
      "epoch 8, iter 205, loss: 38.055336, acc: 0.653061\n",
      "epoch 8, iter 206, loss: 36.855403, acc: 0.775510\n",
      "epoch 8, iter 207, loss: 34.922551, acc: 0.857143\n",
      "epoch 8, iter 208, loss: 33.518051, acc: 0.816327\n",
      "epoch 8, iter 209, loss: 31.786214, acc: 0.938776\n",
      "epoch 8, iter 210, loss: 32.190001, acc: 0.775510\n",
      "epoch 8, iter 211, loss: 31.033519, acc: 0.795918\n",
      "epoch 8, iter 212, loss: 32.506316, acc: 0.673469\n",
      "epoch 8, iter 213, loss: 30.840860, acc: 0.836735\n",
      "epoch 8, iter 214, loss: 29.338107, acc: 0.877551\n",
      "epoch 8, iter 215, loss: 31.687931, acc: 0.714286\n",
      "epoch 8, iter 216, loss: 31.395712, acc: 0.734694\n",
      "epoch 8, iter 217, loss: 33.804706, acc: 0.775510\n",
      "epoch 8, iter 218, loss: 32.204358, acc: 0.877551\n",
      "epoch 8, iter 219, loss: 30.598910, acc: 0.938776\n",
      "epoch 8, iter 220, loss: 32.731575, acc: 0.673469\n",
      "epoch 8, iter 221, loss: 31.903882, acc: 0.816327\n",
      "epoch 8, iter 222, loss: 34.200862, acc: 0.673469\n",
      "epoch 8, iter 223, loss: 31.186392, acc: 0.918367\n",
      "epoch 8, iter 224, loss: 31.561711, acc: 0.755102\n",
      "epoch 8, iter 225, loss: 32.266879, acc: 0.775510\n",
      "epoch 8, iter 226, loss: 33.052887, acc: 0.755102\n",
      "epoch 8, iter 227, loss: 31.886774, acc: 0.836735\n",
      "epoch 8, iter 228, loss: 31.898672, acc: 0.775510\n",
      "epoch 8, iter 229, loss: 29.003664, acc: 0.857143\n",
      "epoch 8, iter 230, loss: 29.601170, acc: 0.836735\n",
      "epoch 8, iter 231, loss: 28.350941, acc: 0.897959\n",
      "epoch 8, iter 232, loss: 29.645730, acc: 0.816327\n",
      "epoch 8, iter 233, loss: 31.786083, acc: 0.755102\n",
      "epoch 8, iter 234, loss: 30.347925, acc: 0.938776\n",
      "epoch 8, iter 235, loss: 30.666071, acc: 0.795918\n",
      "epoch 8, iter 236, loss: 28.168694, acc: 0.959184\n",
      "epoch 8, iter 237, loss: 32.189677, acc: 0.632653\n",
      "epoch 8, iter 238, loss: 35.116346, acc: 0.795918\n",
      "epoch 8, iter 239, loss: 34.808654, acc: 0.836735\n",
      "epoch 8, iter 240, loss: 33.543906, acc: 0.897959\n",
      "epoch 8, iter 241, loss: 32.422036, acc: 0.877551\n",
      "epoch 8, iter 242, loss: 32.918725, acc: 0.775510\n",
      "epoch 8, iter 243, loss: 31.722709, acc: 0.877551\n",
      "epoch 8, iter 244, loss: 30.956506, acc: 0.836735\n",
      "epoch 8, iter 245, loss: 32.748315, acc: 0.755102\n",
      "epoch 8, iter 246, loss: 35.175135, acc: 0.714286\n",
      "epoch 8, iter 247, loss: 34.878236, acc: 0.775510\n",
      "epoch 8, iter 248, loss: 37.532013, acc: 0.755102\n",
      "epoch 8, iter 249, loss: 37.974405, acc: 0.673469\n",
      "epoch 8, acc: 0.804571\n",
      "epoch 9, iter 0, loss: 38.497156, acc: 0.734694\n",
      "epoch 9, iter 1, loss: 38.574640, acc: 0.795918\n",
      "epoch 9, iter 2, loss: 38.828292, acc: 0.795918\n",
      "epoch 9, iter 3, loss: 37.296589, acc: 0.816327\n",
      "epoch 9, iter 4, loss: 35.694969, acc: 0.877551\n",
      "epoch 9, iter 5, loss: 33.245847, acc: 0.938776\n",
      "epoch 9, iter 6, loss: 32.396413, acc: 0.918367\n",
      "epoch 9, iter 7, loss: 34.105102, acc: 0.653061\n",
      "epoch 9, iter 8, loss: 34.189559, acc: 0.755102\n",
      "epoch 9, iter 9, loss: 34.175775, acc: 0.775510\n",
      "epoch 9, iter 10, loss: 33.600553, acc: 0.714286\n",
      "epoch 9, iter 11, loss: 35.067976, acc: 0.673469\n",
      "epoch 9, iter 12, loss: 33.122630, acc: 0.877551\n",
      "epoch 9, iter 13, loss: 31.890685, acc: 0.836735\n",
      "epoch 9, iter 14, loss: 31.127274, acc: 0.857143\n",
      "epoch 9, iter 15, loss: 29.462395, acc: 0.959184\n",
      "epoch 9, iter 16, loss: 30.708516, acc: 0.775510\n",
      "epoch 9, iter 17, loss: 29.816500, acc: 0.857143\n",
      "epoch 9, iter 18, loss: 33.553760, acc: 0.693878\n",
      "epoch 9, iter 19, loss: 31.466168, acc: 0.918367\n",
      "epoch 9, iter 20, loss: 28.706243, acc: 0.918367\n",
      "epoch 9, iter 21, loss: 27.851111, acc: 0.857143\n",
      "epoch 9, iter 22, loss: 26.589740, acc: 0.877551\n",
      "epoch 9, iter 23, loss: 29.997879, acc: 0.693878\n",
      "epoch 9, iter 24, loss: 29.904717, acc: 0.795918\n",
      "epoch 9, iter 25, loss: 31.756547, acc: 0.816327\n",
      "epoch 9, iter 26, loss: 34.203993, acc: 0.775510\n",
      "epoch 9, iter 27, loss: 34.182495, acc: 0.734694\n",
      "epoch 9, iter 28, loss: 32.458377, acc: 0.857143\n",
      "epoch 9, iter 29, loss: 29.786209, acc: 0.857143\n",
      "epoch 9, iter 30, loss: 31.961760, acc: 0.673469\n",
      "epoch 9, iter 31, loss: 36.081077, acc: 0.653061\n",
      "epoch 9, iter 32, loss: 33.907449, acc: 0.857143\n",
      "epoch 9, iter 33, loss: 31.892258, acc: 0.877551\n",
      "epoch 9, iter 34, loss: 32.169434, acc: 0.734694\n",
      "epoch 9, iter 35, loss: 34.116722, acc: 0.714286\n",
      "epoch 9, iter 36, loss: 33.865214, acc: 0.816327\n",
      "epoch 9, iter 37, loss: 31.254553, acc: 0.897959\n",
      "epoch 9, iter 38, loss: 32.062716, acc: 0.775510\n",
      "epoch 9, iter 39, loss: 31.639624, acc: 0.816327\n",
      "epoch 9, iter 40, loss: 33.750313, acc: 0.734694\n",
      "epoch 9, iter 41, loss: 32.592916, acc: 0.836735\n",
      "epoch 9, iter 42, loss: 35.601568, acc: 0.653061\n",
      "epoch 9, iter 43, loss: 33.227553, acc: 0.938776\n",
      "epoch 9, iter 44, loss: 30.281814, acc: 0.897959\n",
      "epoch 9, iter 45, loss: 31.216422, acc: 0.755102\n",
      "epoch 9, iter 46, loss: 31.901033, acc: 0.795918\n",
      "epoch 9, iter 47, loss: 31.231474, acc: 0.816327\n",
      "epoch 9, iter 48, loss: 31.958205, acc: 0.755102\n",
      "epoch 9, iter 49, loss: 31.329294, acc: 0.795918\n",
      "epoch 9, iter 50, loss: 32.147806, acc: 0.836735\n",
      "epoch 9, iter 51, loss: 33.697071, acc: 0.734694\n",
      "epoch 9, iter 52, loss: 32.808015, acc: 0.836735\n",
      "epoch 9, iter 53, loss: 33.407733, acc: 0.775510\n",
      "epoch 9, iter 54, loss: 33.089130, acc: 0.755102\n",
      "epoch 9, iter 55, loss: 32.394103, acc: 0.836735\n",
      "epoch 9, iter 56, loss: 31.145634, acc: 0.857143\n",
      "epoch 9, iter 57, loss: 29.824305, acc: 0.877551\n",
      "epoch 9, iter 58, loss: 31.305160, acc: 0.734694\n",
      "epoch 9, iter 59, loss: 31.044697, acc: 0.816327\n",
      "epoch 9, iter 60, loss: 30.058599, acc: 0.918367\n",
      "epoch 9, iter 61, loss: 30.809296, acc: 0.877551\n",
      "epoch 9, iter 62, loss: 30.532526, acc: 0.857143\n",
      "epoch 9, iter 63, loss: 29.464303, acc: 0.877551\n",
      "epoch 9, iter 64, loss: 32.293472, acc: 0.612245\n",
      "epoch 9, iter 65, loss: 30.995083, acc: 0.816327\n",
      "epoch 9, iter 66, loss: 28.942683, acc: 0.938776\n",
      "epoch 9, iter 67, loss: 31.591056, acc: 0.693878\n",
      "epoch 9, iter 68, loss: 30.333669, acc: 0.836735\n",
      "epoch 9, iter 69, loss: 28.385732, acc: 0.877551\n",
      "epoch 9, iter 70, loss: 27.818783, acc: 0.857143\n",
      "epoch 9, iter 71, loss: 30.570657, acc: 0.795918\n",
      "epoch 9, iter 72, loss: 29.524365, acc: 0.857143\n",
      "epoch 9, iter 73, loss: 27.244437, acc: 0.938776\n",
      "epoch 9, iter 74, loss: 26.273346, acc: 0.836735\n",
      "epoch 9, iter 75, loss: 25.378132, acc: 0.877551\n",
      "epoch 9, iter 76, loss: 28.320295, acc: 0.755102\n",
      "epoch 9, iter 77, loss: 31.644500, acc: 0.632653\n",
      "epoch 9, iter 78, loss: 32.544861, acc: 0.755102\n",
      "epoch 9, iter 79, loss: 30.802012, acc: 0.857143\n",
      "epoch 9, iter 80, loss: 28.869870, acc: 0.877551\n",
      "epoch 9, iter 81, loss: 30.119707, acc: 0.795918\n",
      "epoch 9, iter 82, loss: 30.071931, acc: 0.755102\n",
      "epoch 9, iter 83, loss: 31.828150, acc: 0.755102\n",
      "epoch 9, iter 84, loss: 29.548649, acc: 0.897959\n",
      "epoch 9, iter 85, loss: 27.447048, acc: 0.877551\n",
      "epoch 9, iter 86, loss: 29.998737, acc: 0.693878\n",
      "epoch 9, iter 87, loss: 33.249992, acc: 0.653061\n",
      "epoch 9, iter 88, loss: 31.992566, acc: 0.857143\n",
      "epoch 9, iter 89, loss: 31.946453, acc: 0.775510\n",
      "epoch 9, iter 90, loss: 33.006471, acc: 0.734694\n",
      "epoch 9, iter 91, loss: 33.408694, acc: 0.816327\n",
      "epoch 9, iter 92, loss: 34.843705, acc: 0.755102\n",
      "epoch 9, iter 93, loss: 35.384562, acc: 0.693878\n",
      "epoch 9, iter 94, loss: 33.823972, acc: 0.857143\n",
      "epoch 9, iter 95, loss: 30.721660, acc: 0.959184\n",
      "epoch 9, iter 96, loss: 31.430537, acc: 0.816327\n",
      "epoch 9, iter 97, loss: 31.478179, acc: 0.775510\n",
      "epoch 9, iter 98, loss: 31.652692, acc: 0.775510\n",
      "epoch 9, iter 99, loss: 30.044936, acc: 0.877551\n",
      "epoch 9, iter 100, loss: 34.418841, acc: 0.551020\n",
      "epoch 9, iter 101, loss: 33.185042, acc: 0.795918\n",
      "epoch 9, iter 102, loss: 30.977093, acc: 0.857143\n",
      "epoch 9, iter 103, loss: 29.959060, acc: 0.877551\n",
      "epoch 9, iter 104, loss: 31.244627, acc: 0.775510\n",
      "epoch 9, iter 105, loss: 30.979371, acc: 0.816327\n",
      "epoch 9, iter 106, loss: 30.393539, acc: 0.816327\n",
      "epoch 9, iter 107, loss: 27.669754, acc: 0.938776\n",
      "epoch 9, iter 108, loss: 29.454508, acc: 0.734694\n",
      "epoch 9, iter 109, loss: 31.111637, acc: 0.673469\n",
      "epoch 9, iter 110, loss: 30.656262, acc: 0.816327\n",
      "epoch 9, iter 111, loss: 34.862674, acc: 0.591837\n",
      "epoch 9, iter 112, loss: 35.010207, acc: 0.836735\n",
      "epoch 9, iter 113, loss: 36.883962, acc: 0.693878\n",
      "epoch 9, iter 114, loss: 34.726550, acc: 0.836735\n",
      "epoch 9, iter 115, loss: 35.067680, acc: 0.795918\n",
      "epoch 9, iter 116, loss: 36.160138, acc: 0.693878\n",
      "epoch 9, iter 117, loss: 33.393465, acc: 0.877551\n",
      "epoch 9, iter 118, loss: 35.996181, acc: 0.734694\n",
      "epoch 9, iter 119, loss: 32.526366, acc: 0.959184\n",
      "epoch 9, iter 120, loss: 33.579435, acc: 0.775510\n",
      "epoch 9, iter 121, loss: 31.368757, acc: 0.816327\n",
      "epoch 9, iter 122, loss: 31.248158, acc: 0.775510\n",
      "epoch 9, iter 123, loss: 30.784068, acc: 0.877551\n",
      "epoch 9, iter 124, loss: 31.959516, acc: 0.816327\n",
      "epoch 9, iter 125, loss: 34.372812, acc: 0.673469\n",
      "epoch 9, iter 126, loss: 32.162455, acc: 0.918367\n",
      "epoch 9, iter 127, loss: 36.596708, acc: 0.551020\n",
      "epoch 9, iter 128, loss: 33.780550, acc: 0.897959\n",
      "epoch 9, iter 129, loss: 32.739249, acc: 0.816327\n",
      "epoch 9, iter 130, loss: 30.744649, acc: 0.918367\n",
      "epoch 9, iter 131, loss: 30.200150, acc: 0.795918\n",
      "epoch 9, iter 132, loss: 30.809528, acc: 0.795918\n",
      "epoch 9, iter 133, loss: 29.016003, acc: 0.897959\n",
      "epoch 9, iter 134, loss: 32.573850, acc: 0.632653\n",
      "epoch 9, iter 135, loss: 34.043122, acc: 0.734694\n",
      "epoch 9, iter 136, loss: 33.505721, acc: 0.877551\n",
      "epoch 9, iter 137, loss: 34.492874, acc: 0.755102\n",
      "epoch 9, iter 138, loss: 34.561702, acc: 0.857143\n",
      "epoch 9, iter 139, loss: 33.492899, acc: 0.836735\n",
      "epoch 9, iter 140, loss: 32.999959, acc: 0.816327\n",
      "epoch 9, iter 141, loss: 31.419559, acc: 0.816327\n",
      "epoch 9, iter 142, loss: 32.133091, acc: 0.714286\n",
      "epoch 9, iter 143, loss: 31.417731, acc: 0.857143\n",
      "epoch 9, iter 144, loss: 32.104860, acc: 0.673469\n",
      "epoch 9, iter 145, loss: 30.182207, acc: 0.918367\n",
      "epoch 9, iter 146, loss: 29.829868, acc: 0.857143\n",
      "epoch 9, iter 147, loss: 29.927464, acc: 0.836735\n",
      "epoch 9, iter 148, loss: 29.750151, acc: 0.857143\n",
      "epoch 9, iter 149, loss: 27.999504, acc: 0.938776\n",
      "epoch 9, iter 150, loss: 28.965791, acc: 0.816327\n",
      "epoch 9, iter 151, loss: 29.305650, acc: 0.816327\n",
      "epoch 9, iter 152, loss: 29.668563, acc: 0.816327\n",
      "epoch 9, iter 153, loss: 31.950539, acc: 0.714286\n",
      "epoch 9, iter 154, loss: 33.067936, acc: 0.714286\n",
      "epoch 9, iter 155, loss: 32.278379, acc: 0.795918\n",
      "epoch 9, iter 156, loss: 30.647117, acc: 0.836735\n",
      "epoch 9, iter 157, loss: 31.100574, acc: 0.816327\n",
      "epoch 9, iter 158, loss: 29.512431, acc: 0.877551\n",
      "epoch 9, iter 159, loss: 33.240240, acc: 0.653061\n",
      "epoch 9, iter 160, loss: 34.568856, acc: 0.693878\n",
      "epoch 9, iter 161, loss: 32.256274, acc: 0.857143\n",
      "epoch 9, iter 162, loss: 31.796465, acc: 0.775510\n",
      "epoch 9, iter 163, loss: 31.869271, acc: 0.857143\n",
      "epoch 9, iter 164, loss: 33.293894, acc: 0.755102\n",
      "epoch 9, iter 165, loss: 31.579013, acc: 0.918367\n",
      "epoch 9, iter 166, loss: 30.918165, acc: 0.836735\n",
      "epoch 9, iter 167, loss: 32.238504, acc: 0.795918\n",
      "epoch 9, iter 168, loss: 31.744488, acc: 0.816327\n",
      "epoch 9, iter 169, loss: 31.822704, acc: 0.775510\n",
      "epoch 9, iter 170, loss: 36.247620, acc: 0.714286\n",
      "epoch 9, iter 171, loss: 36.318370, acc: 0.755102\n",
      "epoch 9, iter 172, loss: 35.823742, acc: 0.836735\n",
      "epoch 9, iter 173, loss: 34.315110, acc: 0.775510\n",
      "epoch 9, iter 174, loss: 34.950024, acc: 0.775510\n",
      "epoch 9, iter 175, loss: 33.352477, acc: 0.877551\n",
      "epoch 9, iter 176, loss: 31.543045, acc: 0.877551\n",
      "epoch 9, iter 177, loss: 30.152723, acc: 0.897959\n",
      "epoch 9, iter 178, loss: 30.965020, acc: 0.734694\n",
      "epoch 9, iter 179, loss: 30.399695, acc: 0.775510\n",
      "epoch 9, iter 180, loss: 28.837625, acc: 0.836735\n",
      "epoch 9, iter 181, loss: 31.133695, acc: 0.714286\n",
      "epoch 9, iter 182, loss: 31.262152, acc: 0.816327\n",
      "epoch 9, iter 183, loss: 34.009864, acc: 0.632653\n",
      "epoch 9, iter 184, loss: 32.926958, acc: 0.816327\n",
      "epoch 9, iter 185, loss: 34.211062, acc: 0.755102\n",
      "epoch 9, iter 186, loss: 32.229124, acc: 0.897959\n",
      "epoch 9, iter 187, loss: 33.872200, acc: 0.714286\n",
      "epoch 9, iter 188, loss: 36.623409, acc: 0.693878\n",
      "epoch 9, iter 189, loss: 36.468142, acc: 0.714286\n",
      "epoch 9, iter 190, loss: 35.272386, acc: 0.775510\n",
      "epoch 9, iter 191, loss: 33.135531, acc: 0.938776\n",
      "epoch 9, iter 192, loss: 32.007926, acc: 0.857143\n",
      "epoch 9, iter 193, loss: 34.273239, acc: 0.734694\n",
      "epoch 9, iter 194, loss: 33.750075, acc: 0.734694\n",
      "epoch 9, iter 195, loss: 33.574460, acc: 0.775510\n",
      "epoch 9, iter 196, loss: 31.696969, acc: 0.897959\n",
      "epoch 9, iter 197, loss: 31.902228, acc: 0.775510\n",
      "epoch 9, iter 198, loss: 32.615379, acc: 0.734694\n",
      "epoch 9, iter 199, loss: 32.959993, acc: 0.755102\n",
      "epoch 9, iter 200, loss: 32.453498, acc: 0.816327\n",
      "epoch 9, iter 201, loss: 33.253753, acc: 0.816327\n",
      "epoch 9, iter 202, loss: 31.642055, acc: 0.877551\n",
      "epoch 9, iter 203, loss: 33.336483, acc: 0.734694\n",
      "epoch 9, iter 204, loss: 32.786336, acc: 0.795918\n",
      "epoch 9, iter 205, loss: 37.837549, acc: 0.632653\n",
      "epoch 9, iter 206, loss: 36.570636, acc: 0.795918\n",
      "epoch 9, iter 207, loss: 34.684939, acc: 0.836735\n",
      "epoch 9, iter 208, loss: 33.449319, acc: 0.877551\n",
      "epoch 9, iter 209, loss: 31.587652, acc: 0.938776\n",
      "epoch 9, iter 210, loss: 32.065927, acc: 0.775510\n",
      "epoch 9, iter 211, loss: 30.619111, acc: 0.795918\n",
      "epoch 9, iter 212, loss: 31.842325, acc: 0.734694\n",
      "epoch 9, iter 213, loss: 30.194496, acc: 0.836735\n",
      "epoch 9, iter 214, loss: 28.838548, acc: 0.877551\n",
      "epoch 9, iter 215, loss: 31.418606, acc: 0.755102\n",
      "epoch 9, iter 216, loss: 31.288482, acc: 0.755102\n",
      "epoch 9, iter 217, loss: 33.724570, acc: 0.755102\n",
      "epoch 9, iter 218, loss: 32.035930, acc: 0.857143\n",
      "epoch 9, iter 219, loss: 30.161178, acc: 0.938776\n",
      "epoch 9, iter 220, loss: 32.217527, acc: 0.653061\n",
      "epoch 9, iter 221, loss: 31.482703, acc: 0.836735\n",
      "epoch 9, iter 222, loss: 33.948800, acc: 0.653061\n",
      "epoch 9, iter 223, loss: 31.025407, acc: 0.918367\n",
      "epoch 9, iter 224, loss: 31.470577, acc: 0.795918\n",
      "epoch 9, iter 225, loss: 32.242918, acc: 0.795918\n",
      "epoch 9, iter 226, loss: 32.912721, acc: 0.734694\n",
      "epoch 9, iter 227, loss: 31.806359, acc: 0.836735\n",
      "epoch 9, iter 228, loss: 31.861953, acc: 0.795918\n",
      "epoch 9, iter 229, loss: 28.881869, acc: 0.857143\n",
      "epoch 9, iter 230, loss: 29.474628, acc: 0.795918\n",
      "epoch 9, iter 231, loss: 28.190636, acc: 0.897959\n",
      "epoch 9, iter 232, loss: 29.566924, acc: 0.816327\n",
      "epoch 9, iter 233, loss: 31.557968, acc: 0.755102\n",
      "epoch 9, iter 234, loss: 30.127599, acc: 0.918367\n",
      "epoch 9, iter 235, loss: 30.471617, acc: 0.795918\n",
      "epoch 9, iter 236, loss: 27.928904, acc: 0.959184\n",
      "epoch 9, iter 237, loss: 31.883348, acc: 0.673469\n",
      "epoch 9, iter 238, loss: 35.030238, acc: 0.775510\n",
      "epoch 9, iter 239, loss: 34.907778, acc: 0.795918\n",
      "epoch 9, iter 240, loss: 33.528444, acc: 0.857143\n",
      "epoch 9, iter 241, loss: 32.473238, acc: 0.836735\n",
      "epoch 9, iter 242, loss: 33.092328, acc: 0.775510\n",
      "epoch 9, iter 243, loss: 32.137582, acc: 0.877551\n",
      "epoch 9, iter 244, loss: 31.687329, acc: 0.816327\n",
      "epoch 9, iter 245, loss: 32.221289, acc: 0.775510\n",
      "epoch 9, iter 246, loss: 34.941261, acc: 0.673469\n",
      "epoch 9, iter 247, loss: 34.863869, acc: 0.795918\n",
      "epoch 9, iter 248, loss: 37.645606, acc: 0.714286\n",
      "epoch 9, iter 249, loss: 38.061379, acc: 0.693878\n",
      "epoch 9, acc: 0.801306\n",
      "epoch 10, iter 0, loss: 37.764626, acc: 0.653061\n",
      "epoch 10, iter 1, loss: 38.068443, acc: 0.775510\n",
      "epoch 10, iter 2, loss: 37.762379, acc: 0.755102\n",
      "epoch 10, iter 3, loss: 36.247750, acc: 0.775510\n",
      "epoch 10, iter 4, loss: 34.619677, acc: 0.857143\n",
      "epoch 10, iter 5, loss: 32.745878, acc: 0.857143\n",
      "epoch 10, iter 6, loss: 31.639074, acc: 0.857143\n",
      "epoch 10, iter 7, loss: 33.450569, acc: 0.673469\n",
      "epoch 10, iter 8, loss: 33.556587, acc: 0.755102\n",
      "epoch 10, iter 9, loss: 33.479471, acc: 0.775510\n",
      "epoch 10, iter 10, loss: 33.076725, acc: 0.714286\n",
      "epoch 10, iter 11, loss: 34.544768, acc: 0.673469\n",
      "epoch 10, iter 12, loss: 33.153015, acc: 0.836735\n",
      "epoch 10, iter 13, loss: 32.852065, acc: 0.816327\n",
      "epoch 10, iter 14, loss: 31.552934, acc: 0.857143\n",
      "epoch 10, iter 15, loss: 29.384288, acc: 0.959184\n",
      "epoch 10, iter 16, loss: 30.492226, acc: 0.795918\n",
      "epoch 10, iter 17, loss: 29.702401, acc: 0.816327\n",
      "epoch 10, iter 18, loss: 33.364607, acc: 0.673469\n",
      "epoch 10, iter 19, loss: 31.409309, acc: 0.918367\n",
      "epoch 10, iter 20, loss: 28.616255, acc: 0.918367\n",
      "epoch 10, iter 21, loss: 27.845560, acc: 0.836735\n",
      "epoch 10, iter 22, loss: 26.556074, acc: 0.877551\n",
      "epoch 10, iter 23, loss: 29.784551, acc: 0.673469\n",
      "epoch 10, iter 24, loss: 29.771519, acc: 0.795918\n",
      "epoch 10, iter 25, loss: 31.678312, acc: 0.775510\n",
      "epoch 10, iter 26, loss: 33.967136, acc: 0.775510\n",
      "epoch 10, iter 27, loss: 34.038949, acc: 0.693878\n",
      "epoch 10, iter 28, loss: 32.469905, acc: 0.836735\n",
      "epoch 10, iter 29, loss: 29.550640, acc: 0.877551\n",
      "epoch 10, iter 30, loss: 31.794732, acc: 0.632653\n",
      "epoch 10, iter 31, loss: 35.754667, acc: 0.653061\n",
      "epoch 10, iter 32, loss: 33.586312, acc: 0.857143\n",
      "epoch 10, iter 33, loss: 31.783195, acc: 0.857143\n",
      "epoch 10, iter 34, loss: 32.062910, acc: 0.755102\n",
      "epoch 10, iter 35, loss: 34.040860, acc: 0.693878\n",
      "epoch 10, iter 36, loss: 33.938194, acc: 0.775510\n",
      "epoch 10, iter 37, loss: 31.224329, acc: 0.897959\n",
      "epoch 10, iter 38, loss: 32.144386, acc: 0.734694\n",
      "epoch 10, iter 39, loss: 31.576415, acc: 0.836735\n",
      "epoch 10, iter 40, loss: 33.495648, acc: 0.755102\n",
      "epoch 10, iter 41, loss: 32.496918, acc: 0.836735\n",
      "epoch 10, iter 42, loss: 35.675758, acc: 0.653061\n",
      "epoch 10, iter 43, loss: 32.649703, acc: 0.938776\n",
      "epoch 10, iter 44, loss: 29.737589, acc: 0.897959\n",
      "epoch 10, iter 45, loss: 30.856415, acc: 0.755102\n",
      "epoch 10, iter 46, loss: 31.814743, acc: 0.775510\n",
      "epoch 10, iter 47, loss: 31.132395, acc: 0.795918\n",
      "epoch 10, iter 48, loss: 32.111360, acc: 0.734694\n",
      "epoch 10, iter 49, loss: 31.428231, acc: 0.816327\n",
      "epoch 10, iter 50, loss: 31.806477, acc: 0.836735\n",
      "epoch 10, iter 51, loss: 33.092812, acc: 0.734694\n",
      "epoch 10, iter 52, loss: 32.504311, acc: 0.857143\n",
      "epoch 10, iter 53, loss: 33.200116, acc: 0.795918\n",
      "epoch 10, iter 54, loss: 32.859206, acc: 0.734694\n",
      "epoch 10, iter 55, loss: 32.187900, acc: 0.836735\n",
      "epoch 10, iter 56, loss: 30.889559, acc: 0.816327\n",
      "epoch 10, iter 57, loss: 29.609958, acc: 0.857143\n",
      "epoch 10, iter 58, loss: 30.974406, acc: 0.755102\n",
      "epoch 10, iter 59, loss: 30.858625, acc: 0.816327\n",
      "epoch 10, iter 60, loss: 29.780193, acc: 0.959184\n",
      "epoch 10, iter 61, loss: 30.717134, acc: 0.877551\n",
      "epoch 10, iter 62, loss: 30.599519, acc: 0.816327\n",
      "epoch 10, iter 63, loss: 29.580267, acc: 0.836735\n",
      "epoch 10, iter 64, loss: 32.433423, acc: 0.591837\n",
      "epoch 10, iter 65, loss: 31.146181, acc: 0.816327\n",
      "epoch 10, iter 66, loss: 29.002148, acc: 0.918367\n",
      "epoch 10, iter 67, loss: 31.639175, acc: 0.714286\n",
      "epoch 10, iter 68, loss: 30.001408, acc: 0.816327\n",
      "epoch 10, iter 69, loss: 28.055003, acc: 0.897959\n",
      "epoch 10, iter 70, loss: 27.564568, acc: 0.857143\n",
      "epoch 10, iter 71, loss: 30.195016, acc: 0.775510\n",
      "epoch 10, iter 72, loss: 29.238712, acc: 0.857143\n",
      "epoch 10, iter 73, loss: 27.277582, acc: 0.938776\n",
      "epoch 10, iter 74, loss: 26.281450, acc: 0.836735\n",
      "epoch 10, iter 75, loss: 25.471802, acc: 0.877551\n",
      "epoch 10, iter 76, loss: 28.474845, acc: 0.755102\n",
      "epoch 10, iter 77, loss: 31.381913, acc: 0.693878\n",
      "epoch 10, iter 78, loss: 32.460136, acc: 0.734694\n",
      "epoch 10, iter 79, loss: 30.735432, acc: 0.836735\n",
      "epoch 10, iter 80, loss: 28.751179, acc: 0.897959\n",
      "epoch 10, iter 81, loss: 30.002844, acc: 0.775510\n",
      "epoch 10, iter 82, loss: 30.076763, acc: 0.755102\n",
      "epoch 10, iter 83, loss: 31.767847, acc: 0.755102\n",
      "epoch 10, iter 84, loss: 29.531016, acc: 0.897959\n",
      "epoch 10, iter 85, loss: 27.299072, acc: 0.877551\n",
      "epoch 10, iter 86, loss: 29.959573, acc: 0.693878\n",
      "epoch 10, iter 87, loss: 33.428429, acc: 0.632653\n",
      "epoch 10, iter 88, loss: 31.799589, acc: 0.897959\n",
      "epoch 10, iter 89, loss: 32.051150, acc: 0.755102\n",
      "epoch 10, iter 90, loss: 33.149710, acc: 0.714286\n",
      "epoch 10, iter 91, loss: 33.354437, acc: 0.816327\n",
      "epoch 10, iter 92, loss: 34.859770, acc: 0.734694\n",
      "epoch 10, iter 93, loss: 35.424562, acc: 0.714286\n",
      "epoch 10, iter 94, loss: 33.819975, acc: 0.877551\n",
      "epoch 10, iter 95, loss: 30.656932, acc: 0.938776\n",
      "epoch 10, iter 96, loss: 31.301978, acc: 0.816327\n",
      "epoch 10, iter 97, loss: 31.386778, acc: 0.795918\n",
      "epoch 10, iter 98, loss: 31.620658, acc: 0.775510\n",
      "epoch 10, iter 99, loss: 29.962443, acc: 0.877551\n",
      "epoch 10, iter 100, loss: 34.190891, acc: 0.571429\n",
      "epoch 10, iter 101, loss: 32.897538, acc: 0.816327\n",
      "epoch 10, iter 102, loss: 30.878019, acc: 0.857143\n",
      "epoch 10, iter 103, loss: 29.891567, acc: 0.877551\n",
      "epoch 10, iter 104, loss: 31.401891, acc: 0.755102\n",
      "epoch 10, iter 105, loss: 30.862534, acc: 0.836735\n",
      "epoch 10, iter 106, loss: 30.268447, acc: 0.795918\n",
      "epoch 10, iter 107, loss: 27.569828, acc: 0.938776\n",
      "epoch 10, iter 108, loss: 29.508842, acc: 0.734694\n",
      "epoch 10, iter 109, loss: 31.150578, acc: 0.673469\n",
      "epoch 10, iter 110, loss: 30.756994, acc: 0.836735\n",
      "epoch 10, iter 111, loss: 34.790997, acc: 0.530612\n",
      "epoch 10, iter 112, loss: 35.055555, acc: 0.775510\n",
      "epoch 10, iter 113, loss: 36.952193, acc: 0.714286\n",
      "epoch 10, iter 114, loss: 34.996511, acc: 0.857143\n",
      "epoch 10, iter 115, loss: 34.479345, acc: 0.795918\n",
      "epoch 10, iter 116, loss: 35.667347, acc: 0.673469\n",
      "epoch 10, iter 117, loss: 32.750035, acc: 0.918367\n",
      "epoch 10, iter 118, loss: 35.499815, acc: 0.632653\n",
      "epoch 10, iter 119, loss: 32.480463, acc: 0.938776\n",
      "epoch 10, iter 120, loss: 33.597058, acc: 0.734694\n",
      "epoch 10, iter 121, loss: 31.597629, acc: 0.816327\n",
      "epoch 10, iter 122, loss: 31.584422, acc: 0.795918\n",
      "epoch 10, iter 123, loss: 30.743988, acc: 0.897959\n",
      "epoch 10, iter 124, loss: 31.840729, acc: 0.755102\n",
      "epoch 10, iter 125, loss: 34.397154, acc: 0.693878\n",
      "epoch 10, iter 126, loss: 31.895434, acc: 0.938776\n",
      "epoch 10, iter 127, loss: 35.808940, acc: 0.571429\n",
      "epoch 10, iter 128, loss: 33.493958, acc: 0.877551\n",
      "epoch 10, iter 129, loss: 32.544340, acc: 0.816327\n",
      "epoch 10, iter 130, loss: 30.475235, acc: 0.959184\n",
      "epoch 10, iter 131, loss: 30.066610, acc: 0.795918\n",
      "epoch 10, iter 132, loss: 30.801529, acc: 0.755102\n",
      "epoch 10, iter 133, loss: 29.060465, acc: 0.897959\n",
      "epoch 10, iter 134, loss: 32.362021, acc: 0.632653\n",
      "epoch 10, iter 135, loss: 33.826458, acc: 0.693878\n",
      "epoch 10, iter 136, loss: 33.503500, acc: 0.897959\n",
      "epoch 10, iter 137, loss: 35.110454, acc: 0.857143\n",
      "epoch 10, iter 138, loss: 33.596203, acc: 0.938776\n",
      "epoch 10, iter 139, loss: 32.703406, acc: 0.857143\n",
      "epoch 10, iter 140, loss: 32.372123, acc: 0.795918\n",
      "epoch 10, iter 141, loss: 31.187985, acc: 0.795918\n",
      "epoch 10, iter 142, loss: 31.927410, acc: 0.734694\n",
      "epoch 10, iter 143, loss: 31.097594, acc: 0.857143\n",
      "epoch 10, iter 144, loss: 31.987591, acc: 0.693878\n",
      "epoch 10, iter 145, loss: 30.463245, acc: 0.897959\n",
      "epoch 10, iter 146, loss: 29.940291, acc: 0.877551\n",
      "epoch 10, iter 147, loss: 30.128177, acc: 0.775510\n",
      "epoch 10, iter 148, loss: 29.877194, acc: 0.857143\n",
      "epoch 10, iter 149, loss: 28.041797, acc: 0.938776\n",
      "epoch 10, iter 150, loss: 29.060367, acc: 0.795918\n",
      "epoch 10, iter 151, loss: 29.386749, acc: 0.795918\n",
      "epoch 10, iter 152, loss: 29.399303, acc: 0.816327\n",
      "epoch 10, iter 153, loss: 31.745583, acc: 0.693878\n",
      "epoch 10, iter 154, loss: 32.948648, acc: 0.693878\n",
      "epoch 10, iter 155, loss: 32.110106, acc: 0.795918\n",
      "epoch 10, iter 156, loss: 30.582411, acc: 0.836735\n",
      "epoch 10, iter 157, loss: 31.220901, acc: 0.775510\n",
      "epoch 10, iter 158, loss: 29.569533, acc: 0.897959\n",
      "epoch 10, iter 159, loss: 33.180600, acc: 0.653061\n",
      "epoch 10, iter 160, loss: 34.478520, acc: 0.693878\n",
      "epoch 10, iter 161, loss: 31.978119, acc: 0.877551\n",
      "epoch 10, iter 162, loss: 31.615354, acc: 0.775510\n",
      "epoch 10, iter 163, loss: 31.752272, acc: 0.816327\n",
      "epoch 10, iter 164, loss: 33.037544, acc: 0.734694\n",
      "epoch 10, iter 165, loss: 31.241034, acc: 0.918367\n",
      "epoch 10, iter 166, loss: 30.587105, acc: 0.836735\n",
      "epoch 10, iter 167, loss: 31.965921, acc: 0.714286\n",
      "epoch 10, iter 168, loss: 31.838034, acc: 0.816327\n",
      "epoch 10, iter 169, loss: 31.946404, acc: 0.775510\n",
      "epoch 10, iter 170, loss: 36.126051, acc: 0.673469\n",
      "epoch 10, iter 171, loss: 36.577573, acc: 0.734694\n",
      "epoch 10, iter 172, loss: 36.311669, acc: 0.775510\n",
      "epoch 10, iter 173, loss: 35.108168, acc: 0.755102\n",
      "epoch 10, iter 174, loss: 34.854236, acc: 0.775510\n",
      "epoch 10, iter 175, loss: 33.191711, acc: 0.857143\n",
      "epoch 10, iter 176, loss: 31.222807, acc: 0.877551\n",
      "epoch 10, iter 177, loss: 30.232046, acc: 0.877551\n",
      "epoch 10, iter 178, loss: 31.117530, acc: 0.734694\n",
      "epoch 10, iter 179, loss: 30.303155, acc: 0.816327\n",
      "epoch 10, iter 180, loss: 28.649828, acc: 0.857143\n",
      "epoch 10, iter 181, loss: 30.995670, acc: 0.775510\n",
      "epoch 10, iter 182, loss: 31.043856, acc: 0.816327\n",
      "epoch 10, iter 183, loss: 33.752017, acc: 0.653061\n",
      "epoch 10, iter 184, loss: 32.829239, acc: 0.816327\n",
      "epoch 10, iter 185, loss: 34.024224, acc: 0.775510\n",
      "epoch 10, iter 186, loss: 32.009368, acc: 0.897959\n",
      "epoch 10, iter 187, loss: 33.606522, acc: 0.714286\n",
      "epoch 10, iter 188, loss: 36.245383, acc: 0.632653\n",
      "epoch 10, iter 189, loss: 36.383803, acc: 0.734694\n",
      "epoch 10, iter 190, loss: 35.141423, acc: 0.877551\n",
      "epoch 10, iter 191, loss: 34.209352, acc: 0.877551\n",
      "epoch 10, iter 192, loss: 32.606379, acc: 0.877551\n",
      "epoch 10, iter 193, loss: 34.693128, acc: 0.693878\n",
      "epoch 10, iter 194, loss: 34.098463, acc: 0.734694\n",
      "epoch 10, iter 195, loss: 33.892240, acc: 0.693878\n",
      "epoch 10, iter 196, loss: 31.742255, acc: 0.836735\n",
      "epoch 10, iter 197, loss: 31.969775, acc: 0.775510\n",
      "epoch 10, iter 198, loss: 32.423919, acc: 0.755102\n",
      "epoch 10, iter 199, loss: 32.571093, acc: 0.755102\n",
      "epoch 10, iter 200, loss: 32.217491, acc: 0.795918\n",
      "epoch 10, iter 201, loss: 33.026185, acc: 0.836735\n",
      "epoch 10, iter 202, loss: 31.459685, acc: 0.857143\n",
      "epoch 10, iter 203, loss: 33.269793, acc: 0.755102\n",
      "epoch 10, iter 204, loss: 32.638467, acc: 0.755102\n",
      "epoch 10, iter 205, loss: 37.302986, acc: 0.693878\n",
      "epoch 10, iter 206, loss: 36.583088, acc: 0.755102\n",
      "epoch 10, iter 207, loss: 34.892884, acc: 0.877551\n",
      "epoch 10, iter 208, loss: 33.186772, acc: 0.877551\n",
      "epoch 10, iter 209, loss: 31.343221, acc: 0.918367\n",
      "epoch 10, iter 210, loss: 31.885299, acc: 0.795918\n",
      "epoch 10, iter 211, loss: 30.447017, acc: 0.816327\n",
      "epoch 10, iter 212, loss: 31.617592, acc: 0.734694\n",
      "epoch 10, iter 213, loss: 30.035021, acc: 0.836735\n",
      "epoch 10, iter 214, loss: 28.689591, acc: 0.877551\n",
      "epoch 10, iter 215, loss: 31.309842, acc: 0.693878\n",
      "epoch 10, iter 216, loss: 31.073401, acc: 0.775510\n",
      "epoch 10, iter 217, loss: 33.357226, acc: 0.734694\n",
      "epoch 10, iter 218, loss: 31.876642, acc: 0.877551\n",
      "epoch 10, iter 219, loss: 30.141024, acc: 0.938776\n",
      "epoch 10, iter 220, loss: 32.251989, acc: 0.632653\n",
      "epoch 10, iter 221, loss: 31.448478, acc: 0.836735\n",
      "epoch 10, iter 222, loss: 33.894932, acc: 0.673469\n",
      "epoch 10, iter 223, loss: 30.909759, acc: 0.897959\n",
      "epoch 10, iter 224, loss: 31.221756, acc: 0.775510\n",
      "epoch 10, iter 225, loss: 31.767528, acc: 0.795918\n",
      "epoch 10, iter 226, loss: 32.455743, acc: 0.755102\n",
      "epoch 10, iter 227, loss: 31.523510, acc: 0.836735\n",
      "epoch 10, iter 228, loss: 31.558498, acc: 0.795918\n",
      "epoch 10, iter 229, loss: 28.510454, acc: 0.877551\n",
      "epoch 10, iter 230, loss: 29.164342, acc: 0.795918\n",
      "epoch 10, iter 231, loss: 27.974891, acc: 0.897959\n",
      "epoch 10, iter 232, loss: 29.541947, acc: 0.795918\n",
      "epoch 10, iter 233, loss: 31.519538, acc: 0.734694\n",
      "epoch 10, iter 234, loss: 29.658709, acc: 0.938776\n",
      "epoch 10, iter 235, loss: 30.123301, acc: 0.795918\n",
      "epoch 10, iter 236, loss: 27.661247, acc: 0.959184\n",
      "epoch 10, iter 237, loss: 31.532047, acc: 0.673469\n",
      "epoch 10, iter 238, loss: 34.622510, acc: 0.775510\n",
      "epoch 10, iter 239, loss: 34.376480, acc: 0.775510\n",
      "epoch 10, iter 240, loss: 33.213215, acc: 0.857143\n",
      "epoch 10, iter 241, loss: 32.152733, acc: 0.816327\n",
      "epoch 10, iter 242, loss: 32.901977, acc: 0.775510\n",
      "epoch 10, iter 243, loss: 31.640720, acc: 0.877551\n",
      "epoch 10, iter 244, loss: 30.809032, acc: 0.795918\n",
      "epoch 10, iter 245, loss: 32.813210, acc: 0.795918\n",
      "epoch 10, iter 246, loss: 35.105755, acc: 0.673469\n",
      "epoch 10, iter 247, loss: 34.937942, acc: 0.755102\n",
      "epoch 10, iter 248, loss: 36.962746, acc: 0.714286\n",
      "epoch 10, iter 249, loss: 37.331767, acc: 0.693878\n",
      "epoch 10, acc: 0.796082\n",
      "epoch 11, iter 0, loss: 37.122532, acc: 0.693878\n",
      "epoch 11, iter 1, loss: 37.893584, acc: 0.734694\n",
      "epoch 11, iter 2, loss: 37.197040, acc: 0.714286\n",
      "epoch 11, iter 3, loss: 35.925642, acc: 0.795918\n",
      "epoch 11, iter 4, loss: 34.190420, acc: 0.816327\n",
      "epoch 11, iter 5, loss: 32.325180, acc: 0.918367\n",
      "epoch 11, iter 6, loss: 31.920868, acc: 0.836735\n",
      "epoch 11, iter 7, loss: 33.696133, acc: 0.653061\n",
      "epoch 11, iter 8, loss: 33.800362, acc: 0.755102\n",
      "epoch 11, iter 9, loss: 33.401032, acc: 0.795918\n",
      "epoch 11, iter 10, loss: 33.219684, acc: 0.693878\n",
      "epoch 11, iter 11, loss: 34.564203, acc: 0.693878\n",
      "epoch 11, iter 12, loss: 33.087660, acc: 0.897959\n",
      "epoch 11, iter 13, loss: 32.045910, acc: 0.816327\n",
      "epoch 11, iter 14, loss: 31.123797, acc: 0.836735\n",
      "epoch 11, iter 15, loss: 29.125863, acc: 0.959184\n",
      "epoch 11, iter 16, loss: 30.533171, acc: 0.714286\n",
      "epoch 11, iter 17, loss: 29.648549, acc: 0.836735\n",
      "epoch 11, iter 18, loss: 33.152100, acc: 0.693878\n",
      "epoch 11, iter 19, loss: 30.929607, acc: 0.897959\n",
      "epoch 11, iter 20, loss: 28.288394, acc: 0.897959\n",
      "epoch 11, iter 21, loss: 27.729130, acc: 0.836735\n",
      "epoch 11, iter 22, loss: 26.407808, acc: 0.877551\n",
      "epoch 11, iter 23, loss: 29.701003, acc: 0.653061\n",
      "epoch 11, iter 24, loss: 29.537902, acc: 0.795918\n",
      "epoch 11, iter 25, loss: 31.442837, acc: 0.755102\n",
      "epoch 11, iter 26, loss: 33.563608, acc: 0.775510\n",
      "epoch 11, iter 27, loss: 33.652842, acc: 0.693878\n",
      "epoch 11, iter 28, loss: 32.085747, acc: 0.857143\n",
      "epoch 11, iter 29, loss: 29.259149, acc: 0.877551\n",
      "epoch 11, iter 30, loss: 31.601805, acc: 0.653061\n",
      "epoch 11, iter 31, loss: 35.603995, acc: 0.591837\n",
      "epoch 11, iter 32, loss: 33.609104, acc: 0.836735\n",
      "epoch 11, iter 33, loss: 31.525673, acc: 0.897959\n",
      "epoch 11, iter 34, loss: 31.627824, acc: 0.755102\n",
      "epoch 11, iter 35, loss: 33.640678, acc: 0.714286\n",
      "epoch 11, iter 36, loss: 33.580259, acc: 0.816327\n",
      "epoch 11, iter 37, loss: 30.966547, acc: 0.897959\n",
      "epoch 11, iter 38, loss: 31.903221, acc: 0.714286\n",
      "epoch 11, iter 39, loss: 31.222809, acc: 0.795918\n",
      "epoch 11, iter 40, loss: 33.016384, acc: 0.775510\n",
      "epoch 11, iter 41, loss: 31.994882, acc: 0.857143\n",
      "epoch 11, iter 42, loss: 34.875166, acc: 0.653061\n",
      "epoch 11, iter 43, loss: 32.139567, acc: 0.918367\n",
      "epoch 11, iter 44, loss: 29.405625, acc: 0.877551\n",
      "epoch 11, iter 45, loss: 30.538208, acc: 0.755102\n",
      "epoch 11, iter 46, loss: 31.727258, acc: 0.795918\n",
      "epoch 11, iter 47, loss: 31.075049, acc: 0.755102\n",
      "epoch 11, iter 48, loss: 31.841463, acc: 0.673469\n",
      "epoch 11, iter 49, loss: 31.012547, acc: 0.816327\n",
      "epoch 11, iter 50, loss: 31.385197, acc: 0.816327\n",
      "epoch 11, iter 51, loss: 32.774111, acc: 0.755102\n",
      "epoch 11, iter 52, loss: 32.024421, acc: 0.938776\n",
      "epoch 11, iter 53, loss: 32.725592, acc: 0.775510\n",
      "epoch 11, iter 54, loss: 32.521467, acc: 0.734694\n",
      "epoch 11, iter 55, loss: 31.804818, acc: 0.836735\n",
      "epoch 11, iter 56, loss: 30.458634, acc: 0.836735\n",
      "epoch 11, iter 57, loss: 29.509247, acc: 0.857143\n",
      "epoch 11, iter 58, loss: 30.909014, acc: 0.795918\n",
      "epoch 11, iter 59, loss: 30.821325, acc: 0.816327\n",
      "epoch 11, iter 60, loss: 29.913348, acc: 0.918367\n",
      "epoch 11, iter 61, loss: 30.333354, acc: 0.877551\n",
      "epoch 11, iter 62, loss: 30.311843, acc: 0.836735\n",
      "epoch 11, iter 63, loss: 29.392574, acc: 0.897959\n",
      "epoch 11, iter 64, loss: 31.995598, acc: 0.632653\n",
      "epoch 11, iter 65, loss: 30.717902, acc: 0.775510\n",
      "epoch 11, iter 66, loss: 28.487007, acc: 0.938776\n",
      "epoch 11, iter 67, loss: 31.256155, acc: 0.673469\n",
      "epoch 11, iter 68, loss: 29.875675, acc: 0.795918\n",
      "epoch 11, iter 69, loss: 28.009437, acc: 0.877551\n",
      "epoch 11, iter 70, loss: 27.454547, acc: 0.857143\n",
      "epoch 11, iter 71, loss: 30.018388, acc: 0.775510\n",
      "epoch 11, iter 72, loss: 29.120041, acc: 0.816327\n",
      "epoch 11, iter 73, loss: 26.954440, acc: 0.938776\n",
      "epoch 11, iter 74, loss: 25.942391, acc: 0.857143\n",
      "epoch 11, iter 75, loss: 25.014035, acc: 0.897959\n",
      "epoch 11, iter 76, loss: 28.095784, acc: 0.755102\n",
      "epoch 11, iter 77, loss: 31.092128, acc: 0.673469\n",
      "epoch 11, iter 78, loss: 32.342452, acc: 0.714286\n",
      "epoch 11, iter 79, loss: 30.687042, acc: 0.857143\n",
      "epoch 11, iter 80, loss: 28.687479, acc: 0.897959\n",
      "epoch 11, iter 81, loss: 29.874708, acc: 0.734694\n",
      "epoch 11, iter 82, loss: 29.864891, acc: 0.734694\n",
      "epoch 11, iter 83, loss: 31.430570, acc: 0.755102\n",
      "epoch 11, iter 84, loss: 29.334250, acc: 0.897959\n",
      "epoch 11, iter 85, loss: 27.330547, acc: 0.877551\n",
      "epoch 11, iter 86, loss: 29.694705, acc: 0.693878\n",
      "epoch 11, iter 87, loss: 32.953555, acc: 0.714286\n",
      "epoch 11, iter 88, loss: 31.725085, acc: 0.836735\n",
      "epoch 11, iter 89, loss: 31.953670, acc: 0.734694\n",
      "epoch 11, iter 90, loss: 32.923014, acc: 0.714286\n",
      "epoch 11, iter 91, loss: 33.076760, acc: 0.816327\n",
      "epoch 11, iter 92, loss: 34.478211, acc: 0.755102\n",
      "epoch 11, iter 93, loss: 35.194010, acc: 0.673469\n",
      "epoch 11, iter 94, loss: 33.545831, acc: 0.897959\n",
      "epoch 11, iter 95, loss: 30.336521, acc: 0.897959\n",
      "epoch 11, iter 96, loss: 30.991138, acc: 0.836735\n",
      "epoch 11, iter 97, loss: 31.037724, acc: 0.734694\n",
      "epoch 11, iter 98, loss: 31.229956, acc: 0.775510\n",
      "epoch 11, iter 99, loss: 29.707607, acc: 0.836735\n",
      "epoch 11, iter 100, loss: 33.966450, acc: 0.612245\n",
      "epoch 11, iter 101, loss: 32.686347, acc: 0.775510\n",
      "epoch 11, iter 102, loss: 30.814356, acc: 0.836735\n",
      "epoch 11, iter 103, loss: 29.762043, acc: 0.857143\n",
      "epoch 11, iter 104, loss: 31.190430, acc: 0.755102\n",
      "epoch 11, iter 105, loss: 30.888328, acc: 0.795918\n",
      "epoch 11, iter 106, loss: 30.092687, acc: 0.816327\n",
      "epoch 11, iter 107, loss: 27.338534, acc: 0.938776\n",
      "epoch 11, iter 108, loss: 28.970391, acc: 0.734694\n",
      "epoch 11, iter 109, loss: 30.694129, acc: 0.653061\n",
      "epoch 11, iter 110, loss: 30.417242, acc: 0.795918\n",
      "epoch 11, iter 111, loss: 34.531671, acc: 0.571429\n",
      "epoch 11, iter 112, loss: 34.537529, acc: 0.816327\n",
      "epoch 11, iter 113, loss: 36.361574, acc: 0.693878\n",
      "epoch 11, iter 114, loss: 34.566254, acc: 0.836735\n",
      "epoch 11, iter 115, loss: 34.028316, acc: 0.775510\n",
      "epoch 11, iter 116, loss: 35.227122, acc: 0.693878\n",
      "epoch 11, iter 117, loss: 32.456486, acc: 0.897959\n",
      "epoch 11, iter 118, loss: 35.107981, acc: 0.673469\n",
      "epoch 11, iter 119, loss: 32.238540, acc: 0.918367\n",
      "epoch 11, iter 120, loss: 33.260238, acc: 0.755102\n",
      "epoch 11, iter 121, loss: 31.218532, acc: 0.816327\n",
      "epoch 11, iter 122, loss: 31.016263, acc: 0.755102\n",
      "epoch 11, iter 123, loss: 30.593300, acc: 0.836735\n",
      "epoch 11, iter 124, loss: 31.770763, acc: 0.836735\n",
      "epoch 11, iter 125, loss: 34.062370, acc: 0.673469\n",
      "epoch 11, iter 126, loss: 31.533784, acc: 0.938776\n",
      "epoch 11, iter 127, loss: 35.863450, acc: 0.551020\n",
      "epoch 11, iter 128, loss: 33.461491, acc: 0.897959\n",
      "epoch 11, iter 129, loss: 32.340739, acc: 0.795918\n",
      "epoch 11, iter 130, loss: 30.279322, acc: 0.938776\n",
      "epoch 11, iter 131, loss: 29.767603, acc: 0.816327\n",
      "epoch 11, iter 132, loss: 30.646396, acc: 0.734694\n",
      "epoch 11, iter 133, loss: 28.919458, acc: 0.897959\n",
      "epoch 11, iter 134, loss: 32.321266, acc: 0.612245\n",
      "epoch 11, iter 135, loss: 33.616698, acc: 0.714286\n",
      "epoch 11, iter 136, loss: 33.173896, acc: 0.897959\n",
      "epoch 11, iter 137, loss: 33.060219, acc: 0.857143\n",
      "epoch 11, iter 138, loss: 32.409961, acc: 0.897959\n",
      "epoch 11, iter 139, loss: 31.775094, acc: 0.816327\n",
      "epoch 11, iter 140, loss: 31.903884, acc: 0.795918\n",
      "epoch 11, iter 141, loss: 30.619750, acc: 0.816327\n",
      "epoch 11, iter 142, loss: 31.712020, acc: 0.714286\n",
      "epoch 11, iter 143, loss: 30.999896, acc: 0.836735\n",
      "epoch 11, iter 144, loss: 31.887771, acc: 0.653061\n",
      "epoch 11, iter 145, loss: 30.075377, acc: 0.897959\n",
      "epoch 11, iter 146, loss: 29.712665, acc: 0.857143\n",
      "epoch 11, iter 147, loss: 29.850764, acc: 0.795918\n",
      "epoch 11, iter 148, loss: 29.692978, acc: 0.857143\n",
      "epoch 11, iter 149, loss: 27.797802, acc: 0.938776\n",
      "epoch 11, iter 150, loss: 28.851301, acc: 0.795918\n",
      "epoch 11, iter 151, loss: 29.249014, acc: 0.775510\n",
      "epoch 11, iter 152, loss: 29.296211, acc: 0.816327\n",
      "epoch 11, iter 153, loss: 31.649373, acc: 0.693878\n",
      "epoch 11, iter 154, loss: 32.870141, acc: 0.693878\n",
      "epoch 11, iter 155, loss: 31.972396, acc: 0.816327\n",
      "epoch 11, iter 156, loss: 30.296655, acc: 0.816327\n",
      "epoch 11, iter 157, loss: 31.105853, acc: 0.775510\n",
      "epoch 11, iter 158, loss: 29.348758, acc: 0.877551\n",
      "epoch 11, iter 159, loss: 32.905628, acc: 0.632653\n",
      "epoch 11, iter 160, loss: 34.233697, acc: 0.653061\n",
      "epoch 11, iter 161, loss: 31.745104, acc: 0.857143\n",
      "epoch 11, iter 162, loss: 31.375324, acc: 0.755102\n",
      "epoch 11, iter 163, loss: 31.606279, acc: 0.816327\n",
      "epoch 11, iter 164, loss: 33.022233, acc: 0.734694\n",
      "epoch 11, iter 165, loss: 30.914675, acc: 0.918367\n",
      "epoch 11, iter 166, loss: 30.193566, acc: 0.836735\n",
      "epoch 11, iter 167, loss: 31.559806, acc: 0.714286\n",
      "epoch 11, iter 168, loss: 31.383172, acc: 0.816327\n",
      "epoch 11, iter 169, loss: 31.502853, acc: 0.816327\n",
      "epoch 11, iter 170, loss: 35.424606, acc: 0.653061\n",
      "epoch 11, iter 171, loss: 36.365787, acc: 0.734694\n",
      "epoch 11, iter 172, loss: 36.036608, acc: 0.775510\n",
      "epoch 11, iter 173, loss: 34.892048, acc: 0.734694\n",
      "epoch 11, iter 174, loss: 34.644598, acc: 0.816327\n",
      "epoch 11, iter 175, loss: 33.094737, acc: 0.857143\n",
      "epoch 11, iter 176, loss: 31.047541, acc: 0.857143\n",
      "epoch 11, iter 177, loss: 30.062610, acc: 0.877551\n",
      "epoch 11, iter 178, loss: 31.012031, acc: 0.734694\n",
      "epoch 11, iter 179, loss: 30.101721, acc: 0.795918\n",
      "epoch 11, iter 180, loss: 28.407538, acc: 0.857143\n",
      "epoch 11, iter 181, loss: 30.960086, acc: 0.734694\n",
      "epoch 11, iter 182, loss: 30.822287, acc: 0.795918\n",
      "epoch 11, iter 183, loss: 33.488846, acc: 0.632653\n",
      "epoch 11, iter 184, loss: 32.463513, acc: 0.816327\n",
      "epoch 11, iter 185, loss: 33.702531, acc: 0.734694\n",
      "epoch 11, iter 186, loss: 31.508890, acc: 0.897959\n",
      "epoch 11, iter 187, loss: 33.247003, acc: 0.714286\n",
      "epoch 11, iter 188, loss: 35.966004, acc: 0.632653\n",
      "epoch 11, iter 189, loss: 36.109025, acc: 0.755102\n",
      "epoch 11, iter 190, loss: 34.953147, acc: 0.877551\n",
      "epoch 11, iter 191, loss: 33.657855, acc: 0.918367\n",
      "epoch 11, iter 192, loss: 32.376921, acc: 0.857143\n",
      "epoch 11, iter 193, loss: 34.572712, acc: 0.673469\n",
      "epoch 11, iter 194, loss: 33.663959, acc: 0.734694\n",
      "epoch 11, iter 195, loss: 33.608066, acc: 0.734694\n",
      "epoch 11, iter 196, loss: 31.569762, acc: 0.857143\n",
      "epoch 11, iter 197, loss: 31.941821, acc: 0.775510\n",
      "epoch 11, iter 198, loss: 32.144192, acc: 0.775510\n",
      "epoch 11, iter 199, loss: 32.346337, acc: 0.755102\n",
      "epoch 11, iter 200, loss: 32.050862, acc: 0.775510\n",
      "epoch 11, iter 201, loss: 32.808115, acc: 0.795918\n",
      "epoch 11, iter 202, loss: 31.147805, acc: 0.857143\n",
      "epoch 11, iter 203, loss: 33.069043, acc: 0.734694\n",
      "epoch 11, iter 204, loss: 32.721677, acc: 0.755102\n",
      "epoch 11, iter 205, loss: 37.158238, acc: 0.714286\n",
      "epoch 11, iter 206, loss: 36.688184, acc: 0.775510\n",
      "epoch 11, iter 207, loss: 35.090958, acc: 0.857143\n",
      "epoch 11, iter 208, loss: 33.127984, acc: 0.897959\n",
      "epoch 11, iter 209, loss: 31.302713, acc: 0.918367\n",
      "epoch 11, iter 210, loss: 31.812849, acc: 0.795918\n",
      "epoch 11, iter 211, loss: 30.354128, acc: 0.836735\n",
      "epoch 11, iter 212, loss: 31.415520, acc: 0.734694\n",
      "epoch 11, iter 213, loss: 29.865115, acc: 0.857143\n",
      "epoch 11, iter 214, loss: 28.613986, acc: 0.877551\n",
      "epoch 11, iter 215, loss: 31.274770, acc: 0.714286\n",
      "epoch 11, iter 216, loss: 30.969297, acc: 0.775510\n",
      "epoch 11, iter 217, loss: 33.209298, acc: 0.734694\n",
      "epoch 11, iter 218, loss: 31.877126, acc: 0.857143\n",
      "epoch 11, iter 219, loss: 30.037638, acc: 0.938776\n",
      "epoch 11, iter 220, loss: 32.125856, acc: 0.612245\n",
      "epoch 11, iter 221, loss: 31.339984, acc: 0.816327\n",
      "epoch 11, iter 222, loss: 33.787378, acc: 0.673469\n",
      "epoch 11, iter 223, loss: 30.835517, acc: 0.897959\n",
      "epoch 11, iter 224, loss: 31.095754, acc: 0.755102\n",
      "epoch 11, iter 225, loss: 31.607345, acc: 0.795918\n",
      "epoch 11, iter 226, loss: 32.295985, acc: 0.734694\n",
      "epoch 11, iter 227, loss: 31.417919, acc: 0.836735\n",
      "epoch 11, iter 228, loss: 31.488159, acc: 0.795918\n",
      "epoch 11, iter 229, loss: 28.374272, acc: 0.877551\n",
      "epoch 11, iter 230, loss: 29.052708, acc: 0.795918\n",
      "epoch 11, iter 231, loss: 27.930589, acc: 0.897959\n",
      "epoch 11, iter 232, loss: 29.513651, acc: 0.775510\n",
      "epoch 11, iter 233, loss: 31.421516, acc: 0.714286\n",
      "epoch 11, iter 234, loss: 29.567267, acc: 0.938776\n",
      "epoch 11, iter 235, loss: 29.973243, acc: 0.795918\n",
      "epoch 11, iter 236, loss: 27.586851, acc: 0.959184\n",
      "epoch 11, iter 237, loss: 31.327084, acc: 0.591837\n",
      "epoch 11, iter 238, loss: 34.296330, acc: 0.734694\n",
      "epoch 11, iter 239, loss: 34.132537, acc: 0.816327\n",
      "epoch 11, iter 240, loss: 33.033533, acc: 0.816327\n",
      "epoch 11, iter 241, loss: 32.006900, acc: 0.816327\n",
      "epoch 11, iter 242, loss: 32.844094, acc: 0.775510\n",
      "epoch 11, iter 243, loss: 31.534044, acc: 0.918367\n",
      "epoch 11, iter 244, loss: 30.673749, acc: 0.795918\n",
      "epoch 11, iter 245, loss: 32.299995, acc: 0.775510\n",
      "epoch 11, iter 246, loss: 34.753586, acc: 0.693878\n",
      "epoch 11, iter 247, loss: 34.559630, acc: 0.734694\n",
      "epoch 11, iter 248, loss: 36.905349, acc: 0.734694\n",
      "epoch 11, iter 249, loss: 37.031686, acc: 0.693878\n",
      "epoch 11, acc: 0.792327\n",
      "epoch 12, iter 0, loss: 36.597947, acc: 0.673469\n",
      "epoch 12, iter 1, loss: 37.420080, acc: 0.755102\n",
      "epoch 12, iter 2, loss: 36.964730, acc: 0.734694\n",
      "epoch 12, iter 3, loss: 35.585927, acc: 0.795918\n",
      "epoch 12, iter 4, loss: 33.738651, acc: 0.836735\n",
      "epoch 12, iter 5, loss: 32.113341, acc: 0.918367\n",
      "epoch 12, iter 6, loss: 31.711819, acc: 0.836735\n",
      "epoch 12, iter 7, loss: 33.341553, acc: 0.632653\n",
      "epoch 12, iter 8, loss: 33.283663, acc: 0.775510\n",
      "epoch 12, iter 9, loss: 32.923248, acc: 0.775510\n",
      "epoch 12, iter 10, loss: 32.816844, acc: 0.693878\n",
      "epoch 12, iter 11, loss: 34.393143, acc: 0.734694\n",
      "epoch 12, iter 12, loss: 32.862266, acc: 0.897959\n",
      "epoch 12, iter 13, loss: 31.897982, acc: 0.836735\n",
      "epoch 12, iter 14, loss: 30.952127, acc: 0.836735\n",
      "epoch 12, iter 15, loss: 28.936497, acc: 0.938776\n",
      "epoch 12, iter 16, loss: 30.358320, acc: 0.693878\n",
      "epoch 12, iter 17, loss: 29.591360, acc: 0.857143\n",
      "epoch 12, iter 18, loss: 32.932365, acc: 0.714286\n",
      "epoch 12, iter 19, loss: 30.836741, acc: 0.877551\n",
      "epoch 12, iter 20, loss: 28.190546, acc: 0.897959\n",
      "epoch 12, iter 21, loss: 27.705228, acc: 0.836735\n",
      "epoch 12, iter 22, loss: 26.371184, acc: 0.877551\n",
      "epoch 12, iter 23, loss: 29.632002, acc: 0.693878\n",
      "epoch 12, iter 24, loss: 29.482583, acc: 0.795918\n",
      "epoch 12, iter 25, loss: 31.392204, acc: 0.775510\n",
      "epoch 12, iter 26, loss: 33.337378, acc: 0.795918\n",
      "epoch 12, iter 27, loss: 33.544813, acc: 0.714286\n",
      "epoch 12, iter 28, loss: 31.986134, acc: 0.816327\n",
      "epoch 12, iter 29, loss: 29.070664, acc: 0.877551\n",
      "epoch 12, iter 30, loss: 31.375926, acc: 0.673469\n",
      "epoch 12, iter 31, loss: 35.368318, acc: 0.571429\n",
      "epoch 12, iter 32, loss: 33.415146, acc: 0.816327\n",
      "epoch 12, iter 33, loss: 31.310217, acc: 0.897959\n",
      "epoch 12, iter 34, loss: 31.438806, acc: 0.755102\n",
      "epoch 12, iter 35, loss: 33.551264, acc: 0.693878\n",
      "epoch 12, iter 36, loss: 33.520849, acc: 0.795918\n",
      "epoch 12, iter 37, loss: 30.907397, acc: 0.897959\n",
      "epoch 12, iter 38, loss: 31.780907, acc: 0.714286\n",
      "epoch 12, iter 39, loss: 30.994616, acc: 0.816327\n",
      "epoch 12, iter 40, loss: 32.743235, acc: 0.775510\n",
      "epoch 12, iter 41, loss: 31.720974, acc: 0.857143\n",
      "epoch 12, iter 42, loss: 34.499496, acc: 0.653061\n",
      "epoch 12, iter 43, loss: 31.899879, acc: 0.918367\n",
      "epoch 12, iter 44, loss: 29.337662, acc: 0.897959\n",
      "epoch 12, iter 45, loss: 30.421988, acc: 0.755102\n",
      "epoch 12, iter 46, loss: 31.608733, acc: 0.816327\n",
      "epoch 12, iter 47, loss: 30.890561, acc: 0.755102\n",
      "epoch 12, iter 48, loss: 31.584768, acc: 0.693878\n",
      "epoch 12, iter 49, loss: 30.755989, acc: 0.816327\n",
      "epoch 12, iter 50, loss: 31.189299, acc: 0.816327\n",
      "epoch 12, iter 51, loss: 32.580632, acc: 0.714286\n",
      "epoch 12, iter 52, loss: 31.973702, acc: 0.897959\n",
      "epoch 12, iter 53, loss: 32.345363, acc: 0.775510\n",
      "epoch 12, iter 54, loss: 32.316153, acc: 0.734694\n",
      "epoch 12, iter 55, loss: 31.721125, acc: 0.836735\n",
      "epoch 12, iter 56, loss: 30.281270, acc: 0.836735\n",
      "epoch 12, iter 57, loss: 29.307541, acc: 0.857143\n",
      "epoch 12, iter 58, loss: 30.624866, acc: 0.795918\n",
      "epoch 12, iter 59, loss: 30.635735, acc: 0.816327\n",
      "epoch 12, iter 60, loss: 29.777212, acc: 0.918367\n",
      "epoch 12, iter 61, loss: 30.138177, acc: 0.877551\n",
      "epoch 12, iter 62, loss: 30.184857, acc: 0.836735\n",
      "epoch 12, iter 63, loss: 29.308231, acc: 0.897959\n",
      "epoch 12, iter 64, loss: 31.861425, acc: 0.591837\n",
      "epoch 12, iter 65, loss: 30.564307, acc: 0.816327\n",
      "epoch 12, iter 66, loss: 28.301368, acc: 0.897959\n",
      "epoch 12, iter 67, loss: 31.165701, acc: 0.673469\n",
      "epoch 12, iter 68, loss: 29.601090, acc: 0.775510\n",
      "epoch 12, iter 69, loss: 27.788673, acc: 0.877551\n",
      "epoch 12, iter 70, loss: 27.281878, acc: 0.836735\n",
      "epoch 12, iter 71, loss: 29.738269, acc: 0.755102\n",
      "epoch 12, iter 72, loss: 28.873724, acc: 0.836735\n",
      "epoch 12, iter 73, loss: 26.758472, acc: 0.938776\n",
      "epoch 12, iter 74, loss: 25.619742, acc: 0.857143\n",
      "epoch 12, iter 75, loss: 24.802780, acc: 0.877551\n",
      "epoch 12, iter 76, loss: 28.001012, acc: 0.755102\n",
      "epoch 12, iter 77, loss: 30.939388, acc: 0.673469\n",
      "epoch 12, iter 78, loss: 32.122699, acc: 0.693878\n",
      "epoch 12, iter 79, loss: 30.530831, acc: 0.836735\n",
      "epoch 12, iter 80, loss: 28.731822, acc: 0.897959\n",
      "epoch 12, iter 81, loss: 29.852288, acc: 0.734694\n",
      "epoch 12, iter 82, loss: 29.909292, acc: 0.734694\n",
      "epoch 12, iter 83, loss: 31.374306, acc: 0.734694\n",
      "epoch 12, iter 84, loss: 29.335771, acc: 0.877551\n",
      "epoch 12, iter 85, loss: 27.314785, acc: 0.897959\n",
      "epoch 12, iter 86, loss: 29.563698, acc: 0.693878\n",
      "epoch 12, iter 87, loss: 32.904337, acc: 0.714286\n",
      "epoch 12, iter 88, loss: 31.553479, acc: 0.857143\n",
      "epoch 12, iter 89, loss: 31.946764, acc: 0.714286\n",
      "epoch 12, iter 90, loss: 32.870102, acc: 0.693878\n",
      "epoch 12, iter 91, loss: 32.937653, acc: 0.816327\n",
      "epoch 12, iter 92, loss: 34.354293, acc: 0.734694\n",
      "epoch 12, iter 93, loss: 35.009186, acc: 0.693878\n",
      "epoch 12, iter 94, loss: 33.309085, acc: 0.897959\n",
      "epoch 12, iter 95, loss: 30.073003, acc: 0.918367\n",
      "epoch 12, iter 96, loss: 30.707770, acc: 0.836735\n",
      "epoch 12, iter 97, loss: 30.812700, acc: 0.734694\n",
      "epoch 12, iter 98, loss: 31.080247, acc: 0.775510\n",
      "epoch 12, iter 99, loss: 29.592148, acc: 0.836735\n",
      "epoch 12, iter 100, loss: 33.849213, acc: 0.612245\n",
      "epoch 12, iter 101, loss: 32.610864, acc: 0.775510\n",
      "epoch 12, iter 102, loss: 30.760829, acc: 0.836735\n",
      "epoch 12, iter 103, loss: 29.588617, acc: 0.857143\n",
      "epoch 12, iter 104, loss: 31.103720, acc: 0.755102\n",
      "epoch 12, iter 105, loss: 30.817825, acc: 0.795918\n",
      "epoch 12, iter 106, loss: 29.938912, acc: 0.816327\n",
      "epoch 12, iter 107, loss: 27.194906, acc: 0.938776\n",
      "epoch 12, iter 108, loss: 28.824212, acc: 0.734694\n",
      "epoch 12, iter 109, loss: 30.514981, acc: 0.653061\n",
      "epoch 12, iter 110, loss: 30.299598, acc: 0.775510\n",
      "epoch 12, iter 111, loss: 34.337376, acc: 0.571429\n",
      "epoch 12, iter 112, loss: 34.388595, acc: 0.857143\n",
      "epoch 12, iter 113, loss: 36.101032, acc: 0.714286\n",
      "epoch 12, iter 114, loss: 34.594622, acc: 0.836735\n",
      "epoch 12, iter 115, loss: 33.767593, acc: 0.755102\n",
      "epoch 12, iter 116, loss: 34.833894, acc: 0.673469\n",
      "epoch 12, iter 117, loss: 32.169324, acc: 0.938776\n",
      "epoch 12, iter 118, loss: 34.852055, acc: 0.653061\n",
      "epoch 12, iter 119, loss: 31.989749, acc: 0.877551\n",
      "epoch 12, iter 120, loss: 32.931912, acc: 0.755102\n",
      "epoch 12, iter 121, loss: 31.161969, acc: 0.836735\n",
      "epoch 12, iter 122, loss: 31.327286, acc: 0.755102\n",
      "epoch 12, iter 123, loss: 30.860696, acc: 0.836735\n",
      "epoch 12, iter 124, loss: 32.013730, acc: 0.816327\n",
      "epoch 12, iter 125, loss: 34.086060, acc: 0.693878\n",
      "epoch 12, iter 126, loss: 31.451862, acc: 0.959184\n",
      "epoch 12, iter 127, loss: 35.743512, acc: 0.571429\n",
      "epoch 12, iter 128, loss: 33.560560, acc: 0.897959\n",
      "epoch 12, iter 129, loss: 32.491928, acc: 0.775510\n",
      "epoch 12, iter 130, loss: 30.293714, acc: 0.959184\n",
      "epoch 12, iter 131, loss: 29.778603, acc: 0.816327\n",
      "epoch 12, iter 132, loss: 30.511256, acc: 0.755102\n",
      "epoch 12, iter 133, loss: 28.832106, acc: 0.897959\n",
      "epoch 12, iter 134, loss: 32.371955, acc: 0.612245\n",
      "epoch 12, iter 135, loss: 33.414878, acc: 0.734694\n",
      "epoch 12, iter 136, loss: 33.107030, acc: 0.897959\n",
      "epoch 12, iter 137, loss: 32.475750, acc: 0.897959\n",
      "epoch 12, iter 138, loss: 31.843909, acc: 0.897959\n",
      "epoch 12, iter 139, loss: 31.439256, acc: 0.795918\n",
      "epoch 12, iter 140, loss: 31.679306, acc: 0.795918\n",
      "epoch 12, iter 141, loss: 30.346323, acc: 0.816327\n",
      "epoch 12, iter 142, loss: 31.514509, acc: 0.693878\n",
      "epoch 12, iter 143, loss: 30.922392, acc: 0.836735\n",
      "epoch 12, iter 144, loss: 31.800720, acc: 0.653061\n",
      "epoch 12, iter 145, loss: 29.863924, acc: 0.897959\n",
      "epoch 12, iter 146, loss: 29.606749, acc: 0.857143\n",
      "epoch 12, iter 147, loss: 29.711044, acc: 0.836735\n",
      "epoch 12, iter 148, loss: 29.550044, acc: 0.857143\n",
      "epoch 12, iter 149, loss: 27.662631, acc: 0.938776\n",
      "epoch 12, iter 150, loss: 28.791740, acc: 0.795918\n",
      "epoch 12, iter 151, loss: 29.210508, acc: 0.775510\n",
      "epoch 12, iter 152, loss: 29.108539, acc: 0.816327\n",
      "epoch 12, iter 153, loss: 31.486765, acc: 0.693878\n",
      "epoch 12, iter 154, loss: 32.685638, acc: 0.714286\n",
      "epoch 12, iter 155, loss: 31.747745, acc: 0.795918\n",
      "epoch 12, iter 156, loss: 30.126740, acc: 0.836735\n",
      "epoch 12, iter 157, loss: 31.259193, acc: 0.775510\n",
      "epoch 12, iter 158, loss: 28.865136, acc: 0.877551\n",
      "epoch 12, iter 159, loss: 32.984457, acc: 0.632653\n",
      "epoch 12, iter 160, loss: 34.128413, acc: 0.673469\n",
      "epoch 12, iter 161, loss: 31.666517, acc: 0.816327\n",
      "epoch 12, iter 162, loss: 31.458427, acc: 0.755102\n",
      "epoch 12, iter 163, loss: 31.795992, acc: 0.816327\n",
      "epoch 12, iter 164, loss: 32.899969, acc: 0.734694\n",
      "epoch 12, iter 165, loss: 30.587057, acc: 0.918367\n",
      "epoch 12, iter 166, loss: 29.909077, acc: 0.836735\n",
      "epoch 12, iter 167, loss: 31.298243, acc: 0.673469\n",
      "epoch 12, iter 168, loss: 31.390363, acc: 0.795918\n",
      "epoch 12, iter 169, loss: 31.396783, acc: 0.816327\n",
      "epoch 12, iter 170, loss: 35.217981, acc: 0.632653\n",
      "epoch 12, iter 171, loss: 36.238754, acc: 0.734694\n",
      "epoch 12, iter 172, loss: 35.884543, acc: 0.775510\n",
      "epoch 12, iter 173, loss: 34.968043, acc: 0.714286\n",
      "epoch 12, iter 174, loss: 34.441212, acc: 0.816327\n",
      "epoch 12, iter 175, loss: 32.870972, acc: 0.857143\n",
      "epoch 12, iter 176, loss: 30.906482, acc: 0.857143\n",
      "epoch 12, iter 177, loss: 29.919941, acc: 0.877551\n",
      "epoch 12, iter 178, loss: 30.798564, acc: 0.755102\n",
      "epoch 12, iter 179, loss: 30.066766, acc: 0.795918\n",
      "epoch 12, iter 180, loss: 28.295453, acc: 0.857143\n",
      "epoch 12, iter 181, loss: 30.692378, acc: 0.734694\n",
      "epoch 12, iter 182, loss: 30.510915, acc: 0.816327\n",
      "epoch 12, iter 183, loss: 33.249041, acc: 0.612245\n",
      "epoch 12, iter 184, loss: 32.306499, acc: 0.795918\n",
      "epoch 12, iter 185, loss: 33.648813, acc: 0.755102\n",
      "epoch 12, iter 186, loss: 31.284519, acc: 0.938776\n",
      "epoch 12, iter 187, loss: 33.158599, acc: 0.734694\n",
      "epoch 12, iter 188, loss: 35.776247, acc: 0.632653\n",
      "epoch 12, iter 189, loss: 35.946520, acc: 0.734694\n",
      "epoch 12, iter 190, loss: 34.767810, acc: 0.857143\n",
      "epoch 12, iter 191, loss: 33.561994, acc: 0.897959\n",
      "epoch 12, iter 192, loss: 32.384642, acc: 0.857143\n",
      "epoch 12, iter 193, loss: 34.356245, acc: 0.734694\n",
      "epoch 12, iter 194, loss: 33.427402, acc: 0.755102\n",
      "epoch 12, iter 195, loss: 33.356570, acc: 0.734694\n",
      "epoch 12, iter 196, loss: 31.316319, acc: 0.836735\n",
      "epoch 12, iter 197, loss: 31.626399, acc: 0.775510\n",
      "epoch 12, iter 198, loss: 31.704631, acc: 0.795918\n",
      "epoch 12, iter 199, loss: 31.983895, acc: 0.755102\n",
      "epoch 12, iter 200, loss: 31.761207, acc: 0.775510\n",
      "epoch 12, iter 201, loss: 32.372365, acc: 0.816327\n",
      "epoch 12, iter 202, loss: 30.765601, acc: 0.877551\n",
      "epoch 12, iter 203, loss: 32.703897, acc: 0.755102\n",
      "epoch 12, iter 204, loss: 32.478692, acc: 0.775510\n",
      "epoch 12, iter 205, loss: 36.763174, acc: 0.673469\n",
      "epoch 12, iter 206, loss: 36.230756, acc: 0.755102\n",
      "epoch 12, iter 207, loss: 34.687888, acc: 0.877551\n",
      "epoch 12, iter 208, loss: 32.699494, acc: 0.897959\n",
      "epoch 12, iter 209, loss: 30.897711, acc: 0.918367\n",
      "epoch 12, iter 210, loss: 31.426407, acc: 0.795918\n",
      "epoch 12, iter 211, loss: 30.148235, acc: 0.816327\n",
      "epoch 12, iter 212, loss: 31.141308, acc: 0.734694\n",
      "epoch 12, iter 213, loss: 29.700744, acc: 0.857143\n",
      "epoch 12, iter 214, loss: 28.466653, acc: 0.877551\n",
      "epoch 12, iter 215, loss: 31.187236, acc: 0.693878\n",
      "epoch 12, iter 216, loss: 30.794973, acc: 0.775510\n",
      "epoch 12, iter 217, loss: 33.099045, acc: 0.775510\n",
      "epoch 12, iter 218, loss: 31.832271, acc: 0.877551\n",
      "epoch 12, iter 219, loss: 29.932570, acc: 0.938776\n",
      "epoch 12, iter 220, loss: 32.188610, acc: 0.591837\n",
      "epoch 12, iter 221, loss: 31.382112, acc: 0.795918\n",
      "epoch 12, iter 222, loss: 33.762684, acc: 0.673469\n",
      "epoch 12, iter 223, loss: 30.707165, acc: 0.897959\n",
      "epoch 12, iter 224, loss: 30.932791, acc: 0.795918\n",
      "epoch 12, iter 225, loss: 31.530463, acc: 0.816327\n",
      "epoch 12, iter 226, loss: 32.097485, acc: 0.734694\n",
      "epoch 12, iter 227, loss: 31.243076, acc: 0.836735\n",
      "epoch 12, iter 228, loss: 31.421072, acc: 0.795918\n",
      "epoch 12, iter 229, loss: 28.251050, acc: 0.897959\n",
      "epoch 12, iter 230, loss: 29.010884, acc: 0.775510\n",
      "epoch 12, iter 231, loss: 27.907561, acc: 0.877551\n",
      "epoch 12, iter 232, loss: 29.552796, acc: 0.795918\n",
      "epoch 12, iter 233, loss: 31.418294, acc: 0.693878\n",
      "epoch 12, iter 234, loss: 29.474623, acc: 0.938776\n",
      "epoch 12, iter 235, loss: 29.854315, acc: 0.795918\n",
      "epoch 12, iter 236, loss: 27.558130, acc: 0.959184\n",
      "epoch 12, iter 237, loss: 31.107381, acc: 0.612245\n",
      "epoch 12, iter 238, loss: 33.954702, acc: 0.734694\n",
      "epoch 12, iter 239, loss: 33.826946, acc: 0.816327\n",
      "epoch 12, iter 240, loss: 32.835221, acc: 0.857143\n",
      "epoch 12, iter 241, loss: 31.857867, acc: 0.816327\n",
      "epoch 12, iter 242, loss: 32.727386, acc: 0.775510\n",
      "epoch 12, iter 243, loss: 31.516794, acc: 0.897959\n",
      "epoch 12, iter 244, loss: 30.806682, acc: 0.816327\n",
      "epoch 12, iter 245, loss: 31.563576, acc: 0.755102\n",
      "epoch 12, iter 246, loss: 34.914204, acc: 0.693878\n",
      "epoch 12, iter 247, loss: 34.579984, acc: 0.755102\n",
      "epoch 12, iter 248, loss: 37.750988, acc: 0.734694\n",
      "epoch 12, iter 249, loss: 37.377025, acc: 0.734694\n",
      "epoch 12, acc: 0.793061\n",
      "epoch 13, iter 0, loss: 36.884524, acc: 0.653061\n",
      "epoch 13, iter 1, loss: 37.652515, acc: 0.714286\n",
      "epoch 13, iter 2, loss: 36.924641, acc: 0.734694\n",
      "epoch 13, iter 3, loss: 35.766665, acc: 0.816327\n",
      "epoch 13, iter 4, loss: 33.700286, acc: 0.816327\n",
      "epoch 13, iter 5, loss: 32.172400, acc: 0.897959\n",
      "epoch 13, iter 6, loss: 31.236853, acc: 0.857143\n",
      "epoch 13, iter 7, loss: 32.834144, acc: 0.632653\n",
      "epoch 13, iter 8, loss: 32.928535, acc: 0.755102\n",
      "epoch 13, iter 9, loss: 32.578700, acc: 0.795918\n",
      "epoch 13, iter 10, loss: 32.504475, acc: 0.693878\n",
      "epoch 13, iter 11, loss: 34.331002, acc: 0.714286\n",
      "epoch 13, iter 12, loss: 32.990947, acc: 0.877551\n",
      "epoch 13, iter 13, loss: 31.979953, acc: 0.836735\n",
      "epoch 13, iter 14, loss: 31.037956, acc: 0.836735\n",
      "epoch 13, iter 15, loss: 28.909828, acc: 0.918367\n",
      "epoch 13, iter 16, loss: 30.234016, acc: 0.693878\n",
      "epoch 13, iter 17, loss: 29.612583, acc: 0.877551\n",
      "epoch 13, iter 18, loss: 32.675821, acc: 0.714286\n",
      "epoch 13, iter 19, loss: 30.602664, acc: 0.877551\n",
      "epoch 13, iter 20, loss: 28.023490, acc: 0.897959\n",
      "epoch 13, iter 21, loss: 27.538941, acc: 0.836735\n",
      "epoch 13, iter 22, loss: 26.322965, acc: 0.877551\n",
      "epoch 13, iter 23, loss: 29.527874, acc: 0.673469\n",
      "epoch 13, iter 24, loss: 29.430820, acc: 0.795918\n",
      "epoch 13, iter 25, loss: 31.370498, acc: 0.734694\n",
      "epoch 13, iter 26, loss: 33.098811, acc: 0.795918\n",
      "epoch 13, iter 27, loss: 33.413403, acc: 0.714286\n",
      "epoch 13, iter 28, loss: 31.864413, acc: 0.816327\n",
      "epoch 13, iter 29, loss: 28.948712, acc: 0.857143\n",
      "epoch 13, iter 30, loss: 31.202672, acc: 0.693878\n",
      "epoch 13, iter 31, loss: 35.157232, acc: 0.571429\n",
      "epoch 13, iter 32, loss: 33.183997, acc: 0.816327\n",
      "epoch 13, iter 33, loss: 31.092437, acc: 0.897959\n",
      "epoch 13, iter 34, loss: 31.251192, acc: 0.714286\n",
      "epoch 13, iter 35, loss: 33.402389, acc: 0.693878\n",
      "epoch 13, iter 36, loss: 33.399873, acc: 0.755102\n",
      "epoch 13, iter 37, loss: 30.840122, acc: 0.877551\n",
      "epoch 13, iter 38, loss: 31.623721, acc: 0.734694\n",
      "epoch 13, iter 39, loss: 30.818972, acc: 0.836735\n",
      "epoch 13, iter 40, loss: 32.614613, acc: 0.755102\n",
      "epoch 13, iter 41, loss: 31.676472, acc: 0.836735\n",
      "epoch 13, iter 42, loss: 34.332495, acc: 0.693878\n",
      "epoch 13, iter 43, loss: 31.739524, acc: 0.918367\n",
      "epoch 13, iter 44, loss: 29.260370, acc: 0.897959\n",
      "epoch 13, iter 45, loss: 30.354559, acc: 0.755102\n",
      "epoch 13, iter 46, loss: 31.545251, acc: 0.795918\n",
      "epoch 13, iter 47, loss: 30.804200, acc: 0.755102\n",
      "epoch 13, iter 48, loss: 31.324936, acc: 0.714286\n",
      "epoch 13, iter 49, loss: 30.543236, acc: 0.836735\n",
      "epoch 13, iter 50, loss: 30.998794, acc: 0.836735\n",
      "epoch 13, iter 51, loss: 32.447013, acc: 0.714286\n",
      "epoch 13, iter 52, loss: 31.777601, acc: 0.938776\n",
      "epoch 13, iter 53, loss: 32.087444, acc: 0.775510\n",
      "epoch 13, iter 54, loss: 32.099744, acc: 0.734694\n",
      "epoch 13, iter 55, loss: 31.573515, acc: 0.836735\n",
      "epoch 13, iter 56, loss: 30.134984, acc: 0.836735\n",
      "epoch 13, iter 57, loss: 29.165762, acc: 0.857143\n",
      "epoch 13, iter 58, loss: 30.443974, acc: 0.775510\n",
      "epoch 13, iter 59, loss: 30.461574, acc: 0.816327\n",
      "epoch 13, iter 60, loss: 29.680703, acc: 0.877551\n",
      "epoch 13, iter 61, loss: 29.966485, acc: 0.857143\n",
      "epoch 13, iter 62, loss: 30.033620, acc: 0.836735\n",
      "epoch 13, iter 63, loss: 29.200857, acc: 0.877551\n",
      "epoch 13, iter 64, loss: 31.666610, acc: 0.612245\n",
      "epoch 13, iter 65, loss: 30.363569, acc: 0.816327\n",
      "epoch 13, iter 66, loss: 28.063448, acc: 0.897959\n",
      "epoch 13, iter 67, loss: 31.004219, acc: 0.693878\n",
      "epoch 13, iter 68, loss: 29.369875, acc: 0.775510\n",
      "epoch 13, iter 69, loss: 27.625502, acc: 0.857143\n",
      "epoch 13, iter 70, loss: 27.152418, acc: 0.836735\n",
      "epoch 13, iter 71, loss: 29.491884, acc: 0.755102\n",
      "epoch 13, iter 72, loss: 28.586304, acc: 0.877551\n",
      "epoch 13, iter 73, loss: 26.586938, acc: 0.938776\n",
      "epoch 13, iter 74, loss: 25.309198, acc: 0.877551\n",
      "epoch 13, iter 75, loss: 24.601336, acc: 0.877551\n",
      "epoch 13, iter 76, loss: 27.857879, acc: 0.755102\n",
      "epoch 13, iter 77, loss: 30.745093, acc: 0.673469\n",
      "epoch 13, iter 78, loss: 31.957394, acc: 0.714286\n",
      "epoch 13, iter 79, loss: 30.419310, acc: 0.836735\n",
      "epoch 13, iter 80, loss: 28.762459, acc: 0.897959\n",
      "epoch 13, iter 81, loss: 29.747009, acc: 0.734694\n",
      "epoch 13, iter 82, loss: 29.896656, acc: 0.755102\n",
      "epoch 13, iter 83, loss: 31.261650, acc: 0.734694\n",
      "epoch 13, iter 84, loss: 29.302415, acc: 0.877551\n",
      "epoch 13, iter 85, loss: 27.318110, acc: 0.877551\n",
      "epoch 13, iter 86, loss: 29.462396, acc: 0.693878\n",
      "epoch 13, iter 87, loss: 32.820194, acc: 0.673469\n",
      "epoch 13, iter 88, loss: 31.376664, acc: 0.877551\n",
      "epoch 13, iter 89, loss: 31.918553, acc: 0.714286\n",
      "epoch 13, iter 90, loss: 32.795488, acc: 0.734694\n",
      "epoch 13, iter 91, loss: 32.785057, acc: 0.816327\n",
      "epoch 13, iter 92, loss: 34.223147, acc: 0.734694\n",
      "epoch 13, iter 93, loss: 34.875650, acc: 0.714286\n",
      "epoch 13, iter 94, loss: 33.185785, acc: 0.877551\n",
      "epoch 13, iter 95, loss: 29.900284, acc: 0.918367\n",
      "epoch 13, iter 96, loss: 30.510950, acc: 0.816327\n",
      "epoch 13, iter 97, loss: 30.648395, acc: 0.734694\n",
      "epoch 13, iter 98, loss: 30.948556, acc: 0.755102\n",
      "epoch 13, iter 99, loss: 29.452722, acc: 0.836735\n",
      "epoch 13, iter 100, loss: 33.674032, acc: 0.632653\n",
      "epoch 13, iter 101, loss: 32.495501, acc: 0.734694\n",
      "epoch 13, iter 102, loss: 30.691640, acc: 0.877551\n",
      "epoch 13, iter 103, loss: 29.469399, acc: 0.857143\n",
      "epoch 13, iter 104, loss: 30.975701, acc: 0.734694\n",
      "epoch 13, iter 105, loss: 30.799752, acc: 0.795918\n",
      "epoch 13, iter 106, loss: 29.861899, acc: 0.816327\n",
      "epoch 13, iter 107, loss: 27.131691, acc: 0.938776\n",
      "epoch 13, iter 108, loss: 28.740525, acc: 0.734694\n",
      "epoch 13, iter 109, loss: 30.338519, acc: 0.653061\n",
      "epoch 13, iter 110, loss: 30.206849, acc: 0.755102\n",
      "epoch 13, iter 111, loss: 34.084149, acc: 0.571429\n",
      "epoch 13, iter 112, loss: 34.165261, acc: 0.836735\n",
      "epoch 13, iter 113, loss: 35.765969, acc: 0.714286\n",
      "epoch 13, iter 114, loss: 34.428067, acc: 0.836735\n",
      "epoch 13, iter 115, loss: 33.437864, acc: 0.755102\n",
      "epoch 13, iter 116, loss: 34.600104, acc: 0.693878\n",
      "epoch 13, iter 117, loss: 31.890089, acc: 0.938776\n",
      "epoch 13, iter 118, loss: 34.277092, acc: 0.653061\n",
      "epoch 13, iter 119, loss: 31.520940, acc: 0.918367\n",
      "epoch 13, iter 120, loss: 32.502334, acc: 0.734694\n",
      "epoch 13, iter 121, loss: 30.854228, acc: 0.877551\n",
      "epoch 13, iter 122, loss: 30.825285, acc: 0.775510\n",
      "epoch 13, iter 123, loss: 30.400497, acc: 0.857143\n",
      "epoch 13, iter 124, loss: 31.376218, acc: 0.836735\n",
      "epoch 13, iter 125, loss: 33.721087, acc: 0.673469\n",
      "epoch 13, iter 126, loss: 31.133634, acc: 0.959184\n",
      "epoch 13, iter 127, loss: 35.313846, acc: 0.571429\n",
      "epoch 13, iter 128, loss: 33.155903, acc: 0.877551\n",
      "epoch 13, iter 129, loss: 32.163640, acc: 0.775510\n",
      "epoch 13, iter 130, loss: 29.964124, acc: 0.959184\n",
      "epoch 13, iter 131, loss: 29.464654, acc: 0.816327\n",
      "epoch 13, iter 132, loss: 30.278368, acc: 0.755102\n",
      "epoch 13, iter 133, loss: 28.686231, acc: 0.897959\n",
      "epoch 13, iter 134, loss: 32.092145, acc: 0.612245\n",
      "epoch 13, iter 135, loss: 33.055065, acc: 0.755102\n",
      "epoch 13, iter 136, loss: 32.751897, acc: 0.877551\n",
      "epoch 13, iter 137, loss: 32.213525, acc: 0.836735\n",
      "epoch 13, iter 138, loss: 31.671354, acc: 0.877551\n",
      "epoch 13, iter 139, loss: 31.202208, acc: 0.795918\n",
      "epoch 13, iter 140, loss: 31.455206, acc: 0.795918\n",
      "epoch 13, iter 141, loss: 30.287566, acc: 0.816327\n",
      "epoch 13, iter 142, loss: 31.374504, acc: 0.714286\n",
      "epoch 13, iter 143, loss: 30.814161, acc: 0.836735\n",
      "epoch 13, iter 144, loss: 31.758578, acc: 0.632653\n",
      "epoch 13, iter 145, loss: 29.713682, acc: 0.897959\n",
      "epoch 13, iter 146, loss: 29.437471, acc: 0.836735\n",
      "epoch 13, iter 147, loss: 29.505686, acc: 0.836735\n",
      "epoch 13, iter 148, loss: 29.386680, acc: 0.795918\n",
      "epoch 13, iter 149, loss: 27.475651, acc: 0.938776\n",
      "epoch 13, iter 150, loss: 28.654523, acc: 0.795918\n",
      "epoch 13, iter 151, loss: 29.111518, acc: 0.755102\n",
      "epoch 13, iter 152, loss: 29.029925, acc: 0.816327\n",
      "epoch 13, iter 153, loss: 31.366842, acc: 0.653061\n",
      "epoch 13, iter 154, loss: 32.551347, acc: 0.714286\n",
      "epoch 13, iter 155, loss: 31.537658, acc: 0.795918\n",
      "epoch 13, iter 156, loss: 29.925992, acc: 0.857143\n",
      "epoch 13, iter 157, loss: 31.175397, acc: 0.775510\n",
      "epoch 13, iter 158, loss: 28.515698, acc: 0.877551\n",
      "epoch 13, iter 159, loss: 32.749915, acc: 0.632653\n",
      "epoch 13, iter 160, loss: 34.021757, acc: 0.673469\n",
      "epoch 13, iter 161, loss: 31.551697, acc: 0.816327\n",
      "epoch 13, iter 162, loss: 31.372832, acc: 0.714286\n",
      "epoch 13, iter 163, loss: 31.813903, acc: 0.795918\n",
      "epoch 13, iter 164, loss: 32.903767, acc: 0.714286\n",
      "epoch 13, iter 165, loss: 30.449331, acc: 0.918367\n",
      "epoch 13, iter 166, loss: 29.728334, acc: 0.836735\n",
      "epoch 13, iter 167, loss: 31.162685, acc: 0.673469\n",
      "epoch 13, iter 168, loss: 31.313289, acc: 0.795918\n",
      "epoch 13, iter 169, loss: 31.253307, acc: 0.795918\n",
      "epoch 13, iter 170, loss: 34.791987, acc: 0.673469\n",
      "epoch 13, iter 171, loss: 35.857111, acc: 0.714286\n",
      "epoch 13, iter 172, loss: 35.551369, acc: 0.795918\n",
      "epoch 13, iter 173, loss: 34.804424, acc: 0.734694\n",
      "epoch 13, iter 174, loss: 34.304328, acc: 0.795918\n",
      "epoch 13, iter 175, loss: 32.764655, acc: 0.836735\n",
      "epoch 13, iter 176, loss: 30.791604, acc: 0.857143\n",
      "epoch 13, iter 177, loss: 29.787006, acc: 0.897959\n",
      "epoch 13, iter 178, loss: 30.693370, acc: 0.755102\n",
      "epoch 13, iter 179, loss: 30.032263, acc: 0.775510\n",
      "epoch 13, iter 180, loss: 28.250781, acc: 0.877551\n",
      "epoch 13, iter 181, loss: 30.624615, acc: 0.714286\n",
      "epoch 13, iter 182, loss: 30.340036, acc: 0.816327\n",
      "epoch 13, iter 183, loss: 32.979194, acc: 0.571429\n",
      "epoch 13, iter 184, loss: 32.093386, acc: 0.795918\n",
      "epoch 13, iter 185, loss: 33.442213, acc: 0.734694\n",
      "epoch 13, iter 186, loss: 31.050523, acc: 0.918367\n",
      "epoch 13, iter 187, loss: 33.006648, acc: 0.734694\n",
      "epoch 13, iter 188, loss: 35.632509, acc: 0.612245\n",
      "epoch 13, iter 189, loss: 35.798015, acc: 0.734694\n",
      "epoch 13, iter 190, loss: 34.562426, acc: 0.836735\n",
      "epoch 13, iter 191, loss: 33.207535, acc: 0.877551\n",
      "epoch 13, iter 192, loss: 32.085319, acc: 0.857143\n",
      "epoch 13, iter 193, loss: 34.036208, acc: 0.734694\n",
      "epoch 13, iter 194, loss: 33.192409, acc: 0.755102\n",
      "epoch 13, iter 195, loss: 33.096534, acc: 0.714286\n",
      "epoch 13, iter 196, loss: 31.099226, acc: 0.816327\n",
      "epoch 13, iter 197, loss: 31.392784, acc: 0.775510\n",
      "epoch 13, iter 198, loss: 31.471368, acc: 0.795918\n",
      "epoch 13, iter 199, loss: 31.820570, acc: 0.755102\n",
      "epoch 13, iter 200, loss: 31.638058, acc: 0.755102\n",
      "epoch 13, iter 201, loss: 32.158790, acc: 0.816327\n",
      "epoch 13, iter 202, loss: 30.512581, acc: 0.857143\n",
      "epoch 13, iter 203, loss: 32.520757, acc: 0.734694\n",
      "epoch 13, iter 204, loss: 32.340544, acc: 0.734694\n",
      "epoch 13, iter 205, loss: 36.577027, acc: 0.693878\n",
      "epoch 13, iter 206, loss: 35.913320, acc: 0.755102\n",
      "epoch 13, iter 207, loss: 34.453290, acc: 0.857143\n",
      "epoch 13, iter 208, loss: 32.461753, acc: 0.918367\n",
      "epoch 13, iter 209, loss: 30.667196, acc: 0.897959\n",
      "epoch 13, iter 210, loss: 31.247428, acc: 0.795918\n",
      "epoch 13, iter 211, loss: 30.053574, acc: 0.816327\n",
      "epoch 13, iter 212, loss: 30.968486, acc: 0.734694\n",
      "epoch 13, iter 213, loss: 29.633183, acc: 0.836735\n",
      "epoch 13, iter 214, loss: 28.407464, acc: 0.877551\n",
      "epoch 13, iter 215, loss: 31.131536, acc: 0.714286\n",
      "epoch 13, iter 216, loss: 30.622657, acc: 0.775510\n",
      "epoch 13, iter 217, loss: 32.887459, acc: 0.836735\n",
      "epoch 13, iter 218, loss: 31.909621, acc: 0.877551\n",
      "epoch 13, iter 219, loss: 30.080354, acc: 0.918367\n",
      "epoch 13, iter 220, loss: 32.267076, acc: 0.632653\n",
      "epoch 13, iter 221, loss: 31.470024, acc: 0.795918\n",
      "epoch 13, iter 222, loss: 33.703714, acc: 0.673469\n",
      "epoch 13, iter 223, loss: 30.628621, acc: 0.897959\n",
      "epoch 13, iter 224, loss: 30.768476, acc: 0.775510\n",
      "epoch 13, iter 225, loss: 31.499292, acc: 0.775510\n",
      "epoch 13, iter 226, loss: 31.925500, acc: 0.734694\n",
      "epoch 13, iter 227, loss: 31.058079, acc: 0.816327\n",
      "epoch 13, iter 228, loss: 31.242423, acc: 0.795918\n",
      "epoch 13, iter 229, loss: 28.107897, acc: 0.918367\n",
      "epoch 13, iter 230, loss: 28.911909, acc: 0.775510\n",
      "epoch 13, iter 231, loss: 27.841632, acc: 0.877551\n",
      "epoch 13, iter 232, loss: 29.451972, acc: 0.795918\n",
      "epoch 13, iter 233, loss: 31.283622, acc: 0.693878\n",
      "epoch 13, iter 234, loss: 29.370174, acc: 0.938776\n",
      "epoch 13, iter 235, loss: 29.725799, acc: 0.836735\n",
      "epoch 13, iter 236, loss: 27.560672, acc: 0.959184\n",
      "epoch 13, iter 237, loss: 30.872519, acc: 0.612245\n",
      "epoch 13, iter 238, loss: 33.681158, acc: 0.714286\n",
      "epoch 13, iter 239, loss: 33.597821, acc: 0.816327\n",
      "epoch 13, iter 240, loss: 32.554437, acc: 0.877551\n",
      "epoch 13, iter 241, loss: 31.741480, acc: 0.816327\n",
      "epoch 13, iter 242, loss: 32.756271, acc: 0.755102\n",
      "epoch 13, iter 243, loss: 31.656607, acc: 0.877551\n",
      "epoch 13, iter 244, loss: 31.007181, acc: 0.816327\n",
      "epoch 13, iter 245, loss: 31.678715, acc: 0.755102\n",
      "epoch 13, iter 246, loss: 35.017578, acc: 0.653061\n",
      "epoch 13, iter 247, loss: 35.086464, acc: 0.755102\n",
      "epoch 13, iter 248, loss: 37.443788, acc: 0.693878\n",
      "epoch 13, iter 249, loss: 37.335464, acc: 0.693878\n",
      "epoch 13, acc: 0.789959\n",
      "epoch 14, iter 0, loss: 36.767161, acc: 0.653061\n",
      "epoch 14, iter 1, loss: 37.471130, acc: 0.714286\n",
      "epoch 14, iter 2, loss: 36.641790, acc: 0.734694\n",
      "epoch 14, iter 3, loss: 35.250922, acc: 0.816327\n",
      "epoch 14, iter 4, loss: 33.182333, acc: 0.836735\n",
      "epoch 14, iter 5, loss: 31.871903, acc: 0.897959\n",
      "epoch 14, iter 6, loss: 31.039510, acc: 0.857143\n",
      "epoch 14, iter 7, loss: 32.639194, acc: 0.653061\n",
      "epoch 14, iter 8, loss: 32.680270, acc: 0.755102\n",
      "epoch 14, iter 9, loss: 32.572073, acc: 0.795918\n",
      "epoch 14, iter 10, loss: 32.648166, acc: 0.693878\n",
      "epoch 14, iter 11, loss: 34.726737, acc: 0.714286\n",
      "epoch 14, iter 12, loss: 32.969767, acc: 0.877551\n",
      "epoch 14, iter 13, loss: 31.923979, acc: 0.836735\n",
      "epoch 14, iter 14, loss: 30.975947, acc: 0.836735\n",
      "epoch 14, iter 15, loss: 28.785684, acc: 0.918367\n",
      "epoch 14, iter 16, loss: 30.083133, acc: 0.714286\n",
      "epoch 14, iter 17, loss: 29.454736, acc: 0.857143\n",
      "epoch 14, iter 18, loss: 32.331591, acc: 0.734694\n",
      "epoch 14, iter 19, loss: 30.207337, acc: 0.877551\n",
      "epoch 14, iter 20, loss: 27.745765, acc: 0.918367\n",
      "epoch 14, iter 21, loss: 27.361633, acc: 0.795918\n",
      "epoch 14, iter 22, loss: 26.217560, acc: 0.877551\n",
      "epoch 14, iter 23, loss: 29.429596, acc: 0.653061\n",
      "epoch 14, iter 24, loss: 29.366045, acc: 0.816327\n",
      "epoch 14, iter 25, loss: 31.287802, acc: 0.714286\n",
      "epoch 14, iter 26, loss: 32.716951, acc: 0.775510\n",
      "epoch 14, iter 27, loss: 33.292113, acc: 0.755102\n",
      "epoch 14, iter 28, loss: 31.763159, acc: 0.816327\n",
      "epoch 14, iter 29, loss: 28.830966, acc: 0.857143\n",
      "epoch 14, iter 30, loss: 31.017736, acc: 0.673469\n",
      "epoch 14, iter 31, loss: 34.961670, acc: 0.591837\n",
      "epoch 14, iter 32, loss: 33.000109, acc: 0.816327\n",
      "epoch 14, iter 33, loss: 30.939339, acc: 0.857143\n",
      "epoch 14, iter 34, loss: 31.126885, acc: 0.693878\n",
      "epoch 14, iter 35, loss: 33.250706, acc: 0.693878\n",
      "epoch 14, iter 36, loss: 33.289506, acc: 0.816327\n",
      "epoch 14, iter 37, loss: 30.788454, acc: 0.877551\n",
      "epoch 14, iter 38, loss: 31.576454, acc: 0.714286\n",
      "epoch 14, iter 39, loss: 30.705740, acc: 0.836735\n",
      "epoch 14, iter 40, loss: 32.417660, acc: 0.755102\n",
      "epoch 14, iter 41, loss: 31.543542, acc: 0.816327\n",
      "epoch 14, iter 42, loss: 34.062004, acc: 0.693878\n",
      "epoch 14, iter 43, loss: 31.588184, acc: 0.918367\n",
      "epoch 14, iter 44, loss: 29.167811, acc: 0.877551\n",
      "epoch 14, iter 45, loss: 30.214918, acc: 0.755102\n",
      "epoch 14, iter 46, loss: 31.445493, acc: 0.755102\n",
      "epoch 14, iter 47, loss: 30.608515, acc: 0.755102\n",
      "epoch 14, iter 48, loss: 31.034000, acc: 0.714286\n",
      "epoch 14, iter 49, loss: 30.290065, acc: 0.857143\n",
      "epoch 14, iter 50, loss: 30.781881, acc: 0.836735\n",
      "epoch 14, iter 51, loss: 32.340656, acc: 0.714286\n",
      "epoch 14, iter 52, loss: 31.551160, acc: 0.959184\n",
      "epoch 14, iter 53, loss: 31.865749, acc: 0.775510\n",
      "epoch 14, iter 54, loss: 31.892470, acc: 0.755102\n",
      "epoch 14, iter 55, loss: 31.386298, acc: 0.836735\n",
      "epoch 14, iter 56, loss: 29.910155, acc: 0.836735\n",
      "epoch 14, iter 57, loss: 29.088659, acc: 0.857143\n",
      "epoch 14, iter 58, loss: 30.481933, acc: 0.775510\n",
      "epoch 14, iter 59, loss: 30.300976, acc: 0.836735\n",
      "epoch 14, iter 60, loss: 29.607718, acc: 0.816327\n",
      "epoch 14, iter 61, loss: 29.776155, acc: 0.857143\n",
      "epoch 14, iter 62, loss: 29.907436, acc: 0.836735\n",
      "epoch 14, iter 63, loss: 29.100495, acc: 0.897959\n",
      "epoch 14, iter 64, loss: 31.655819, acc: 0.591837\n",
      "epoch 14, iter 65, loss: 30.309556, acc: 0.816327\n",
      "epoch 14, iter 66, loss: 27.896745, acc: 0.897959\n",
      "epoch 14, iter 67, loss: 30.874645, acc: 0.693878\n",
      "epoch 14, iter 68, loss: 29.174064, acc: 0.775510\n",
      "epoch 14, iter 69, loss: 27.422812, acc: 0.857143\n",
      "epoch 14, iter 70, loss: 26.959347, acc: 0.836735\n",
      "epoch 14, iter 71, loss: 29.297483, acc: 0.755102\n",
      "epoch 14, iter 72, loss: 28.317054, acc: 0.877551\n",
      "epoch 14, iter 73, loss: 26.401780, acc: 0.938776\n",
      "epoch 14, iter 74, loss: 25.108954, acc: 0.877551\n",
      "epoch 14, iter 75, loss: 24.420270, acc: 0.877551\n",
      "epoch 14, iter 76, loss: 27.759115, acc: 0.755102\n",
      "epoch 14, iter 77, loss: 30.639464, acc: 0.673469\n",
      "epoch 14, iter 78, loss: 31.915272, acc: 0.714286\n",
      "epoch 14, iter 79, loss: 30.390206, acc: 0.816327\n",
      "epoch 14, iter 80, loss: 28.808260, acc: 0.897959\n",
      "epoch 14, iter 81, loss: 29.754422, acc: 0.714286\n",
      "epoch 14, iter 82, loss: 29.886294, acc: 0.734694\n",
      "epoch 14, iter 83, loss: 31.210438, acc: 0.734694\n",
      "epoch 14, iter 84, loss: 29.252676, acc: 0.877551\n",
      "epoch 14, iter 85, loss: 27.317009, acc: 0.877551\n",
      "epoch 14, iter 86, loss: 29.344849, acc: 0.734694\n",
      "epoch 14, iter 87, loss: 32.765271, acc: 0.693878\n",
      "epoch 14, iter 88, loss: 31.286714, acc: 0.877551\n",
      "epoch 14, iter 89, loss: 31.954751, acc: 0.714286\n",
      "epoch 14, iter 90, loss: 32.777519, acc: 0.734694\n",
      "epoch 14, iter 91, loss: 32.665888, acc: 0.816327\n",
      "epoch 14, iter 92, loss: 34.063592, acc: 0.734694\n",
      "epoch 14, iter 93, loss: 34.750219, acc: 0.734694\n",
      "epoch 14, iter 94, loss: 33.344502, acc: 0.857143\n",
      "epoch 14, iter 95, loss: 29.946389, acc: 0.918367\n",
      "epoch 14, iter 96, loss: 30.582959, acc: 0.816327\n",
      "epoch 14, iter 97, loss: 30.621189, acc: 0.755102\n",
      "epoch 14, iter 98, loss: 30.908477, acc: 0.755102\n",
      "epoch 14, iter 99, loss: 29.342923, acc: 0.836735\n",
      "epoch 14, iter 100, loss: 33.587724, acc: 0.612245\n",
      "epoch 14, iter 101, loss: 32.375131, acc: 0.734694\n",
      "epoch 14, iter 102, loss: 30.534291, acc: 0.877551\n",
      "epoch 14, iter 103, loss: 29.292914, acc: 0.857143\n",
      "epoch 14, iter 104, loss: 30.856066, acc: 0.775510\n",
      "epoch 14, iter 105, loss: 30.700441, acc: 0.795918\n",
      "epoch 14, iter 106, loss: 29.715145, acc: 0.795918\n",
      "epoch 14, iter 107, loss: 27.015847, acc: 0.938776\n",
      "epoch 14, iter 108, loss: 28.601173, acc: 0.734694\n",
      "epoch 14, iter 109, loss: 30.142369, acc: 0.632653\n",
      "epoch 14, iter 110, loss: 30.053704, acc: 0.775510\n",
      "epoch 14, iter 111, loss: 33.796531, acc: 0.571429\n",
      "epoch 14, iter 112, loss: 33.909046, acc: 0.836735\n",
      "epoch 14, iter 113, loss: 35.380237, acc: 0.714286\n",
      "epoch 14, iter 114, loss: 34.078523, acc: 0.816327\n",
      "epoch 14, iter 115, loss: 33.262351, acc: 0.734694\n",
      "epoch 14, iter 116, loss: 34.736835, acc: 0.714286\n",
      "epoch 14, iter 117, loss: 32.365671, acc: 0.918367\n",
      "epoch 14, iter 118, loss: 34.655522, acc: 0.632653\n",
      "epoch 14, iter 119, loss: 31.522552, acc: 0.918367\n",
      "epoch 14, iter 120, loss: 32.342802, acc: 0.755102\n",
      "epoch 14, iter 121, loss: 30.627734, acc: 0.877551\n",
      "epoch 14, iter 122, loss: 30.670606, acc: 0.816327\n",
      "epoch 14, iter 123, loss: 30.219552, acc: 0.857143\n",
      "epoch 14, iter 124, loss: 31.172154, acc: 0.836735\n",
      "epoch 14, iter 125, loss: 33.629654, acc: 0.653061\n",
      "epoch 14, iter 126, loss: 31.105691, acc: 0.959184\n",
      "epoch 14, iter 127, loss: 35.162851, acc: 0.571429\n",
      "epoch 14, iter 128, loss: 33.013101, acc: 0.897959\n",
      "epoch 14, iter 129, loss: 32.048018, acc: 0.755102\n",
      "epoch 14, iter 130, loss: 29.835128, acc: 0.959184\n",
      "epoch 14, iter 131, loss: 29.318725, acc: 0.816327\n",
      "epoch 14, iter 132, loss: 30.130053, acc: 0.755102\n",
      "epoch 14, iter 133, loss: 28.632380, acc: 0.897959\n",
      "epoch 14, iter 134, loss: 31.944123, acc: 0.653061\n",
      "epoch 14, iter 135, loss: 32.863291, acc: 0.755102\n",
      "epoch 14, iter 136, loss: 32.450039, acc: 0.857143\n",
      "epoch 14, iter 137, loss: 31.671062, acc: 0.877551\n",
      "epoch 14, iter 138, loss: 31.258593, acc: 0.877551\n",
      "epoch 14, iter 139, loss: 30.820797, acc: 0.795918\n",
      "epoch 14, iter 140, loss: 31.249952, acc: 0.775510\n",
      "epoch 14, iter 141, loss: 30.059897, acc: 0.857143\n",
      "epoch 14, iter 142, loss: 31.147778, acc: 0.734694\n",
      "epoch 14, iter 143, loss: 30.697855, acc: 0.836735\n",
      "epoch 14, iter 144, loss: 31.644606, acc: 0.632653\n",
      "epoch 14, iter 145, loss: 29.531833, acc: 0.897959\n",
      "epoch 14, iter 146, loss: 29.309739, acc: 0.836735\n",
      "epoch 14, iter 147, loss: 29.253911, acc: 0.836735\n",
      "epoch 14, iter 148, loss: 29.177029, acc: 0.795918\n",
      "epoch 14, iter 149, loss: 27.279801, acc: 0.938776\n",
      "epoch 14, iter 150, loss: 28.516539, acc: 0.795918\n",
      "epoch 14, iter 151, loss: 29.055617, acc: 0.734694\n",
      "epoch 14, iter 152, loss: 28.976911, acc: 0.816327\n",
      "epoch 14, iter 153, loss: 31.199768, acc: 0.653061\n",
      "epoch 14, iter 154, loss: 32.361684, acc: 0.714286\n",
      "epoch 14, iter 155, loss: 31.356093, acc: 0.816327\n",
      "epoch 14, iter 156, loss: 29.775217, acc: 0.857143\n",
      "epoch 14, iter 157, loss: 31.071727, acc: 0.755102\n",
      "epoch 14, iter 158, loss: 28.197284, acc: 0.897959\n",
      "epoch 14, iter 159, loss: 32.541305, acc: 0.632653\n",
      "epoch 14, iter 160, loss: 33.814259, acc: 0.653061\n",
      "epoch 14, iter 161, loss: 31.373454, acc: 0.816327\n",
      "epoch 14, iter 162, loss: 31.216374, acc: 0.734694\n",
      "epoch 14, iter 163, loss: 31.745718, acc: 0.775510\n",
      "epoch 14, iter 164, loss: 32.848426, acc: 0.693878\n",
      "epoch 14, iter 165, loss: 30.339134, acc: 0.918367\n",
      "epoch 14, iter 166, loss: 29.583200, acc: 0.857143\n",
      "epoch 14, iter 167, loss: 31.050866, acc: 0.693878\n",
      "epoch 14, iter 168, loss: 31.102509, acc: 0.775510\n",
      "epoch 14, iter 169, loss: 30.953613, acc: 0.755102\n",
      "epoch 14, iter 170, loss: 34.483495, acc: 0.714286\n",
      "epoch 14, iter 171, loss: 35.440026, acc: 0.693878\n",
      "epoch 14, iter 172, loss: 35.227626, acc: 0.795918\n",
      "epoch 14, iter 173, loss: 34.519950, acc: 0.734694\n",
      "epoch 14, iter 174, loss: 34.209589, acc: 0.795918\n",
      "epoch 14, iter 175, loss: 32.667937, acc: 0.857143\n",
      "epoch 14, iter 176, loss: 30.781489, acc: 0.857143\n",
      "epoch 14, iter 177, loss: 29.727518, acc: 0.897959\n",
      "epoch 14, iter 178, loss: 30.679883, acc: 0.755102\n",
      "epoch 14, iter 179, loss: 29.975254, acc: 0.734694\n",
      "epoch 14, iter 180, loss: 28.240604, acc: 0.857143\n",
      "epoch 14, iter 181, loss: 30.611529, acc: 0.693878\n",
      "epoch 14, iter 182, loss: 30.204849, acc: 0.857143\n",
      "epoch 14, iter 183, loss: 32.778357, acc: 0.571429\n",
      "epoch 14, iter 184, loss: 31.907857, acc: 0.816327\n",
      "epoch 14, iter 185, loss: 33.142784, acc: 0.734694\n",
      "epoch 14, iter 186, loss: 30.879360, acc: 0.918367\n",
      "epoch 14, iter 187, loss: 32.900930, acc: 0.734694\n",
      "epoch 14, iter 188, loss: 35.525357, acc: 0.591837\n",
      "epoch 14, iter 189, loss: 35.790986, acc: 0.714286\n",
      "epoch 14, iter 190, loss: 34.671011, acc: 0.775510\n",
      "epoch 14, iter 191, loss: 32.773526, acc: 0.897959\n",
      "epoch 14, iter 192, loss: 31.729388, acc: 0.857143\n",
      "epoch 14, iter 193, loss: 33.793455, acc: 0.693878\n",
      "epoch 14, iter 194, loss: 32.958673, acc: 0.755102\n",
      "epoch 14, iter 195, loss: 32.853028, acc: 0.734694\n",
      "epoch 14, iter 196, loss: 30.938365, acc: 0.816327\n",
      "epoch 14, iter 197, loss: 31.228715, acc: 0.775510\n",
      "epoch 14, iter 198, loss: 31.326801, acc: 0.795918\n",
      "epoch 14, iter 199, loss: 31.682116, acc: 0.734694\n",
      "epoch 14, iter 200, loss: 31.474490, acc: 0.755102\n",
      "epoch 14, iter 201, loss: 31.902011, acc: 0.816327\n",
      "epoch 14, iter 202, loss: 30.255932, acc: 0.836735\n",
      "epoch 14, iter 203, loss: 32.235652, acc: 0.734694\n",
      "epoch 14, iter 204, loss: 32.114513, acc: 0.755102\n",
      "epoch 14, iter 205, loss: 36.216621, acc: 0.693878\n",
      "epoch 14, iter 206, loss: 35.646240, acc: 0.775510\n",
      "epoch 14, iter 207, loss: 34.362966, acc: 0.857143\n",
      "epoch 14, iter 208, loss: 32.140592, acc: 0.918367\n",
      "epoch 14, iter 209, loss: 30.481670, acc: 0.897959\n",
      "epoch 14, iter 210, loss: 31.176527, acc: 0.775510\n",
      "epoch 14, iter 211, loss: 29.886855, acc: 0.795918\n",
      "epoch 14, iter 212, loss: 30.797142, acc: 0.734694\n",
      "epoch 14, iter 213, loss: 29.518768, acc: 0.836735\n",
      "epoch 14, iter 214, loss: 28.353714, acc: 0.897959\n",
      "epoch 14, iter 215, loss: 31.068377, acc: 0.714286\n",
      "epoch 14, iter 216, loss: 30.448862, acc: 0.795918\n",
      "epoch 14, iter 217, loss: 32.658683, acc: 0.816327\n",
      "epoch 14, iter 218, loss: 31.980293, acc: 0.877551\n",
      "epoch 14, iter 219, loss: 30.099240, acc: 0.897959\n",
      "epoch 14, iter 220, loss: 32.182166, acc: 0.591837\n",
      "epoch 14, iter 221, loss: 31.412916, acc: 0.775510\n",
      "epoch 14, iter 222, loss: 33.545454, acc: 0.673469\n",
      "epoch 14, iter 223, loss: 30.541459, acc: 0.918367\n",
      "epoch 14, iter 224, loss: 30.702137, acc: 0.755102\n",
      "epoch 14, iter 225, loss: 31.405417, acc: 0.775510\n",
      "epoch 14, iter 226, loss: 31.810937, acc: 0.734694\n",
      "epoch 14, iter 227, loss: 30.908397, acc: 0.816327\n",
      "epoch 14, iter 228, loss: 31.106916, acc: 0.795918\n",
      "epoch 14, iter 229, loss: 27.959602, acc: 0.938776\n",
      "epoch 14, iter 230, loss: 28.824419, acc: 0.775510\n",
      "epoch 14, iter 231, loss: 27.750901, acc: 0.877551\n",
      "epoch 14, iter 232, loss: 29.382527, acc: 0.795918\n",
      "epoch 14, iter 233, loss: 31.163620, acc: 0.693878\n",
      "epoch 14, iter 234, loss: 29.301297, acc: 0.938776\n",
      "epoch 14, iter 235, loss: 29.614080, acc: 0.816327\n",
      "epoch 14, iter 236, loss: 27.548560, acc: 0.959184\n",
      "epoch 14, iter 237, loss: 30.641198, acc: 0.632653\n",
      "epoch 14, iter 238, loss: 33.418615, acc: 0.714286\n",
      "epoch 14, iter 239, loss: 33.374421, acc: 0.734694\n",
      "epoch 14, iter 240, loss: 32.246649, acc: 0.877551\n",
      "epoch 14, iter 241, loss: 31.658024, acc: 0.816327\n",
      "epoch 14, iter 242, loss: 32.899369, acc: 0.755102\n",
      "epoch 14, iter 243, loss: 31.914712, acc: 0.857143\n",
      "epoch 14, iter 244, loss: 31.541936, acc: 0.795918\n",
      "epoch 14, iter 245, loss: 31.706484, acc: 0.714286\n",
      "epoch 14, iter 246, loss: 34.552178, acc: 0.632653\n",
      "epoch 14, iter 247, loss: 34.145815, acc: 0.755102\n",
      "epoch 14, iter 248, loss: 36.963450, acc: 0.693878\n",
      "epoch 14, iter 249, loss: 36.582156, acc: 0.714286\n",
      "epoch 14, acc: 0.788653\n",
      "epoch 15, iter 0, loss: 36.208294, acc: 0.673469\n",
      "epoch 15, iter 1, loss: 36.547347, acc: 0.775510\n",
      "epoch 15, iter 2, loss: 36.009365, acc: 0.755102\n",
      "epoch 15, iter 3, loss: 34.892661, acc: 0.795918\n",
      "epoch 15, iter 4, loss: 32.986385, acc: 0.857143\n",
      "epoch 15, iter 5, loss: 31.596434, acc: 0.897959\n",
      "epoch 15, iter 6, loss: 30.727931, acc: 0.857143\n",
      "epoch 15, iter 7, loss: 32.447898, acc: 0.632653\n",
      "epoch 15, iter 8, loss: 32.519967, acc: 0.755102\n",
      "epoch 15, iter 9, loss: 32.547792, acc: 0.775510\n",
      "epoch 15, iter 10, loss: 32.748367, acc: 0.693878\n",
      "epoch 15, iter 11, loss: 34.951384, acc: 0.714286\n",
      "epoch 15, iter 12, loss: 32.819998, acc: 0.897959\n",
      "epoch 15, iter 13, loss: 31.811181, acc: 0.816327\n",
      "epoch 15, iter 14, loss: 30.818489, acc: 0.836735\n",
      "epoch 15, iter 15, loss: 28.726098, acc: 0.938776\n",
      "epoch 15, iter 16, loss: 29.907249, acc: 0.714286\n",
      "epoch 15, iter 17, loss: 29.261969, acc: 0.857143\n",
      "epoch 15, iter 18, loss: 32.086025, acc: 0.714286\n",
      "epoch 15, iter 19, loss: 29.777476, acc: 0.877551\n",
      "epoch 15, iter 20, loss: 27.463927, acc: 0.918367\n",
      "epoch 15, iter 21, loss: 27.113164, acc: 0.816327\n",
      "epoch 15, iter 22, loss: 26.088401, acc: 0.836735\n",
      "epoch 15, iter 23, loss: 29.246875, acc: 0.734694\n",
      "epoch 15, iter 24, loss: 29.270945, acc: 0.795918\n",
      "epoch 15, iter 25, loss: 31.193504, acc: 0.693878\n",
      "epoch 15, iter 26, loss: 32.484134, acc: 0.795918\n",
      "epoch 15, iter 27, loss: 33.208887, acc: 0.734694\n",
      "epoch 15, iter 28, loss: 31.622444, acc: 0.795918\n",
      "epoch 15, iter 29, loss: 28.757948, acc: 0.857143\n",
      "epoch 15, iter 30, loss: 30.842055, acc: 0.673469\n",
      "epoch 15, iter 31, loss: 34.805828, acc: 0.591837\n",
      "epoch 15, iter 32, loss: 32.851689, acc: 0.836735\n",
      "epoch 15, iter 33, loss: 30.814134, acc: 0.857143\n",
      "epoch 15, iter 34, loss: 31.067624, acc: 0.693878\n",
      "epoch 15, iter 35, loss: 33.115135, acc: 0.673469\n",
      "epoch 15, iter 36, loss: 33.167563, acc: 0.857143\n",
      "epoch 15, iter 37, loss: 30.791509, acc: 0.877551\n",
      "epoch 15, iter 38, loss: 31.478582, acc: 0.714286\n",
      "epoch 15, iter 39, loss: 30.588351, acc: 0.816327\n",
      "epoch 15, iter 40, loss: 32.234077, acc: 0.755102\n",
      "epoch 15, iter 41, loss: 31.472835, acc: 0.836735\n",
      "epoch 15, iter 42, loss: 34.012867, acc: 0.714286\n",
      "epoch 15, iter 43, loss: 31.443927, acc: 0.918367\n",
      "epoch 15, iter 44, loss: 29.098402, acc: 0.877551\n",
      "epoch 15, iter 45, loss: 30.052729, acc: 0.755102\n",
      "epoch 15, iter 46, loss: 31.311660, acc: 0.755102\n",
      "epoch 15, iter 47, loss: 30.438898, acc: 0.775510\n",
      "epoch 15, iter 48, loss: 30.754823, acc: 0.714286\n",
      "epoch 15, iter 49, loss: 30.073229, acc: 0.836735\n",
      "epoch 15, iter 50, loss: 30.624267, acc: 0.836735\n",
      "epoch 15, iter 51, loss: 32.288628, acc: 0.693878\n",
      "epoch 15, iter 52, loss: 31.485139, acc: 0.959184\n",
      "epoch 15, iter 53, loss: 31.721684, acc: 0.755102\n",
      "epoch 15, iter 54, loss: 31.815878, acc: 0.714286\n",
      "epoch 15, iter 55, loss: 31.356680, acc: 0.836735\n",
      "epoch 15, iter 56, loss: 29.868036, acc: 0.857143\n",
      "epoch 15, iter 57, loss: 28.961870, acc: 0.857143\n",
      "epoch 15, iter 58, loss: 30.487550, acc: 0.795918\n",
      "epoch 15, iter 59, loss: 30.008473, acc: 0.836735\n",
      "epoch 15, iter 60, loss: 29.474254, acc: 0.816327\n",
      "epoch 15, iter 61, loss: 29.622388, acc: 0.857143\n",
      "epoch 15, iter 62, loss: 29.800356, acc: 0.836735\n",
      "epoch 15, iter 63, loss: 29.011529, acc: 0.877551\n",
      "epoch 15, iter 64, loss: 31.579791, acc: 0.612245\n",
      "epoch 15, iter 65, loss: 30.219689, acc: 0.816327\n",
      "epoch 15, iter 66, loss: 27.755042, acc: 0.897959\n",
      "epoch 15, iter 67, loss: 30.745304, acc: 0.693878\n",
      "epoch 15, iter 68, loss: 29.003934, acc: 0.775510\n",
      "epoch 15, iter 69, loss: 27.298532, acc: 0.857143\n",
      "epoch 15, iter 70, loss: 26.825850, acc: 0.836735\n",
      "epoch 15, iter 71, loss: 29.191266, acc: 0.755102\n",
      "epoch 15, iter 72, loss: 28.194363, acc: 0.877551\n",
      "epoch 15, iter 73, loss: 26.259671, acc: 0.918367\n",
      "epoch 15, iter 74, loss: 24.996773, acc: 0.877551\n",
      "epoch 15, iter 75, loss: 24.363615, acc: 0.877551\n",
      "epoch 15, iter 76, loss: 27.808151, acc: 0.755102\n",
      "epoch 15, iter 77, loss: 30.602604, acc: 0.673469\n",
      "epoch 15, iter 78, loss: 31.932869, acc: 0.693878\n",
      "epoch 15, iter 79, loss: 30.406272, acc: 0.816327\n",
      "epoch 15, iter 80, loss: 28.711793, acc: 0.918367\n",
      "epoch 15, iter 81, loss: 29.758667, acc: 0.714286\n",
      "epoch 15, iter 82, loss: 29.888222, acc: 0.734694\n",
      "epoch 15, iter 83, loss: 31.225088, acc: 0.755102\n",
      "epoch 15, iter 84, loss: 29.228662, acc: 0.877551\n",
      "epoch 15, iter 85, loss: 27.264250, acc: 0.877551\n",
      "epoch 15, iter 86, loss: 29.209325, acc: 0.714286\n",
      "epoch 15, iter 87, loss: 32.750313, acc: 0.653061\n",
      "epoch 15, iter 88, loss: 31.187971, acc: 0.857143\n",
      "epoch 15, iter 89, loss: 31.909594, acc: 0.714286\n",
      "epoch 15, iter 90, loss: 32.694571, acc: 0.714286\n",
      "epoch 15, iter 91, loss: 32.544408, acc: 0.795918\n",
      "epoch 15, iter 92, loss: 33.930039, acc: 0.734694\n",
      "epoch 15, iter 93, loss: 34.554271, acc: 0.693878\n",
      "epoch 15, iter 94, loss: 33.404757, acc: 0.836735\n",
      "epoch 15, iter 95, loss: 29.822293, acc: 0.918367\n",
      "epoch 15, iter 96, loss: 30.521698, acc: 0.816327\n",
      "epoch 15, iter 97, loss: 30.533241, acc: 0.755102\n",
      "epoch 15, iter 98, loss: 30.807464, acc: 0.755102\n",
      "epoch 15, iter 99, loss: 29.250514, acc: 0.836735\n",
      "epoch 15, iter 100, loss: 33.430983, acc: 0.612245\n",
      "epoch 15, iter 101, loss: 32.246990, acc: 0.734694\n",
      "epoch 15, iter 102, loss: 30.405778, acc: 0.877551\n",
      "epoch 15, iter 103, loss: 29.132376, acc: 0.857143\n",
      "epoch 15, iter 104, loss: 30.741867, acc: 0.734694\n",
      "epoch 15, iter 105, loss: 30.618954, acc: 0.775510\n",
      "epoch 15, iter 106, loss: 29.624302, acc: 0.795918\n",
      "epoch 15, iter 107, loss: 26.925011, acc: 0.938776\n",
      "epoch 15, iter 108, loss: 28.458318, acc: 0.734694\n",
      "epoch 15, iter 109, loss: 29.927238, acc: 0.632653\n",
      "epoch 15, iter 110, loss: 29.805570, acc: 0.816327\n",
      "epoch 15, iter 111, loss: 33.362356, acc: 0.591837\n",
      "epoch 15, iter 112, loss: 33.424758, acc: 0.836735\n",
      "epoch 15, iter 113, loss: 34.886498, acc: 0.673469\n",
      "epoch 15, iter 114, loss: 33.699023, acc: 0.816327\n",
      "epoch 15, iter 115, loss: 32.876918, acc: 0.734694\n",
      "epoch 15, iter 116, loss: 34.336430, acc: 0.714286\n",
      "epoch 15, iter 117, loss: 32.288224, acc: 0.918367\n",
      "epoch 15, iter 118, loss: 34.332672, acc: 0.693878\n",
      "epoch 15, iter 119, loss: 31.052611, acc: 0.918367\n",
      "epoch 15, iter 120, loss: 31.958787, acc: 0.734694\n",
      "epoch 15, iter 121, loss: 30.162321, acc: 0.857143\n",
      "epoch 15, iter 122, loss: 30.241820, acc: 0.795918\n",
      "epoch 15, iter 123, loss: 29.805129, acc: 0.836735\n",
      "epoch 15, iter 124, loss: 30.859267, acc: 0.816327\n",
      "epoch 15, iter 125, loss: 33.414234, acc: 0.653061\n",
      "epoch 15, iter 126, loss: 30.893622, acc: 0.938776\n",
      "epoch 15, iter 127, loss: 34.676779, acc: 0.612245\n",
      "epoch 15, iter 128, loss: 33.801335, acc: 0.775510\n",
      "epoch 15, iter 129, loss: 32.605346, acc: 0.836735\n",
      "epoch 15, iter 130, loss: 30.177862, acc: 0.918367\n",
      "epoch 15, iter 131, loss: 29.628455, acc: 0.795918\n",
      "epoch 15, iter 132, loss: 30.333618, acc: 0.734694\n",
      "epoch 15, iter 133, loss: 28.792141, acc: 0.877551\n",
      "epoch 15, iter 134, loss: 32.128235, acc: 0.653061\n",
      "epoch 15, iter 135, loss: 32.730521, acc: 0.734694\n",
      "epoch 15, iter 136, loss: 32.447053, acc: 0.857143\n",
      "epoch 15, iter 137, loss: 31.590918, acc: 0.836735\n",
      "epoch 15, iter 138, loss: 31.312138, acc: 0.877551\n",
      "epoch 15, iter 139, loss: 30.777468, acc: 0.795918\n",
      "epoch 15, iter 140, loss: 31.207565, acc: 0.775510\n",
      "epoch 15, iter 141, loss: 29.914948, acc: 0.877551\n",
      "epoch 15, iter 142, loss: 31.149490, acc: 0.693878\n",
      "epoch 15, iter 143, loss: 30.747753, acc: 0.836735\n",
      "epoch 15, iter 144, loss: 31.592195, acc: 0.653061\n",
      "epoch 15, iter 145, loss: 29.402261, acc: 0.918367\n",
      "epoch 15, iter 146, loss: 29.304112, acc: 0.816327\n",
      "epoch 15, iter 147, loss: 29.163031, acc: 0.857143\n",
      "epoch 15, iter 148, loss: 29.091835, acc: 0.816327\n",
      "epoch 15, iter 149, loss: 27.210894, acc: 0.938776\n",
      "epoch 15, iter 150, loss: 28.371436, acc: 0.795918\n",
      "epoch 15, iter 151, loss: 28.991794, acc: 0.734694\n",
      "epoch 15, iter 152, loss: 28.922794, acc: 0.816327\n",
      "epoch 15, iter 153, loss: 31.088362, acc: 0.693878\n",
      "epoch 15, iter 154, loss: 32.142578, acc: 0.714286\n",
      "epoch 15, iter 155, loss: 31.195814, acc: 0.795918\n",
      "epoch 15, iter 156, loss: 29.696025, acc: 0.857143\n",
      "epoch 15, iter 157, loss: 30.823097, acc: 0.795918\n",
      "epoch 15, iter 158, loss: 27.992556, acc: 0.897959\n",
      "epoch 15, iter 159, loss: 32.390686, acc: 0.653061\n",
      "epoch 15, iter 160, loss: 33.516631, acc: 0.693878\n",
      "epoch 15, iter 161, loss: 31.087803, acc: 0.816327\n",
      "epoch 15, iter 162, loss: 31.044859, acc: 0.734694\n",
      "epoch 15, iter 163, loss: 31.740675, acc: 0.775510\n",
      "epoch 15, iter 164, loss: 32.736722, acc: 0.734694\n",
      "epoch 15, iter 165, loss: 30.245284, acc: 0.918367\n",
      "epoch 15, iter 166, loss: 29.421965, acc: 0.816327\n",
      "epoch 15, iter 167, loss: 30.589054, acc: 0.714286\n",
      "epoch 15, iter 168, loss: 30.585354, acc: 0.755102\n",
      "epoch 15, iter 169, loss: 30.450248, acc: 0.755102\n",
      "epoch 15, iter 170, loss: 34.080733, acc: 0.714286\n",
      "epoch 15, iter 171, loss: 34.930979, acc: 0.714286\n",
      "epoch 15, iter 172, loss: 34.708947, acc: 0.795918\n",
      "epoch 15, iter 173, loss: 34.074212, acc: 0.755102\n",
      "epoch 15, iter 174, loss: 34.164248, acc: 0.795918\n",
      "epoch 15, iter 175, loss: 32.585188, acc: 0.857143\n",
      "epoch 15, iter 176, loss: 30.710738, acc: 0.857143\n",
      "epoch 15, iter 177, loss: 29.617573, acc: 0.897959\n",
      "epoch 15, iter 178, loss: 30.651171, acc: 0.755102\n",
      "epoch 15, iter 179, loss: 29.970831, acc: 0.734694\n",
      "epoch 15, iter 180, loss: 28.335060, acc: 0.836735\n",
      "epoch 15, iter 181, loss: 30.585302, acc: 0.734694\n",
      "epoch 15, iter 182, loss: 30.082387, acc: 0.857143\n",
      "epoch 15, iter 183, loss: 32.547095, acc: 0.591837\n",
      "epoch 15, iter 184, loss: 31.634419, acc: 0.816327\n",
      "epoch 15, iter 185, loss: 32.771553, acc: 0.714286\n",
      "epoch 15, iter 186, loss: 30.663643, acc: 0.918367\n",
      "epoch 15, iter 187, loss: 32.752000, acc: 0.714286\n",
      "epoch 15, iter 188, loss: 35.298868, acc: 0.653061\n",
      "epoch 15, iter 189, loss: 35.827088, acc: 0.714286\n",
      "epoch 15, iter 190, loss: 34.749039, acc: 0.795918\n",
      "epoch 15, iter 191, loss: 32.658628, acc: 0.877551\n",
      "epoch 15, iter 192, loss: 31.727017, acc: 0.857143\n",
      "epoch 15, iter 193, loss: 34.001958, acc: 0.653061\n",
      "epoch 15, iter 194, loss: 32.957120, acc: 0.755102\n",
      "epoch 15, iter 195, loss: 32.785838, acc: 0.734694\n",
      "epoch 15, iter 196, loss: 30.863949, acc: 0.836735\n",
      "epoch 15, iter 197, loss: 31.113819, acc: 0.775510\n",
      "epoch 15, iter 198, loss: 31.245783, acc: 0.795918\n",
      "epoch 15, iter 199, loss: 31.716035, acc: 0.714286\n",
      "epoch 15, iter 200, loss: 31.415743, acc: 0.775510\n",
      "epoch 15, iter 201, loss: 31.731225, acc: 0.836735\n",
      "epoch 15, iter 202, loss: 30.178959, acc: 0.877551\n",
      "epoch 15, iter 203, loss: 32.092736, acc: 0.714286\n",
      "epoch 15, iter 204, loss: 31.996586, acc: 0.734694\n",
      "epoch 15, iter 205, loss: 36.035205, acc: 0.693878\n",
      "epoch 15, iter 206, loss: 35.480692, acc: 0.775510\n",
      "epoch 15, iter 207, loss: 34.269081, acc: 0.857143\n",
      "epoch 15, iter 208, loss: 32.020960, acc: 0.897959\n",
      "epoch 15, iter 209, loss: 30.337939, acc: 0.877551\n",
      "epoch 15, iter 210, loss: 31.140391, acc: 0.795918\n",
      "epoch 15, iter 211, loss: 29.744720, acc: 0.795918\n",
      "epoch 15, iter 212, loss: 30.563612, acc: 0.795918\n",
      "epoch 15, iter 213, loss: 29.395360, acc: 0.836735\n",
      "epoch 15, iter 214, loss: 28.305372, acc: 0.897959\n",
      "epoch 15, iter 215, loss: 30.964655, acc: 0.714286\n",
      "epoch 15, iter 216, loss: 30.248819, acc: 0.795918\n",
      "epoch 15, iter 217, loss: 32.289186, acc: 0.795918\n",
      "epoch 15, iter 218, loss: 31.884435, acc: 0.857143\n",
      "epoch 15, iter 219, loss: 30.122837, acc: 0.897959\n",
      "epoch 15, iter 220, loss: 32.066801, acc: 0.591837\n",
      "epoch 15, iter 221, loss: 31.374747, acc: 0.795918\n",
      "epoch 15, iter 222, loss: 33.570724, acc: 0.673469\n",
      "epoch 15, iter 223, loss: 30.594660, acc: 0.918367\n",
      "epoch 15, iter 224, loss: 30.829649, acc: 0.714286\n",
      "epoch 15, iter 225, loss: 31.336804, acc: 0.755102\n",
      "epoch 15, iter 226, loss: 31.726361, acc: 0.734694\n",
      "epoch 15, iter 227, loss: 30.738785, acc: 0.816327\n",
      "epoch 15, iter 228, loss: 30.960711, acc: 0.795918\n",
      "epoch 15, iter 229, loss: 27.828046, acc: 0.918367\n",
      "epoch 15, iter 230, loss: 28.740112, acc: 0.775510\n",
      "epoch 15, iter 231, loss: 27.627585, acc: 0.877551\n",
      "epoch 15, iter 232, loss: 29.362032, acc: 0.795918\n",
      "epoch 15, iter 233, loss: 31.140502, acc: 0.673469\n",
      "epoch 15, iter 234, loss: 29.241376, acc: 0.938776\n",
      "epoch 15, iter 235, loss: 29.532294, acc: 0.836735\n",
      "epoch 15, iter 236, loss: 27.455816, acc: 0.959184\n",
      "epoch 15, iter 237, loss: 30.431629, acc: 0.612245\n",
      "epoch 15, iter 238, loss: 33.195675, acc: 0.755102\n",
      "epoch 15, iter 239, loss: 33.157259, acc: 0.795918\n",
      "epoch 15, iter 240, loss: 32.010850, acc: 0.877551\n",
      "epoch 15, iter 241, loss: 31.571044, acc: 0.795918\n",
      "epoch 15, iter 242, loss: 32.872784, acc: 0.734694\n",
      "epoch 15, iter 243, loss: 31.879600, acc: 0.857143\n",
      "epoch 15, iter 244, loss: 31.509064, acc: 0.775510\n",
      "epoch 15, iter 245, loss: 31.592366, acc: 0.775510\n",
      "epoch 15, iter 246, loss: 34.178072, acc: 0.653061\n",
      "epoch 15, iter 247, loss: 33.878448, acc: 0.775510\n",
      "epoch 15, iter 248, loss: 36.175189, acc: 0.653061\n",
      "epoch 15, iter 249, loss: 36.372999, acc: 0.714286\n",
      "epoch 15, acc: 0.788327\n",
      "epoch 16, iter 0, loss: 36.199382, acc: 0.673469\n",
      "epoch 16, iter 1, loss: 36.526066, acc: 0.836735\n",
      "epoch 16, iter 2, loss: 35.890498, acc: 0.755102\n",
      "epoch 16, iter 3, loss: 34.742918, acc: 0.857143\n",
      "epoch 16, iter 4, loss: 32.893226, acc: 0.857143\n",
      "epoch 16, iter 5, loss: 31.209406, acc: 0.918367\n",
      "epoch 16, iter 6, loss: 30.394442, acc: 0.897959\n",
      "epoch 16, iter 7, loss: 32.264198, acc: 0.673469\n",
      "epoch 16, iter 8, loss: 32.364535, acc: 0.775510\n",
      "epoch 16, iter 9, loss: 32.584700, acc: 0.755102\n",
      "epoch 16, iter 10, loss: 32.801036, acc: 0.714286\n",
      "epoch 16, iter 11, loss: 34.956587, acc: 0.673469\n",
      "epoch 16, iter 12, loss: 32.770601, acc: 0.877551\n",
      "epoch 16, iter 13, loss: 32.127121, acc: 0.836735\n",
      "epoch 16, iter 14, loss: 31.250001, acc: 0.857143\n",
      "epoch 16, iter 15, loss: 29.252082, acc: 0.938776\n",
      "epoch 16, iter 16, loss: 30.273227, acc: 0.755102\n",
      "epoch 16, iter 17, loss: 29.589417, acc: 0.836735\n",
      "epoch 16, iter 18, loss: 32.205410, acc: 0.734694\n",
      "epoch 16, iter 19, loss: 29.760374, acc: 0.877551\n",
      "epoch 16, iter 20, loss: 27.387388, acc: 0.918367\n",
      "epoch 16, iter 21, loss: 27.030426, acc: 0.836735\n",
      "epoch 16, iter 22, loss: 26.058144, acc: 0.836735\n",
      "epoch 16, iter 23, loss: 29.181380, acc: 0.714286\n",
      "epoch 16, iter 24, loss: 29.194197, acc: 0.795918\n",
      "epoch 16, iter 25, loss: 31.094185, acc: 0.693878\n",
      "epoch 16, iter 26, loss: 32.342869, acc: 0.775510\n",
      "epoch 16, iter 27, loss: 33.162809, acc: 0.755102\n",
      "epoch 16, iter 28, loss: 31.509079, acc: 0.795918\n",
      "epoch 16, iter 29, loss: 28.707386, acc: 0.857143\n",
      "epoch 16, iter 30, loss: 30.693214, acc: 0.673469\n",
      "epoch 16, iter 31, loss: 34.651797, acc: 0.591837\n",
      "epoch 16, iter 32, loss: 32.736831, acc: 0.857143\n",
      "epoch 16, iter 33, loss: 30.685776, acc: 0.836735\n",
      "epoch 16, iter 34, loss: 30.956314, acc: 0.734694\n",
      "epoch 16, iter 35, loss: 32.990019, acc: 0.653061\n",
      "epoch 16, iter 36, loss: 33.036795, acc: 0.836735\n",
      "epoch 16, iter 37, loss: 30.716415, acc: 0.877551\n",
      "epoch 16, iter 38, loss: 31.521904, acc: 0.693878\n",
      "epoch 16, iter 39, loss: 30.608592, acc: 0.816327\n",
      "epoch 16, iter 40, loss: 32.195959, acc: 0.734694\n",
      "epoch 16, iter 41, loss: 31.460734, acc: 0.816327\n",
      "epoch 16, iter 42, loss: 34.039957, acc: 0.693878\n",
      "epoch 16, iter 43, loss: 31.272776, acc: 0.918367\n",
      "epoch 16, iter 44, loss: 28.976099, acc: 0.857143\n",
      "epoch 16, iter 45, loss: 29.884522, acc: 0.755102\n",
      "epoch 16, iter 46, loss: 31.166514, acc: 0.775510\n",
      "epoch 16, iter 47, loss: 30.269421, acc: 0.775510\n",
      "epoch 16, iter 48, loss: 30.529460, acc: 0.755102\n",
      "epoch 16, iter 49, loss: 29.919727, acc: 0.816327\n",
      "epoch 16, iter 50, loss: 30.513161, acc: 0.836735\n",
      "epoch 16, iter 51, loss: 32.209595, acc: 0.693878\n",
      "epoch 16, iter 52, loss: 31.456021, acc: 0.959184\n",
      "epoch 16, iter 53, loss: 31.647881, acc: 0.755102\n",
      "epoch 16, iter 54, loss: 31.716745, acc: 0.734694\n",
      "epoch 16, iter 55, loss: 31.322447, acc: 0.816327\n",
      "epoch 16, iter 56, loss: 29.789240, acc: 0.857143\n",
      "epoch 16, iter 57, loss: 28.848305, acc: 0.857143\n",
      "epoch 16, iter 58, loss: 30.517063, acc: 0.693878\n",
      "epoch 16, iter 59, loss: 29.835160, acc: 0.795918\n",
      "epoch 16, iter 60, loss: 29.394247, acc: 0.795918\n",
      "epoch 16, iter 61, loss: 29.565530, acc: 0.857143\n",
      "epoch 16, iter 62, loss: 29.773223, acc: 0.816327\n",
      "epoch 16, iter 63, loss: 28.980984, acc: 0.857143\n",
      "epoch 16, iter 64, loss: 31.521282, acc: 0.632653\n",
      "epoch 16, iter 65, loss: 30.119397, acc: 0.816327\n",
      "epoch 16, iter 66, loss: 27.619512, acc: 0.897959\n",
      "epoch 16, iter 67, loss: 30.617256, acc: 0.653061\n",
      "epoch 16, iter 68, loss: 28.877727, acc: 0.775510\n",
      "epoch 16, iter 69, loss: 27.192586, acc: 0.836735\n",
      "epoch 16, iter 70, loss: 26.692873, acc: 0.836735\n",
      "epoch 16, iter 71, loss: 29.105135, acc: 0.775510\n",
      "epoch 16, iter 72, loss: 28.087372, acc: 0.877551\n",
      "epoch 16, iter 73, loss: 26.074532, acc: 0.938776\n",
      "epoch 16, iter 74, loss: 24.920308, acc: 0.857143\n",
      "epoch 16, iter 75, loss: 24.315697, acc: 0.857143\n",
      "epoch 16, iter 76, loss: 27.715759, acc: 0.755102\n",
      "epoch 16, iter 77, loss: 30.440975, acc: 0.673469\n",
      "epoch 16, iter 78, loss: 31.896944, acc: 0.693878\n",
      "epoch 16, iter 79, loss: 30.344622, acc: 0.836735\n",
      "epoch 16, iter 80, loss: 28.677742, acc: 0.918367\n",
      "epoch 16, iter 81, loss: 29.832341, acc: 0.734694\n",
      "epoch 16, iter 82, loss: 29.884824, acc: 0.714286\n",
      "epoch 16, iter 83, loss: 31.205231, acc: 0.755102\n",
      "epoch 16, iter 84, loss: 29.196209, acc: 0.857143\n",
      "epoch 16, iter 85, loss: 27.174775, acc: 0.877551\n",
      "epoch 16, iter 86, loss: 29.115496, acc: 0.693878\n",
      "epoch 16, iter 87, loss: 32.775064, acc: 0.653061\n",
      "epoch 16, iter 88, loss: 31.153829, acc: 0.857143\n",
      "epoch 16, iter 89, loss: 31.897541, acc: 0.714286\n",
      "epoch 16, iter 90, loss: 32.687735, acc: 0.693878\n",
      "epoch 16, iter 91, loss: 32.461775, acc: 0.795918\n",
      "epoch 16, iter 92, loss: 33.753925, acc: 0.734694\n",
      "epoch 16, iter 93, loss: 34.292204, acc: 0.734694\n",
      "epoch 16, iter 94, loss: 33.242881, acc: 0.836735\n",
      "epoch 16, iter 95, loss: 29.604382, acc: 0.918367\n",
      "epoch 16, iter 96, loss: 30.434444, acc: 0.836735\n",
      "epoch 16, iter 97, loss: 30.511032, acc: 0.775510\n",
      "epoch 16, iter 98, loss: 30.716889, acc: 0.775510\n",
      "epoch 16, iter 99, loss: 29.255443, acc: 0.836735\n",
      "epoch 16, iter 100, loss: 33.394632, acc: 0.612245\n",
      "epoch 16, iter 101, loss: 32.200844, acc: 0.734694\n",
      "epoch 16, iter 102, loss: 30.316306, acc: 0.877551\n",
      "epoch 16, iter 103, loss: 29.032484, acc: 0.857143\n",
      "epoch 16, iter 104, loss: 30.733060, acc: 0.734694\n",
      "epoch 16, iter 105, loss: 30.593847, acc: 0.775510\n",
      "epoch 16, iter 106, loss: 29.637405, acc: 0.795918\n",
      "epoch 16, iter 107, loss: 26.899852, acc: 0.938776\n",
      "epoch 16, iter 108, loss: 28.361833, acc: 0.734694\n",
      "epoch 16, iter 109, loss: 29.747089, acc: 0.653061\n",
      "epoch 16, iter 110, loss: 29.545286, acc: 0.795918\n",
      "epoch 16, iter 111, loss: 32.924520, acc: 0.612245\n",
      "epoch 16, iter 112, loss: 33.013292, acc: 0.816327\n",
      "epoch 16, iter 113, loss: 34.532391, acc: 0.673469\n",
      "epoch 16, iter 114, loss: 33.534035, acc: 0.775510\n",
      "epoch 16, iter 115, loss: 32.533364, acc: 0.714286\n",
      "epoch 16, iter 116, loss: 33.987814, acc: 0.734694\n",
      "epoch 16, iter 117, loss: 31.865524, acc: 0.918367\n",
      "epoch 16, iter 118, loss: 33.745943, acc: 0.714286\n",
      "epoch 16, iter 119, loss: 30.428892, acc: 0.918367\n",
      "epoch 16, iter 120, loss: 31.380037, acc: 0.734694\n",
      "epoch 16, iter 121, loss: 29.832340, acc: 0.857143\n",
      "epoch 16, iter 122, loss: 29.912839, acc: 0.775510\n",
      "epoch 16, iter 123, loss: 29.647313, acc: 0.816327\n",
      "epoch 16, iter 124, loss: 30.728588, acc: 0.816327\n",
      "epoch 16, iter 125, loss: 33.322560, acc: 0.653061\n",
      "epoch 16, iter 126, loss: 30.809918, acc: 0.959184\n",
      "epoch 16, iter 127, loss: 34.812099, acc: 0.551020\n",
      "epoch 16, iter 128, loss: 32.769918, acc: 0.877551\n",
      "epoch 16, iter 129, loss: 31.958227, acc: 0.734694\n",
      "epoch 16, iter 130, loss: 29.707925, acc: 0.938776\n",
      "epoch 16, iter 131, loss: 29.136527, acc: 0.816327\n",
      "epoch 16, iter 132, loss: 29.875075, acc: 0.755102\n",
      "epoch 16, iter 133, loss: 28.399814, acc: 0.897959\n",
      "epoch 16, iter 134, loss: 31.655822, acc: 0.632653\n",
      "epoch 16, iter 135, loss: 32.457560, acc: 0.693878\n",
      "epoch 16, iter 136, loss: 32.034666, acc: 0.857143\n",
      "epoch 16, iter 137, loss: 31.037776, acc: 0.836735\n",
      "epoch 16, iter 138, loss: 30.965509, acc: 0.857143\n",
      "epoch 16, iter 139, loss: 30.501550, acc: 0.816327\n",
      "epoch 16, iter 140, loss: 31.044613, acc: 0.775510\n",
      "epoch 16, iter 141, loss: 29.646543, acc: 0.877551\n",
      "epoch 16, iter 142, loss: 30.846572, acc: 0.714286\n",
      "epoch 16, iter 143, loss: 30.553288, acc: 0.836735\n",
      "epoch 16, iter 144, loss: 31.429087, acc: 0.632653\n",
      "epoch 16, iter 145, loss: 29.219536, acc: 0.918367\n",
      "epoch 16, iter 146, loss: 29.162917, acc: 0.857143\n",
      "epoch 16, iter 147, loss: 28.902132, acc: 0.836735\n",
      "epoch 16, iter 148, loss: 28.861207, acc: 0.816327\n",
      "epoch 16, iter 149, loss: 27.050383, acc: 0.938776\n",
      "epoch 16, iter 150, loss: 28.232684, acc: 0.795918\n",
      "epoch 16, iter 151, loss: 28.881798, acc: 0.734694\n",
      "epoch 16, iter 152, loss: 28.897131, acc: 0.816327\n",
      "epoch 16, iter 153, loss: 30.907659, acc: 0.693878\n",
      "epoch 16, iter 154, loss: 31.978333, acc: 0.693878\n",
      "epoch 16, iter 155, loss: 31.052109, acc: 0.795918\n",
      "epoch 16, iter 156, loss: 29.535777, acc: 0.877551\n",
      "epoch 16, iter 157, loss: 30.617314, acc: 0.775510\n",
      "epoch 16, iter 158, loss: 27.887871, acc: 0.897959\n",
      "epoch 16, iter 159, loss: 32.204278, acc: 0.673469\n",
      "epoch 16, iter 160, loss: 33.237904, acc: 0.693878\n",
      "epoch 16, iter 161, loss: 30.929470, acc: 0.897959\n",
      "epoch 16, iter 162, loss: 31.012171, acc: 0.734694\n",
      "epoch 16, iter 163, loss: 31.747170, acc: 0.734694\n",
      "epoch 16, iter 164, loss: 32.584229, acc: 0.775510\n",
      "epoch 16, iter 165, loss: 30.189670, acc: 0.897959\n",
      "epoch 16, iter 166, loss: 29.479254, acc: 0.816327\n",
      "epoch 16, iter 167, loss: 30.536974, acc: 0.775510\n",
      "epoch 16, iter 168, loss: 30.420662, acc: 0.795918\n",
      "epoch 16, iter 169, loss: 30.429679, acc: 0.816327\n",
      "epoch 16, iter 170, loss: 33.512960, acc: 0.693878\n",
      "epoch 16, iter 171, loss: 34.653379, acc: 0.693878\n",
      "epoch 16, iter 172, loss: 34.750021, acc: 0.734694\n",
      "epoch 16, iter 173, loss: 33.738707, acc: 0.734694\n",
      "epoch 16, iter 174, loss: 33.538948, acc: 0.795918\n",
      "epoch 16, iter 175, loss: 32.759038, acc: 0.795918\n",
      "epoch 16, iter 176, loss: 31.011186, acc: 0.836735\n",
      "epoch 16, iter 177, loss: 29.645331, acc: 0.897959\n",
      "epoch 16, iter 178, loss: 30.618039, acc: 0.775510\n",
      "epoch 16, iter 179, loss: 29.914311, acc: 0.734694\n",
      "epoch 16, iter 180, loss: 28.454905, acc: 0.877551\n",
      "epoch 16, iter 181, loss: 30.753230, acc: 0.714286\n",
      "epoch 16, iter 182, loss: 30.189384, acc: 0.816327\n",
      "epoch 16, iter 183, loss: 32.313923, acc: 0.612245\n",
      "epoch 16, iter 184, loss: 31.241850, acc: 0.836735\n",
      "epoch 16, iter 185, loss: 32.762335, acc: 0.693878\n",
      "epoch 16, iter 186, loss: 30.560727, acc: 0.918367\n",
      "epoch 16, iter 187, loss: 32.626193, acc: 0.714286\n",
      "epoch 16, iter 188, loss: 35.130946, acc: 0.714286\n",
      "epoch 16, iter 189, loss: 36.024274, acc: 0.734694\n",
      "epoch 16, iter 190, loss: 34.837699, acc: 0.816327\n",
      "epoch 16, iter 191, loss: 32.750230, acc: 0.836735\n",
      "epoch 16, iter 192, loss: 31.313777, acc: 0.857143\n",
      "epoch 16, iter 193, loss: 34.173256, acc: 0.653061\n",
      "epoch 16, iter 194, loss: 32.987962, acc: 0.734694\n",
      "epoch 16, iter 195, loss: 32.721814, acc: 0.734694\n",
      "epoch 16, iter 196, loss: 30.802616, acc: 0.857143\n",
      "epoch 16, iter 197, loss: 30.822437, acc: 0.775510\n",
      "epoch 16, iter 198, loss: 31.162918, acc: 0.775510\n",
      "epoch 16, iter 199, loss: 31.638950, acc: 0.734694\n",
      "epoch 16, iter 200, loss: 31.114789, acc: 0.795918\n",
      "epoch 16, iter 201, loss: 31.644214, acc: 0.836735\n",
      "epoch 16, iter 202, loss: 30.165749, acc: 0.857143\n",
      "epoch 16, iter 203, loss: 32.105237, acc: 0.714286\n",
      "epoch 16, iter 204, loss: 32.188376, acc: 0.734694\n",
      "epoch 16, iter 205, loss: 35.979800, acc: 0.673469\n",
      "epoch 16, iter 206, loss: 34.743264, acc: 0.795918\n",
      "epoch 16, iter 207, loss: 33.469947, acc: 0.836735\n",
      "epoch 16, iter 208, loss: 31.906692, acc: 0.897959\n",
      "epoch 16, iter 209, loss: 30.045275, acc: 0.877551\n",
      "epoch 16, iter 210, loss: 30.911864, acc: 0.775510\n",
      "epoch 16, iter 211, loss: 29.554726, acc: 0.816327\n",
      "epoch 16, iter 212, loss: 30.378373, acc: 0.734694\n",
      "epoch 16, iter 213, loss: 29.125707, acc: 0.836735\n",
      "epoch 16, iter 214, loss: 28.033664, acc: 0.897959\n",
      "epoch 16, iter 215, loss: 30.672820, acc: 0.693878\n",
      "epoch 16, iter 216, loss: 29.900736, acc: 0.795918\n",
      "epoch 16, iter 217, loss: 31.965112, acc: 0.795918\n",
      "epoch 16, iter 218, loss: 31.646987, acc: 0.857143\n",
      "epoch 16, iter 219, loss: 29.923111, acc: 0.897959\n",
      "epoch 16, iter 220, loss: 31.869338, acc: 0.653061\n",
      "epoch 16, iter 221, loss: 31.252104, acc: 0.795918\n",
      "epoch 16, iter 222, loss: 33.545475, acc: 0.673469\n",
      "epoch 16, iter 223, loss: 30.582288, acc: 0.918367\n",
      "epoch 16, iter 224, loss: 30.812420, acc: 0.734694\n",
      "epoch 16, iter 225, loss: 31.280304, acc: 0.755102\n",
      "epoch 16, iter 226, loss: 31.662831, acc: 0.755102\n",
      "epoch 16, iter 227, loss: 30.565680, acc: 0.816327\n",
      "epoch 16, iter 228, loss: 30.825102, acc: 0.795918\n",
      "epoch 16, iter 229, loss: 27.768188, acc: 0.918367\n",
      "epoch 16, iter 230, loss: 28.722908, acc: 0.775510\n",
      "epoch 16, iter 231, loss: 27.558227, acc: 0.877551\n",
      "epoch 16, iter 232, loss: 29.424469, acc: 0.775510\n",
      "epoch 16, iter 233, loss: 31.239716, acc: 0.693878\n",
      "epoch 16, iter 234, loss: 29.296590, acc: 0.938776\n",
      "epoch 16, iter 235, loss: 29.517633, acc: 0.836735\n",
      "epoch 16, iter 236, loss: 27.392320, acc: 0.979592\n",
      "epoch 16, iter 237, loss: 30.354343, acc: 0.612245\n",
      "epoch 16, iter 238, loss: 33.166746, acc: 0.734694\n",
      "epoch 16, iter 239, loss: 33.063078, acc: 0.775510\n",
      "epoch 16, iter 240, loss: 31.740949, acc: 0.877551\n",
      "epoch 16, iter 241, loss: 31.451915, acc: 0.795918\n",
      "epoch 16, iter 242, loss: 32.861837, acc: 0.755102\n",
      "epoch 16, iter 243, loss: 31.891587, acc: 0.857143\n",
      "epoch 16, iter 244, loss: 31.637701, acc: 0.775510\n",
      "epoch 16, iter 245, loss: 31.549672, acc: 0.795918\n",
      "epoch 16, iter 246, loss: 33.847560, acc: 0.632653\n",
      "epoch 16, iter 247, loss: 33.573115, acc: 0.795918\n",
      "epoch 16, iter 248, loss: 35.487442, acc: 0.653061\n",
      "epoch 16, iter 249, loss: 35.780475, acc: 0.755102\n",
      "epoch 16, acc: 0.788816\n",
      "epoch 17, iter 0, loss: 35.714107, acc: 0.693878\n",
      "epoch 17, iter 1, loss: 36.082648, acc: 0.857143\n",
      "epoch 17, iter 2, loss: 35.385362, acc: 0.755102\n",
      "epoch 17, iter 3, loss: 34.104406, acc: 0.816327\n",
      "epoch 17, iter 4, loss: 32.249473, acc: 0.918367\n",
      "epoch 17, iter 5, loss: 30.735868, acc: 0.918367\n",
      "epoch 17, iter 6, loss: 29.858537, acc: 0.897959\n",
      "epoch 17, iter 7, loss: 31.742278, acc: 0.673469\n",
      "epoch 17, iter 8, loss: 32.006271, acc: 0.755102\n",
      "epoch 17, iter 9, loss: 32.279713, acc: 0.816327\n",
      "epoch 17, iter 10, loss: 32.549125, acc: 0.673469\n",
      "epoch 17, iter 11, loss: 34.558538, acc: 0.693878\n",
      "epoch 17, iter 12, loss: 32.796744, acc: 0.877551\n",
      "epoch 17, iter 13, loss: 32.093045, acc: 0.816327\n",
      "epoch 17, iter 14, loss: 31.140703, acc: 0.816327\n",
      "epoch 17, iter 15, loss: 28.878586, acc: 0.938776\n",
      "epoch 17, iter 16, loss: 29.996111, acc: 0.755102\n",
      "epoch 17, iter 17, loss: 29.353527, acc: 0.836735\n",
      "epoch 17, iter 18, loss: 31.918240, acc: 0.714286\n",
      "epoch 17, iter 19, loss: 29.201060, acc: 0.877551\n",
      "epoch 17, iter 20, loss: 27.169213, acc: 0.918367\n",
      "epoch 17, iter 21, loss: 26.922657, acc: 0.836735\n",
      "epoch 17, iter 22, loss: 26.047038, acc: 0.836735\n",
      "epoch 17, iter 23, loss: 29.114976, acc: 0.714286\n",
      "epoch 17, iter 24, loss: 29.160017, acc: 0.795918\n",
      "epoch 17, iter 25, loss: 31.181226, acc: 0.673469\n",
      "epoch 17, iter 26, loss: 32.308309, acc: 0.775510\n",
      "epoch 17, iter 27, loss: 33.061138, acc: 0.714286\n",
      "epoch 17, iter 28, loss: 31.485080, acc: 0.795918\n",
      "epoch 17, iter 29, loss: 28.616044, acc: 0.877551\n",
      "epoch 17, iter 30, loss: 30.465333, acc: 0.673469\n",
      "epoch 17, iter 31, loss: 34.453747, acc: 0.591837\n",
      "epoch 17, iter 32, loss: 32.480933, acc: 0.836735\n",
      "epoch 17, iter 33, loss: 30.467516, acc: 0.857143\n",
      "epoch 17, iter 34, loss: 30.724717, acc: 0.693878\n",
      "epoch 17, iter 35, loss: 32.860007, acc: 0.673469\n",
      "epoch 17, iter 36, loss: 33.096703, acc: 0.836735\n",
      "epoch 17, iter 37, loss: 30.656590, acc: 0.877551\n",
      "epoch 17, iter 38, loss: 31.351339, acc: 0.755102\n",
      "epoch 17, iter 39, loss: 30.387851, acc: 0.816327\n",
      "epoch 17, iter 40, loss: 31.971361, acc: 0.755102\n",
      "epoch 17, iter 41, loss: 31.366368, acc: 0.836735\n",
      "epoch 17, iter 42, loss: 34.065358, acc: 0.693878\n",
      "epoch 17, iter 43, loss: 31.131992, acc: 0.897959\n",
      "epoch 17, iter 44, loss: 28.863460, acc: 0.836735\n",
      "epoch 17, iter 45, loss: 29.774106, acc: 0.734694\n",
      "epoch 17, iter 46, loss: 30.928267, acc: 0.775510\n",
      "epoch 17, iter 47, loss: 29.984092, acc: 0.795918\n",
      "epoch 17, iter 48, loss: 30.164862, acc: 0.755102\n",
      "epoch 17, iter 49, loss: 29.663730, acc: 0.836735\n",
      "epoch 17, iter 50, loss: 30.343382, acc: 0.816327\n",
      "epoch 17, iter 51, loss: 32.076782, acc: 0.673469\n",
      "epoch 17, iter 52, loss: 31.536433, acc: 0.897959\n",
      "epoch 17, iter 53, loss: 31.768057, acc: 0.775510\n",
      "epoch 17, iter 54, loss: 31.634339, acc: 0.734694\n",
      "epoch 17, iter 55, loss: 31.364616, acc: 0.795918\n",
      "epoch 17, iter 56, loss: 29.827046, acc: 0.857143\n",
      "epoch 17, iter 57, loss: 28.758124, acc: 0.857143\n",
      "epoch 17, iter 58, loss: 30.480188, acc: 0.693878\n",
      "epoch 17, iter 59, loss: 29.829174, acc: 0.795918\n",
      "epoch 17, iter 60, loss: 29.359872, acc: 0.795918\n",
      "epoch 17, iter 61, loss: 29.518232, acc: 0.836735\n",
      "epoch 17, iter 62, loss: 29.752962, acc: 0.836735\n",
      "epoch 17, iter 63, loss: 28.960021, acc: 0.836735\n",
      "epoch 17, iter 64, loss: 31.415187, acc: 0.591837\n",
      "epoch 17, iter 65, loss: 30.033412, acc: 0.836735\n",
      "epoch 17, iter 66, loss: 27.535014, acc: 0.897959\n",
      "epoch 17, iter 67, loss: 30.502452, acc: 0.673469\n",
      "epoch 17, iter 68, loss: 28.732241, acc: 0.775510\n",
      "epoch 17, iter 69, loss: 27.031519, acc: 0.857143\n",
      "epoch 17, iter 70, loss: 26.520753, acc: 0.857143\n",
      "epoch 17, iter 71, loss: 28.974966, acc: 0.775510\n",
      "epoch 17, iter 72, loss: 28.045171, acc: 0.877551\n",
      "epoch 17, iter 73, loss: 25.946047, acc: 0.938776\n",
      "epoch 17, iter 74, loss: 24.901102, acc: 0.857143\n",
      "epoch 17, iter 75, loss: 24.272249, acc: 0.857143\n",
      "epoch 17, iter 76, loss: 27.639510, acc: 0.734694\n",
      "epoch 17, iter 77, loss: 30.381255, acc: 0.673469\n",
      "epoch 17, iter 78, loss: 31.923476, acc: 0.693878\n",
      "epoch 17, iter 79, loss: 30.357708, acc: 0.795918\n",
      "epoch 17, iter 80, loss: 28.438399, acc: 0.918367\n",
      "epoch 17, iter 81, loss: 29.837778, acc: 0.755102\n",
      "epoch 17, iter 82, loss: 29.884816, acc: 0.734694\n",
      "epoch 17, iter 83, loss: 31.122579, acc: 0.755102\n",
      "epoch 17, iter 84, loss: 29.060477, acc: 0.857143\n",
      "epoch 17, iter 85, loss: 26.970109, acc: 0.877551\n",
      "epoch 17, iter 86, loss: 29.037095, acc: 0.673469\n",
      "epoch 17, iter 87, loss: 32.876478, acc: 0.653061\n",
      "epoch 17, iter 88, loss: 31.154945, acc: 0.857143\n",
      "epoch 17, iter 89, loss: 31.910246, acc: 0.714286\n",
      "epoch 17, iter 90, loss: 32.717341, acc: 0.693878\n",
      "epoch 17, iter 91, loss: 32.490867, acc: 0.816327\n",
      "epoch 17, iter 92, loss: 33.989749, acc: 0.714286\n",
      "epoch 17, iter 93, loss: 34.385303, acc: 0.714286\n",
      "epoch 17, iter 94, loss: 33.192989, acc: 0.816327\n",
      "epoch 17, iter 95, loss: 29.555705, acc: 0.918367\n",
      "epoch 17, iter 96, loss: 30.420345, acc: 0.836735\n",
      "epoch 17, iter 97, loss: 30.483973, acc: 0.775510\n",
      "epoch 17, iter 98, loss: 30.737187, acc: 0.775510\n",
      "epoch 17, iter 99, loss: 29.315110, acc: 0.836735\n",
      "epoch 17, iter 100, loss: 33.359162, acc: 0.612245\n",
      "epoch 17, iter 101, loss: 32.162657, acc: 0.755102\n",
      "epoch 17, iter 102, loss: 30.125359, acc: 0.877551\n",
      "epoch 17, iter 103, loss: 28.891156, acc: 0.857143\n",
      "epoch 17, iter 104, loss: 30.623345, acc: 0.755102\n",
      "epoch 17, iter 105, loss: 30.587607, acc: 0.755102\n",
      "epoch 17, iter 106, loss: 29.679494, acc: 0.795918\n",
      "epoch 17, iter 107, loss: 26.875363, acc: 0.938776\n",
      "epoch 17, iter 108, loss: 28.270628, acc: 0.734694\n",
      "epoch 17, iter 109, loss: 29.581952, acc: 0.673469\n",
      "epoch 17, iter 110, loss: 29.408472, acc: 0.775510\n",
      "epoch 17, iter 111, loss: 32.710492, acc: 0.632653\n",
      "epoch 17, iter 112, loss: 32.724175, acc: 0.836735\n",
      "epoch 17, iter 113, loss: 34.289723, acc: 0.693878\n",
      "epoch 17, iter 114, loss: 33.379383, acc: 0.795918\n",
      "epoch 17, iter 115, loss: 32.265258, acc: 0.714286\n",
      "epoch 17, iter 116, loss: 33.845286, acc: 0.693878\n",
      "epoch 17, iter 117, loss: 31.779630, acc: 0.938776\n",
      "epoch 17, iter 118, loss: 33.545300, acc: 0.714286\n",
      "epoch 17, iter 119, loss: 30.308335, acc: 0.918367\n",
      "epoch 17, iter 120, loss: 31.034592, acc: 0.734694\n",
      "epoch 17, iter 121, loss: 29.769010, acc: 0.836735\n",
      "epoch 17, iter 122, loss: 29.748000, acc: 0.795918\n",
      "epoch 17, iter 123, loss: 29.563042, acc: 0.795918\n",
      "epoch 17, iter 124, loss: 30.829908, acc: 0.795918\n",
      "epoch 17, iter 125, loss: 33.252498, acc: 0.653061\n",
      "epoch 17, iter 126, loss: 30.629251, acc: 0.938776\n",
      "epoch 17, iter 127, loss: 34.578828, acc: 0.551020\n",
      "epoch 17, iter 128, loss: 32.682674, acc: 0.877551\n",
      "epoch 17, iter 129, loss: 31.909418, acc: 0.734694\n",
      "epoch 17, iter 130, loss: 29.542052, acc: 0.938776\n",
      "epoch 17, iter 131, loss: 29.018496, acc: 0.816327\n",
      "epoch 17, iter 132, loss: 29.752057, acc: 0.755102\n",
      "epoch 17, iter 133, loss: 28.304597, acc: 0.897959\n",
      "epoch 17, iter 134, loss: 31.540949, acc: 0.612245\n",
      "epoch 17, iter 135, loss: 32.399816, acc: 0.673469\n",
      "epoch 17, iter 136, loss: 32.017463, acc: 0.857143\n",
      "epoch 17, iter 137, loss: 30.922801, acc: 0.857143\n",
      "epoch 17, iter 138, loss: 30.996426, acc: 0.877551\n",
      "epoch 17, iter 139, loss: 30.600525, acc: 0.816327\n",
      "epoch 17, iter 140, loss: 31.092869, acc: 0.775510\n",
      "epoch 17, iter 141, loss: 29.546325, acc: 0.877551\n",
      "epoch 17, iter 142, loss: 30.732182, acc: 0.693878\n",
      "epoch 17, iter 143, loss: 30.459608, acc: 0.816327\n",
      "epoch 17, iter 144, loss: 31.397647, acc: 0.653061\n",
      "epoch 17, iter 145, loss: 29.173813, acc: 0.918367\n",
      "epoch 17, iter 146, loss: 29.101650, acc: 0.857143\n",
      "epoch 17, iter 147, loss: 28.743448, acc: 0.857143\n",
      "epoch 17, iter 148, loss: 28.698622, acc: 0.816327\n",
      "epoch 17, iter 149, loss: 26.930794, acc: 0.938776\n",
      "epoch 17, iter 150, loss: 28.158392, acc: 0.795918\n",
      "epoch 17, iter 151, loss: 28.840521, acc: 0.734694\n",
      "epoch 17, iter 152, loss: 28.885693, acc: 0.816327\n",
      "epoch 17, iter 153, loss: 30.757463, acc: 0.714286\n",
      "epoch 17, iter 154, loss: 31.884901, acc: 0.693878\n",
      "epoch 17, iter 155, loss: 31.000181, acc: 0.775510\n",
      "epoch 17, iter 156, loss: 29.480386, acc: 0.857143\n",
      "epoch 17, iter 157, loss: 30.472155, acc: 0.775510\n",
      "epoch 17, iter 158, loss: 27.837647, acc: 0.897959\n",
      "epoch 17, iter 159, loss: 32.049824, acc: 0.673469\n",
      "epoch 17, iter 160, loss: 33.038900, acc: 0.714286\n",
      "epoch 17, iter 161, loss: 30.838229, acc: 0.877551\n",
      "epoch 17, iter 162, loss: 30.912711, acc: 0.755102\n",
      "epoch 17, iter 163, loss: 31.728886, acc: 0.775510\n",
      "epoch 17, iter 164, loss: 32.500846, acc: 0.755102\n",
      "epoch 17, iter 165, loss: 30.146831, acc: 0.897959\n",
      "epoch 17, iter 166, loss: 29.476444, acc: 0.816327\n",
      "epoch 17, iter 167, loss: 30.374575, acc: 0.775510\n",
      "epoch 17, iter 168, loss: 30.269036, acc: 0.795918\n",
      "epoch 17, iter 169, loss: 30.287399, acc: 0.816327\n",
      "epoch 17, iter 170, loss: 33.280417, acc: 0.693878\n",
      "epoch 17, iter 171, loss: 34.413774, acc: 0.693878\n",
      "epoch 17, iter 172, loss: 34.486370, acc: 0.775510\n",
      "epoch 17, iter 173, loss: 33.560713, acc: 0.755102\n",
      "epoch 17, iter 174, loss: 33.265791, acc: 0.795918\n",
      "epoch 17, iter 175, loss: 32.583041, acc: 0.775510\n",
      "epoch 17, iter 176, loss: 30.901886, acc: 0.836735\n",
      "epoch 17, iter 177, loss: 29.585683, acc: 0.897959\n",
      "epoch 17, iter 178, loss: 30.542704, acc: 0.775510\n",
      "epoch 17, iter 179, loss: 29.862400, acc: 0.734694\n",
      "epoch 17, iter 180, loss: 28.422263, acc: 0.857143\n",
      "epoch 17, iter 181, loss: 30.630350, acc: 0.714286\n",
      "epoch 17, iter 182, loss: 30.051724, acc: 0.795918\n",
      "epoch 17, iter 183, loss: 32.149763, acc: 0.591837\n",
      "epoch 17, iter 184, loss: 30.986477, acc: 0.836735\n",
      "epoch 17, iter 185, loss: 32.541464, acc: 0.693878\n",
      "epoch 17, iter 186, loss: 30.464241, acc: 0.918367\n",
      "epoch 17, iter 187, loss: 32.474658, acc: 0.714286\n",
      "epoch 17, iter 188, loss: 34.889659, acc: 0.734694\n",
      "epoch 17, iter 189, loss: 36.116219, acc: 0.714286\n",
      "epoch 17, iter 190, loss: 34.271928, acc: 0.897959\n",
      "epoch 17, iter 191, loss: 32.591257, acc: 0.816327\n",
      "epoch 17, iter 192, loss: 31.209075, acc: 0.857143\n",
      "epoch 17, iter 193, loss: 33.576335, acc: 0.632653\n",
      "epoch 17, iter 194, loss: 32.573949, acc: 0.734694\n",
      "epoch 17, iter 195, loss: 32.252182, acc: 0.775510\n",
      "epoch 17, iter 196, loss: 30.509246, acc: 0.857143\n",
      "epoch 17, iter 197, loss: 30.739231, acc: 0.795918\n",
      "epoch 17, iter 198, loss: 31.129338, acc: 0.775510\n",
      "epoch 17, iter 199, loss: 31.760598, acc: 0.693878\n",
      "epoch 17, iter 200, loss: 31.180086, acc: 0.775510\n",
      "epoch 17, iter 201, loss: 31.490405, acc: 0.816327\n",
      "epoch 17, iter 202, loss: 30.069082, acc: 0.857143\n",
      "epoch 17, iter 203, loss: 32.211110, acc: 0.755102\n",
      "epoch 17, iter 204, loss: 32.406785, acc: 0.775510\n",
      "epoch 17, iter 205, loss: 37.004811, acc: 0.632653\n",
      "epoch 17, iter 206, loss: 34.852169, acc: 0.795918\n",
      "epoch 17, iter 207, loss: 33.624535, acc: 0.836735\n",
      "epoch 17, iter 208, loss: 31.623968, acc: 0.877551\n",
      "epoch 17, iter 209, loss: 29.968220, acc: 0.877551\n",
      "epoch 17, iter 210, loss: 30.710058, acc: 0.775510\n",
      "epoch 17, iter 211, loss: 29.466126, acc: 0.816327\n",
      "epoch 17, iter 212, loss: 30.171984, acc: 0.734694\n",
      "epoch 17, iter 213, loss: 28.951299, acc: 0.836735\n",
      "epoch 17, iter 214, loss: 27.933358, acc: 0.897959\n",
      "epoch 17, iter 215, loss: 30.530929, acc: 0.693878\n",
      "epoch 17, iter 216, loss: 29.637432, acc: 0.795918\n",
      "epoch 17, iter 217, loss: 31.498985, acc: 0.795918\n",
      "epoch 17, iter 218, loss: 31.491775, acc: 0.836735\n",
      "epoch 17, iter 219, loss: 29.897686, acc: 0.897959\n",
      "epoch 17, iter 220, loss: 31.697987, acc: 0.632653\n",
      "epoch 17, iter 221, loss: 31.149965, acc: 0.775510\n",
      "epoch 17, iter 222, loss: 33.579741, acc: 0.673469\n",
      "epoch 17, iter 223, loss: 30.684330, acc: 0.918367\n",
      "epoch 17, iter 224, loss: 30.905111, acc: 0.734694\n",
      "epoch 17, iter 225, loss: 31.321878, acc: 0.775510\n",
      "epoch 17, iter 226, loss: 31.594801, acc: 0.755102\n",
      "epoch 17, iter 227, loss: 30.464370, acc: 0.816327\n",
      "epoch 17, iter 228, loss: 30.679571, acc: 0.795918\n",
      "epoch 17, iter 229, loss: 27.676373, acc: 0.918367\n",
      "epoch 17, iter 230, loss: 28.615968, acc: 0.795918\n",
      "epoch 17, iter 231, loss: 27.485417, acc: 0.877551\n",
      "epoch 17, iter 232, loss: 29.470836, acc: 0.775510\n",
      "epoch 17, iter 233, loss: 31.316336, acc: 0.693878\n",
      "epoch 17, iter 234, loss: 29.328503, acc: 0.938776\n",
      "epoch 17, iter 235, loss: 29.517478, acc: 0.836735\n",
      "epoch 17, iter 236, loss: 27.309451, acc: 0.959184\n",
      "epoch 17, iter 237, loss: 30.196359, acc: 0.612245\n",
      "epoch 17, iter 238, loss: 33.170134, acc: 0.714286\n",
      "epoch 17, iter 239, loss: 32.946564, acc: 0.775510\n",
      "epoch 17, iter 240, loss: 31.598664, acc: 0.877551\n",
      "epoch 17, iter 241, loss: 31.397182, acc: 0.795918\n",
      "epoch 17, iter 242, loss: 32.740238, acc: 0.755102\n",
      "epoch 17, iter 243, loss: 31.849852, acc: 0.816327\n",
      "epoch 17, iter 244, loss: 31.633355, acc: 0.795918\n",
      "epoch 17, iter 245, loss: 31.623276, acc: 0.795918\n",
      "epoch 17, iter 246, loss: 33.689581, acc: 0.653061\n",
      "epoch 17, iter 247, loss: 32.894839, acc: 0.795918\n",
      "epoch 17, iter 248, loss: 34.918627, acc: 0.673469\n",
      "epoch 17, iter 249, loss: 34.947738, acc: 0.755102\n",
      "epoch 17, acc: 0.788327\n",
      "epoch 18, iter 0, loss: 35.142802, acc: 0.653061\n",
      "epoch 18, iter 1, loss: 35.537569, acc: 0.775510\n",
      "epoch 18, iter 2, loss: 34.867400, acc: 0.734694\n",
      "epoch 18, iter 3, loss: 33.473211, acc: 0.795918\n",
      "epoch 18, iter 4, loss: 31.942813, acc: 0.938776\n",
      "epoch 18, iter 5, loss: 30.460650, acc: 0.918367\n",
      "epoch 18, iter 6, loss: 29.542149, acc: 0.877551\n",
      "epoch 18, iter 7, loss: 31.487376, acc: 0.714286\n",
      "epoch 18, iter 8, loss: 31.549170, acc: 0.795918\n",
      "epoch 18, iter 9, loss: 32.094957, acc: 0.734694\n",
      "epoch 18, iter 10, loss: 32.270383, acc: 0.693878\n",
      "epoch 18, iter 11, loss: 33.993412, acc: 0.673469\n",
      "epoch 18, iter 12, loss: 32.428424, acc: 0.877551\n",
      "epoch 18, iter 13, loss: 31.685233, acc: 0.816327\n",
      "epoch 18, iter 14, loss: 30.854275, acc: 0.795918\n",
      "epoch 18, iter 15, loss: 28.489583, acc: 0.959184\n",
      "epoch 18, iter 16, loss: 29.741969, acc: 0.714286\n",
      "epoch 18, iter 17, loss: 29.317903, acc: 0.857143\n",
      "epoch 18, iter 18, loss: 32.068011, acc: 0.714286\n",
      "epoch 18, iter 19, loss: 29.386698, acc: 0.877551\n",
      "epoch 18, iter 20, loss: 27.303083, acc: 0.918367\n",
      "epoch 18, iter 21, loss: 27.035729, acc: 0.795918\n",
      "epoch 18, iter 22, loss: 26.031791, acc: 0.836735\n",
      "epoch 18, iter 23, loss: 29.141562, acc: 0.714286\n",
      "epoch 18, iter 24, loss: 29.215593, acc: 0.836735\n",
      "epoch 18, iter 25, loss: 31.340786, acc: 0.693878\n",
      "epoch 18, iter 26, loss: 32.465641, acc: 0.775510\n",
      "epoch 18, iter 27, loss: 33.288363, acc: 0.734694\n",
      "epoch 18, iter 28, loss: 31.566693, acc: 0.816327\n",
      "epoch 18, iter 29, loss: 28.711792, acc: 0.877551\n",
      "epoch 18, iter 30, loss: 30.534591, acc: 0.673469\n",
      "epoch 18, iter 31, loss: 34.509678, acc: 0.591837\n",
      "epoch 18, iter 32, loss: 32.465592, acc: 0.836735\n",
      "epoch 18, iter 33, loss: 30.458608, acc: 0.877551\n",
      "epoch 18, iter 34, loss: 30.750353, acc: 0.714286\n",
      "epoch 18, iter 35, loss: 32.912358, acc: 0.693878\n",
      "epoch 18, iter 36, loss: 33.135184, acc: 0.836735\n",
      "epoch 18, iter 37, loss: 30.680546, acc: 0.877551\n",
      "epoch 18, iter 38, loss: 31.436972, acc: 0.714286\n",
      "epoch 18, iter 39, loss: 30.493422, acc: 0.857143\n",
      "epoch 18, iter 40, loss: 32.030704, acc: 0.734694\n",
      "epoch 18, iter 41, loss: 31.255160, acc: 0.836735\n",
      "epoch 18, iter 42, loss: 33.966938, acc: 0.673469\n",
      "epoch 18, iter 43, loss: 30.996477, acc: 0.877551\n",
      "epoch 18, iter 44, loss: 28.842053, acc: 0.836735\n",
      "epoch 18, iter 45, loss: 29.731232, acc: 0.734694\n",
      "epoch 18, iter 46, loss: 30.843944, acc: 0.775510\n",
      "epoch 18, iter 47, loss: 29.927029, acc: 0.816327\n",
      "epoch 18, iter 48, loss: 30.056907, acc: 0.755102\n",
      "epoch 18, iter 49, loss: 29.560032, acc: 0.836735\n",
      "epoch 18, iter 50, loss: 30.324806, acc: 0.816327\n",
      "epoch 18, iter 51, loss: 32.033269, acc: 0.693878\n",
      "epoch 18, iter 52, loss: 31.499828, acc: 0.897959\n",
      "epoch 18, iter 53, loss: 31.612488, acc: 0.775510\n",
      "epoch 18, iter 54, loss: 31.399759, acc: 0.755102\n",
      "epoch 18, iter 55, loss: 31.152612, acc: 0.795918\n",
      "epoch 18, iter 56, loss: 29.636390, acc: 0.836735\n",
      "epoch 18, iter 57, loss: 28.550162, acc: 0.857143\n",
      "epoch 18, iter 58, loss: 30.256485, acc: 0.673469\n",
      "epoch 18, iter 59, loss: 29.675062, acc: 0.816327\n",
      "epoch 18, iter 60, loss: 29.207321, acc: 0.816327\n",
      "epoch 18, iter 61, loss: 29.345761, acc: 0.836735\n",
      "epoch 18, iter 62, loss: 29.631469, acc: 0.816327\n",
      "epoch 18, iter 63, loss: 28.859291, acc: 0.816327\n",
      "epoch 18, iter 64, loss: 31.357699, acc: 0.571429\n",
      "epoch 18, iter 65, loss: 30.064937, acc: 0.836735\n",
      "epoch 18, iter 66, loss: 27.495382, acc: 0.897959\n",
      "epoch 18, iter 67, loss: 30.449745, acc: 0.693878\n",
      "epoch 18, iter 68, loss: 28.600406, acc: 0.775510\n",
      "epoch 18, iter 69, loss: 26.898565, acc: 0.877551\n",
      "epoch 18, iter 70, loss: 26.383550, acc: 0.857143\n",
      "epoch 18, iter 71, loss: 28.843029, acc: 0.755102\n",
      "epoch 18, iter 72, loss: 27.946800, acc: 0.877551\n",
      "epoch 18, iter 73, loss: 25.826496, acc: 0.938776\n",
      "epoch 18, iter 74, loss: 24.876182, acc: 0.857143\n",
      "epoch 18, iter 75, loss: 24.241940, acc: 0.857143\n",
      "epoch 18, iter 76, loss: 27.590379, acc: 0.734694\n",
      "epoch 18, iter 77, loss: 30.324682, acc: 0.693878\n",
      "epoch 18, iter 78, loss: 31.986942, acc: 0.693878\n",
      "epoch 18, iter 79, loss: 30.445418, acc: 0.816327\n",
      "epoch 18, iter 80, loss: 28.370050, acc: 0.918367\n",
      "epoch 18, iter 81, loss: 29.881351, acc: 0.755102\n",
      "epoch 18, iter 82, loss: 29.911279, acc: 0.734694\n",
      "epoch 18, iter 83, loss: 31.099172, acc: 0.755102\n",
      "epoch 18, iter 84, loss: 28.968229, acc: 0.857143\n",
      "epoch 18, iter 85, loss: 26.844701, acc: 0.877551\n",
      "epoch 18, iter 86, loss: 28.913880, acc: 0.673469\n",
      "epoch 18, iter 87, loss: 32.791779, acc: 0.673469\n",
      "epoch 18, iter 88, loss: 31.119773, acc: 0.857143\n",
      "epoch 18, iter 89, loss: 31.915917, acc: 0.673469\n",
      "epoch 18, iter 90, loss: 32.609775, acc: 0.714286\n",
      "epoch 18, iter 91, loss: 32.560765, acc: 0.816327\n",
      "epoch 18, iter 92, loss: 34.018106, acc: 0.673469\n",
      "epoch 18, iter 93, loss: 34.699534, acc: 0.693878\n",
      "epoch 18, iter 94, loss: 33.106750, acc: 0.857143\n",
      "epoch 18, iter 95, loss: 29.713232, acc: 0.897959\n",
      "epoch 18, iter 96, loss: 30.424858, acc: 0.836735\n",
      "epoch 18, iter 97, loss: 30.439250, acc: 0.795918\n",
      "epoch 18, iter 98, loss: 30.733361, acc: 0.775510\n",
      "epoch 18, iter 99, loss: 29.333894, acc: 0.836735\n",
      "epoch 18, iter 100, loss: 33.278519, acc: 0.591837\n",
      "epoch 18, iter 101, loss: 32.006561, acc: 0.734694\n",
      "epoch 18, iter 102, loss: 29.833795, acc: 0.897959\n",
      "epoch 18, iter 103, loss: 28.750709, acc: 0.857143\n",
      "epoch 18, iter 104, loss: 30.483669, acc: 0.775510\n",
      "epoch 18, iter 105, loss: 30.396367, acc: 0.755102\n",
      "epoch 18, iter 106, loss: 29.644968, acc: 0.775510\n",
      "epoch 18, iter 107, loss: 26.801695, acc: 0.938776\n",
      "epoch 18, iter 108, loss: 28.266107, acc: 0.734694\n",
      "epoch 18, iter 109, loss: 29.547074, acc: 0.653061\n",
      "epoch 18, iter 110, loss: 29.378524, acc: 0.775510\n",
      "epoch 18, iter 111, loss: 32.667134, acc: 0.612245\n",
      "epoch 18, iter 112, loss: 32.605398, acc: 0.836735\n",
      "epoch 18, iter 113, loss: 34.192768, acc: 0.673469\n",
      "epoch 18, iter 114, loss: 33.284463, acc: 0.795918\n",
      "epoch 18, iter 115, loss: 32.226386, acc: 0.734694\n",
      "epoch 18, iter 116, loss: 33.801381, acc: 0.673469\n",
      "epoch 18, iter 117, loss: 31.698384, acc: 0.918367\n",
      "epoch 18, iter 118, loss: 33.489507, acc: 0.714286\n",
      "epoch 18, iter 119, loss: 30.275791, acc: 0.918367\n",
      "epoch 18, iter 120, loss: 30.857091, acc: 0.734694\n",
      "epoch 18, iter 121, loss: 29.506092, acc: 0.857143\n",
      "epoch 18, iter 122, loss: 29.490523, acc: 0.775510\n",
      "epoch 18, iter 123, loss: 29.340498, acc: 0.775510\n",
      "epoch 18, iter 124, loss: 30.672978, acc: 0.755102\n",
      "epoch 18, iter 125, loss: 33.152852, acc: 0.612245\n",
      "epoch 18, iter 126, loss: 30.549724, acc: 0.959184\n",
      "epoch 18, iter 127, loss: 34.511942, acc: 0.551020\n",
      "epoch 18, iter 128, loss: 32.705377, acc: 0.897959\n",
      "epoch 18, iter 129, loss: 31.874265, acc: 0.755102\n",
      "epoch 18, iter 130, loss: 29.428968, acc: 0.938776\n",
      "epoch 18, iter 131, loss: 28.964963, acc: 0.816327\n",
      "epoch 18, iter 132, loss: 29.711243, acc: 0.775510\n",
      "epoch 18, iter 133, loss: 28.259388, acc: 0.918367\n",
      "epoch 18, iter 134, loss: 31.419575, acc: 0.591837\n",
      "epoch 18, iter 135, loss: 32.326448, acc: 0.673469\n",
      "epoch 18, iter 136, loss: 31.905199, acc: 0.857143\n",
      "epoch 18, iter 137, loss: 30.724595, acc: 0.877551\n",
      "epoch 18, iter 138, loss: 30.749784, acc: 0.877551\n",
      "epoch 18, iter 139, loss: 30.407978, acc: 0.816327\n",
      "epoch 18, iter 140, loss: 30.977827, acc: 0.775510\n",
      "epoch 18, iter 141, loss: 29.350039, acc: 0.877551\n",
      "epoch 18, iter 142, loss: 30.511747, acc: 0.693878\n",
      "epoch 18, iter 143, loss: 30.322453, acc: 0.795918\n",
      "epoch 18, iter 144, loss: 31.290959, acc: 0.632653\n",
      "epoch 18, iter 145, loss: 29.080342, acc: 0.897959\n",
      "epoch 18, iter 146, loss: 29.052446, acc: 0.857143\n",
      "epoch 18, iter 147, loss: 28.604531, acc: 0.857143\n",
      "epoch 18, iter 148, loss: 28.587298, acc: 0.816327\n",
      "epoch 18, iter 149, loss: 26.834163, acc: 0.938776\n",
      "epoch 18, iter 150, loss: 28.089576, acc: 0.795918\n",
      "epoch 18, iter 151, loss: 28.831212, acc: 0.734694\n",
      "epoch 18, iter 152, loss: 28.897600, acc: 0.795918\n",
      "epoch 18, iter 153, loss: 30.651645, acc: 0.714286\n",
      "epoch 18, iter 154, loss: 31.831517, acc: 0.693878\n",
      "epoch 18, iter 155, loss: 30.946117, acc: 0.775510\n",
      "epoch 18, iter 156, loss: 29.407880, acc: 0.857143\n",
      "epoch 18, iter 157, loss: 30.455348, acc: 0.795918\n",
      "epoch 18, iter 158, loss: 27.823848, acc: 0.897959\n",
      "epoch 18, iter 159, loss: 31.953260, acc: 0.673469\n",
      "epoch 18, iter 160, loss: 32.905290, acc: 0.734694\n",
      "epoch 18, iter 161, loss: 30.795932, acc: 0.857143\n",
      "epoch 18, iter 162, loss: 30.809896, acc: 0.755102\n",
      "epoch 18, iter 163, loss: 31.748111, acc: 0.795918\n",
      "epoch 18, iter 164, loss: 32.425398, acc: 0.755102\n",
      "epoch 18, iter 165, loss: 30.019382, acc: 0.877551\n",
      "epoch 18, iter 166, loss: 29.422837, acc: 0.836735\n",
      "epoch 18, iter 167, loss: 30.353992, acc: 0.755102\n",
      "epoch 18, iter 168, loss: 30.237369, acc: 0.755102\n",
      "epoch 18, iter 169, loss: 30.287785, acc: 0.836735\n",
      "epoch 18, iter 170, loss: 33.176240, acc: 0.693878\n",
      "epoch 18, iter 171, loss: 34.085515, acc: 0.693878\n",
      "epoch 18, iter 172, loss: 33.952613, acc: 0.775510\n",
      "epoch 18, iter 173, loss: 33.415775, acc: 0.775510\n",
      "epoch 18, iter 174, loss: 33.432571, acc: 0.755102\n",
      "epoch 18, iter 175, loss: 32.532632, acc: 0.755102\n",
      "epoch 18, iter 176, loss: 30.844258, acc: 0.857143\n",
      "epoch 18, iter 177, loss: 29.543006, acc: 0.897959\n",
      "epoch 18, iter 178, loss: 30.551106, acc: 0.755102\n",
      "epoch 18, iter 179, loss: 29.866697, acc: 0.714286\n",
      "epoch 18, iter 180, loss: 28.368569, acc: 0.836735\n",
      "epoch 18, iter 181, loss: 30.425290, acc: 0.734694\n",
      "epoch 18, iter 182, loss: 29.885014, acc: 0.795918\n",
      "epoch 18, iter 183, loss: 32.005537, acc: 0.612245\n",
      "epoch 18, iter 184, loss: 30.819837, acc: 0.836735\n",
      "epoch 18, iter 185, loss: 32.259484, acc: 0.714286\n",
      "epoch 18, iter 186, loss: 30.204462, acc: 0.918367\n",
      "epoch 18, iter 187, loss: 32.284902, acc: 0.755102\n",
      "epoch 18, iter 188, loss: 34.747139, acc: 0.734694\n",
      "epoch 18, iter 189, loss: 35.944118, acc: 0.693878\n",
      "epoch 18, iter 190, loss: 33.925646, acc: 0.836735\n",
      "epoch 18, iter 191, loss: 31.814007, acc: 0.857143\n",
      "epoch 18, iter 192, loss: 30.575199, acc: 0.857143\n",
      "epoch 18, iter 193, loss: 33.272919, acc: 0.653061\n",
      "epoch 18, iter 194, loss: 32.496592, acc: 0.734694\n",
      "epoch 18, iter 195, loss: 32.158128, acc: 0.775510\n",
      "epoch 18, iter 196, loss: 30.194974, acc: 0.877551\n",
      "epoch 18, iter 197, loss: 30.469018, acc: 0.795918\n",
      "epoch 18, iter 198, loss: 30.852167, acc: 0.795918\n",
      "epoch 18, iter 199, loss: 31.628502, acc: 0.673469\n",
      "epoch 18, iter 200, loss: 31.189485, acc: 0.816327\n",
      "epoch 18, iter 201, loss: 30.882968, acc: 0.816327\n",
      "epoch 18, iter 202, loss: 29.606508, acc: 0.816327\n",
      "epoch 18, iter 203, loss: 31.867229, acc: 0.693878\n",
      "epoch 18, iter 204, loss: 32.186404, acc: 0.775510\n",
      "epoch 18, iter 205, loss: 37.096349, acc: 0.632653\n",
      "epoch 18, iter 206, loss: 34.795913, acc: 0.795918\n",
      "epoch 18, iter 207, loss: 33.650609, acc: 0.816327\n",
      "epoch 18, iter 208, loss: 31.637186, acc: 0.877551\n",
      "epoch 18, iter 209, loss: 29.920615, acc: 0.877551\n",
      "epoch 18, iter 210, loss: 30.692195, acc: 0.755102\n",
      "epoch 18, iter 211, loss: 29.337555, acc: 0.816327\n",
      "epoch 18, iter 212, loss: 29.728951, acc: 0.755102\n",
      "epoch 18, iter 213, loss: 28.661009, acc: 0.836735\n",
      "epoch 18, iter 214, loss: 27.723189, acc: 0.877551\n",
      "epoch 18, iter 215, loss: 30.302285, acc: 0.693878\n",
      "epoch 18, iter 216, loss: 29.403168, acc: 0.795918\n",
      "epoch 18, iter 217, loss: 31.242600, acc: 0.816327\n",
      "epoch 18, iter 218, loss: 31.352174, acc: 0.877551\n",
      "epoch 18, iter 219, loss: 29.810501, acc: 0.897959\n",
      "epoch 18, iter 220, loss: 31.645265, acc: 0.632653\n",
      "epoch 18, iter 221, loss: 31.118888, acc: 0.795918\n",
      "epoch 18, iter 222, loss: 33.635123, acc: 0.673469\n",
      "epoch 18, iter 223, loss: 30.635032, acc: 0.918367\n",
      "epoch 18, iter 224, loss: 30.757619, acc: 0.775510\n",
      "epoch 18, iter 225, loss: 31.446118, acc: 0.755102\n",
      "epoch 18, iter 226, loss: 31.554356, acc: 0.755102\n",
      "epoch 18, iter 227, loss: 30.368000, acc: 0.836735\n",
      "epoch 18, iter 228, loss: 30.560066, acc: 0.775510\n",
      "epoch 18, iter 229, loss: 27.508991, acc: 0.938776\n",
      "epoch 18, iter 230, loss: 28.508741, acc: 0.795918\n",
      "epoch 18, iter 231, loss: 27.409056, acc: 0.877551\n",
      "epoch 18, iter 232, loss: 29.539209, acc: 0.755102\n",
      "epoch 18, iter 233, loss: 31.316755, acc: 0.673469\n",
      "epoch 18, iter 234, loss: 29.371715, acc: 0.938776\n",
      "epoch 18, iter 235, loss: 29.450240, acc: 0.857143\n",
      "epoch 18, iter 236, loss: 27.165229, acc: 0.959184\n",
      "epoch 18, iter 237, loss: 30.021704, acc: 0.591837\n",
      "epoch 18, iter 238, loss: 33.092063, acc: 0.693878\n",
      "epoch 18, iter 239, loss: 32.693773, acc: 0.775510\n",
      "epoch 18, iter 240, loss: 31.451049, acc: 0.877551\n",
      "epoch 18, iter 241, loss: 31.283360, acc: 0.816327\n",
      "epoch 18, iter 242, loss: 32.495819, acc: 0.734694\n",
      "epoch 18, iter 243, loss: 31.645991, acc: 0.816327\n",
      "epoch 18, iter 244, loss: 31.370973, acc: 0.816327\n",
      "epoch 18, iter 245, loss: 31.538437, acc: 0.714286\n",
      "epoch 18, iter 246, loss: 33.837971, acc: 0.612245\n",
      "epoch 18, iter 247, loss: 33.168662, acc: 0.775510\n",
      "epoch 18, iter 248, loss: 34.818053, acc: 0.673469\n",
      "epoch 18, iter 249, loss: 34.913207, acc: 0.775510\n",
      "epoch 18, acc: 0.786776\n",
      "epoch 19, iter 0, loss: 34.956912, acc: 0.653061\n",
      "epoch 19, iter 1, loss: 35.144065, acc: 0.816327\n",
      "epoch 19, iter 2, loss: 34.721972, acc: 0.775510\n",
      "epoch 19, iter 3, loss: 33.443642, acc: 0.795918\n",
      "epoch 19, iter 4, loss: 31.492638, acc: 0.897959\n",
      "epoch 19, iter 5, loss: 30.174697, acc: 0.897959\n",
      "epoch 19, iter 6, loss: 29.214293, acc: 0.877551\n",
      "epoch 19, iter 7, loss: 31.343193, acc: 0.693878\n",
      "epoch 19, iter 8, loss: 31.616803, acc: 0.755102\n",
      "epoch 19, iter 9, loss: 32.170542, acc: 0.714286\n",
      "epoch 19, iter 10, loss: 32.330227, acc: 0.673469\n",
      "epoch 19, iter 11, loss: 33.946067, acc: 0.673469\n",
      "epoch 19, iter 12, loss: 32.349290, acc: 0.877551\n",
      "epoch 19, iter 13, loss: 31.533577, acc: 0.816327\n",
      "epoch 19, iter 14, loss: 30.791471, acc: 0.816327\n",
      "epoch 19, iter 15, loss: 28.508161, acc: 0.938776\n",
      "epoch 19, iter 16, loss: 29.925542, acc: 0.714286\n",
      "epoch 19, iter 17, loss: 29.290347, acc: 0.836735\n",
      "epoch 19, iter 18, loss: 32.106224, acc: 0.714286\n",
      "epoch 19, iter 19, loss: 29.265616, acc: 0.877551\n",
      "epoch 19, iter 20, loss: 27.158584, acc: 0.918367\n",
      "epoch 19, iter 21, loss: 26.960712, acc: 0.816327\n",
      "epoch 19, iter 22, loss: 26.041354, acc: 0.836735\n",
      "epoch 19, iter 23, loss: 29.088617, acc: 0.693878\n",
      "epoch 19, iter 24, loss: 29.215553, acc: 0.795918\n",
      "epoch 19, iter 25, loss: 31.492926, acc: 0.673469\n",
      "epoch 19, iter 26, loss: 32.366524, acc: 0.755102\n",
      "epoch 19, iter 27, loss: 33.360947, acc: 0.755102\n",
      "epoch 19, iter 28, loss: 31.522826, acc: 0.816327\n",
      "epoch 19, iter 29, loss: 28.667305, acc: 0.857143\n",
      "epoch 19, iter 30, loss: 30.442332, acc: 0.714286\n",
      "epoch 19, iter 31, loss: 34.430004, acc: 0.591837\n",
      "epoch 19, iter 32, loss: 32.276232, acc: 0.857143\n",
      "epoch 19, iter 33, loss: 30.281526, acc: 0.857143\n",
      "epoch 19, iter 34, loss: 30.564330, acc: 0.734694\n",
      "epoch 19, iter 35, loss: 32.697874, acc: 0.693878\n",
      "epoch 19, iter 36, loss: 33.190729, acc: 0.795918\n",
      "epoch 19, iter 37, loss: 30.532240, acc: 0.877551\n",
      "epoch 19, iter 38, loss: 31.277621, acc: 0.714286\n",
      "epoch 19, iter 39, loss: 30.256634, acc: 0.795918\n",
      "epoch 19, iter 40, loss: 31.848211, acc: 0.734694\n",
      "epoch 19, iter 41, loss: 31.195593, acc: 0.816327\n",
      "epoch 19, iter 42, loss: 33.891856, acc: 0.653061\n",
      "epoch 19, iter 43, loss: 30.836349, acc: 0.897959\n",
      "epoch 19, iter 44, loss: 28.655493, acc: 0.836735\n",
      "epoch 19, iter 45, loss: 29.580113, acc: 0.714286\n",
      "epoch 19, iter 46, loss: 30.655886, acc: 0.775510\n",
      "epoch 19, iter 47, loss: 29.742230, acc: 0.816327\n",
      "epoch 19, iter 48, loss: 29.780582, acc: 0.755102\n",
      "epoch 19, iter 49, loss: 29.329237, acc: 0.836735\n",
      "epoch 19, iter 50, loss: 30.112095, acc: 0.795918\n",
      "epoch 19, iter 51, loss: 31.890529, acc: 0.673469\n",
      "epoch 19, iter 52, loss: 31.366681, acc: 0.897959\n",
      "epoch 19, iter 53, loss: 31.447189, acc: 0.775510\n",
      "epoch 19, iter 54, loss: 31.256668, acc: 0.755102\n",
      "epoch 19, iter 55, loss: 31.106132, acc: 0.795918\n",
      "epoch 19, iter 56, loss: 29.458935, acc: 0.836735\n",
      "epoch 19, iter 57, loss: 28.465973, acc: 0.877551\n",
      "epoch 19, iter 58, loss: 30.068715, acc: 0.693878\n",
      "epoch 19, iter 59, loss: 29.523259, acc: 0.816327\n",
      "epoch 19, iter 60, loss: 29.084994, acc: 0.816327\n",
      "epoch 19, iter 61, loss: 29.214822, acc: 0.836735\n",
      "epoch 19, iter 62, loss: 29.546026, acc: 0.816327\n",
      "epoch 19, iter 63, loss: 28.781205, acc: 0.816327\n",
      "epoch 19, iter 64, loss: 31.318906, acc: 0.571429\n",
      "epoch 19, iter 65, loss: 30.087607, acc: 0.836735\n",
      "epoch 19, iter 66, loss: 27.418082, acc: 0.897959\n",
      "epoch 19, iter 67, loss: 30.383016, acc: 0.714286\n",
      "epoch 19, iter 68, loss: 28.458398, acc: 0.775510\n",
      "epoch 19, iter 69, loss: 26.814491, acc: 0.877551\n",
      "epoch 19, iter 70, loss: 26.285783, acc: 0.877551\n",
      "epoch 19, iter 71, loss: 28.749467, acc: 0.755102\n",
      "epoch 19, iter 72, loss: 27.903865, acc: 0.877551\n",
      "epoch 19, iter 73, loss: 25.783980, acc: 0.938776\n",
      "epoch 19, iter 74, loss: 24.933254, acc: 0.877551\n",
      "epoch 19, iter 75, loss: 24.269313, acc: 0.836735\n",
      "epoch 19, iter 76, loss: 27.602887, acc: 0.734694\n",
      "epoch 19, iter 77, loss: 30.330517, acc: 0.673469\n",
      "epoch 19, iter 78, loss: 31.906301, acc: 0.673469\n",
      "epoch 19, iter 79, loss: 30.379446, acc: 0.816327\n",
      "epoch 19, iter 80, loss: 28.240792, acc: 0.918367\n",
      "epoch 19, iter 81, loss: 29.860526, acc: 0.755102\n",
      "epoch 19, iter 82, loss: 29.888255, acc: 0.714286\n",
      "epoch 19, iter 83, loss: 30.998970, acc: 0.755102\n",
      "epoch 19, iter 84, loss: 28.859101, acc: 0.857143\n",
      "epoch 19, iter 85, loss: 26.720143, acc: 0.877551\n",
      "epoch 19, iter 86, loss: 28.789082, acc: 0.673469\n",
      "epoch 19, iter 87, loss: 32.729642, acc: 0.653061\n",
      "epoch 19, iter 88, loss: 31.112929, acc: 0.857143\n",
      "epoch 19, iter 89, loss: 31.916026, acc: 0.673469\n",
      "epoch 19, iter 90, loss: 32.560905, acc: 0.714286\n",
      "epoch 19, iter 91, loss: 32.586391, acc: 0.816327\n",
      "epoch 19, iter 92, loss: 33.924215, acc: 0.693878\n",
      "epoch 19, iter 93, loss: 34.832900, acc: 0.693878\n",
      "epoch 19, iter 94, loss: 33.026669, acc: 0.836735\n",
      "epoch 19, iter 95, loss: 29.656329, acc: 0.877551\n",
      "epoch 19, iter 96, loss: 30.354006, acc: 0.816327\n",
      "epoch 19, iter 97, loss: 30.385038, acc: 0.755102\n",
      "epoch 19, iter 98, loss: 30.764120, acc: 0.734694\n",
      "epoch 19, iter 99, loss: 29.531053, acc: 0.836735\n",
      "epoch 19, iter 100, loss: 33.324376, acc: 0.612245\n",
      "epoch 19, iter 101, loss: 31.908340, acc: 0.795918\n",
      "epoch 19, iter 102, loss: 29.767411, acc: 0.918367\n",
      "epoch 19, iter 103, loss: 28.689782, acc: 0.857143\n",
      "epoch 19, iter 104, loss: 30.384811, acc: 0.714286\n",
      "epoch 19, iter 105, loss: 30.314284, acc: 0.755102\n",
      "epoch 19, iter 106, loss: 29.637964, acc: 0.775510\n",
      "epoch 19, iter 107, loss: 26.747541, acc: 0.938776\n",
      "epoch 19, iter 108, loss: 28.044655, acc: 0.734694\n",
      "epoch 19, iter 109, loss: 29.317787, acc: 0.673469\n",
      "epoch 19, iter 110, loss: 29.208438, acc: 0.775510\n",
      "epoch 19, iter 111, loss: 32.438133, acc: 0.612245\n",
      "epoch 19, iter 112, loss: 32.631904, acc: 0.836735\n",
      "epoch 19, iter 113, loss: 34.162792, acc: 0.673469\n",
      "epoch 19, iter 114, loss: 33.190562, acc: 0.816327\n",
      "epoch 19, iter 115, loss: 32.111194, acc: 0.734694\n",
      "epoch 19, iter 116, loss: 33.789940, acc: 0.734694\n",
      "epoch 19, iter 117, loss: 31.455027, acc: 0.877551\n",
      "epoch 19, iter 118, loss: 33.433338, acc: 0.714286\n",
      "epoch 19, iter 119, loss: 30.303282, acc: 0.938776\n",
      "epoch 19, iter 120, loss: 30.803917, acc: 0.734694\n",
      "epoch 19, iter 121, loss: 29.537539, acc: 0.857143\n",
      "epoch 19, iter 122, loss: 29.503441, acc: 0.795918\n",
      "epoch 19, iter 123, loss: 29.377081, acc: 0.755102\n",
      "epoch 19, iter 124, loss: 30.709560, acc: 0.734694\n",
      "epoch 19, iter 125, loss: 33.164148, acc: 0.632653\n",
      "epoch 19, iter 126, loss: 30.506711, acc: 0.959184\n",
      "epoch 19, iter 127, loss: 34.449981, acc: 0.551020\n",
      "epoch 19, iter 128, loss: 32.711716, acc: 0.897959\n",
      "epoch 19, iter 129, loss: 31.758496, acc: 0.755102\n",
      "epoch 19, iter 130, loss: 29.256113, acc: 0.959184\n",
      "epoch 19, iter 131, loss: 28.889651, acc: 0.816327\n",
      "epoch 19, iter 132, loss: 29.693010, acc: 0.755102\n",
      "epoch 19, iter 133, loss: 28.210751, acc: 0.918367\n",
      "epoch 19, iter 134, loss: 31.295899, acc: 0.612245\n",
      "epoch 19, iter 135, loss: 32.232983, acc: 0.673469\n",
      "epoch 19, iter 136, loss: 31.861796, acc: 0.836735\n",
      "epoch 19, iter 137, loss: 30.626816, acc: 0.857143\n",
      "epoch 19, iter 138, loss: 30.636592, acc: 0.877551\n",
      "epoch 19, iter 139, loss: 30.331006, acc: 0.816327\n",
      "epoch 19, iter 140, loss: 30.870832, acc: 0.775510\n",
      "epoch 19, iter 141, loss: 29.325766, acc: 0.857143\n",
      "epoch 19, iter 142, loss: 30.455782, acc: 0.673469\n",
      "epoch 19, iter 143, loss: 30.334567, acc: 0.795918\n",
      "epoch 19, iter 144, loss: 31.323029, acc: 0.632653\n",
      "epoch 19, iter 145, loss: 29.089575, acc: 0.897959\n",
      "epoch 19, iter 146, loss: 29.086887, acc: 0.836735\n",
      "epoch 19, iter 147, loss: 28.519400, acc: 0.857143\n",
      "epoch 19, iter 148, loss: 28.509194, acc: 0.816327\n",
      "epoch 19, iter 149, loss: 26.729431, acc: 0.938776\n",
      "epoch 19, iter 150, loss: 28.027526, acc: 0.795918\n",
      "epoch 19, iter 151, loss: 28.815964, acc: 0.714286\n",
      "epoch 19, iter 152, loss: 28.891479, acc: 0.795918\n",
      "epoch 19, iter 153, loss: 30.540467, acc: 0.734694\n",
      "epoch 19, iter 154, loss: 31.765810, acc: 0.693878\n",
      "epoch 19, iter 155, loss: 30.889680, acc: 0.775510\n",
      "epoch 19, iter 156, loss: 29.319142, acc: 0.857143\n",
      "epoch 19, iter 157, loss: 30.375544, acc: 0.775510\n",
      "epoch 19, iter 158, loss: 27.741336, acc: 0.897959\n",
      "epoch 19, iter 159, loss: 31.811672, acc: 0.673469\n",
      "epoch 19, iter 160, loss: 32.720984, acc: 0.755102\n",
      "epoch 19, iter 161, loss: 30.792182, acc: 0.857143\n",
      "epoch 19, iter 162, loss: 30.678476, acc: 0.734694\n",
      "epoch 19, iter 163, loss: 31.714294, acc: 0.795918\n",
      "epoch 19, iter 164, loss: 32.332215, acc: 0.775510\n",
      "epoch 19, iter 165, loss: 29.847969, acc: 0.877551\n",
      "epoch 19, iter 166, loss: 29.360246, acc: 0.816327\n",
      "epoch 19, iter 167, loss: 30.305173, acc: 0.734694\n",
      "epoch 19, iter 168, loss: 30.218419, acc: 0.775510\n",
      "epoch 19, iter 169, loss: 30.215532, acc: 0.836735\n",
      "epoch 19, iter 170, loss: 32.971362, acc: 0.714286\n",
      "epoch 19, iter 171, loss: 34.028115, acc: 0.714286\n",
      "epoch 19, iter 172, loss: 33.924304, acc: 0.775510\n",
      "epoch 19, iter 173, loss: 33.159202, acc: 0.775510\n",
      "epoch 19, iter 174, loss: 33.135292, acc: 0.775510\n",
      "epoch 19, iter 175, loss: 32.235120, acc: 0.775510\n",
      "epoch 19, iter 176, loss: 30.697431, acc: 0.857143\n",
      "epoch 19, iter 177, loss: 29.443536, acc: 0.897959\n",
      "epoch 19, iter 178, loss: 30.426161, acc: 0.775510\n",
      "epoch 19, iter 179, loss: 29.779721, acc: 0.714286\n",
      "epoch 19, iter 180, loss: 28.240701, acc: 0.836735\n",
      "epoch 19, iter 181, loss: 30.343817, acc: 0.734694\n",
      "epoch 19, iter 182, loss: 29.753768, acc: 0.755102\n",
      "epoch 19, iter 183, loss: 31.822872, acc: 0.632653\n",
      "epoch 19, iter 184, loss: 30.732547, acc: 0.836735\n",
      "epoch 19, iter 185, loss: 32.253936, acc: 0.673469\n",
      "epoch 19, iter 186, loss: 30.089916, acc: 0.897959\n",
      "epoch 19, iter 187, loss: 32.182117, acc: 0.755102\n",
      "epoch 19, iter 188, loss: 34.561544, acc: 0.714286\n",
      "epoch 19, iter 189, loss: 35.834561, acc: 0.693878\n",
      "epoch 19, iter 190, loss: 33.908198, acc: 0.816327\n",
      "epoch 19, iter 191, loss: 31.769879, acc: 0.877551\n",
      "epoch 19, iter 192, loss: 30.458642, acc: 0.877551\n",
      "epoch 19, iter 193, loss: 33.062488, acc: 0.653061\n",
      "epoch 19, iter 194, loss: 32.189436, acc: 0.734694\n",
      "epoch 19, iter 195, loss: 31.908857, acc: 0.775510\n",
      "epoch 19, iter 196, loss: 29.976659, acc: 0.877551\n",
      "epoch 19, iter 197, loss: 30.325145, acc: 0.816327\n",
      "epoch 19, iter 198, loss: 30.703843, acc: 0.775510\n",
      "epoch 19, iter 199, loss: 31.528828, acc: 0.673469\n",
      "epoch 19, iter 200, loss: 31.007049, acc: 0.816327\n",
      "epoch 19, iter 201, loss: 30.623786, acc: 0.816327\n",
      "epoch 19, iter 202, loss: 29.434749, acc: 0.816327\n",
      "epoch 19, iter 203, loss: 31.637176, acc: 0.673469\n",
      "epoch 19, iter 204, loss: 31.925584, acc: 0.775510\n",
      "epoch 19, iter 205, loss: 36.805261, acc: 0.632653\n",
      "epoch 19, iter 206, loss: 34.567450, acc: 0.795918\n",
      "epoch 19, iter 207, loss: 33.509624, acc: 0.816327\n",
      "epoch 19, iter 208, loss: 31.550957, acc: 0.877551\n",
      "epoch 19, iter 209, loss: 29.787891, acc: 0.877551\n",
      "epoch 19, iter 210, loss: 30.599717, acc: 0.755102\n",
      "epoch 19, iter 211, loss: 29.250663, acc: 0.836735\n",
      "epoch 19, iter 212, loss: 29.507473, acc: 0.775510\n",
      "epoch 19, iter 213, loss: 28.496312, acc: 0.836735\n",
      "epoch 19, iter 214, loss: 27.610583, acc: 0.877551\n",
      "epoch 19, iter 215, loss: 30.089960, acc: 0.693878\n",
      "epoch 19, iter 216, loss: 29.252978, acc: 0.816327\n",
      "epoch 19, iter 217, loss: 31.129096, acc: 0.836735\n",
      "epoch 19, iter 218, loss: 31.320582, acc: 0.857143\n",
      "epoch 19, iter 219, loss: 29.824581, acc: 0.897959\n",
      "epoch 19, iter 220, loss: 31.670156, acc: 0.632653\n",
      "epoch 19, iter 221, loss: 31.143933, acc: 0.795918\n",
      "epoch 19, iter 222, loss: 33.644215, acc: 0.653061\n",
      "epoch 19, iter 223, loss: 30.640431, acc: 0.918367\n",
      "epoch 19, iter 224, loss: 30.748628, acc: 0.755102\n",
      "epoch 19, iter 225, loss: 31.474215, acc: 0.755102\n",
      "epoch 19, iter 226, loss: 31.500796, acc: 0.755102\n",
      "epoch 19, iter 227, loss: 30.263276, acc: 0.816327\n",
      "epoch 19, iter 228, loss: 30.450058, acc: 0.755102\n",
      "epoch 19, iter 229, loss: 27.389562, acc: 0.938776\n",
      "epoch 19, iter 230, loss: 28.401335, acc: 0.775510\n",
      "epoch 19, iter 231, loss: 27.327556, acc: 0.857143\n",
      "epoch 19, iter 232, loss: 29.580494, acc: 0.755102\n",
      "epoch 19, iter 233, loss: 31.376634, acc: 0.673469\n",
      "epoch 19, iter 234, loss: 29.341748, acc: 0.918367\n",
      "epoch 19, iter 235, loss: 29.314107, acc: 0.877551\n",
      "epoch 19, iter 236, loss: 27.010100, acc: 0.959184\n",
      "epoch 19, iter 237, loss: 29.859925, acc: 0.591837\n",
      "epoch 19, iter 238, loss: 32.986968, acc: 0.734694\n",
      "epoch 19, iter 239, loss: 32.558467, acc: 0.795918\n",
      "epoch 19, iter 240, loss: 31.260102, acc: 0.877551\n",
      "epoch 19, iter 241, loss: 31.094244, acc: 0.816327\n",
      "epoch 19, iter 242, loss: 32.315604, acc: 0.693878\n",
      "epoch 19, iter 243, loss: 31.523638, acc: 0.816327\n",
      "epoch 19, iter 244, loss: 31.288034, acc: 0.816327\n",
      "epoch 19, iter 245, loss: 31.519327, acc: 0.734694\n",
      "epoch 19, iter 246, loss: 33.869880, acc: 0.612245\n",
      "epoch 19, iter 247, loss: 33.265864, acc: 0.795918\n",
      "epoch 19, iter 248, loss: 34.139240, acc: 0.653061\n",
      "epoch 19, iter 249, loss: 34.626775, acc: 0.714286\n",
      "epoch 19, acc: 0.784816\n"
     ]
    }
   ],
   "source": [
    "mWxh, mWhh, mWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
    "mbh, mby = np.zeros_like(bh), np.zeros_like(by) # memory variables for Adagrad\n",
    "smooth_loss = -np.log(1.0/num_problems)*num_timesteps # loss at iteration 0\n",
    "\n",
    "losses = []\n",
    "accuracies = []\n",
    "for e in xrange(epochs):\n",
    "    hprev = np.zeros((hidden_size,1)) # reset RNN memory\n",
    "    total_acc = 0.0\n",
    "    for i in xrange(num_train):\n",
    "        inputs = X_train[i,:,:].reshape((num_timesteps, num_problems * 2))\n",
    "        targets = y_train[i,:].reshape((num_timesteps,))\n",
    "        correctness_for_student = correctness[i,:].reshape((num_problems))\n",
    "\n",
    "        # forward num_timesteps characters through the net and fetch gradient\n",
    "        loss, dWxh, dWhh, dWhy, dbh, dby, hprev = lossFun(inputs, targets, correctness_for_student, hprev)\n",
    "        smooth_loss = smooth_loss * 0.7 + loss * 0.3\n",
    "        losses.append(smooth_loss)\n",
    "\n",
    "        # perform parameter update with Adagrad\n",
    "        for param, dparam, mem in zip([Wxh, Whh, Why, bh, by], \n",
    "                                      [dWxh, dWhh, dWhy, dbh, dby], \n",
    "                                      [mWxh, mWhh, mWhy, mbh, mby]):\n",
    "            mem += dparam * dparam\n",
    "            param += -learning_rate * dparam / np.sqrt(mem + 1e-8) # adagrad update\n",
    "        ps = forward_pass(inputs)\n",
    "        acc = accuracy(ps, targets, correctness_for_student) \n",
    "        accuracies.append(acc)\n",
    "        print ('epoch %d, iter %d, loss: %f, acc: %f' % (e, i, smooth_loss, acc)) # print progress\n",
    "        total_acc += acc\n",
    "    total_acc /= num_train\n",
    "    print ('epoch %d, acc: %f' % (e, total_acc)) # print progress\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "smooth_accs = []\n",
    "\n",
    "smooth_window = 100\n",
    "for i in xrange(len(accuracies)-smooth_window):\n",
    "    smooth_accs.append(np.mean(accuracies[i:i+smooth_window]))\n",
    "\n",
    "for i in xrange(len(accuracies)-smooth_window, len(accuracies)):\n",
    "    smooth_accs.append(np.mean(accuracies[i:len(accuracies)]))\n",
    "                    \n",
    "fig = plt.figure()\n",
    "\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.plot(xrange(len(smooth_accs)/2), smooth_accs[:len(smooth_accs)/2], 'b-')\n",
    "ax1.set_ylabel('accuracies', color='b')\n",
    "ax1.set_xlabel('iterations')\n",
    "for tl in ax1.get_yticklabels():\n",
    "    tl.set_color('b')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(xrange(len(losses)/2), losses[:len(losses)/2], 'r-')\n",
    "ax2.set_ylabel('losses', color='r')\n",
    "for tl in ax2.get_yticklabels():\n",
    "    tl.set_color('r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
