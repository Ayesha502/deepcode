{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nImplements an RNN on a synthetic data set, following the architecture \\ndescribed in \"Deep Knowledge Tracing\" by Chris Piech et al.\\nThe RNN implementation is based on min-char-rnn.py by Andrej Karpathy (@karpathy).\\nBSD License\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Implements an RNN on a synthetic data set, following the architecture \n",
    "described in \"Deep Knowledge Tracing\" by Chris Piech et al.\n",
    "The RNN implementation is based on min-char-rnn.py by Andrej Karpathy (@karpathy).\n",
    "BSD License\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "synthetic_data_set = \"syntheticDetailed/naive_c5_q50_s4000_v0.csv\"\n",
    "code_org_data_set = \"data/hoc_1-9_binary_input.csv\"\n",
    "\n",
    "DATA_SET = code_org_data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "Vectorization done!\n",
      "X_train\n",
      "(2000, 8, 18)\n",
      "[[[ True False False False False False False False False False False False\n",
      "   False False False False False False]\n",
      "  [False False False False False False False False False False  True False\n",
      "   False False False False False False]\n",
      "  [False False  True False False False False False False False False False\n",
      "   False False False False False False]\n",
      "  [False False False  True False False False False False False False False\n",
      "   False False False False False False]\n",
      "  [False False False False  True False False False False False False False\n",
      "   False False False False False False]\n",
      "  [False False False False False False False False False False False False\n",
      "   False False  True False False False]\n",
      "  [False False False False False False  True False False False False False\n",
      "   False False False False False False]\n",
      "  [False False False False False False False  True False False False False\n",
      "   False False False False False False]]\n",
      "\n",
      " [[ True False False False False False False False False False False False\n",
      "   False False False False False False]\n",
      "  [False  True False False False False False False False False False False\n",
      "   False False False False False False]\n",
      "  [False False  True False False False False False False False False False\n",
      "   False False False False False False]\n",
      "  [False False False  True False False False False False False False False\n",
      "   False False False False False False]\n",
      "  [False False False False  True False False False False False False False\n",
      "   False False False False False False]\n",
      "  [False False False False False  True False False False False False False\n",
      "   False False False False False False]\n",
      "  [False False False False False False  True False False False False False\n",
      "   False False False False False False]\n",
      "  [False False False False False False False  True False False False False\n",
      "   False False False False False False]]\n",
      "\n",
      " [[ True False False False False False False False False False False False\n",
      "   False False False False False False]\n",
      "  [False  True False False False False False False False False False False\n",
      "   False False False False False False]\n",
      "  [False False  True False False False False False False False False False\n",
      "   False False False False False False]\n",
      "  [False False False  True False False False False False False False False\n",
      "   False False False False False False]\n",
      "  [False False False False  True False False False False False False False\n",
      "   False False False False False False]\n",
      "  [False False False False False False False False False False False False\n",
      "   False False  True False False False]\n",
      "  [False False False False False False False False False False False False\n",
      "   False False False  True False False]\n",
      "  [False False False False False False False False False False False False\n",
      "   False False False False  True False]]\n",
      "\n",
      " [[ True False False False False False False False False False False False\n",
      "   False False False False False False]\n",
      "  [False  True False False False False False False False False False False\n",
      "   False False False False False False]\n",
      "  [False False  True False False False False False False False False False\n",
      "   False False False False False False]\n",
      "  [False False False  True False False False False False False False False\n",
      "   False False False False False False]\n",
      "  [False False False False  True False False False False False False False\n",
      "   False False False False False False]\n",
      "  [False False False False False  True False False False False False False\n",
      "   False False False False False False]\n",
      "  [False False False False False False  True False False False False False\n",
      "   False False False False False False]\n",
      "  [False False False False False False False  True False False False False\n",
      "   False False False False False False]]\n",
      "\n",
      " [[ True False False False False False False False False False False False\n",
      "   False False False False False False]\n",
      "  [False  True False False False False False False False False False False\n",
      "   False False False False False False]\n",
      "  [False False  True False False False False False False False False False\n",
      "   False False False False False False]\n",
      "  [False False False  True False False False False False False False False\n",
      "   False False False False False False]\n",
      "  [False False False False  True False False False False False False False\n",
      "   False False False False False False]\n",
      "  [False False False False False  True False False False False False False\n",
      "   False False False False False False]\n",
      "  [False False False False False False  True False False False False False\n",
      "   False False False False False False]\n",
      "  [False False False False False False False False False False False False\n",
      "   False False False False  True False]]]\n",
      "y_train\n",
      "(2000, 8)\n",
      "[[1 2 3 4 5 6 7 8]\n",
      " [1 2 3 4 5 6 7 8]\n",
      " [1 2 3 4 5 6 7 8]\n",
      " [1 2 3 4 5 6 7 8]\n",
      " [1 2 3 4 5 6 7 8]]\n"
     ]
    }
   ],
   "source": [
    "# Read in the data set\n",
    "# This function can be moved to utils.py\n",
    "data_array = np.array(list(csv.reader(open(DATA_SET,\"rb\"),delimiter=','))).astype('int')\n",
    "num_samples = data_array.shape[0]\n",
    "num_problems = data_array.shape[1]\n",
    "\n",
    "# time steps is number of problems - 1 because we cannot predict on the last problem.\n",
    "num_timesteps = num_problems - 1 \n",
    "# Split data into train and test (half and half)\n",
    "num_samples = 4000  # Note: for code.org sample, enforcing limit on num_students as a trial\n",
    "train = data_array[0:num_samples/2,:]\n",
    "test = data_array[num_samples/2:num_samples,:]\n",
    "\n",
    "num_train = train.shape[0]\n",
    "num_test = test.shape[0]\n",
    "\n",
    "\n",
    "print('Vectorization...')\n",
    "X_train = np.zeros((num_train, num_timesteps, num_problems * 2), dtype=np.bool)\n",
    "y_train = np.zeros((num_train, num_timesteps), dtype=np.int)\n",
    "\n",
    "# Create 3-dimensional input tensor with one-hot encodings for each sample\n",
    "# the dimension of each vector for a student i and time t is 2 * num_problems\n",
    "# where the first half corresponds to the correctly answered problems and the\n",
    "# second half to the incorrectly answered ones.\n",
    "for i in xrange(num_train):\n",
    "    \n",
    "    # for the first time step. Done separately so we can populate the output \n",
    "    # tensor at the same time, which is shifted back by 1.\n",
    "\n",
    "    for t in xrange(0,num_timesteps):\n",
    "        p = t # since timestep t corresponds to problem p where t=p\n",
    "        if train[i,p] == 1:\n",
    "            X_train[i, t, p] = 1 \n",
    "        else:\n",
    "            X_train[i, t, num_problems + p] = 1\n",
    "        # this is a special case for the synthetic data set, where the next problem \n",
    "        # is just the current problem index + 1\n",
    "        y_train[i,t] = p + 1\n",
    "correctness = train\n",
    "\n",
    "print (\"Vectorization done!\")\n",
    "\n",
    "print (\"X_train\")\n",
    "print (X_train.shape)\n",
    "print (X_train[:5])\n",
    "\n",
    "print (\"y_train\")\n",
    "print (y_train.shape)\n",
    "print (y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "hidden_size = 200 # size of hidden layer of neurons\n",
    "learning_rate = 1e-1\n",
    "epochs = 10\n",
    "\n",
    "# model parameters\n",
    "Wxh = np.random.randn(hidden_size, num_problems * 2)*0.01 # input to hidden\n",
    "Whh = np.random.randn(hidden_size, hidden_size)*0.01 # hidden to hidden\n",
    "Why = np.random.randn(num_problems, hidden_size)*0.01 # hidden to output\n",
    "bh = np.zeros((hidden_size, 1)) # hidden bias\n",
    "by = np.zeros((num_problems, 1)) # output bias\n",
    "\n",
    "def lossFun(inputs, targets, correctness, hprev):\n",
    "    \"\"\"\n",
    "    inputs,targets are both list of integers.\n",
    "    hprev is Hx1 array of initial hidden state\n",
    "    returns the loss, gradients on model parameters, and last hidden state\n",
    "    \"\"\"\n",
    "    xs, hs, ys, ps, ps_denom = {}, {}, {}, {}, {}\n",
    "    hs[-1] = np.copy(hprev)\n",
    "    loss = 0\n",
    "    # forward pass\n",
    "    for t in xrange(len(inputs)):\n",
    "        xs[t] = inputs[t,:].reshape((num_problems * 2, 1))\n",
    "        hs[t] = np.tanh(np.dot(Wxh, xs[t]) + np.dot(Whh, hs[t-1]) + bh) # hidden state\n",
    "        ys[t] = np.dot(Why, hs[t]) + by # unnormalized log probabilities for next chars\n",
    "        ps_denom[t] = np.sum(np.exp(ys[t]))\n",
    "        ps[t] = np.exp(ys[t]) / ps_denom[t] # probabilities for next chars\n",
    "\n",
    "        # softmax (cross-entropy loss)\n",
    "        if correctness[targets[t]] == 1:\n",
    "            loss += -np.log(ps[t][targets[t],0]) \n",
    "        else:\n",
    "            loss += -np.log(1-ps[t][targets[t],0]) \n",
    "        # backward pass: compute gradients going backwards\n",
    "        dWxh, dWhh, dWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
    "        dbh, dby = np.zeros_like(bh), np.zeros_like(by)\n",
    "        dhnext = np.zeros_like(hs[0])\n",
    "\n",
    "\n",
    "    for t in reversed(xrange(len(inputs))):\n",
    "        dy = np.copy(ps[t])\n",
    "        if correctness[targets[t]] == 1:\n",
    "            dy[targets[t]] -= 1 # backprop into y\n",
    "        else:\n",
    "            for p in xrange(num_problems):\n",
    "                if p != targets[t]:\n",
    "                    dy[p] -= np.exp(ys[t][p]) / (ps_denom[t] - np.exp(ys[t][targets[t]]))\n",
    "\n",
    "\n",
    "\n",
    "        dWhy += np.dot(dy, hs[t].T)\n",
    "        dby += dy\n",
    "        dh = np.dot(Why.T, dy) + dhnext # backprop into h\n",
    "        dhraw = (1 - hs[t] * hs[t]) * dh # backprop through tanh nonlinearity\n",
    "        dbh += dhraw\n",
    "        dWxh += np.dot(dhraw, xs[t].T)\n",
    "        dWhh += np.dot(dhraw, hs[t-1].T)\n",
    "        dhnext = np.dot(Whh.T, dhraw)\n",
    "        for dparam in [dWxh, dWhh, dWhy, dbh, dby]:\n",
    "            np.clip(dparam, -5, 5, out=dparam) # clip to mitigate exploding gradients\n",
    "    return loss, dWxh, dWhh, dWhy, dbh, dby, hs[len(inputs)-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(ps, targets, correctness):\n",
    "    \"\"\"\n",
    "    Computes the accuracy using the predictions at each time step.\n",
    "    For each t, if probability of next problem is > 0.5 for correct, or <= 0.5 \n",
    "    for incorrect, then count this as correct prediction.\n",
    "    \"\"\"\n",
    "    num_correct = 0\n",
    "    for t in xrange(num_timesteps):\n",
    "        predicted_prob = ps[t][targets[t],0] \n",
    "        if (predicted_prob >= 0.5 and correctness[targets[t]] == 1) or (predicted_prob < 0.5 and correctness[targets[t]] == 0):\n",
    "            num_correct += 1\n",
    "    accuracy = num_correct / float(num_timesteps)\n",
    "    return accuracy\n",
    "\n",
    "def forward_pass(inputs):\n",
    "    xs, hs, ys, ps, ps_denom = {}, {}, {}, {}, {}\n",
    "    hs[-1] = np.copy(hprev)\n",
    "    for t in xrange(len(inputs)):\n",
    "        xs[t] = inputs[t,:].reshape((num_problems * 2, 1))\n",
    "        hs[t] = np.tanh(np.dot(Wxh, xs[t]) + np.dot(Whh, hs[t-1]) + bh) # hidden state\n",
    "        ys[t] = np.dot(Why, hs[t]) + by # unnormalized log probabilities for next chars\n",
    "        ps_denom[t] = np.sum(np.exp(ys[t]))\n",
    "        ps[t] = np.exp(ys[t]) / ps_denom[t] # probabilities for next chars\n",
    "    return ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, iter 0, loss: 15.706893, acc: 0.375000\n",
      "epoch 0, iter 1, loss: 16.655030, acc: 0.375000\n",
      "epoch 0, iter 2, loss: 14.934259, acc: 1.000000\n",
      "epoch 0, iter 3, loss: 32.150693, acc: 0.375000\n",
      "epoch 0, iter 4, loss: 41.783036, acc: 0.250000\n",
      "epoch 0, iter 5, loss: 40.448952, acc: 0.625000\n",
      "epoch 0, iter 6, loss: 29.769118, acc: 1.000000\n",
      "epoch 0, iter 7, loss: 36.920142, acc: 0.625000\n",
      "epoch 0, iter 8, loss: 33.540691, acc: 0.750000\n",
      "epoch 0, iter 9, loss: 27.351012, acc: 0.625000\n",
      "epoch 0, iter 10, loss: 36.377068, acc: 0.625000\n",
      "epoch 0, iter 11, loss: 34.820490, acc: 0.500000\n",
      "epoch 0, iter 12, loss: 30.825766, acc: 0.500000\n",
      "epoch 0, iter 13, loss: 28.300181, acc: 0.500000\n",
      "epoch 0, iter 14, loss: 26.964429, acc: 0.625000\n",
      "epoch 0, iter 15, loss: 23.404608, acc: 0.875000\n",
      "epoch 0, iter 16, loss: 26.141018, acc: 0.500000\n",
      "epoch 0, iter 17, loss: 25.905018, acc: 0.750000\n",
      "epoch 0, iter 18, loss: 25.079950, acc: 0.500000\n",
      "epoch 0, iter 19, loss: 21.936701, acc: 0.625000\n",
      "epoch 0, iter 20, loss: 19.493432, acc: 0.625000\n",
      "epoch 0, iter 21, loss: 17.318367, acc: 0.625000\n",
      "epoch 0, iter 22, loss: 20.213372, acc: 0.500000\n",
      "epoch 0, iter 23, loss: 17.739904, acc: 0.625000\n",
      "epoch 0, iter 24, loss: 17.295590, acc: 0.500000\n",
      "epoch 0, iter 25, loss: 18.484062, acc: 0.625000\n",
      "epoch 0, iter 26, loss: 19.798017, acc: 0.500000\n",
      "epoch 0, iter 27, loss: 18.484510, acc: 0.500000\n",
      "epoch 0, iter 28, loss: 17.599708, acc: 0.500000\n",
      "epoch 0, iter 29, loss: 16.821633, acc: 0.500000\n",
      "epoch 0, iter 30, loss: 14.947102, acc: 0.625000\n",
      "epoch 0, iter 31, loss: 12.552489, acc: 0.750000\n",
      "epoch 0, iter 32, loss: 13.391492, acc: 0.500000\n",
      "epoch 0, iter 33, loss: 13.473476, acc: 0.500000\n",
      "epoch 0, iter 34, loss: 13.679037, acc: 0.500000\n",
      "epoch 0, iter 35, loss: 13.626608, acc: 0.500000\n",
      "epoch 0, iter 36, loss: 13.630022, acc: 0.500000\n",
      "epoch 0, iter 37, loss: 14.606590, acc: 0.625000\n",
      "epoch 0, iter 38, loss: 12.929798, acc: 0.625000\n",
      "epoch 0, iter 39, loss: 12.673001, acc: 0.750000\n",
      "epoch 0, iter 40, loss: 13.376649, acc: 0.625000\n",
      "epoch 0, iter 41, loss: 12.021618, acc: 0.625000\n",
      "epoch 0, iter 42, loss: 14.178460, acc: 0.500000\n",
      "epoch 0, iter 43, loss: 12.530565, acc: 0.625000\n",
      "epoch 0, iter 44, loss: 13.244369, acc: 0.625000\n",
      "epoch 0, iter 45, loss: 15.343719, acc: 0.625000\n",
      "epoch 0, iter 46, loss: 16.076457, acc: 0.500000\n",
      "epoch 0, iter 47, loss: 13.578305, acc: 0.875000\n",
      "epoch 0, iter 48, loss: 15.348162, acc: 0.625000\n",
      "epoch 0, iter 49, loss: 14.679630, acc: 0.625000\n",
      "epoch 0, iter 50, loss: 13.064841, acc: 0.625000\n",
      "epoch 0, iter 51, loss: 12.557339, acc: 0.500000\n",
      "epoch 0, iter 52, loss: 10.896172, acc: 0.875000\n",
      "epoch 0, iter 53, loss: 12.727405, acc: 0.500000\n",
      "epoch 0, iter 54, loss: 11.644415, acc: 0.500000\n",
      "epoch 0, iter 55, loss: 10.781727, acc: 0.750000\n",
      "epoch 0, iter 56, loss: 10.085284, acc: 0.625000\n",
      "epoch 0, iter 57, loss: 11.373140, acc: 0.500000\n",
      "epoch 0, iter 58, loss: 10.739247, acc: 0.500000\n",
      "epoch 0, iter 59, loss: 10.365708, acc: 0.500000\n",
      "epoch 0, iter 60, loss: 9.476418, acc: 0.625000\n",
      "epoch 0, iter 61, loss: 9.832985, acc: 0.500000\n",
      "epoch 0, iter 62, loss: 9.671901, acc: 0.500000\n",
      "epoch 0, iter 63, loss: 9.634617, acc: 0.500000\n",
      "epoch 0, iter 64, loss: 9.667206, acc: 0.750000\n",
      "epoch 0, iter 65, loss: 11.630387, acc: 0.500000\n",
      "epoch 0, iter 66, loss: 10.836831, acc: 0.500000\n",
      "epoch 0, iter 67, loss: 9.611260, acc: 0.625000\n",
      "epoch 0, iter 68, loss: 9.156373, acc: 0.625000\n",
      "epoch 0, iter 69, loss: 9.348529, acc: 0.500000\n",
      "epoch 0, iter 70, loss: 9.132616, acc: 0.500000\n",
      "epoch 0, iter 71, loss: 9.650799, acc: 0.625000\n",
      "epoch 0, iter 72, loss: 9.260745, acc: 0.750000\n",
      "epoch 0, iter 73, loss: 9.804714, acc: 0.625000\n",
      "epoch 0, iter 74, loss: 10.879500, acc: 0.500000\n",
      "epoch 0, iter 75, loss: 9.593510, acc: 0.625000\n",
      "epoch 0, iter 76, loss: 9.021665, acc: 0.625000\n",
      "epoch 0, iter 77, loss: 8.342529, acc: 0.750000\n",
      "epoch 0, iter 78, loss: 8.183686, acc: 0.625000\n",
      "epoch 0, iter 79, loss: 9.285926, acc: 0.500000\n",
      "epoch 0, iter 80, loss: 7.885524, acc: 0.750000\n",
      "epoch 0, iter 81, loss: 8.712139, acc: 0.500000\n",
      "epoch 0, iter 82, loss: 8.329147, acc: 0.500000\n",
      "epoch 0, iter 83, loss: 7.274702, acc: 1.000000\n",
      "epoch 0, iter 84, loss: 10.033384, acc: 0.500000\n",
      "epoch 0, iter 85, loss: 8.711303, acc: 0.625000\n",
      "epoch 0, iter 86, loss: 8.402509, acc: 0.625000\n",
      "epoch 0, iter 87, loss: 8.923688, acc: 0.625000\n",
      "epoch 0, iter 88, loss: 7.287752, acc: 1.000000\n",
      "epoch 0, iter 89, loss: 10.632619, acc: 0.500000\n",
      "epoch 0, iter 90, loss: 9.535437, acc: 0.500000\n",
      "epoch 0, iter 91, loss: 9.197882, acc: 0.625000\n",
      "epoch 0, iter 92, loss: 7.271042, acc: 0.875000\n",
      "epoch 0, iter 93, loss: 7.662693, acc: 0.625000\n",
      "epoch 0, iter 94, loss: 8.701506, acc: 0.500000\n",
      "epoch 0, iter 95, loss: 7.856617, acc: 0.625000\n",
      "epoch 0, iter 96, loss: 8.160547, acc: 0.500000\n",
      "epoch 0, iter 97, loss: 7.865652, acc: 0.500000\n",
      "epoch 0, iter 98, loss: 8.200253, acc: 0.875000\n",
      "epoch 0, iter 99, loss: 9.764839, acc: 0.625000\n",
      "epoch 0, iter 100, loss: 9.623300, acc: 0.500000\n",
      "epoch 0, iter 101, loss: 9.372050, acc: 0.750000\n",
      "epoch 0, iter 102, loss: 10.593062, acc: 0.625000\n",
      "epoch 0, iter 103, loss: 9.949688, acc: 0.500000\n",
      "epoch 0, iter 104, loss: 9.195082, acc: 0.625000\n",
      "epoch 0, iter 105, loss: 9.565483, acc: 0.500000\n",
      "epoch 0, iter 106, loss: 8.407275, acc: 0.625000\n",
      "epoch 0, iter 107, loss: 8.181300, acc: 0.625000\n",
      "epoch 0, iter 108, loss: 7.243345, acc: 0.625000\n",
      "epoch 0, iter 109, loss: 7.690183, acc: 0.500000\n",
      "epoch 0, iter 110, loss: 7.467608, acc: 0.625000\n",
      "epoch 0, iter 111, loss: 8.196063, acc: 0.500000\n",
      "epoch 0, iter 112, loss: 7.706710, acc: 0.500000\n",
      "epoch 0, iter 113, loss: 7.446050, acc: 0.500000\n",
      "epoch 0, iter 114, loss: 7.343028, acc: 0.500000\n",
      "epoch 0, iter 115, loss: 7.223518, acc: 0.500000\n",
      "epoch 0, iter 116, loss: 7.756892, acc: 0.625000\n",
      "epoch 0, iter 117, loss: 6.919175, acc: 0.625000\n",
      "epoch 0, iter 118, loss: 6.336998, acc: 0.625000\n",
      "epoch 0, iter 119, loss: 7.640798, acc: 0.500000\n",
      "epoch 0, iter 120, loss: 6.719337, acc: 0.750000\n",
      "epoch 0, iter 121, loss: 5.786003, acc: 0.750000\n",
      "epoch 0, iter 122, loss: 6.195382, acc: 0.875000\n",
      "epoch 0, iter 123, loss: 8.588316, acc: 0.500000\n",
      "epoch 0, iter 124, loss: 8.420404, acc: 1.000000\n",
      "epoch 0, iter 125, loss: 10.398143, acc: 0.625000\n",
      "epoch 0, iter 126, loss: 9.816866, acc: 0.500000\n",
      "epoch 0, iter 127, loss: 9.413988, acc: 0.625000\n",
      "epoch 0, iter 128, loss: 8.033326, acc: 0.750000\n",
      "epoch 0, iter 129, loss: 7.896885, acc: 0.625000\n",
      "epoch 0, iter 130, loss: 8.239626, acc: 0.500000\n",
      "epoch 0, iter 131, loss: 7.641105, acc: 0.625000\n",
      "epoch 0, iter 132, loss: 6.859695, acc: 0.750000\n",
      "epoch 0, iter 133, loss: 5.761606, acc: 0.750000\n",
      "epoch 0, iter 134, loss: 7.907630, acc: 0.625000\n",
      "epoch 0, iter 135, loss: 8.426126, acc: 0.500000\n",
      "epoch 0, iter 136, loss: 8.424843, acc: 0.875000\n",
      "epoch 0, iter 137, loss: 10.648324, acc: 0.500000\n",
      "epoch 0, iter 138, loss: 9.077721, acc: 0.625000\n",
      "epoch 0, iter 139, loss: 7.754129, acc: 0.625000\n",
      "epoch 0, iter 140, loss: 7.904120, acc: 0.500000\n",
      "epoch 0, iter 141, loss: 7.371203, acc: 0.625000\n",
      "epoch 0, iter 142, loss: 7.772158, acc: 0.500000\n",
      "epoch 0, iter 143, loss: 7.122392, acc: 0.625000\n",
      "epoch 0, iter 144, loss: 7.470310, acc: 0.500000\n",
      "epoch 0, iter 145, loss: 7.023554, acc: 0.625000\n",
      "epoch 0, iter 146, loss: 6.297995, acc: 0.625000\n",
      "epoch 0, iter 147, loss: 5.865888, acc: 0.625000\n",
      "epoch 0, iter 148, loss: 5.508759, acc: 0.625000\n",
      "epoch 0, iter 149, loss: 5.232337, acc: 0.625000\n",
      "epoch 0, iter 150, loss: 6.198892, acc: 0.625000\n",
      "epoch 0, iter 151, loss: 6.738675, acc: 0.500000\n",
      "epoch 0, iter 152, loss: 6.507667, acc: 0.875000\n",
      "epoch 0, iter 153, loss: 8.608061, acc: 0.500000\n",
      "epoch 0, iter 154, loss: 7.519402, acc: 0.750000\n",
      "epoch 0, iter 155, loss: 7.291357, acc: 0.625000\n",
      "epoch 0, iter 156, loss: 6.525290, acc: 0.625000\n",
      "epoch 0, iter 157, loss: 5.726569, acc: 0.875000\n",
      "epoch 0, iter 158, loss: 7.922666, acc: 0.500000\n",
      "epoch 0, iter 159, loss: 7.189700, acc: 0.625000\n",
      "epoch 0, iter 160, loss: 7.419825, acc: 0.500000\n",
      "epoch 0, iter 161, loss: 6.687943, acc: 0.875000\n",
      "epoch 0, iter 162, loss: 7.287853, acc: 0.625000\n",
      "epoch 0, iter 163, loss: 7.552970, acc: 0.625000\n",
      "epoch 0, iter 164, loss: 6.582870, acc: 0.625000\n",
      "epoch 0, iter 165, loss: 7.176187, acc: 0.625000\n",
      "epoch 0, iter 166, loss: 6.326063, acc: 0.625000\n",
      "epoch 0, iter 167, loss: 5.747408, acc: 0.625000\n",
      "epoch 0, iter 168, loss: 4.786229, acc: 0.875000\n",
      "epoch 0, iter 169, loss: 7.161466, acc: 0.500000\n",
      "epoch 0, iter 170, loss: 6.484287, acc: 0.625000\n",
      "epoch 0, iter 171, loss: 5.857888, acc: 0.625000\n",
      "epoch 0, iter 172, loss: 5.447975, acc: 0.750000\n",
      "epoch 0, iter 173, loss: 4.707467, acc: 0.750000\n",
      "epoch 0, iter 174, loss: 4.182233, acc: 0.750000\n",
      "epoch 0, iter 175, loss: 6.251170, acc: 0.500000\n",
      "epoch 0, iter 176, loss: 5.739027, acc: 0.875000\n",
      "epoch 0, iter 177, loss: 6.609373, acc: 0.625000\n",
      "epoch 0, iter 178, loss: 5.896541, acc: 0.625000\n",
      "epoch 0, iter 179, loss: 6.552482, acc: 0.625000\n",
      "epoch 0, iter 180, loss: 6.988250, acc: 0.750000\n",
      "epoch 0, iter 181, loss: 6.909546, acc: 0.625000\n",
      "epoch 0, iter 182, loss: 6.103626, acc: 0.625000\n",
      "epoch 0, iter 183, loss: 5.567540, acc: 0.875000\n",
      "epoch 0, iter 184, loss: 7.810402, acc: 0.500000\n",
      "epoch 0, iter 185, loss: 6.974783, acc: 0.625000\n",
      "epoch 0, iter 186, loss: 6.161198, acc: 0.625000\n",
      "epoch 0, iter 187, loss: 5.510414, acc: 0.875000\n",
      "epoch 0, iter 188, loss: 7.556397, acc: 0.625000\n",
      "epoch 0, iter 189, loss: 7.704733, acc: 0.500000\n",
      "epoch 0, iter 190, loss: 7.166487, acc: 0.625000\n",
      "epoch 0, iter 191, loss: 6.266357, acc: 0.875000\n",
      "epoch 0, iter 192, loss: 8.407476, acc: 0.625000\n",
      "epoch 0, iter 193, loss: 8.262970, acc: 0.500000\n",
      "epoch 0, iter 194, loss: 7.501384, acc: 0.750000\n",
      "epoch 0, iter 195, loss: 7.134787, acc: 0.625000\n",
      "epoch 0, iter 196, loss: 7.462751, acc: 0.500000\n",
      "epoch 0, iter 197, loss: 6.764335, acc: 0.750000\n",
      "epoch 0, iter 198, loss: 5.608897, acc: 0.750000\n",
      "epoch 0, iter 199, loss: 6.977766, acc: 0.500000\n",
      "epoch 0, iter 200, loss: 6.421508, acc: 0.750000\n",
      "epoch 0, iter 201, loss: 7.386822, acc: 0.500000\n",
      "epoch 0, iter 202, loss: 6.849308, acc: 0.500000\n",
      "epoch 0, iter 203, loss: 6.438363, acc: 0.625000\n",
      "epoch 0, iter 204, loss: 6.193235, acc: 0.750000\n",
      "epoch 0, iter 205, loss: 5.614741, acc: 0.750000\n",
      "epoch 0, iter 206, loss: 7.021556, acc: 0.500000\n",
      "epoch 0, iter 207, loss: 6.944902, acc: 0.750000\n",
      "epoch 0, iter 208, loss: 5.807733, acc: 0.875000\n",
      "epoch 0, iter 209, loss: 8.353736, acc: 0.500000\n",
      "epoch 0, iter 210, loss: 7.611634, acc: 0.750000\n",
      "epoch 0, iter 211, loss: 8.423248, acc: 0.500000\n",
      "epoch 0, iter 212, loss: 7.632106, acc: 0.500000\n",
      "epoch 0, iter 213, loss: 7.130540, acc: 0.625000\n",
      "epoch 0, iter 214, loss: 6.271772, acc: 0.750000\n",
      "epoch 0, iter 215, loss: 7.436838, acc: 0.500000\n",
      "epoch 0, iter 216, loss: 7.066216, acc: 0.625000\n",
      "epoch 0, iter 217, loss: 8.439492, acc: 0.625000\n",
      "epoch 0, iter 218, loss: 8.035295, acc: 0.625000\n",
      "epoch 0, iter 219, loss: 7.315501, acc: 0.500000\n",
      "epoch 0, iter 220, loss: 6.810345, acc: 0.625000\n",
      "epoch 0, iter 221, loss: 6.465521, acc: 0.500000\n",
      "epoch 0, iter 222, loss: 6.218186, acc: 0.500000\n",
      "epoch 0, iter 223, loss: 6.022378, acc: 0.625000\n",
      "epoch 0, iter 224, loss: 6.494433, acc: 0.625000\n",
      "epoch 0, iter 225, loss: 6.776693, acc: 0.500000\n",
      "epoch 0, iter 226, loss: 6.327290, acc: 1.000000\n",
      "epoch 0, iter 227, loss: 6.826919, acc: 0.750000\n",
      "epoch 0, iter 228, loss: 7.713774, acc: 0.500000\n",
      "epoch 0, iter 229, loss: 6.951826, acc: 0.625000\n",
      "epoch 0, iter 230, loss: 6.243613, acc: 0.875000\n",
      "epoch 0, iter 231, loss: 5.223652, acc: 0.750000\n",
      "epoch 0, iter 232, loss: 5.761443, acc: 0.625000\n",
      "epoch 0, iter 233, loss: 6.472349, acc: 0.625000\n",
      "epoch 0, iter 234, loss: 6.010253, acc: 0.750000\n",
      "epoch 0, iter 235, loss: 6.500042, acc: 0.500000\n",
      "epoch 0, iter 236, loss: 6.260963, acc: 0.625000\n",
      "epoch 0, iter 237, loss: 6.513356, acc: 0.750000\n",
      "epoch 0, iter 238, loss: 5.813882, acc: 0.750000\n",
      "epoch 0, iter 239, loss: 5.917174, acc: 0.750000\n",
      "epoch 0, iter 240, loss: 6.865685, acc: 0.625000\n",
      "epoch 0, iter 241, loss: 7.336842, acc: 0.500000\n",
      "epoch 0, iter 242, loss: 6.866336, acc: 0.500000\n",
      "epoch 0, iter 243, loss: 6.397303, acc: 0.625000\n",
      "epoch 0, iter 244, loss: 5.761853, acc: 0.750000\n",
      "epoch 0, iter 245, loss: 5.242711, acc: 0.625000\n",
      "epoch 0, iter 246, loss: 4.964719, acc: 0.625000\n",
      "epoch 0, iter 247, loss: 5.956790, acc: 0.625000\n",
      "epoch 0, iter 248, loss: 6.461009, acc: 0.625000\n",
      "epoch 0, iter 249, loss: 6.775534, acc: 0.500000\n",
      "epoch 0, iter 250, loss: 7.153162, acc: 0.625000\n",
      "epoch 0, iter 251, loss: 7.253721, acc: 0.500000\n",
      "epoch 0, iter 252, loss: 6.760673, acc: 0.750000\n",
      "epoch 0, iter 253, loss: 7.563572, acc: 0.500000\n",
      "epoch 0, iter 254, loss: 6.828234, acc: 0.750000\n",
      "epoch 0, iter 255, loss: 6.569944, acc: 0.625000\n",
      "epoch 0, iter 256, loss: 5.869769, acc: 0.625000\n",
      "epoch 0, iter 257, loss: 5.374888, acc: 0.625000\n",
      "epoch 0, iter 258, loss: 5.024863, acc: 0.625000\n",
      "epoch 0, iter 259, loss: 5.962900, acc: 0.500000\n",
      "epoch 0, iter 260, loss: 5.887359, acc: 0.625000\n",
      "epoch 0, iter 261, loss: 5.392159, acc: 0.625000\n",
      "epoch 0, iter 262, loss: 5.004122, acc: 0.750000\n",
      "epoch 0, iter 263, loss: 6.600589, acc: 0.500000\n",
      "epoch 0, iter 264, loss: 6.138568, acc: 0.750000\n",
      "epoch 0, iter 265, loss: 6.266560, acc: 0.625000\n",
      "epoch 0, iter 266, loss: 6.633829, acc: 0.500000\n",
      "epoch 0, iter 267, loss: 6.370323, acc: 0.625000\n",
      "epoch 0, iter 268, loss: 5.800100, acc: 0.875000\n",
      "epoch 0, iter 269, loss: 7.691464, acc: 0.500000\n",
      "epoch 0, iter 270, loss: 7.094695, acc: 0.500000\n",
      "epoch 0, iter 271, loss: 6.654304, acc: 0.500000\n",
      "epoch 0, iter 272, loss: 6.372048, acc: 0.875000\n",
      "epoch 0, iter 273, loss: 9.209452, acc: 0.625000\n",
      "epoch 0, iter 274, loss: 8.610179, acc: 0.625000\n",
      "epoch 0, iter 275, loss: 7.358912, acc: 0.750000\n",
      "epoch 0, iter 276, loss: 7.005416, acc: 0.625000\n",
      "epoch 0, iter 277, loss: 7.240123, acc: 0.625000\n",
      "epoch 0, iter 278, loss: 6.626509, acc: 0.750000\n",
      "epoch 0, iter 279, loss: 6.401108, acc: 0.625000\n",
      "epoch 0, iter 280, loss: 6.807085, acc: 0.500000\n",
      "epoch 0, iter 281, loss: 6.463529, acc: 0.500000\n",
      "epoch 0, iter 282, loss: 6.205821, acc: 0.375000\n",
      "epoch 0, iter 283, loss: 6.017196, acc: 0.625000\n",
      "epoch 0, iter 284, loss: 5.403320, acc: 0.875000\n",
      "epoch 0, iter 285, loss: 4.245589, acc: 0.875000\n",
      "epoch 0, iter 286, loss: 6.981428, acc: 0.500000\n",
      "epoch 0, iter 287, loss: 6.311860, acc: 0.625000\n",
      "epoch 0, iter 288, loss: 6.518315, acc: 0.375000\n",
      "epoch 0, iter 289, loss: 6.202021, acc: 0.750000\n",
      "epoch 0, iter 290, loss: 6.145948, acc: 0.625000\n",
      "epoch 0, iter 291, loss: 6.583829, acc: 0.500000\n",
      "epoch 0, iter 292, loss: 6.372873, acc: 0.875000\n",
      "epoch 0, iter 293, loss: 8.118865, acc: 0.500000\n",
      "epoch 0, iter 294, loss: 7.491606, acc: 0.875000\n",
      "epoch 0, iter 295, loss: 8.728152, acc: 0.500000\n",
      "epoch 0, iter 296, loss: 7.810926, acc: 0.500000\n",
      "epoch 0, iter 297, loss: 7.165366, acc: 0.875000\n",
      "epoch 0, iter 298, loss: 8.440516, acc: 0.500000\n",
      "epoch 0, iter 299, loss: 7.501298, acc: 0.625000\n",
      "epoch 0, iter 300, loss: 7.399570, acc: 0.500000\n",
      "epoch 0, iter 301, loss: 6.858458, acc: 0.500000\n",
      "epoch 0, iter 302, loss: 6.501476, acc: 0.750000\n",
      "epoch 0, iter 303, loss: 7.267422, acc: 0.500000\n",
      "epoch 0, iter 304, loss: 6.676819, acc: 0.625000\n",
      "epoch 0, iter 305, loss: 6.812742, acc: 0.500000\n",
      "epoch 0, iter 306, loss: 6.444164, acc: 0.500000\n",
      "epoch 0, iter 307, loss: 6.183512, acc: 0.500000\n",
      "epoch 0, iter 308, loss: 5.980893, acc: 0.625000\n",
      "epoch 0, iter 309, loss: 6.351867, acc: 0.500000\n",
      "epoch 0, iter 310, loss: 6.035806, acc: 0.750000\n",
      "epoch 0, iter 311, loss: 6.836425, acc: 0.750000\n",
      "epoch 0, iter 312, loss: 7.707221, acc: 0.625000\n",
      "epoch 0, iter 313, loss: 7.572304, acc: 0.625000\n",
      "epoch 0, iter 314, loss: 6.576423, acc: 0.875000\n",
      "epoch 0, iter 315, loss: 7.197114, acc: 0.625000\n",
      "epoch 0, iter 316, loss: 7.296426, acc: 0.500000\n",
      "epoch 0, iter 317, loss: 6.804636, acc: 0.500000\n",
      "epoch 0, iter 318, loss: 6.457729, acc: 0.750000\n",
      "epoch 0, iter 319, loss: 5.445692, acc: 1.000000\n",
      "epoch 0, iter 320, loss: 7.001870, acc: 0.625000\n",
      "epoch 0, iter 321, loss: 6.051293, acc: 0.750000\n",
      "epoch 0, iter 322, loss: 5.126774, acc: 0.750000\n",
      "epoch 0, iter 323, loss: 4.464355, acc: 0.750000\n",
      "epoch 0, iter 324, loss: 3.967582, acc: 0.875000\n",
      "epoch 0, iter 325, loss: 6.565311, acc: 0.500000\n",
      "epoch 0, iter 326, loss: 6.419152, acc: 0.500000\n",
      "epoch 0, iter 327, loss: 6.283157, acc: 0.625000\n",
      "epoch 0, iter 328, loss: 6.591382, acc: 0.500000\n",
      "epoch 0, iter 329, loss: 6.171143, acc: 0.625000\n",
      "epoch 0, iter 330, loss: 5.598736, acc: 0.750000\n",
      "epoch 0, iter 331, loss: 6.620114, acc: 0.500000\n",
      "epoch 0, iter 332, loss: 6.187432, acc: 0.625000\n",
      "epoch 0, iter 333, loss: 5.621301, acc: 0.625000\n",
      "epoch 0, iter 334, loss: 5.185191, acc: 0.875000\n",
      "epoch 0, iter 335, loss: 7.030082, acc: 0.500000\n",
      "epoch 0, iter 336, loss: 6.629811, acc: 0.500000\n",
      "epoch 0, iter 337, loss: 6.342762, acc: 0.750000\n",
      "epoch 0, iter 338, loss: 7.297441, acc: 0.625000\n",
      "epoch 0, iter 339, loss: 8.118835, acc: 0.625000\n",
      "epoch 0, iter 340, loss: 6.989784, acc: 0.625000\n",
      "epoch 0, iter 341, loss: 6.176882, acc: 0.625000\n",
      "epoch 0, iter 342, loss: 6.554576, acc: 0.500000\n",
      "epoch 0, iter 343, loss: 6.282477, acc: 0.500000\n",
      "epoch 0, iter 344, loss: 6.055718, acc: 0.625000\n",
      "epoch 0, iter 345, loss: 5.909681, acc: 0.625000\n",
      "epoch 0, iter 346, loss: 6.283196, acc: 0.750000\n",
      "epoch 0, iter 347, loss: 6.703746, acc: 0.750000\n",
      "epoch 0, iter 348, loss: 6.825082, acc: 0.625000\n",
      "epoch 0, iter 349, loss: 6.453458, acc: 0.500000\n",
      "epoch 0, iter 350, loss: 6.171994, acc: 0.375000\n",
      "epoch 0, iter 351, loss: 5.989469, acc: 0.625000\n",
      "epoch 0, iter 352, loss: 5.481963, acc: 1.000000\n",
      "epoch 0, iter 353, loss: 6.881366, acc: 0.625000\n",
      "epoch 0, iter 354, loss: 6.098574, acc: 0.625000\n",
      "epoch 0, iter 355, loss: 6.675920, acc: 0.625000\n",
      "epoch 0, iter 356, loss: 7.028889, acc: 0.500000\n",
      "epoch 0, iter 357, loss: 6.731201, acc: 0.625000\n",
      "epoch 0, iter 358, loss: 6.883429, acc: 0.500000\n",
      "epoch 0, iter 359, loss: 6.404080, acc: 0.875000\n",
      "epoch 0, iter 360, loss: 8.768446, acc: 0.625000\n",
      "epoch 0, iter 361, loss: 8.352596, acc: 0.500000\n",
      "epoch 0, iter 362, loss: 7.555426, acc: 0.625000\n",
      "epoch 0, iter 363, loss: 7.427675, acc: 0.500000\n",
      "epoch 0, iter 364, loss: 6.872080, acc: 0.625000\n",
      "epoch 0, iter 365, loss: 6.931967, acc: 0.500000\n",
      "epoch 0, iter 366, loss: 6.429240, acc: 0.625000\n",
      "epoch 0, iter 367, loss: 6.590697, acc: 0.500000\n",
      "epoch 0, iter 368, loss: 6.235153, acc: 0.750000\n",
      "epoch 0, iter 369, loss: 7.095637, acc: 0.500000\n",
      "epoch 0, iter 370, loss: 6.643973, acc: 0.375000\n",
      "epoch 0, iter 371, loss: 6.320458, acc: 0.375000\n",
      "epoch 0, iter 372, loss: 6.091549, acc: 0.375000\n",
      "epoch 0, iter 373, loss: 5.927085, acc: 0.625000\n",
      "epoch 0, iter 374, loss: 5.424066, acc: 0.625000\n",
      "epoch 0, iter 375, loss: 4.965259, acc: 0.750000\n",
      "epoch 0, iter 376, loss: 5.156752, acc: 0.625000\n",
      "epoch 0, iter 377, loss: 4.841888, acc: 0.750000\n",
      "epoch 0, iter 378, loss: 6.494285, acc: 0.500000\n",
      "epoch 0, iter 379, loss: 5.899589, acc: 0.625000\n",
      "epoch 0, iter 380, loss: 6.209470, acc: 0.500000\n",
      "epoch 0, iter 381, loss: 5.950657, acc: 0.625000\n",
      "epoch 0, iter 382, loss: 6.290987, acc: 0.750000\n",
      "epoch 0, iter 383, loss: 7.116522, acc: 0.625000\n",
      "epoch 0, iter 384, loss: 6.294480, acc: 0.625000\n",
      "epoch 0, iter 385, loss: 6.579132, acc: 0.500000\n",
      "epoch 0, iter 386, loss: 6.143573, acc: 0.625000\n",
      "epoch 0, iter 387, loss: 6.362460, acc: 0.500000\n",
      "epoch 0, iter 388, loss: 6.048107, acc: 1.000000\n",
      "epoch 0, iter 389, loss: 7.220214, acc: 0.625000\n",
      "epoch 0, iter 390, loss: 7.237053, acc: 0.500000\n",
      "epoch 0, iter 391, loss: 6.753803, acc: 1.000000\n",
      "epoch 0, iter 392, loss: 5.993379, acc: 0.875000\n",
      "epoch 0, iter 393, loss: 7.584668, acc: 0.500000\n",
      "epoch 0, iter 394, loss: 7.034830, acc: 0.500000\n",
      "epoch 0, iter 395, loss: 6.599502, acc: 0.500000\n",
      "epoch 0, iter 396, loss: 6.292806, acc: 0.500000\n",
      "epoch 0, iter 397, loss: 6.010980, acc: 0.875000\n",
      "epoch 0, iter 398, loss: 6.033135, acc: 0.750000\n",
      "epoch 0, iter 399, loss: 7.355438, acc: 0.500000\n",
      "epoch 0, iter 400, loss: 7.132198, acc: 0.625000\n",
      "epoch 0, iter 401, loss: 8.486372, acc: 0.875000\n",
      "epoch 0, iter 402, loss: 6.474242, acc: 0.875000\n",
      "epoch 0, iter 403, loss: 7.800563, acc: 0.500000\n",
      "epoch 0, iter 404, loss: 7.177287, acc: 0.375000\n",
      "epoch 0, iter 405, loss: 6.692914, acc: 0.375000\n",
      "epoch 0, iter 406, loss: 6.304364, acc: 0.750000\n",
      "epoch 0, iter 407, loss: 6.164201, acc: 0.625000\n",
      "epoch 0, iter 408, loss: 6.174958, acc: 0.500000\n",
      "epoch 0, iter 409, loss: 6.579810, acc: 0.375000\n",
      "epoch 0, iter 410, loss: 6.082997, acc: 0.500000\n",
      "epoch 0, iter 411, loss: 6.295218, acc: 0.375000\n",
      "epoch 0, iter 412, loss: 6.075416, acc: 0.500000\n",
      "epoch 0, iter 413, loss: 5.916917, acc: 0.500000\n",
      "epoch 0, iter 414, loss: 5.795630, acc: 0.500000\n",
      "epoch 0, iter 415, loss: 5.730855, acc: 0.500000\n",
      "epoch 0, iter 416, loss: 5.708347, acc: 0.750000\n",
      "epoch 0, iter 417, loss: 6.889324, acc: 0.750000\n",
      "epoch 0, iter 418, loss: 7.258463, acc: 0.500000\n",
      "epoch 0, iter 419, loss: 6.750968, acc: 0.500000\n",
      "epoch 0, iter 420, loss: 6.447625, acc: 0.750000\n",
      "epoch 0, iter 421, loss: 6.268173, acc: 0.625000\n",
      "epoch 0, iter 422, loss: 6.590199, acc: 0.500000\n",
      "epoch 0, iter 423, loss: 6.306868, acc: 0.500000\n",
      "epoch 0, iter 424, loss: 6.132980, acc: 0.625000\n",
      "epoch 0, iter 425, loss: 6.430592, acc: 0.875000\n",
      "epoch 0, iter 426, loss: 7.796612, acc: 0.500000\n",
      "epoch 0, iter 427, loss: 6.912791, acc: 1.000000\n",
      "epoch 0, iter 428, loss: 7.581267, acc: 0.625000\n",
      "epoch 0, iter 429, loss: 7.408814, acc: 0.625000\n",
      "epoch 0, iter 430, loss: 7.380616, acc: 0.625000\n",
      "epoch 0, iter 431, loss: 6.331232, acc: 0.875000\n",
      "epoch 0, iter 432, loss: 7.726636, acc: 0.625000\n",
      "epoch 0, iter 433, loss: 6.726137, acc: 0.625000\n",
      "epoch 0, iter 434, loss: 6.147725, acc: 1.000000\n",
      "epoch 0, iter 435, loss: 5.363717, acc: 0.875000\n",
      "epoch 0, iter 436, loss: 7.315531, acc: 0.500000\n",
      "epoch 0, iter 437, loss: 6.401471, acc: 1.000000\n",
      "epoch 0, iter 438, loss: 7.086483, acc: 0.625000\n",
      "epoch 0, iter 439, loss: 7.125458, acc: 0.625000\n",
      "epoch 0, iter 440, loss: 6.472539, acc: 0.750000\n",
      "epoch 0, iter 441, loss: 6.544582, acc: 0.625000\n",
      "epoch 0, iter 442, loss: 6.708421, acc: 0.625000\n",
      "epoch 0, iter 443, loss: 6.337135, acc: 0.875000\n",
      "epoch 0, iter 444, loss: 7.241060, acc: 0.750000\n",
      "epoch 0, iter 445, loss: 5.993936, acc: 0.750000\n",
      "epoch 0, iter 446, loss: 6.003157, acc: 0.625000\n",
      "epoch 0, iter 447, loss: 5.503376, acc: 0.625000\n",
      "epoch 0, iter 448, loss: 5.119488, acc: 0.625000\n",
      "epoch 0, iter 449, loss: 4.838537, acc: 0.750000\n",
      "epoch 0, iter 450, loss: 4.646677, acc: 0.750000\n",
      "epoch 0, iter 451, loss: 4.925043, acc: 0.625000\n",
      "epoch 0, iter 452, loss: 4.699912, acc: 0.625000\n",
      "epoch 0, iter 453, loss: 4.590037, acc: 0.750000\n",
      "epoch 0, iter 454, loss: 4.993322, acc: 0.750000\n",
      "epoch 0, iter 455, loss: 6.626414, acc: 0.500000\n",
      "epoch 0, iter 456, loss: 5.903581, acc: 1.000000\n",
      "epoch 0, iter 457, loss: 6.885390, acc: 0.625000\n",
      "epoch 0, iter 458, loss: 6.093881, acc: 0.625000\n",
      "epoch 0, iter 459, loss: 5.514191, acc: 0.750000\n",
      "epoch 0, iter 460, loss: 5.101942, acc: 0.750000\n",
      "epoch 0, iter 461, loss: 4.812466, acc: 0.625000\n",
      "epoch 0, iter 462, loss: 4.664605, acc: 0.750000\n",
      "epoch 0, iter 463, loss: 6.273211, acc: 0.500000\n",
      "epoch 0, iter 464, loss: 5.747041, acc: 0.625000\n",
      "epoch 0, iter 465, loss: 6.035112, acc: 0.500000\n",
      "epoch 0, iter 466, loss: 5.886934, acc: 0.500000\n",
      "epoch 0, iter 467, loss: 5.817489, acc: 0.625000\n",
      "epoch 0, iter 468, loss: 5.370657, acc: 0.625000\n",
      "epoch 0, iter 469, loss: 5.036747, acc: 0.750000\n",
      "epoch 0, iter 470, loss: 4.758006, acc: 0.625000\n",
      "epoch 0, iter 471, loss: 5.510381, acc: 0.750000\n",
      "epoch 0, iter 472, loss: 5.711656, acc: 0.875000\n",
      "epoch 0, iter 473, loss: 7.069490, acc: 0.500000\n",
      "epoch 0, iter 474, loss: 6.555651, acc: 0.625000\n",
      "epoch 0, iter 475, loss: 5.900795, acc: 0.750000\n",
      "epoch 0, iter 476, loss: 6.692850, acc: 0.500000\n",
      "epoch 0, iter 477, loss: 6.381659, acc: 0.500000\n",
      "epoch 0, iter 478, loss: 6.135087, acc: 0.625000\n",
      "epoch 0, iter 479, loss: 5.985335, acc: 0.625000\n",
      "epoch 0, iter 480, loss: 5.477596, acc: 0.625000\n",
      "epoch 0, iter 481, loss: 5.110959, acc: 0.750000\n",
      "epoch 0, iter 482, loss: 4.387217, acc: 1.000000\n",
      "epoch 0, iter 483, loss: 4.131498, acc: 0.875000\n",
      "epoch 0, iter 484, loss: 6.412238, acc: 0.500000\n",
      "epoch 0, iter 485, loss: 6.330893, acc: 0.500000\n",
      "epoch 0, iter 486, loss: 6.140160, acc: 0.625000\n",
      "epoch 0, iter 487, loss: 5.576785, acc: 0.750000\n",
      "epoch 0, iter 488, loss: 6.451529, acc: 0.750000\n",
      "epoch 0, iter 489, loss: 7.094525, acc: 0.625000\n",
      "epoch 0, iter 490, loss: 6.989046, acc: 0.500000\n",
      "epoch 0, iter 491, loss: 6.479171, acc: 0.625000\n",
      "epoch 0, iter 492, loss: 6.564127, acc: 0.500000\n",
      "epoch 0, iter 493, loss: 6.268465, acc: 0.625000\n",
      "epoch 0, iter 494, loss: 6.454177, acc: 0.625000\n",
      "epoch 0, iter 495, loss: 6.180141, acc: 0.625000\n",
      "epoch 0, iter 496, loss: 6.448634, acc: 0.500000\n",
      "epoch 0, iter 497, loss: 6.193192, acc: 0.500000\n",
      "epoch 0, iter 498, loss: 6.021619, acc: 0.500000\n",
      "epoch 0, iter 499, loss: 5.510918, acc: 0.625000\n",
      "epoch 0, iter 500, loss: 5.977354, acc: 0.750000\n",
      "epoch 0, iter 501, loss: 6.745481, acc: 0.625000\n",
      "epoch 0, iter 502, loss: 6.744963, acc: 0.500000\n",
      "epoch 0, iter 503, loss: 6.347435, acc: 0.625000\n",
      "epoch 0, iter 504, loss: 6.625836, acc: 0.500000\n",
      "epoch 0, iter 505, loss: 6.293113, acc: 0.625000\n",
      "epoch 0, iter 506, loss: 5.694063, acc: 0.625000\n",
      "epoch 0, iter 507, loss: 6.210883, acc: 0.500000\n",
      "epoch 0, iter 508, loss: 6.057000, acc: 0.625000\n",
      "epoch 0, iter 509, loss: 6.344617, acc: 0.625000\n",
      "epoch 0, iter 510, loss: 6.494164, acc: 0.500000\n",
      "epoch 0, iter 511, loss: 6.224296, acc: 0.500000\n",
      "epoch 0, iter 512, loss: 6.045853, acc: 0.750000\n",
      "epoch 0, iter 513, loss: 5.525190, acc: 0.500000\n",
      "epoch 0, iter 514, loss: 5.136393, acc: 0.500000\n",
      "epoch 0, iter 515, loss: 4.856476, acc: 0.625000\n",
      "epoch 0, iter 516, loss: 4.655591, acc: 0.500000\n",
      "epoch 0, iter 517, loss: 4.521744, acc: 0.875000\n",
      "epoch 0, iter 518, loss: 6.461209, acc: 0.500000\n",
      "epoch 0, iter 519, loss: 6.335164, acc: 0.875000\n",
      "epoch 0, iter 520, loss: 6.867878, acc: 0.750000\n",
      "epoch 0, iter 521, loss: 5.743233, acc: 0.750000\n",
      "epoch 0, iter 522, loss: 6.809995, acc: 0.750000\n",
      "epoch 0, iter 523, loss: 6.238983, acc: 0.875000\n",
      "epoch 0, iter 524, loss: 7.323151, acc: 0.500000\n",
      "epoch 0, iter 525, loss: 6.829523, acc: 0.500000\n",
      "epoch 0, iter 526, loss: 6.478874, acc: 0.625000\n",
      "epoch 0, iter 527, loss: 5.827732, acc: 0.750000\n",
      "epoch 0, iter 528, loss: 6.608937, acc: 0.500000\n",
      "epoch 0, iter 529, loss: 6.207882, acc: 0.875000\n",
      "epoch 0, iter 530, loss: 7.397004, acc: 0.500000\n",
      "epoch 0, iter 531, loss: 6.861790, acc: 0.375000\n",
      "epoch 0, iter 532, loss: 6.470308, acc: 0.625000\n",
      "epoch 0, iter 533, loss: 6.554753, acc: 0.625000\n",
      "epoch 0, iter 534, loss: 6.260363, acc: 0.500000\n",
      "epoch 0, iter 535, loss: 6.005527, acc: 0.500000\n",
      "epoch 0, iter 536, loss: 5.773347, acc: 0.625000\n",
      "epoch 0, iter 537, loss: 5.293788, acc: 1.000000\n",
      "epoch 0, iter 538, loss: 6.390091, acc: 0.625000\n",
      "epoch 0, iter 539, loss: 5.770381, acc: 0.625000\n",
      "epoch 0, iter 540, loss: 6.296780, acc: 0.500000\n",
      "epoch 0, iter 541, loss: 6.148781, acc: 0.500000\n",
      "epoch 0, iter 542, loss: 5.969687, acc: 0.500000\n",
      "epoch 0, iter 543, loss: 5.842376, acc: 0.625000\n",
      "epoch 0, iter 544, loss: 5.752736, acc: 0.500000\n",
      "epoch 0, iter 545, loss: 5.701797, acc: 0.375000\n",
      "epoch 0, iter 546, loss: 5.688516, acc: 0.625000\n",
      "epoch 0, iter 547, loss: 5.651321, acc: 0.625000\n",
      "epoch 0, iter 548, loss: 5.618112, acc: 0.625000\n",
      "epoch 0, iter 549, loss: 5.618945, acc: 0.875000\n",
      "epoch 0, iter 550, loss: 5.231953, acc: 0.875000\n",
      "epoch 0, iter 551, loss: 5.787890, acc: 0.750000\n",
      "epoch 0, iter 552, loss: 6.129797, acc: 0.500000\n",
      "epoch 0, iter 553, loss: 5.876084, acc: 0.875000\n",
      "epoch 0, iter 554, loss: 5.051412, acc: 0.875000\n",
      "epoch 0, iter 555, loss: 6.120141, acc: 0.500000\n",
      "epoch 0, iter 556, loss: 5.628289, acc: 0.750000\n",
      "epoch 0, iter 557, loss: 4.770500, acc: 0.875000\n",
      "epoch 0, iter 558, loss: 5.580993, acc: 0.625000\n",
      "epoch 0, iter 559, loss: 6.120218, acc: 0.500000\n",
      "epoch 0, iter 560, loss: 5.988024, acc: 0.500000\n",
      "epoch 0, iter 561, loss: 5.867893, acc: 0.625000\n",
      "epoch 0, iter 562, loss: 6.133084, acc: 0.500000\n",
      "epoch 0, iter 563, loss: 5.981901, acc: 0.625000\n",
      "epoch 0, iter 564, loss: 5.937471, acc: 0.500000\n",
      "epoch 0, iter 565, loss: 6.301774, acc: 0.750000\n",
      "epoch 0, iter 566, loss: 6.881480, acc: 0.500000\n",
      "epoch 0, iter 567, loss: 6.325096, acc: 0.625000\n",
      "epoch 0, iter 568, loss: 6.464168, acc: 0.750000\n",
      "epoch 0, iter 569, loss: 6.206349, acc: 0.500000\n",
      "epoch 0, iter 570, loss: 6.113809, acc: 1.000000\n",
      "epoch 0, iter 571, loss: 6.965015, acc: 0.625000\n",
      "epoch 0, iter 572, loss: 7.022083, acc: 0.500000\n",
      "epoch 0, iter 573, loss: 6.610716, acc: 0.500000\n",
      "epoch 0, iter 574, loss: 6.264929, acc: 0.625000\n",
      "epoch 0, iter 575, loss: 6.015180, acc: 0.625000\n",
      "epoch 0, iter 576, loss: 5.535156, acc: 0.875000\n",
      "epoch 0, iter 577, loss: 6.036340, acc: 0.625000\n",
      "epoch 0, iter 578, loss: 6.435504, acc: 0.500000\n",
      "epoch 0, iter 579, loss: 5.946399, acc: 0.625000\n",
      "epoch 0, iter 580, loss: 5.421632, acc: 0.625000\n",
      "epoch 0, iter 581, loss: 5.886312, acc: 0.500000\n",
      "epoch 0, iter 582, loss: 5.824178, acc: 0.625000\n",
      "epoch 0, iter 583, loss: 5.664075, acc: 0.750000\n",
      "epoch 0, iter 584, loss: 6.101588, acc: 0.625000\n",
      "epoch 0, iter 585, loss: 5.501721, acc: 0.625000\n",
      "epoch 0, iter 586, loss: 5.786887, acc: 0.625000\n",
      "epoch 0, iter 587, loss: 6.130367, acc: 0.500000\n",
      "epoch 0, iter 588, loss: 5.974212, acc: 0.875000\n",
      "epoch 0, iter 589, loss: 5.588287, acc: 0.875000\n",
      "epoch 0, iter 590, loss: 6.661674, acc: 0.625000\n",
      "epoch 0, iter 591, loss: 5.861546, acc: 0.875000\n",
      "epoch 0, iter 592, loss: 6.256027, acc: 0.625000\n",
      "epoch 0, iter 593, loss: 6.406999, acc: 0.625000\n",
      "epoch 0, iter 594, loss: 6.464457, acc: 0.625000\n",
      "epoch 0, iter 595, loss: 5.828990, acc: 0.625000\n",
      "epoch 0, iter 596, loss: 5.365311, acc: 0.625000\n",
      "epoch 0, iter 597, loss: 5.920341, acc: 0.500000\n",
      "epoch 0, iter 598, loss: 5.600784, acc: 0.875000\n",
      "epoch 0, iter 599, loss: 6.199024, acc: 0.625000\n",
      "epoch 0, iter 600, loss: 6.432926, acc: 0.500000\n",
      "epoch 0, iter 601, loss: 6.034757, acc: 0.750000\n",
      "epoch 0, iter 602, loss: 5.936098, acc: 0.625000\n",
      "epoch 0, iter 603, loss: 6.259148, acc: 0.625000\n",
      "epoch 0, iter 604, loss: 5.930905, acc: 1.000000\n",
      "epoch 0, iter 605, loss: 6.964794, acc: 0.500000\n",
      "epoch 0, iter 606, loss: 6.529684, acc: 0.500000\n",
      "epoch 0, iter 607, loss: 6.230695, acc: 0.625000\n",
      "epoch 0, iter 608, loss: 5.627021, acc: 0.625000\n",
      "epoch 0, iter 609, loss: 6.054820, acc: 0.500000\n",
      "epoch 0, iter 610, loss: 5.715897, acc: 0.625000\n",
      "epoch 0, iter 611, loss: 5.972734, acc: 0.625000\n",
      "epoch 0, iter 612, loss: 5.758950, acc: 0.750000\n",
      "epoch 0, iter 613, loss: 5.733366, acc: 0.625000\n",
      "epoch 0, iter 614, loss: 5.166248, acc: 0.750000\n",
      "epoch 0, iter 615, loss: 4.529110, acc: 0.875000\n",
      "epoch 0, iter 616, loss: 5.846220, acc: 0.625000\n",
      "epoch 0, iter 617, loss: 5.851206, acc: 0.750000\n",
      "epoch 0, iter 618, loss: 5.688983, acc: 0.625000\n",
      "epoch 0, iter 619, loss: 5.990366, acc: 0.500000\n",
      "epoch 0, iter 620, loss: 5.781737, acc: 0.500000\n",
      "epoch 0, iter 621, loss: 5.754081, acc: 0.625000\n",
      "epoch 0, iter 622, loss: 5.664757, acc: 0.625000\n",
      "epoch 0, iter 623, loss: 5.633153, acc: 0.500000\n",
      "epoch 0, iter 624, loss: 5.574295, acc: 0.500000\n",
      "epoch 0, iter 625, loss: 5.544969, acc: 0.625000\n",
      "epoch 0, iter 626, loss: 5.949985, acc: 0.500000\n",
      "epoch 0, iter 627, loss: 5.905447, acc: 0.875000\n",
      "epoch 0, iter 628, loss: 7.160366, acc: 0.625000\n",
      "epoch 0, iter 629, loss: 6.932434, acc: 0.625000\n",
      "epoch 0, iter 630, loss: 6.965043, acc: 0.500000\n",
      "epoch 0, iter 631, loss: 6.554190, acc: 0.750000\n",
      "epoch 0, iter 632, loss: 6.934114, acc: 0.500000\n",
      "epoch 0, iter 633, loss: 6.536363, acc: 0.625000\n",
      "epoch 0, iter 634, loss: 6.258809, acc: 0.750000\n",
      "epoch 0, iter 635, loss: 6.696146, acc: 0.625000\n",
      "epoch 0, iter 636, loss: 6.381187, acc: 0.625000\n",
      "epoch 0, iter 637, loss: 6.162360, acc: 0.875000\n",
      "epoch 0, iter 638, loss: 5.977072, acc: 0.750000\n",
      "epoch 0, iter 639, loss: 5.481829, acc: 0.750000\n",
      "epoch 0, iter 640, loss: 6.002919, acc: 0.500000\n",
      "epoch 0, iter 641, loss: 5.629370, acc: 0.500000\n",
      "epoch 0, iter 642, loss: 5.113458, acc: 0.750000\n",
      "epoch 0, iter 643, loss: 7.325106, acc: 0.625000\n",
      "epoch 0, iter 644, loss: 7.154635, acc: 0.500000\n",
      "epoch 0, iter 645, loss: 6.670646, acc: 0.500000\n",
      "epoch 0, iter 646, loss: 6.318711, acc: 0.750000\n",
      "epoch 0, iter 647, loss: 6.405748, acc: 0.500000\n",
      "epoch 0, iter 648, loss: 6.177065, acc: 0.500000\n",
      "epoch 0, iter 649, loss: 5.986242, acc: 0.500000\n",
      "epoch 0, iter 650, loss: 5.866253, acc: 0.875000\n",
      "epoch 0, iter 651, loss: 6.098475, acc: 0.625000\n",
      "epoch 0, iter 652, loss: 5.929666, acc: 0.500000\n",
      "epoch 0, iter 653, loss: 5.829554, acc: 0.625000\n",
      "epoch 0, iter 654, loss: 5.533656, acc: 0.875000\n",
      "epoch 0, iter 655, loss: 6.332715, acc: 1.000000\n",
      "epoch 0, iter 656, loss: 6.959263, acc: 0.625000\n",
      "epoch 0, iter 657, loss: 7.146518, acc: 0.500000\n",
      "epoch 0, iter 658, loss: 6.421433, acc: 0.625000\n",
      "epoch 0, iter 659, loss: 6.471267, acc: 0.500000\n",
      "epoch 0, iter 660, loss: 6.080333, acc: 0.625000\n",
      "epoch 0, iter 661, loss: 5.911063, acc: 0.500000\n",
      "epoch 0, iter 662, loss: 5.309487, acc: 0.625000\n",
      "epoch 0, iter 663, loss: 6.239883, acc: 0.500000\n",
      "epoch 0, iter 664, loss: 5.812655, acc: 0.625000\n",
      "epoch 0, iter 665, loss: 6.035526, acc: 0.500000\n",
      "epoch 0, iter 666, loss: 5.886076, acc: 0.500000\n",
      "epoch 0, iter 667, loss: 5.795740, acc: 0.750000\n",
      "epoch 0, iter 668, loss: 6.059678, acc: 0.500000\n",
      "epoch 0, iter 669, loss: 5.892088, acc: 0.500000\n",
      "epoch 0, iter 670, loss: 5.827011, acc: 0.625000\n",
      "epoch 0, iter 671, loss: 5.712343, acc: 0.625000\n",
      "epoch 0, iter 672, loss: 5.572980, acc: 1.000000\n",
      "epoch 0, iter 673, loss: 6.506665, acc: 0.625000\n",
      "epoch 0, iter 674, loss: 6.667353, acc: 0.500000\n",
      "epoch 0, iter 675, loss: 6.366840, acc: 0.500000\n",
      "epoch 0, iter 676, loss: 6.118409, acc: 0.625000\n",
      "epoch 0, iter 677, loss: 6.291225, acc: 0.500000\n",
      "epoch 0, iter 678, loss: 6.056080, acc: 0.500000\n",
      "epoch 0, iter 679, loss: 5.950588, acc: 0.625000\n",
      "epoch 0, iter 680, loss: 6.154225, acc: 0.500000\n",
      "epoch 0, iter 681, loss: 5.988769, acc: 0.500000\n",
      "epoch 0, iter 682, loss: 5.854882, acc: 0.500000\n",
      "epoch 0, iter 683, loss: 5.763208, acc: 0.875000\n",
      "epoch 0, iter 684, loss: 7.822653, acc: 0.625000\n",
      "epoch 0, iter 685, loss: 7.540062, acc: 0.500000\n",
      "epoch 0, iter 686, loss: 6.941446, acc: 0.500000\n",
      "epoch 0, iter 687, loss: 6.515899, acc: 0.500000\n",
      "epoch 0, iter 688, loss: 6.260266, acc: 0.875000\n",
      "epoch 0, iter 689, loss: 6.856942, acc: 0.750000\n",
      "epoch 0, iter 690, loss: 6.325469, acc: 0.750000\n",
      "epoch 0, iter 691, loss: 5.733785, acc: 0.750000\n",
      "epoch 0, iter 692, loss: 5.303165, acc: 0.750000\n",
      "epoch 0, iter 693, loss: 6.215244, acc: 0.500000\n",
      "epoch 0, iter 694, loss: 5.800712, acc: 0.750000\n",
      "epoch 0, iter 695, loss: 5.997627, acc: 0.500000\n",
      "epoch 0, iter 696, loss: 5.849509, acc: 0.750000\n",
      "epoch 0, iter 697, loss: 5.748661, acc: 0.625000\n",
      "epoch 0, iter 698, loss: 5.982644, acc: 0.750000\n",
      "epoch 0, iter 699, loss: 5.840906, acc: 0.875000\n",
      "epoch 0, iter 700, loss: 5.718692, acc: 1.000000\n",
      "epoch 0, iter 701, loss: 6.922620, acc: 0.625000\n",
      "epoch 0, iter 702, loss: 5.957018, acc: 0.875000\n",
      "epoch 0, iter 703, loss: 6.237608, acc: 0.625000\n",
      "epoch 0, iter 704, loss: 6.271602, acc: 0.875000\n",
      "epoch 0, iter 705, loss: 5.553462, acc: 0.875000\n",
      "epoch 0, iter 706, loss: 6.063787, acc: 0.750000\n",
      "epoch 0, iter 707, loss: 6.014004, acc: 0.625000\n",
      "epoch 0, iter 708, loss: 6.369594, acc: 0.500000\n",
      "epoch 0, iter 709, loss: 5.898054, acc: 0.750000\n",
      "epoch 0, iter 710, loss: 5.771212, acc: 0.750000\n",
      "epoch 0, iter 711, loss: 5.341088, acc: 0.750000\n",
      "epoch 0, iter 712, loss: 5.010461, acc: 0.500000\n",
      "epoch 0, iter 713, loss: 5.665526, acc: 0.500000\n",
      "epoch 0, iter 714, loss: 5.694766, acc: 0.500000\n",
      "epoch 0, iter 715, loss: 5.671285, acc: 0.750000\n",
      "epoch 0, iter 716, loss: 6.100559, acc: 0.625000\n",
      "epoch 0, iter 717, loss: 5.925484, acc: 0.750000\n",
      "epoch 0, iter 718, loss: 5.696679, acc: 0.625000\n",
      "epoch 0, iter 719, loss: 5.973764, acc: 0.750000\n",
      "epoch 0, iter 720, loss: 6.052307, acc: 0.625000\n",
      "epoch 0, iter 721, loss: 6.180695, acc: 0.500000\n",
      "epoch 0, iter 722, loss: 5.788497, acc: 1.000000\n",
      "epoch 0, iter 723, loss: 7.279017, acc: 0.500000\n",
      "epoch 0, iter 724, loss: 6.774237, acc: 0.625000\n",
      "epoch 0, iter 725, loss: 6.376564, acc: 0.625000\n",
      "epoch 0, iter 726, loss: 5.724569, acc: 0.750000\n",
      "epoch 0, iter 727, loss: 5.616132, acc: 0.625000\n",
      "epoch 0, iter 728, loss: 5.093122, acc: 0.625000\n",
      "epoch 0, iter 729, loss: 6.071817, acc: 0.375000\n",
      "epoch 0, iter 730, loss: 5.989129, acc: 0.625000\n",
      "epoch 0, iter 731, loss: 6.287490, acc: 0.500000\n",
      "epoch 0, iter 732, loss: 6.091376, acc: 0.750000\n",
      "epoch 0, iter 733, loss: 5.890020, acc: 0.625000\n",
      "epoch 0, iter 734, loss: 5.279035, acc: 0.875000\n",
      "epoch 0, iter 735, loss: 5.261840, acc: 0.625000\n",
      "epoch 0, iter 736, loss: 4.834394, acc: 0.625000\n",
      "epoch 0, iter 737, loss: 4.271500, acc: 0.625000\n",
      "epoch 0, iter 738, loss: 3.911894, acc: 0.875000\n",
      "epoch 0, iter 739, loss: 4.117930, acc: 0.750000\n",
      "epoch 0, iter 740, loss: 4.839412, acc: 0.625000\n",
      "epoch 0, iter 741, loss: 5.335049, acc: 0.625000\n",
      "epoch 0, iter 742, loss: 5.126215, acc: 0.750000\n",
      "epoch 0, iter 743, loss: 4.852900, acc: 0.750000\n",
      "epoch 0, iter 744, loss: 4.624784, acc: 0.750000\n",
      "epoch 0, iter 745, loss: 5.432957, acc: 0.500000\n",
      "epoch 0, iter 746, loss: 5.527655, acc: 0.625000\n",
      "epoch 0, iter 747, loss: 5.519242, acc: 0.625000\n",
      "epoch 0, iter 748, loss: 5.177513, acc: 0.625000\n",
      "epoch 0, iter 749, loss: 5.703448, acc: 0.500000\n",
      "epoch 0, iter 750, loss: 5.700375, acc: 0.750000\n",
      "epoch 0, iter 751, loss: 5.649774, acc: 0.750000\n",
      "epoch 0, iter 752, loss: 5.598151, acc: 0.625000\n",
      "epoch 0, iter 753, loss: 5.539520, acc: 0.500000\n",
      "epoch 0, iter 754, loss: 5.531430, acc: 0.750000\n",
      "epoch 0, iter 755, loss: 6.145200, acc: 0.500000\n",
      "epoch 0, iter 756, loss: 5.832197, acc: 0.875000\n",
      "epoch 0, iter 757, loss: 6.352078, acc: 1.000000\n",
      "epoch 0, iter 758, loss: 6.920823, acc: 0.625000\n",
      "epoch 0, iter 759, loss: 7.029712, acc: 0.500000\n",
      "epoch 0, iter 760, loss: 6.358375, acc: 0.750000\n",
      "epoch 0, iter 761, loss: 6.398586, acc: 0.750000\n",
      "epoch 0, iter 762, loss: 5.985589, acc: 0.750000\n",
      "epoch 0, iter 763, loss: 5.566120, acc: 0.875000\n",
      "epoch 0, iter 764, loss: 5.944185, acc: 0.625000\n",
      "epoch 0, iter 765, loss: 5.345166, acc: 0.750000\n",
      "epoch 0, iter 766, loss: 5.326635, acc: 0.500000\n",
      "epoch 0, iter 767, loss: 5.970630, acc: 0.375000\n",
      "epoch 0, iter 768, loss: 5.943198, acc: 0.375000\n",
      "epoch 0, iter 769, loss: 5.812611, acc: 0.500000\n",
      "epoch 0, iter 770, loss: 5.703579, acc: 0.500000\n",
      "epoch 0, iter 771, loss: 6.001308, acc: 0.625000\n",
      "epoch 0, iter 772, loss: 6.372364, acc: 0.625000\n",
      "epoch 0, iter 773, loss: 6.454691, acc: 0.750000\n",
      "epoch 0, iter 774, loss: 6.789502, acc: 0.500000\n",
      "epoch 0, iter 775, loss: 6.437727, acc: 0.500000\n",
      "epoch 0, iter 776, loss: 6.151818, acc: 0.625000\n",
      "epoch 0, iter 777, loss: 5.623147, acc: 0.875000\n",
      "epoch 0, iter 778, loss: 4.826065, acc: 0.875000\n",
      "epoch 0, iter 779, loss: 5.347296, acc: 0.750000\n",
      "epoch 0, iter 780, loss: 6.522780, acc: 0.500000\n",
      "epoch 0, iter 781, loss: 6.133544, acc: 0.750000\n",
      "epoch 0, iter 782, loss: 6.243193, acc: 0.750000\n",
      "epoch 0, iter 783, loss: 5.696577, acc: 0.750000\n",
      "epoch 0, iter 784, loss: 6.036822, acc: 0.875000\n",
      "epoch 0, iter 785, loss: 5.879694, acc: 0.500000\n",
      "epoch 0, iter 786, loss: 5.774496, acc: 0.625000\n",
      "epoch 0, iter 787, loss: 5.639395, acc: 0.625000\n",
      "epoch 0, iter 788, loss: 5.945994, acc: 0.500000\n",
      "epoch 0, iter 789, loss: 5.644522, acc: 0.625000\n",
      "epoch 0, iter 790, loss: 5.887189, acc: 0.500000\n",
      "epoch 0, iter 791, loss: 5.565471, acc: 0.875000\n",
      "epoch 0, iter 792, loss: 6.044979, acc: 0.500000\n",
      "epoch 0, iter 793, loss: 5.694404, acc: 0.750000\n",
      "epoch 0, iter 794, loss: 6.381580, acc: 0.625000\n",
      "epoch 0, iter 795, loss: 6.695356, acc: 0.750000\n",
      "epoch 0, iter 796, loss: 6.255814, acc: 1.000000\n",
      "epoch 0, iter 797, loss: 5.637758, acc: 1.000000\n",
      "epoch 0, iter 798, loss: 5.967561, acc: 0.625000\n",
      "epoch 0, iter 799, loss: 5.458667, acc: 0.625000\n",
      "epoch 0, iter 800, loss: 5.109903, acc: 0.750000\n",
      "epoch 0, iter 801, loss: 6.128872, acc: 0.625000\n",
      "epoch 0, iter 802, loss: 5.851368, acc: 0.875000\n",
      "epoch 0, iter 803, loss: 5.958934, acc: 0.625000\n",
      "epoch 0, iter 804, loss: 5.855607, acc: 0.625000\n",
      "epoch 0, iter 805, loss: 5.739336, acc: 0.625000\n",
      "epoch 0, iter 806, loss: 5.686077, acc: 0.875000\n",
      "epoch 0, iter 807, loss: 5.216012, acc: 0.750000\n",
      "epoch 0, iter 808, loss: 4.918676, acc: 0.625000\n",
      "epoch 0, iter 809, loss: 4.715157, acc: 0.875000\n",
      "epoch 0, iter 810, loss: 5.875324, acc: 0.750000\n",
      "epoch 0, iter 811, loss: 6.821667, acc: 0.500000\n",
      "epoch 0, iter 812, loss: 6.455292, acc: 0.500000\n",
      "epoch 0, iter 813, loss: 6.163322, acc: 0.625000\n",
      "epoch 0, iter 814, loss: 6.282412, acc: 0.750000\n",
      "epoch 0, iter 815, loss: 6.323007, acc: 0.500000\n",
      "epoch 0, iter 816, loss: 6.103188, acc: 0.875000\n",
      "epoch 0, iter 817, loss: 5.918905, acc: 0.500000\n",
      "epoch 0, iter 818, loss: 5.789978, acc: 0.750000\n",
      "epoch 0, iter 819, loss: 6.437102, acc: 0.375000\n",
      "epoch 0, iter 820, loss: 6.192263, acc: 0.500000\n",
      "epoch 0, iter 821, loss: 5.991714, acc: 0.750000\n",
      "epoch 0, iter 822, loss: 6.101953, acc: 0.500000\n",
      "epoch 0, iter 823, loss: 5.900035, acc: 0.500000\n",
      "epoch 0, iter 824, loss: 5.785127, acc: 0.500000\n",
      "epoch 0, iter 825, loss: 5.664891, acc: 0.500000\n",
      "epoch 0, iter 826, loss: 5.668900, acc: 0.875000\n",
      "epoch 0, iter 827, loss: 6.604221, acc: 0.500000\n",
      "epoch 0, iter 828, loss: 6.301369, acc: 0.625000\n",
      "epoch 0, iter 829, loss: 6.013991, acc: 0.500000\n",
      "epoch 0, iter 830, loss: 5.860789, acc: 0.500000\n",
      "epoch 0, iter 831, loss: 5.759852, acc: 0.750000\n",
      "epoch 0, iter 832, loss: 6.553807, acc: 0.625000\n",
      "epoch 0, iter 833, loss: 6.058201, acc: 0.875000\n",
      "epoch 0, iter 834, loss: 7.213865, acc: 0.625000\n",
      "epoch 0, iter 835, loss: 6.750283, acc: 0.625000\n",
      "epoch 0, iter 836, loss: 6.355335, acc: 0.500000\n",
      "epoch 0, iter 837, loss: 6.127138, acc: 0.750000\n",
      "epoch 0, iter 838, loss: 6.487913, acc: 0.625000\n",
      "epoch 0, iter 839, loss: 6.188750, acc: 0.500000\n",
      "epoch 0, iter 840, loss: 5.984772, acc: 0.375000\n",
      "epoch 0, iter 841, loss: 5.901562, acc: 1.000000\n",
      "epoch 0, iter 842, loss: 6.920966, acc: 0.500000\n",
      "epoch 0, iter 843, loss: 6.368269, acc: 0.750000\n",
      "epoch 0, iter 844, loss: 6.067250, acc: 0.750000\n",
      "epoch 0, iter 845, loss: 5.338058, acc: 0.875000\n",
      "epoch 0, iter 846, loss: 6.500002, acc: 0.500000\n",
      "epoch 0, iter 847, loss: 6.250324, acc: 0.625000\n",
      "epoch 0, iter 848, loss: 6.007303, acc: 0.750000\n",
      "epoch 0, iter 849, loss: 5.775727, acc: 1.000000\n",
      "epoch 0, iter 850, loss: 7.033771, acc: 0.500000\n",
      "epoch 0, iter 851, loss: 6.406199, acc: 0.750000\n",
      "epoch 0, iter 852, loss: 6.374962, acc: 0.500000\n",
      "epoch 0, iter 853, loss: 6.129872, acc: 0.625000\n",
      "epoch 0, iter 854, loss: 5.963552, acc: 0.875000\n",
      "epoch 0, iter 855, loss: 5.465655, acc: 0.875000\n",
      "epoch 0, iter 856, loss: 4.741889, acc: 1.000000\n",
      "epoch 0, iter 857, loss: 4.112173, acc: 0.875000\n",
      "epoch 0, iter 858, loss: 6.116951, acc: 0.375000\n",
      "epoch 0, iter 859, loss: 6.055216, acc: 0.750000\n",
      "epoch 0, iter 860, loss: 5.803943, acc: 0.500000\n",
      "epoch 0, iter 861, loss: 5.587349, acc: 0.625000\n",
      "epoch 0, iter 862, loss: 5.795832, acc: 0.500000\n",
      "epoch 0, iter 863, loss: 5.630069, acc: 0.625000\n",
      "epoch 0, iter 864, loss: 5.288187, acc: 0.750000\n",
      "epoch 0, iter 865, loss: 5.317958, acc: 0.750000\n",
      "epoch 0, iter 866, loss: 5.829844, acc: 0.500000\n",
      "epoch 0, iter 867, loss: 5.651896, acc: 0.500000\n",
      "epoch 0, iter 868, loss: 5.744205, acc: 0.750000\n",
      "epoch 0, iter 869, loss: 5.287392, acc: 0.875000\n",
      "epoch 0, iter 870, loss: 5.674854, acc: 0.750000\n",
      "epoch 0, iter 871, loss: 5.729277, acc: 0.625000\n",
      "epoch 0, iter 872, loss: 5.882862, acc: 0.500000\n",
      "epoch 0, iter 873, loss: 5.743509, acc: 0.750000\n",
      "epoch 0, iter 874, loss: 5.441541, acc: 1.000000\n",
      "epoch 0, iter 875, loss: 4.899583, acc: 0.625000\n",
      "epoch 0, iter 876, loss: 5.480624, acc: 0.625000\n",
      "epoch 0, iter 877, loss: 5.594334, acc: 0.875000\n",
      "epoch 0, iter 878, loss: 4.454162, acc: 1.000000\n",
      "epoch 0, iter 879, loss: 6.238989, acc: 0.500000\n",
      "epoch 0, iter 880, loss: 6.132119, acc: 0.500000\n",
      "epoch 0, iter 881, loss: 5.910134, acc: 0.375000\n",
      "epoch 0, iter 882, loss: 5.773131, acc: 1.000000\n",
      "epoch 0, iter 883, loss: 6.960855, acc: 0.625000\n",
      "epoch 0, iter 884, loss: 6.370498, acc: 0.625000\n",
      "epoch 0, iter 885, loss: 6.434697, acc: 0.500000\n",
      "epoch 0, iter 886, loss: 6.210046, acc: 0.500000\n",
      "epoch 0, iter 887, loss: 5.994347, acc: 0.750000\n",
      "epoch 0, iter 888, loss: 6.074666, acc: 0.625000\n",
      "epoch 0, iter 889, loss: 6.347220, acc: 0.750000\n",
      "epoch 0, iter 890, loss: 6.062789, acc: 0.875000\n",
      "epoch 0, iter 891, loss: 5.519531, acc: 1.000000\n",
      "epoch 0, iter 892, loss: 5.510273, acc: 0.875000\n",
      "epoch 0, iter 893, loss: 4.831855, acc: 1.000000\n",
      "epoch 0, iter 894, loss: 4.596014, acc: 0.875000\n",
      "epoch 0, iter 895, loss: 4.709152, acc: 0.875000\n",
      "epoch 0, iter 896, loss: 4.408606, acc: 0.750000\n",
      "epoch 0, iter 897, loss: 5.108126, acc: 0.500000\n",
      "epoch 0, iter 898, loss: 4.985940, acc: 0.625000\n",
      "epoch 0, iter 899, loss: 4.770859, acc: 1.000000\n",
      "epoch 0, iter 900, loss: 5.110404, acc: 0.500000\n",
      "epoch 0, iter 901, loss: 5.063505, acc: 0.875000\n",
      "epoch 0, iter 902, loss: 5.372898, acc: 0.625000\n",
      "epoch 0, iter 903, loss: 5.851647, acc: 0.500000\n",
      "epoch 0, iter 904, loss: 5.782457, acc: 0.625000\n",
      "epoch 0, iter 905, loss: 5.651560, acc: 0.625000\n",
      "epoch 0, iter 906, loss: 5.848014, acc: 0.500000\n",
      "epoch 0, iter 907, loss: 5.562493, acc: 0.875000\n",
      "epoch 0, iter 908, loss: 6.479735, acc: 0.625000\n",
      "epoch 0, iter 909, loss: 5.983677, acc: 0.875000\n",
      "epoch 0, iter 910, loss: 6.887525, acc: 0.375000\n",
      "epoch 0, iter 911, loss: 6.523106, acc: 0.625000\n",
      "epoch 0, iter 912, loss: 6.479966, acc: 0.625000\n",
      "epoch 0, iter 913, loss: 6.350717, acc: 0.875000\n",
      "epoch 0, iter 914, loss: 6.375079, acc: 0.500000\n",
      "epoch 0, iter 915, loss: 6.116768, acc: 0.500000\n",
      "epoch 0, iter 916, loss: 5.821529, acc: 1.000000\n",
      "epoch 0, iter 917, loss: 6.932459, acc: 0.500000\n",
      "epoch 0, iter 918, loss: 6.553720, acc: 0.750000\n",
      "epoch 0, iter 919, loss: 6.162131, acc: 0.500000\n",
      "epoch 0, iter 920, loss: 6.175669, acc: 0.750000\n",
      "epoch 0, iter 921, loss: 6.647745, acc: 0.500000\n",
      "epoch 0, iter 922, loss: 6.092322, acc: 0.875000\n",
      "epoch 0, iter 923, loss: 6.060633, acc: 0.500000\n",
      "epoch 0, iter 924, loss: 5.909756, acc: 0.500000\n",
      "epoch 0, iter 925, loss: 5.721712, acc: 0.375000\n",
      "epoch 0, iter 926, loss: 5.688387, acc: 0.375000\n",
      "epoch 0, iter 927, loss: 5.566135, acc: 1.000000\n",
      "epoch 0, iter 928, loss: 5.420693, acc: 0.750000\n",
      "epoch 0, iter 929, loss: 4.991826, acc: 0.625000\n",
      "epoch 0, iter 930, loss: 5.527180, acc: 0.750000\n",
      "epoch 0, iter 931, loss: 5.112263, acc: 0.875000\n",
      "epoch 0, iter 932, loss: 4.892427, acc: 0.875000\n",
      "epoch 0, iter 933, loss: 5.489008, acc: 0.625000\n",
      "epoch 0, iter 934, loss: 7.180407, acc: 0.875000\n",
      "epoch 0, iter 935, loss: 7.502871, acc: 0.500000\n",
      "epoch 0, iter 936, loss: 6.817328, acc: 0.375000\n",
      "epoch 0, iter 937, loss: 6.447916, acc: 0.375000\n",
      "epoch 0, iter 938, loss: 6.198876, acc: 0.500000\n",
      "epoch 0, iter 939, loss: 5.823438, acc: 0.750000\n",
      "epoch 0, iter 940, loss: 5.967518, acc: 0.625000\n",
      "epoch 0, iter 941, loss: 5.916595, acc: 0.625000\n",
      "epoch 0, iter 942, loss: 5.665516, acc: 0.750000\n",
      "epoch 0, iter 943, loss: 5.698224, acc: 0.625000\n",
      "epoch 0, iter 944, loss: 5.535319, acc: 0.625000\n",
      "epoch 0, iter 945, loss: 5.859430, acc: 0.500000\n",
      "epoch 0, iter 946, loss: 5.758329, acc: 0.875000\n",
      "epoch 0, iter 947, loss: 6.510863, acc: 0.500000\n",
      "epoch 0, iter 948, loss: 6.028538, acc: 0.625000\n",
      "epoch 0, iter 949, loss: 6.065490, acc: 0.500000\n",
      "epoch 0, iter 950, loss: 5.970407, acc: 0.875000\n",
      "epoch 0, iter 951, loss: 6.699395, acc: 0.625000\n",
      "epoch 0, iter 952, loss: 6.088219, acc: 0.875000\n",
      "epoch 0, iter 953, loss: 5.983697, acc: 0.875000\n",
      "epoch 0, iter 954, loss: 5.721748, acc: 0.625000\n",
      "epoch 0, iter 955, loss: 5.761660, acc: 0.750000\n",
      "epoch 0, iter 956, loss: 5.335076, acc: 0.750000\n",
      "epoch 0, iter 957, loss: 5.752749, acc: 0.750000\n",
      "epoch 0, iter 958, loss: 6.488861, acc: 0.625000\n",
      "epoch 0, iter 959, loss: 6.096343, acc: 0.875000\n",
      "epoch 0, iter 960, loss: 6.291629, acc: 0.625000\n",
      "epoch 0, iter 961, loss: 6.013406, acc: 0.625000\n",
      "epoch 0, iter 962, loss: 5.672213, acc: 0.875000\n",
      "epoch 0, iter 963, loss: 5.038127, acc: 0.875000\n",
      "epoch 0, iter 964, loss: 5.324530, acc: 0.750000\n",
      "epoch 0, iter 965, loss: 5.171879, acc: 0.750000\n",
      "epoch 0, iter 966, loss: 5.144319, acc: 0.875000\n",
      "epoch 0, iter 967, loss: 5.558129, acc: 0.500000\n",
      "epoch 0, iter 968, loss: 5.468959, acc: 0.500000\n",
      "epoch 0, iter 969, loss: 5.402612, acc: 0.500000\n",
      "epoch 0, iter 970, loss: 5.619339, acc: 0.875000\n",
      "epoch 0, iter 971, loss: 4.823355, acc: 1.000000\n",
      "epoch 0, iter 972, loss: 5.878882, acc: 0.625000\n",
      "epoch 0, iter 973, loss: 5.561454, acc: 0.875000\n",
      "epoch 0, iter 974, loss: 5.474076, acc: 1.000000\n",
      "epoch 0, iter 975, loss: 5.046767, acc: 0.875000\n",
      "epoch 0, iter 976, loss: 5.021812, acc: 0.875000\n",
      "epoch 0, iter 977, loss: 4.349758, acc: 1.000000\n",
      "epoch 0, iter 978, loss: 3.726344, acc: 1.000000\n",
      "epoch 0, iter 979, loss: 4.884396, acc: 0.750000\n",
      "epoch 0, iter 980, loss: 4.930143, acc: 0.875000\n",
      "epoch 0, iter 981, loss: 4.741132, acc: 1.000000\n",
      "epoch 0, iter 982, loss: 4.976013, acc: 0.875000\n",
      "epoch 0, iter 983, loss: 5.220410, acc: 0.750000\n",
      "epoch 0, iter 984, loss: 5.336150, acc: 0.875000\n",
      "epoch 0, iter 985, loss: 4.806346, acc: 1.000000\n",
      "epoch 0, iter 986, loss: 5.333823, acc: 0.750000\n",
      "epoch 0, iter 987, loss: 5.233358, acc: 0.875000\n",
      "epoch 0, iter 988, loss: 6.315564, acc: 0.500000\n",
      "epoch 0, iter 989, loss: 6.086390, acc: 0.500000\n",
      "epoch 0, iter 990, loss: 5.781534, acc: 0.875000\n",
      "epoch 0, iter 991, loss: 5.095529, acc: 0.875000\n",
      "epoch 0, iter 992, loss: 5.303458, acc: 0.750000\n",
      "epoch 0, iter 993, loss: 5.100958, acc: 0.750000\n",
      "epoch 0, iter 994, loss: 5.006915, acc: 0.875000\n",
      "epoch 0, iter 995, loss: 5.311100, acc: 0.750000\n",
      "epoch 0, iter 996, loss: 4.897095, acc: 1.000000\n",
      "epoch 0, iter 997, loss: 4.449182, acc: 1.000000\n",
      "epoch 0, iter 998, loss: 5.305196, acc: 0.750000\n",
      "epoch 0, iter 999, loss: 5.603800, acc: 0.875000\n",
      "epoch 0, iter 1000, loss: 5.070979, acc: 1.000000\n",
      "epoch 0, iter 1001, loss: 4.716249, acc: 0.750000\n",
      "epoch 0, iter 1002, loss: 5.013603, acc: 0.875000\n",
      "epoch 0, iter 1003, loss: 4.547424, acc: 1.000000\n",
      "epoch 0, iter 1004, loss: 4.090491, acc: 1.000000\n",
      "epoch 0, iter 1005, loss: 4.616730, acc: 0.875000\n",
      "epoch 0, iter 1006, loss: 5.872239, acc: 0.625000\n",
      "epoch 0, iter 1007, loss: 5.752786, acc: 0.875000\n",
      "epoch 0, iter 1008, loss: 5.444728, acc: 0.750000\n",
      "epoch 0, iter 1009, loss: 5.473832, acc: 0.875000\n",
      "epoch 0, iter 1010, loss: 5.704410, acc: 0.875000\n",
      "epoch 0, iter 1011, loss: 6.264749, acc: 0.625000\n",
      "epoch 0, iter 1012, loss: 5.800045, acc: 0.875000\n",
      "epoch 0, iter 1013, loss: 5.361892, acc: 0.875000\n",
      "epoch 0, iter 1014, loss: 5.387186, acc: 1.000000\n",
      "epoch 0, iter 1015, loss: 6.307962, acc: 0.875000\n",
      "epoch 0, iter 1016, loss: 5.762584, acc: 0.625000\n",
      "epoch 0, iter 1017, loss: 5.903912, acc: 0.500000\n",
      "epoch 0, iter 1018, loss: 5.855111, acc: 0.750000\n",
      "epoch 0, iter 1019, loss: 5.586429, acc: 0.875000\n",
      "epoch 0, iter 1020, loss: 4.904240, acc: 1.000000\n",
      "epoch 0, iter 1021, loss: 4.358509, acc: 1.000000\n",
      "epoch 0, iter 1022, loss: 3.870938, acc: 1.000000\n",
      "epoch 0, iter 1023, loss: 3.496209, acc: 1.000000\n",
      "epoch 0, iter 1024, loss: 4.122814, acc: 0.875000\n",
      "epoch 0, iter 1025, loss: 4.089233, acc: 0.875000\n",
      "epoch 0, iter 1026, loss: 3.988693, acc: 0.875000\n",
      "epoch 0, iter 1027, loss: 4.415720, acc: 0.750000\n",
      "epoch 0, iter 1028, loss: 5.187213, acc: 0.875000\n",
      "epoch 0, iter 1029, loss: 5.291333, acc: 0.750000\n",
      "epoch 0, iter 1030, loss: 4.667493, acc: 1.000000\n",
      "epoch 0, iter 1031, loss: 5.181683, acc: 0.625000\n",
      "epoch 0, iter 1032, loss: 4.815119, acc: 0.875000\n",
      "epoch 0, iter 1033, loss: 4.689849, acc: 0.750000\n",
      "epoch 0, iter 1034, loss: 5.223698, acc: 0.625000\n",
      "epoch 0, iter 1035, loss: 4.965575, acc: 0.750000\n",
      "epoch 0, iter 1036, loss: 5.553493, acc: 0.750000\n",
      "epoch 0, iter 1037, loss: 5.140220, acc: 0.875000\n",
      "epoch 0, iter 1038, loss: 5.408869, acc: 0.625000\n",
      "epoch 0, iter 1039, loss: 4.957962, acc: 0.875000\n",
      "epoch 0, iter 1040, loss: 5.674700, acc: 0.875000\n",
      "epoch 0, iter 1041, loss: 5.575702, acc: 1.000000\n",
      "epoch 0, iter 1042, loss: 7.025495, acc: 1.000000\n",
      "epoch 0, iter 1043, loss: 6.033274, acc: 0.875000\n",
      "epoch 0, iter 1044, loss: 5.827701, acc: 0.875000\n",
      "epoch 0, iter 1045, loss: 6.071632, acc: 0.750000\n",
      "epoch 0, iter 1046, loss: 5.632196, acc: 0.750000\n",
      "epoch 0, iter 1047, loss: 5.381586, acc: 0.750000\n",
      "epoch 0, iter 1048, loss: 4.825826, acc: 0.875000\n",
      "epoch 0, iter 1049, loss: 4.087599, acc: 0.875000\n",
      "epoch 0, iter 1050, loss: 4.929452, acc: 0.625000\n",
      "epoch 0, iter 1051, loss: 4.420379, acc: 0.875000\n",
      "epoch 0, iter 1052, loss: 4.885465, acc: 0.875000\n",
      "epoch 0, iter 1053, loss: 5.598094, acc: 0.625000\n",
      "epoch 0, iter 1054, loss: 5.249988, acc: 0.750000\n",
      "epoch 0, iter 1055, loss: 4.824866, acc: 1.000000\n",
      "epoch 0, iter 1056, loss: 4.468101, acc: 1.000000\n",
      "epoch 0, iter 1057, loss: 4.551106, acc: 0.625000\n",
      "epoch 0, iter 1058, loss: 4.840560, acc: 0.750000\n",
      "epoch 0, iter 1059, loss: 4.741928, acc: 0.750000\n",
      "epoch 0, iter 1060, loss: 4.423439, acc: 0.875000\n",
      "epoch 0, iter 1061, loss: 5.069106, acc: 0.750000\n",
      "epoch 0, iter 1062, loss: 4.835030, acc: 0.875000\n",
      "epoch 0, iter 1063, loss: 4.506613, acc: 0.750000\n",
      "epoch 0, iter 1064, loss: 5.007541, acc: 0.875000\n",
      "epoch 0, iter 1065, loss: 6.215594, acc: 0.625000\n",
      "epoch 0, iter 1066, loss: 5.988060, acc: 0.750000\n",
      "epoch 0, iter 1067, loss: 5.825484, acc: 0.750000\n",
      "epoch 0, iter 1068, loss: 5.843857, acc: 0.875000\n",
      "epoch 0, iter 1069, loss: 5.679298, acc: 0.875000\n",
      "epoch 0, iter 1070, loss: 6.630244, acc: 0.625000\n",
      "epoch 0, iter 1071, loss: 6.144985, acc: 0.625000\n",
      "epoch 0, iter 1072, loss: 5.749507, acc: 0.750000\n",
      "epoch 0, iter 1073, loss: 5.495946, acc: 0.875000\n",
      "epoch 0, iter 1074, loss: 5.596397, acc: 0.750000\n",
      "epoch 0, iter 1075, loss: 5.296524, acc: 0.875000\n",
      "epoch 0, iter 1076, loss: 5.712184, acc: 0.625000\n",
      "epoch 0, iter 1077, loss: 5.478818, acc: 0.750000\n",
      "epoch 0, iter 1078, loss: 5.263259, acc: 1.000000\n",
      "epoch 0, iter 1079, loss: 5.107148, acc: 1.000000\n",
      "epoch 0, iter 1080, loss: 5.020910, acc: 1.000000\n",
      "epoch 0, iter 1081, loss: 5.416529, acc: 0.750000\n",
      "epoch 0, iter 1082, loss: 6.446331, acc: 0.625000\n",
      "epoch 0, iter 1083, loss: 6.258739, acc: 0.750000\n",
      "epoch 0, iter 1084, loss: 6.015311, acc: 0.500000\n",
      "epoch 0, iter 1085, loss: 6.062671, acc: 0.875000\n",
      "epoch 0, iter 1086, loss: 6.621348, acc: 0.625000\n",
      "epoch 0, iter 1087, loss: 6.148812, acc: 0.875000\n",
      "epoch 0, iter 1088, loss: 6.108892, acc: 0.875000\n",
      "epoch 0, iter 1089, loss: 5.873494, acc: 0.750000\n",
      "epoch 0, iter 1090, loss: 5.730388, acc: 0.750000\n",
      "epoch 0, iter 1091, loss: 5.616187, acc: 0.750000\n",
      "epoch 0, iter 1092, loss: 5.729880, acc: 1.000000\n",
      "epoch 0, iter 1093, loss: 6.435349, acc: 0.625000\n",
      "epoch 0, iter 1094, loss: 6.110855, acc: 0.875000\n",
      "epoch 0, iter 1095, loss: 5.863979, acc: 1.000000\n",
      "epoch 0, iter 1096, loss: 5.253492, acc: 1.000000\n",
      "epoch 0, iter 1097, loss: 5.824062, acc: 0.625000\n",
      "epoch 0, iter 1098, loss: 5.362507, acc: 0.875000\n",
      "epoch 0, iter 1099, loss: 4.897928, acc: 1.000000\n",
      "epoch 0, iter 1100, loss: 4.521291, acc: 1.000000\n",
      "epoch 0, iter 1101, loss: 4.177422, acc: 1.000000\n",
      "epoch 0, iter 1102, loss: 3.979763, acc: 1.000000\n",
      "epoch 0, iter 1103, loss: 3.670878, acc: 1.000000\n",
      "epoch 0, iter 1104, loss: 3.476806, acc: 1.000000\n",
      "epoch 0, iter 1105, loss: 3.946803, acc: 0.875000\n",
      "epoch 0, iter 1106, loss: 3.814641, acc: 1.000000\n",
      "epoch 0, iter 1107, loss: 3.934741, acc: 1.000000\n",
      "epoch 0, iter 1108, loss: 4.125517, acc: 0.875000\n",
      "epoch 0, iter 1109, loss: 4.037823, acc: 1.000000\n",
      "epoch 0, iter 1110, loss: 3.970108, acc: 1.000000\n",
      "epoch 0, iter 1111, loss: 4.228084, acc: 0.875000\n",
      "epoch 0, iter 1112, loss: 4.489040, acc: 0.875000\n",
      "epoch 0, iter 1113, loss: 5.035531, acc: 0.875000\n",
      "epoch 0, iter 1114, loss: 4.552640, acc: 1.000000\n",
      "epoch 0, iter 1115, loss: 4.198735, acc: 1.000000\n",
      "epoch 0, iter 1116, loss: 4.212887, acc: 1.000000\n",
      "epoch 0, iter 1117, loss: 3.685080, acc: 1.000000\n",
      "epoch 0, iter 1118, loss: 4.243665, acc: 0.875000\n",
      "epoch 0, iter 1119, loss: 3.992889, acc: 1.000000\n",
      "epoch 0, iter 1120, loss: 4.196090, acc: 0.875000\n",
      "epoch 0, iter 1121, loss: 4.166140, acc: 1.000000\n",
      "epoch 0, iter 1122, loss: 3.917296, acc: 1.000000\n",
      "epoch 0, iter 1123, loss: 3.389411, acc: 1.000000\n",
      "epoch 0, iter 1124, loss: 3.642859, acc: 0.875000\n",
      "epoch 0, iter 1125, loss: 4.136553, acc: 0.875000\n",
      "epoch 0, iter 1126, loss: 4.941040, acc: 0.875000\n",
      "epoch 0, iter 1127, loss: 4.448929, acc: 1.000000\n",
      "epoch 0, iter 1128, loss: 4.466240, acc: 0.750000\n",
      "epoch 0, iter 1129, loss: 4.165370, acc: 0.875000\n",
      "epoch 0, iter 1130, loss: 4.396537, acc: 0.750000\n",
      "epoch 0, iter 1131, loss: 4.209277, acc: 0.875000\n",
      "epoch 0, iter 1132, loss: 4.055888, acc: 0.875000\n",
      "epoch 0, iter 1133, loss: 4.137066, acc: 1.000000\n",
      "epoch 0, iter 1134, loss: 3.948788, acc: 0.875000\n",
      "epoch 0, iter 1135, loss: 4.023956, acc: 0.875000\n",
      "epoch 0, iter 1136, loss: 3.745517, acc: 1.000000\n",
      "epoch 0, iter 1137, loss: 3.700250, acc: 1.000000\n",
      "epoch 0, iter 1138, loss: 3.441715, acc: 1.000000\n",
      "epoch 0, iter 1139, loss: 3.014618, acc: 1.000000\n",
      "epoch 0, iter 1140, loss: 2.673987, acc: 1.000000\n",
      "epoch 0, iter 1141, loss: 2.421903, acc: 1.000000\n",
      "epoch 0, iter 1142, loss: 2.235848, acc: 1.000000\n",
      "epoch 0, iter 1143, loss: 2.097530, acc: 1.000000\n",
      "epoch 0, iter 1144, loss: 1.993159, acc: 1.000000\n",
      "epoch 0, iter 1145, loss: 1.913187, acc: 1.000000\n",
      "epoch 0, iter 1146, loss: 2.841211, acc: 0.875000\n",
      "epoch 0, iter 1147, loss: 2.618983, acc: 1.000000\n",
      "epoch 0, iter 1148, loss: 2.377815, acc: 1.000000\n",
      "epoch 0, iter 1149, loss: 4.040127, acc: 1.000000\n",
      "epoch 0, iter 1150, loss: 3.902201, acc: 0.875000\n",
      "epoch 0, iter 1151, loss: 3.585509, acc: 0.875000\n",
      "epoch 0, iter 1152, loss: 4.492451, acc: 0.625000\n",
      "epoch 0, iter 1153, loss: 4.298227, acc: 1.000000\n",
      "epoch 0, iter 1154, loss: 3.951862, acc: 1.000000\n",
      "epoch 0, iter 1155, loss: 4.266622, acc: 0.625000\n",
      "epoch 0, iter 1156, loss: 4.599005, acc: 0.750000\n",
      "epoch 0, iter 1157, loss: 4.283372, acc: 1.000000\n",
      "epoch 0, iter 1158, loss: 4.878447, acc: 0.750000\n",
      "epoch 0, iter 1159, loss: 4.316608, acc: 1.000000\n",
      "epoch 0, iter 1160, loss: 4.045117, acc: 0.875000\n",
      "epoch 0, iter 1161, loss: 4.129366, acc: 0.875000\n",
      "epoch 0, iter 1162, loss: 3.791935, acc: 1.000000\n",
      "epoch 0, iter 1163, loss: 3.638294, acc: 1.000000\n",
      "epoch 0, iter 1164, loss: 3.796362, acc: 0.875000\n",
      "epoch 0, iter 1165, loss: 3.465603, acc: 1.000000\n",
      "epoch 0, iter 1166, loss: 3.442180, acc: 0.875000\n",
      "epoch 0, iter 1167, loss: 3.158320, acc: 1.000000\n",
      "epoch 0, iter 1168, loss: 4.270258, acc: 0.750000\n",
      "epoch 0, iter 1169, loss: 4.998520, acc: 0.875000\n",
      "epoch 0, iter 1170, loss: 4.481356, acc: 1.000000\n",
      "epoch 0, iter 1171, loss: 3.984049, acc: 1.000000\n",
      "epoch 0, iter 1172, loss: 3.573624, acc: 1.000000\n",
      "epoch 0, iter 1173, loss: 4.105721, acc: 0.875000\n",
      "epoch 0, iter 1174, loss: 4.220799, acc: 1.000000\n",
      "epoch 0, iter 1175, loss: 3.406141, acc: 1.000000\n",
      "epoch 0, iter 1176, loss: 3.244771, acc: 0.875000\n",
      "epoch 0, iter 1177, loss: 3.640879, acc: 0.875000\n",
      "epoch 0, iter 1178, loss: 4.469412, acc: 0.875000\n",
      "epoch 0, iter 1179, loss: 4.697054, acc: 0.875000\n",
      "epoch 0, iter 1180, loss: 4.737243, acc: 1.000000\n",
      "epoch 0, iter 1181, loss: 3.897986, acc: 1.000000\n",
      "epoch 0, iter 1182, loss: 5.015064, acc: 0.875000\n",
      "epoch 0, iter 1183, loss: 4.474714, acc: 1.000000\n",
      "epoch 0, iter 1184, loss: 3.903620, acc: 1.000000\n",
      "epoch 0, iter 1185, loss: 3.492237, acc: 1.000000\n",
      "epoch 0, iter 1186, loss: 3.198300, acc: 1.000000\n",
      "epoch 0, iter 1187, loss: 3.370115, acc: 0.625000\n",
      "epoch 0, iter 1188, loss: 3.804608, acc: 0.875000\n",
      "epoch 0, iter 1189, loss: 3.399614, acc: 1.000000\n",
      "epoch 0, iter 1190, loss: 3.653222, acc: 1.000000\n",
      "epoch 0, iter 1191, loss: 3.375123, acc: 1.000000\n",
      "epoch 0, iter 1192, loss: 2.888247, acc: 1.000000\n",
      "epoch 0, iter 1193, loss: 3.090016, acc: 0.875000\n",
      "epoch 0, iter 1194, loss: 3.060461, acc: 1.000000\n",
      "epoch 0, iter 1195, loss: 4.334695, acc: 0.750000\n",
      "epoch 0, iter 1196, loss: 4.403876, acc: 0.625000\n",
      "epoch 0, iter 1197, loss: 4.734417, acc: 0.750000\n",
      "epoch 0, iter 1198, loss: 4.552568, acc: 0.750000\n",
      "epoch 0, iter 1199, loss: 4.883608, acc: 0.750000\n",
      "epoch 0, iter 1200, loss: 4.974716, acc: 1.000000\n",
      "epoch 0, iter 1201, loss: 6.245350, acc: 0.625000\n",
      "epoch 0, iter 1202, loss: 5.295645, acc: 0.875000\n",
      "epoch 0, iter 1203, loss: 6.376765, acc: 0.500000\n",
      "epoch 0, iter 1204, loss: 6.190472, acc: 0.625000\n",
      "epoch 0, iter 1205, loss: 5.660402, acc: 0.750000\n",
      "epoch 0, iter 1206, loss: 5.246375, acc: 0.750000\n",
      "epoch 0, iter 1207, loss: 5.024850, acc: 0.750000\n",
      "epoch 0, iter 1208, loss: 5.040427, acc: 0.875000\n",
      "epoch 0, iter 1209, loss: 6.451334, acc: 0.500000\n",
      "epoch 0, iter 1210, loss: 6.264432, acc: 0.500000\n",
      "epoch 0, iter 1211, loss: 5.946945, acc: 0.750000\n",
      "epoch 0, iter 1212, loss: 5.751532, acc: 0.875000\n",
      "epoch 0, iter 1213, loss: 6.406517, acc: 0.500000\n",
      "epoch 0, iter 1214, loss: 6.112448, acc: 0.875000\n",
      "epoch 0, iter 1215, loss: 6.203794, acc: 0.750000\n",
      "epoch 0, iter 1216, loss: 6.350526, acc: 0.625000\n",
      "epoch 0, iter 1217, loss: 5.850090, acc: 0.875000\n",
      "epoch 0, iter 1218, loss: 5.329268, acc: 0.750000\n",
      "epoch 0, iter 1219, loss: 4.506197, acc: 1.000000\n",
      "epoch 0, iter 1220, loss: 5.329954, acc: 0.750000\n",
      "epoch 0, iter 1221, loss: 5.146723, acc: 0.875000\n",
      "epoch 0, iter 1222, loss: 5.326627, acc: 0.750000\n",
      "epoch 0, iter 1223, loss: 5.102882, acc: 0.875000\n",
      "epoch 0, iter 1224, loss: 5.157883, acc: 0.875000\n",
      "epoch 0, iter 1225, loss: 5.154438, acc: 0.750000\n",
      "epoch 0, iter 1226, loss: 4.945721, acc: 0.875000\n",
      "epoch 0, iter 1227, loss: 4.974282, acc: 0.750000\n",
      "epoch 0, iter 1228, loss: 4.942879, acc: 0.750000\n",
      "epoch 0, iter 1229, loss: 5.043507, acc: 0.750000\n",
      "epoch 0, iter 1230, loss: 4.796649, acc: 0.875000\n",
      "epoch 0, iter 1231, loss: 4.709025, acc: 0.750000\n",
      "epoch 0, iter 1232, loss: 5.387778, acc: 0.750000\n",
      "epoch 0, iter 1233, loss: 5.442886, acc: 0.875000\n",
      "epoch 0, iter 1234, loss: 5.521942, acc: 0.625000\n",
      "epoch 0, iter 1235, loss: 5.277193, acc: 0.875000\n",
      "epoch 0, iter 1236, loss: 5.672219, acc: 0.750000\n",
      "epoch 0, iter 1237, loss: 6.011176, acc: 0.750000\n",
      "epoch 0, iter 1238, loss: 5.664821, acc: 1.000000\n",
      "epoch 0, iter 1239, loss: 4.984524, acc: 0.750000\n",
      "epoch 0, iter 1240, loss: 4.700531, acc: 1.000000\n",
      "epoch 0, iter 1241, loss: 4.456972, acc: 0.875000\n",
      "epoch 0, iter 1242, loss: 3.715817, acc: 1.000000\n",
      "epoch 0, iter 1243, loss: 3.889419, acc: 0.875000\n",
      "epoch 0, iter 1244, loss: 3.540257, acc: 1.000000\n",
      "epoch 0, iter 1245, loss: 3.690601, acc: 1.000000\n",
      "epoch 0, iter 1246, loss: 3.647625, acc: 1.000000\n",
      "epoch 0, iter 1247, loss: 3.049151, acc: 1.000000\n",
      "epoch 0, iter 1248, loss: 4.144371, acc: 0.750000\n",
      "epoch 0, iter 1249, loss: 4.633888, acc: 0.875000\n",
      "epoch 0, iter 1250, loss: 4.105503, acc: 0.750000\n",
      "epoch 0, iter 1251, loss: 3.821401, acc: 1.000000\n",
      "epoch 0, iter 1252, loss: 4.108953, acc: 1.000000\n",
      "epoch 0, iter 1253, loss: 4.199550, acc: 0.875000\n",
      "epoch 0, iter 1254, loss: 3.764983, acc: 1.000000\n",
      "epoch 0, iter 1255, loss: 3.334374, acc: 1.000000\n",
      "epoch 0, iter 1256, loss: 3.819916, acc: 1.000000\n",
      "epoch 0, iter 1257, loss: 3.967116, acc: 1.000000\n",
      "epoch 0, iter 1258, loss: 3.531007, acc: 1.000000\n",
      "epoch 0, iter 1259, loss: 3.542421, acc: 1.000000\n",
      "epoch 0, iter 1260, loss: 3.695254, acc: 1.000000\n",
      "epoch 0, iter 1261, loss: 4.844997, acc: 0.625000\n",
      "epoch 0, iter 1262, loss: 5.449605, acc: 0.625000\n",
      "epoch 0, iter 1263, loss: 4.884022, acc: 1.000000\n",
      "epoch 0, iter 1264, loss: 4.421091, acc: 1.000000\n",
      "epoch 0, iter 1265, loss: 4.151088, acc: 0.875000\n",
      "epoch 0, iter 1266, loss: 3.760405, acc: 1.000000\n",
      "epoch 0, iter 1267, loss: 3.446325, acc: 1.000000\n",
      "epoch 0, iter 1268, loss: 3.181248, acc: 1.000000\n",
      "epoch 0, iter 1269, loss: 2.925966, acc: 1.000000\n",
      "epoch 0, iter 1270, loss: 2.707059, acc: 1.000000\n",
      "epoch 0, iter 1271, loss: 2.542219, acc: 1.000000\n",
      "epoch 0, iter 1272, loss: 2.420524, acc: 1.000000\n",
      "epoch 0, iter 1273, loss: 2.330326, acc: 1.000000\n",
      "epoch 0, iter 1274, loss: 2.262411, acc: 1.000000\n",
      "epoch 0, iter 1275, loss: 2.210047, acc: 1.000000\n",
      "epoch 0, iter 1276, loss: 2.602234, acc: 1.000000\n",
      "epoch 0, iter 1277, loss: 2.843858, acc: 1.000000\n",
      "epoch 0, iter 1278, loss: 2.649532, acc: 1.000000\n",
      "epoch 0, iter 1279, loss: 2.472916, acc: 1.000000\n",
      "epoch 0, iter 1280, loss: 2.340981, acc: 1.000000\n",
      "epoch 0, iter 1281, loss: 3.089706, acc: 0.875000\n",
      "epoch 0, iter 1282, loss: 4.234737, acc: 1.000000\n",
      "epoch 0, iter 1283, loss: 5.243424, acc: 0.750000\n",
      "epoch 0, iter 1284, loss: 5.062930, acc: 0.750000\n",
      "epoch 0, iter 1285, loss: 4.521302, acc: 0.750000\n",
      "epoch 0, iter 1286, loss: 4.130059, acc: 0.750000\n",
      "epoch 0, iter 1287, loss: 4.282599, acc: 1.000000\n",
      "epoch 0, iter 1288, loss: 3.552205, acc: 1.000000\n",
      "epoch 0, iter 1289, loss: 4.088127, acc: 0.875000\n",
      "epoch 0, iter 1290, loss: 4.206099, acc: 1.000000\n",
      "epoch 0, iter 1291, loss: 3.998886, acc: 1.000000\n",
      "epoch 0, iter 1292, loss: 3.643081, acc: 0.875000\n",
      "epoch 0, iter 1293, loss: 3.185023, acc: 1.000000\n",
      "epoch 0, iter 1294, loss: 3.715789, acc: 0.750000\n",
      "epoch 0, iter 1295, loss: 5.030269, acc: 0.625000\n",
      "epoch 0, iter 1296, loss: 5.691120, acc: 0.750000\n",
      "epoch 0, iter 1297, loss: 5.314486, acc: 0.875000\n",
      "epoch 0, iter 1298, loss: 5.480972, acc: 0.875000\n",
      "epoch 0, iter 1299, loss: 5.114278, acc: 0.875000\n",
      "epoch 0, iter 1300, loss: 4.921156, acc: 0.750000\n",
      "epoch 0, iter 1301, loss: 5.713364, acc: 0.625000\n",
      "epoch 0, iter 1302, loss: 5.005518, acc: 0.875000\n",
      "epoch 0, iter 1303, loss: 5.781319, acc: 0.625000\n",
      "epoch 0, iter 1304, loss: 5.124106, acc: 0.875000\n",
      "epoch 0, iter 1305, loss: 4.889342, acc: 0.750000\n",
      "epoch 0, iter 1306, loss: 5.169592, acc: 0.750000\n",
      "epoch 0, iter 1307, loss: 5.002417, acc: 0.875000\n",
      "epoch 0, iter 1308, loss: 4.768166, acc: 0.750000\n",
      "epoch 0, iter 1309, loss: 4.127143, acc: 0.875000\n",
      "epoch 0, iter 1310, loss: 5.031280, acc: 0.625000\n",
      "epoch 0, iter 1311, loss: 4.815650, acc: 0.750000\n",
      "epoch 0, iter 1312, loss: 4.895014, acc: 0.875000\n",
      "epoch 0, iter 1313, loss: 4.663995, acc: 1.000000\n",
      "epoch 0, iter 1314, loss: 4.566829, acc: 0.750000\n",
      "epoch 0, iter 1315, loss: 4.634184, acc: 0.875000\n",
      "epoch 0, iter 1316, loss: 4.410304, acc: 0.750000\n",
      "epoch 0, iter 1317, loss: 4.368571, acc: 0.875000\n",
      "epoch 0, iter 1318, loss: 4.574152, acc: 0.875000\n",
      "epoch 0, iter 1319, loss: 4.432050, acc: 0.875000\n",
      "epoch 0, iter 1320, loss: 4.658821, acc: 0.750000\n",
      "epoch 0, iter 1321, loss: 4.806892, acc: 0.875000\n",
      "epoch 0, iter 1322, loss: 4.056329, acc: 0.875000\n",
      "epoch 0, iter 1323, loss: 4.719194, acc: 0.750000\n",
      "epoch 0, iter 1324, loss: 4.354595, acc: 0.750000\n",
      "epoch 0, iter 1325, loss: 5.167029, acc: 0.875000\n",
      "epoch 0, iter 1326, loss: 5.124206, acc: 0.875000\n",
      "epoch 0, iter 1327, loss: 4.875764, acc: 0.750000\n",
      "epoch 0, iter 1328, loss: 5.093384, acc: 0.625000\n",
      "epoch 0, iter 1329, loss: 4.575531, acc: 0.875000\n",
      "epoch 0, iter 1330, loss: 3.823875, acc: 1.000000\n",
      "epoch 0, iter 1331, loss: 4.494801, acc: 0.750000\n",
      "epoch 0, iter 1332, loss: 4.408946, acc: 0.875000\n",
      "epoch 0, iter 1333, loss: 4.229911, acc: 0.750000\n",
      "epoch 0, iter 1334, loss: 4.314662, acc: 0.500000\n",
      "epoch 0, iter 1335, loss: 4.699444, acc: 0.625000\n",
      "epoch 0, iter 1336, loss: 4.898192, acc: 0.625000\n",
      "epoch 0, iter 1337, loss: 4.626395, acc: 0.875000\n",
      "epoch 0, iter 1338, loss: 4.801400, acc: 0.750000\n",
      "epoch 0, iter 1339, loss: 4.689172, acc: 0.750000\n",
      "epoch 0, iter 1340, loss: 4.591319, acc: 0.875000\n",
      "epoch 0, iter 1341, loss: 4.902581, acc: 0.750000\n",
      "epoch 0, iter 1342, loss: 5.404265, acc: 0.750000\n",
      "epoch 0, iter 1343, loss: 5.065091, acc: 1.000000\n",
      "epoch 0, iter 1344, loss: 4.647414, acc: 1.000000\n",
      "epoch 0, iter 1345, loss: 4.405386, acc: 0.875000\n",
      "epoch 0, iter 1346, loss: 4.273658, acc: 0.875000\n",
      "epoch 0, iter 1347, loss: 3.756777, acc: 0.875000\n",
      "epoch 0, iter 1348, loss: 4.502154, acc: 0.750000\n",
      "epoch 0, iter 1349, loss: 4.108178, acc: 0.875000\n",
      "epoch 0, iter 1350, loss: 4.510170, acc: 0.750000\n",
      "epoch 0, iter 1351, loss: 5.067379, acc: 0.625000\n",
      "epoch 0, iter 1352, loss: 4.970338, acc: 0.875000\n",
      "epoch 0, iter 1353, loss: 4.461859, acc: 1.000000\n",
      "epoch 0, iter 1354, loss: 4.749140, acc: 0.875000\n",
      "epoch 0, iter 1355, loss: 4.516321, acc: 0.875000\n",
      "epoch 0, iter 1356, loss: 4.266424, acc: 0.875000\n",
      "epoch 0, iter 1357, loss: 4.449955, acc: 0.750000\n",
      "epoch 0, iter 1358, loss: 4.360729, acc: 0.750000\n",
      "epoch 0, iter 1359, loss: 4.385405, acc: 0.750000\n",
      "epoch 0, iter 1360, loss: 4.224651, acc: 0.750000\n",
      "epoch 0, iter 1361, loss: 4.251646, acc: 0.750000\n",
      "epoch 0, iter 1362, loss: 4.295269, acc: 0.875000\n",
      "epoch 0, iter 1363, loss: 4.139169, acc: 0.875000\n",
      "epoch 0, iter 1364, loss: 4.695169, acc: 0.875000\n",
      "epoch 0, iter 1365, loss: 4.493332, acc: 1.000000\n",
      "epoch 0, iter 1366, loss: 4.605410, acc: 0.750000\n",
      "epoch 0, iter 1367, loss: 4.382348, acc: 0.750000\n",
      "epoch 0, iter 1368, loss: 4.402047, acc: 0.875000\n",
      "epoch 0, iter 1369, loss: 4.089441, acc: 0.875000\n",
      "epoch 0, iter 1370, loss: 4.320399, acc: 0.625000\n",
      "epoch 0, iter 1371, loss: 4.104787, acc: 0.875000\n",
      "epoch 0, iter 1372, loss: 4.033181, acc: 0.875000\n",
      "epoch 0, iter 1373, loss: 3.856361, acc: 1.000000\n",
      "epoch 0, iter 1374, loss: 5.070264, acc: 0.625000\n",
      "epoch 0, iter 1375, loss: 5.064487, acc: 0.750000\n",
      "epoch 0, iter 1376, loss: 4.951161, acc: 0.750000\n",
      "epoch 0, iter 1377, loss: 4.891497, acc: 0.750000\n",
      "epoch 0, iter 1378, loss: 4.345232, acc: 0.875000\n",
      "epoch 0, iter 1379, loss: 4.238208, acc: 0.750000\n",
      "epoch 0, iter 1380, loss: 4.539353, acc: 0.875000\n",
      "epoch 0, iter 1381, loss: 4.239602, acc: 1.000000\n",
      "epoch 0, iter 1382, loss: 4.184533, acc: 0.875000\n",
      "epoch 0, iter 1383, loss: 3.898736, acc: 0.875000\n",
      "epoch 0, iter 1384, loss: 3.656114, acc: 0.875000\n",
      "epoch 0, iter 1385, loss: 3.462702, acc: 0.875000\n",
      "epoch 0, iter 1386, loss: 3.318744, acc: 0.875000\n",
      "epoch 0, iter 1387, loss: 4.213955, acc: 0.625000\n",
      "epoch 0, iter 1388, loss: 3.781525, acc: 0.875000\n",
      "epoch 0, iter 1389, loss: 3.811980, acc: 0.750000\n",
      "epoch 0, iter 1390, loss: 3.410837, acc: 0.875000\n",
      "epoch 0, iter 1391, loss: 4.093596, acc: 0.625000\n",
      "epoch 0, iter 1392, loss: 3.939360, acc: 0.750000\n",
      "epoch 0, iter 1393, loss: 4.448215, acc: 0.750000\n",
      "epoch 0, iter 1394, loss: 4.472223, acc: 0.875000\n",
      "epoch 0, iter 1395, loss: 4.375805, acc: 0.875000\n",
      "epoch 0, iter 1396, loss: 3.946400, acc: 1.000000\n",
      "epoch 0, iter 1397, loss: 3.718007, acc: 0.875000\n",
      "epoch 0, iter 1398, loss: 5.635919, acc: 0.875000\n",
      "epoch 0, iter 1399, loss: 5.662055, acc: 0.750000\n",
      "epoch 0, iter 1400, loss: 4.872662, acc: 1.000000\n",
      "epoch 0, iter 1401, loss: 5.235208, acc: 0.875000\n",
      "epoch 0, iter 1402, loss: 4.813088, acc: 0.875000\n",
      "epoch 0, iter 1403, loss: 4.713230, acc: 0.750000\n",
      "epoch 0, iter 1404, loss: 4.147404, acc: 1.000000\n",
      "epoch 0, iter 1405, loss: 5.336684, acc: 0.500000\n",
      "epoch 0, iter 1406, loss: 5.027905, acc: 0.875000\n",
      "epoch 0, iter 1407, loss: 4.866387, acc: 0.875000\n",
      "epoch 0, iter 1408, loss: 4.627525, acc: 1.000000\n",
      "epoch 0, iter 1409, loss: 4.384972, acc: 1.000000\n",
      "epoch 0, iter 1410, loss: 4.338277, acc: 0.875000\n",
      "epoch 0, iter 1411, loss: 4.313053, acc: 0.750000\n",
      "epoch 0, iter 1412, loss: 4.011467, acc: 0.875000\n",
      "epoch 0, iter 1413, loss: 3.750892, acc: 0.750000\n",
      "epoch 0, iter 1414, loss: 3.608331, acc: 1.000000\n",
      "epoch 0, iter 1415, loss: 3.459446, acc: 1.000000\n",
      "epoch 0, iter 1416, loss: 3.336840, acc: 1.000000\n",
      "epoch 0, iter 1417, loss: 3.235910, acc: 1.000000\n",
      "epoch 0, iter 1418, loss: 3.155920, acc: 1.000000\n",
      "epoch 0, iter 1419, loss: 3.086377, acc: 1.000000\n",
      "epoch 0, iter 1420, loss: 2.986221, acc: 1.000000\n",
      "epoch 0, iter 1421, loss: 2.946568, acc: 0.875000\n",
      "epoch 0, iter 1422, loss: 2.948452, acc: 1.000000\n",
      "epoch 0, iter 1423, loss: 3.693001, acc: 0.750000\n",
      "epoch 0, iter 1424, loss: 3.350382, acc: 1.000000\n",
      "epoch 0, iter 1425, loss: 3.969736, acc: 0.750000\n",
      "epoch 0, iter 1426, loss: 4.232290, acc: 0.750000\n",
      "epoch 0, iter 1427, loss: 4.628706, acc: 0.750000\n",
      "epoch 0, iter 1428, loss: 4.359930, acc: 0.875000\n",
      "epoch 0, iter 1429, loss: 4.383545, acc: 0.875000\n",
      "epoch 0, iter 1430, loss: 4.366899, acc: 0.875000\n",
      "epoch 0, iter 1431, loss: 4.212267, acc: 0.875000\n",
      "epoch 0, iter 1432, loss: 4.065127, acc: 1.000000\n",
      "epoch 0, iter 1433, loss: 3.675158, acc: 1.000000\n",
      "epoch 0, iter 1434, loss: 3.779087, acc: 1.000000\n",
      "epoch 0, iter 1435, loss: 3.539893, acc: 1.000000\n",
      "epoch 0, iter 1436, loss: 3.314546, acc: 1.000000\n",
      "epoch 0, iter 1437, loss: 3.605693, acc: 0.750000\n",
      "epoch 0, iter 1438, loss: 4.156768, acc: 0.750000\n",
      "epoch 0, iter 1439, loss: 4.129817, acc: 0.875000\n",
      "epoch 0, iter 1440, loss: 3.835936, acc: 0.875000\n",
      "epoch 0, iter 1441, loss: 3.970395, acc: 0.875000\n",
      "epoch 0, iter 1442, loss: 4.369780, acc: 0.750000\n",
      "epoch 0, iter 1443, loss: 4.196050, acc: 0.750000\n",
      "epoch 0, iter 1444, loss: 3.923491, acc: 0.875000\n",
      "epoch 0, iter 1445, loss: 5.153233, acc: 1.000000\n",
      "epoch 0, iter 1446, loss: 5.072250, acc: 0.875000\n",
      "epoch 0, iter 1447, loss: 5.205179, acc: 0.750000\n",
      "epoch 0, iter 1448, loss: 4.632328, acc: 1.000000\n",
      "epoch 0, iter 1449, loss: 4.032999, acc: 1.000000\n",
      "epoch 0, iter 1450, loss: 3.562277, acc: 1.000000\n",
      "epoch 0, iter 1451, loss: 3.766973, acc: 0.875000\n",
      "epoch 0, iter 1452, loss: 4.520026, acc: 0.750000\n",
      "epoch 0, iter 1453, loss: 5.492856, acc: 0.750000\n",
      "epoch 0, iter 1454, loss: 5.485595, acc: 0.750000\n",
      "epoch 0, iter 1455, loss: 4.976589, acc: 1.000000\n",
      "epoch 0, iter 1456, loss: 5.622246, acc: 0.750000\n",
      "epoch 0, iter 1457, loss: 4.848940, acc: 0.750000\n",
      "epoch 0, iter 1458, loss: 6.121648, acc: 0.750000\n",
      "epoch 0, iter 1459, loss: 5.422283, acc: 1.000000\n",
      "epoch 0, iter 1460, loss: 4.885084, acc: 0.875000\n",
      "epoch 0, iter 1461, loss: 5.253803, acc: 0.875000\n",
      "epoch 0, iter 1462, loss: 6.291032, acc: 0.875000\n",
      "epoch 0, iter 1463, loss: 5.973330, acc: 0.875000\n",
      "epoch 0, iter 1464, loss: 5.840196, acc: 0.750000\n",
      "epoch 0, iter 1465, loss: 5.351107, acc: 0.875000\n",
      "epoch 0, iter 1466, loss: 5.156471, acc: 0.750000\n",
      "epoch 0, iter 1467, loss: 4.857157, acc: 0.875000\n",
      "epoch 0, iter 1468, loss: 4.989579, acc: 0.875000\n",
      "epoch 0, iter 1469, loss: 5.265105, acc: 0.625000\n",
      "epoch 0, iter 1470, loss: 4.777377, acc: 1.000000\n",
      "epoch 0, iter 1471, loss: 5.608114, acc: 0.750000\n",
      "epoch 0, iter 1472, loss: 5.009201, acc: 0.875000\n",
      "epoch 0, iter 1473, loss: 4.784607, acc: 0.750000\n",
      "epoch 0, iter 1474, loss: 4.653961, acc: 1.000000\n",
      "epoch 0, iter 1475, loss: 4.272858, acc: 1.000000\n",
      "epoch 0, iter 1476, loss: 3.827217, acc: 1.000000\n",
      "epoch 0, iter 1477, loss: 3.446222, acc: 1.000000\n",
      "epoch 0, iter 1478, loss: 3.971349, acc: 0.875000\n",
      "epoch 0, iter 1479, loss: 3.598298, acc: 1.000000\n",
      "epoch 0, iter 1480, loss: 3.999169, acc: 0.750000\n",
      "epoch 0, iter 1481, loss: 3.679526, acc: 1.000000\n",
      "epoch 0, iter 1482, loss: 3.874572, acc: 0.750000\n",
      "epoch 0, iter 1483, loss: 3.553056, acc: 0.875000\n",
      "epoch 0, iter 1484, loss: 3.753844, acc: 0.750000\n",
      "epoch 0, iter 1485, loss: 4.542054, acc: 0.750000\n",
      "epoch 0, iter 1486, loss: 5.102778, acc: 0.750000\n",
      "epoch 0, iter 1487, loss: 4.624315, acc: 0.750000\n",
      "epoch 0, iter 1488, loss: 4.304221, acc: 0.875000\n",
      "epoch 0, iter 1489, loss: 4.233975, acc: 0.875000\n",
      "epoch 0, iter 1490, loss: 4.123549, acc: 0.750000\n",
      "epoch 0, iter 1491, loss: 4.601833, acc: 0.750000\n",
      "epoch 0, iter 1492, loss: 4.561398, acc: 0.750000\n",
      "epoch 0, iter 1493, loss: 4.678980, acc: 0.750000\n",
      "epoch 0, iter 1494, loss: 5.197046, acc: 0.500000\n",
      "epoch 0, iter 1495, loss: 4.827864, acc: 0.750000\n",
      "epoch 0, iter 1496, loss: 5.345994, acc: 0.500000\n",
      "epoch 0, iter 1497, loss: 5.019451, acc: 0.500000\n",
      "epoch 0, iter 1498, loss: 5.733768, acc: 0.750000\n",
      "epoch 0, iter 1499, loss: 5.695592, acc: 0.625000\n",
      "epoch 0, iter 1500, loss: 5.162501, acc: 0.625000\n",
      "epoch 0, iter 1501, loss: 4.696849, acc: 0.750000\n",
      "epoch 0, iter 1502, loss: 4.420680, acc: 0.750000\n",
      "epoch 0, iter 1503, loss: 5.040205, acc: 0.625000\n",
      "epoch 0, iter 1504, loss: 4.707456, acc: 0.750000\n",
      "epoch 0, iter 1505, loss: 4.472286, acc: 0.875000\n",
      "epoch 0, iter 1506, loss: 3.782843, acc: 0.750000\n",
      "epoch 0, iter 1507, loss: 3.232126, acc: 0.875000\n",
      "epoch 0, iter 1508, loss: 3.903678, acc: 0.875000\n",
      "epoch 0, iter 1509, loss: 3.514456, acc: 0.875000\n",
      "epoch 0, iter 1510, loss: 3.786447, acc: 0.875000\n",
      "epoch 0, iter 1511, loss: 3.996140, acc: 0.750000\n",
      "epoch 0, iter 1512, loss: 3.832953, acc: 0.750000\n",
      "epoch 0, iter 1513, loss: 3.653451, acc: 0.750000\n",
      "epoch 0, iter 1514, loss: 3.571543, acc: 0.750000\n",
      "epoch 0, iter 1515, loss: 3.394029, acc: 0.875000\n",
      "epoch 0, iter 1516, loss: 3.528654, acc: 1.000000\n",
      "epoch 0, iter 1517, loss: 3.196890, acc: 1.000000\n",
      "epoch 0, iter 1518, loss: 3.246722, acc: 1.000000\n",
      "epoch 0, iter 1519, loss: 3.058796, acc: 0.875000\n",
      "epoch 0, iter 1520, loss: 2.939176, acc: 1.000000\n",
      "epoch 0, iter 1521, loss: 3.661497, acc: 0.750000\n",
      "epoch 0, iter 1522, loss: 3.199957, acc: 1.000000\n",
      "epoch 0, iter 1523, loss: 4.469565, acc: 0.625000\n",
      "epoch 0, iter 1524, loss: 4.595801, acc: 0.750000\n",
      "epoch 0, iter 1525, loss: 4.728936, acc: 0.750000\n",
      "epoch 0, iter 1526, loss: 4.428021, acc: 1.000000\n",
      "epoch 0, iter 1527, loss: 4.072263, acc: 1.000000\n",
      "epoch 0, iter 1528, loss: 3.995964, acc: 1.000000\n",
      "epoch 0, iter 1529, loss: 3.565587, acc: 1.000000\n",
      "epoch 0, iter 1530, loss: 3.527611, acc: 1.000000\n",
      "epoch 0, iter 1531, loss: 3.796836, acc: 1.000000\n",
      "epoch 0, iter 1532, loss: 4.103467, acc: 1.000000\n",
      "epoch 0, iter 1533, loss: 3.786699, acc: 1.000000\n",
      "epoch 0, iter 1534, loss: 3.450252, acc: 1.000000\n",
      "epoch 0, iter 1535, loss: 3.285632, acc: 1.000000\n",
      "epoch 0, iter 1536, loss: 3.640163, acc: 0.750000\n",
      "epoch 0, iter 1537, loss: 3.774028, acc: 0.875000\n",
      "epoch 0, iter 1538, loss: 3.567466, acc: 0.875000\n",
      "epoch 0, iter 1539, loss: 3.365037, acc: 1.000000\n",
      "epoch 0, iter 1540, loss: 3.155543, acc: 1.000000\n",
      "epoch 0, iter 1541, loss: 3.761878, acc: 1.000000\n",
      "epoch 0, iter 1542, loss: 3.407061, acc: 1.000000\n",
      "epoch 0, iter 1543, loss: 3.107868, acc: 1.000000\n",
      "epoch 0, iter 1544, loss: 3.231371, acc: 0.625000\n",
      "epoch 0, iter 1545, loss: 3.351189, acc: 1.000000\n",
      "epoch 0, iter 1546, loss: 4.271756, acc: 0.750000\n",
      "epoch 0, iter 1547, loss: 5.590396, acc: 0.750000\n",
      "epoch 0, iter 1548, loss: 5.022906, acc: 0.875000\n",
      "epoch 0, iter 1549, loss: 4.298469, acc: 1.000000\n",
      "epoch 0, iter 1550, loss: 3.721007, acc: 1.000000\n",
      "epoch 0, iter 1551, loss: 3.296307, acc: 1.000000\n",
      "epoch 0, iter 1552, loss: 3.042862, acc: 1.000000\n",
      "epoch 0, iter 1553, loss: 2.832041, acc: 1.000000\n",
      "epoch 0, iter 1554, loss: 3.090344, acc: 1.000000\n",
      "epoch 0, iter 1555, loss: 3.736073, acc: 1.000000\n",
      "epoch 0, iter 1556, loss: 3.599350, acc: 1.000000\n",
      "epoch 0, iter 1557, loss: 3.282445, acc: 1.000000\n",
      "epoch 0, iter 1558, loss: 3.006812, acc: 1.000000\n",
      "epoch 0, iter 1559, loss: 2.798444, acc: 1.000000\n",
      "epoch 0, iter 1560, loss: 2.645785, acc: 1.000000\n",
      "epoch 0, iter 1561, loss: 2.810675, acc: 1.000000\n",
      "epoch 0, iter 1562, loss: 3.494974, acc: 0.750000\n",
      "epoch 0, iter 1563, loss: 4.205439, acc: 1.000000\n",
      "epoch 0, iter 1564, loss: 3.768389, acc: 1.000000\n",
      "epoch 0, iter 1565, loss: 3.287812, acc: 1.000000\n",
      "epoch 0, iter 1566, loss: 2.909020, acc: 1.000000\n",
      "epoch 0, iter 1567, loss: 2.625143, acc: 1.000000\n",
      "epoch 0, iter 1568, loss: 3.838028, acc: 0.750000\n",
      "epoch 0, iter 1569, loss: 3.741716, acc: 0.875000\n",
      "epoch 0, iter 1570, loss: 3.282012, acc: 0.875000\n",
      "epoch 0, iter 1571, loss: 3.241064, acc: 0.750000\n",
      "epoch 0, iter 1572, loss: 3.808222, acc: 0.750000\n",
      "epoch 0, iter 1573, loss: 3.886708, acc: 1.000000\n",
      "epoch 0, iter 1574, loss: 3.399937, acc: 1.000000\n",
      "epoch 0, iter 1575, loss: 4.280075, acc: 0.875000\n",
      "epoch 0, iter 1576, loss: 4.151814, acc: 0.875000\n",
      "epoch 0, iter 1577, loss: 3.849330, acc: 1.000000\n",
      "epoch 0, iter 1578, loss: 3.479349, acc: 1.000000\n",
      "epoch 0, iter 1579, loss: 3.318987, acc: 1.000000\n",
      "epoch 0, iter 1580, loss: 3.155645, acc: 1.000000\n",
      "epoch 0, iter 1581, loss: 3.309193, acc: 1.000000\n",
      "epoch 0, iter 1582, loss: 4.519047, acc: 0.500000\n",
      "epoch 0, iter 1583, loss: 4.718541, acc: 0.875000\n",
      "epoch 0, iter 1584, loss: 4.260202, acc: 1.000000\n",
      "epoch 0, iter 1585, loss: 3.684325, acc: 1.000000\n",
      "epoch 0, iter 1586, loss: 3.701751, acc: 1.000000\n",
      "epoch 0, iter 1587, loss: 3.264337, acc: 1.000000\n",
      "epoch 0, iter 1588, loss: 2.869009, acc: 1.000000\n",
      "epoch 0, iter 1589, loss: 3.457268, acc: 0.875000\n",
      "epoch 0, iter 1590, loss: 4.206888, acc: 0.750000\n",
      "epoch 0, iter 1591, loss: 4.139162, acc: 0.750000\n",
      "epoch 0, iter 1592, loss: 4.230615, acc: 1.000000\n",
      "epoch 0, iter 1593, loss: 3.880264, acc: 1.000000\n",
      "epoch 0, iter 1594, loss: 3.548074, acc: 1.000000\n",
      "epoch 0, iter 1595, loss: 3.302658, acc: 1.000000\n",
      "epoch 0, iter 1596, loss: 2.764392, acc: 1.000000\n",
      "epoch 0, iter 1597, loss: 2.322912, acc: 1.000000\n",
      "epoch 0, iter 1598, loss: 4.313504, acc: 0.625000\n",
      "epoch 0, iter 1599, loss: 4.434470, acc: 1.000000\n",
      "epoch 0, iter 1600, loss: 5.027359, acc: 0.750000\n",
      "epoch 0, iter 1601, loss: 6.318088, acc: 0.875000\n",
      "epoch 0, iter 1602, loss: 5.560199, acc: 1.000000\n",
      "epoch 0, iter 1603, loss: 4.784179, acc: 1.000000\n",
      "epoch 0, iter 1604, loss: 5.247686, acc: 0.875000\n",
      "epoch 0, iter 1605, loss: 5.994940, acc: 1.000000\n",
      "epoch 0, iter 1606, loss: 5.017843, acc: 1.000000\n",
      "epoch 0, iter 1607, loss: 4.113025, acc: 1.000000\n",
      "epoch 0, iter 1608, loss: 3.299630, acc: 1.000000\n",
      "epoch 0, iter 1609, loss: 3.845216, acc: 0.750000\n",
      "epoch 0, iter 1610, loss: 3.558977, acc: 1.000000\n",
      "epoch 0, iter 1611, loss: 3.218777, acc: 1.000000\n",
      "epoch 0, iter 1612, loss: 3.172028, acc: 1.000000\n",
      "epoch 0, iter 1613, loss: 2.894031, acc: 1.000000\n",
      "epoch 0, iter 1614, loss: 3.337223, acc: 0.875000\n",
      "epoch 0, iter 1615, loss: 3.164587, acc: 1.000000\n",
      "epoch 0, iter 1616, loss: 4.177853, acc: 0.875000\n",
      "epoch 0, iter 1617, loss: 3.763865, acc: 1.000000\n",
      "epoch 0, iter 1618, loss: 3.494359, acc: 0.875000\n",
      "epoch 0, iter 1619, loss: 3.566559, acc: 1.000000\n",
      "epoch 0, iter 1620, loss: 3.137724, acc: 1.000000\n",
      "epoch 0, iter 1621, loss: 2.871432, acc: 0.875000\n",
      "epoch 0, iter 1622, loss: 2.894295, acc: 0.875000\n",
      "epoch 0, iter 1623, loss: 3.218448, acc: 0.750000\n",
      "epoch 0, iter 1624, loss: 2.958721, acc: 0.875000\n",
      "epoch 0, iter 1625, loss: 3.224280, acc: 0.875000\n",
      "epoch 0, iter 1626, loss: 2.915677, acc: 1.000000\n",
      "epoch 0, iter 1627, loss: 3.286273, acc: 0.875000\n",
      "epoch 0, iter 1628, loss: 3.434135, acc: 0.875000\n",
      "epoch 0, iter 1629, loss: 3.180111, acc: 1.000000\n",
      "epoch 0, iter 1630, loss: 2.784339, acc: 1.000000\n",
      "epoch 0, iter 1631, loss: 3.067873, acc: 0.875000\n",
      "epoch 0, iter 1632, loss: 3.714569, acc: 1.000000\n",
      "epoch 0, iter 1633, loss: 3.256590, acc: 1.000000\n",
      "epoch 0, iter 1634, loss: 3.860791, acc: 1.000000\n",
      "epoch 0, iter 1635, loss: 5.579307, acc: 1.000000\n",
      "epoch 0, iter 1636, loss: 5.317264, acc: 0.875000\n",
      "epoch 0, iter 1637, loss: 4.700494, acc: 1.000000\n",
      "epoch 0, iter 1638, loss: 4.000744, acc: 1.000000\n",
      "epoch 0, iter 1639, loss: 3.349131, acc: 1.000000\n",
      "epoch 0, iter 1640, loss: 2.889293, acc: 1.000000\n",
      "epoch 0, iter 1641, loss: 2.542524, acc: 1.000000\n",
      "epoch 0, iter 1642, loss: 3.014056, acc: 1.000000\n",
      "epoch 0, iter 1643, loss: 3.458909, acc: 1.000000\n",
      "epoch 0, iter 1644, loss: 3.483381, acc: 0.875000\n",
      "epoch 0, iter 1645, loss: 3.377372, acc: 1.000000\n",
      "epoch 0, iter 1646, loss: 4.301173, acc: 1.000000\n",
      "epoch 0, iter 1647, loss: 5.700754, acc: 0.625000\n",
      "epoch 0, iter 1648, loss: 5.639920, acc: 0.750000\n",
      "epoch 0, iter 1649, loss: 5.164208, acc: 1.000000\n",
      "epoch 0, iter 1650, loss: 4.643837, acc: 1.000000\n",
      "epoch 0, iter 1651, loss: 4.132960, acc: 1.000000\n",
      "epoch 0, iter 1652, loss: 3.991427, acc: 1.000000\n",
      "epoch 0, iter 1653, loss: 3.426203, acc: 1.000000\n",
      "epoch 0, iter 1654, loss: 3.364029, acc: 1.000000\n",
      "epoch 0, iter 1655, loss: 3.094050, acc: 1.000000\n",
      "epoch 0, iter 1656, loss: 3.712953, acc: 0.875000\n",
      "epoch 0, iter 1657, loss: 3.917948, acc: 1.000000\n",
      "epoch 0, iter 1658, loss: 4.776474, acc: 0.750000\n",
      "epoch 0, iter 1659, loss: 4.487581, acc: 0.875000\n",
      "epoch 0, iter 1660, loss: 3.783696, acc: 1.000000\n",
      "epoch 0, iter 1661, loss: 3.747686, acc: 0.875000\n",
      "epoch 0, iter 1662, loss: 4.042213, acc: 0.875000\n",
      "epoch 0, iter 1663, loss: 3.616459, acc: 1.000000\n",
      "epoch 0, iter 1664, loss: 3.132894, acc: 1.000000\n",
      "epoch 0, iter 1665, loss: 2.760109, acc: 1.000000\n",
      "epoch 0, iter 1666, loss: 2.831249, acc: 1.000000\n",
      "epoch 0, iter 1667, loss: 3.907329, acc: 0.750000\n",
      "epoch 0, iter 1668, loss: 3.464453, acc: 1.000000\n",
      "epoch 0, iter 1669, loss: 3.016138, acc: 1.000000\n",
      "epoch 0, iter 1670, loss: 3.087979, acc: 1.000000\n",
      "epoch 0, iter 1671, loss: 2.973097, acc: 1.000000\n",
      "epoch 0, iter 1672, loss: 2.890186, acc: 1.000000\n",
      "epoch 0, iter 1673, loss: 3.472761, acc: 0.875000\n",
      "epoch 0, iter 1674, loss: 3.170323, acc: 1.000000\n",
      "epoch 0, iter 1675, loss: 3.206431, acc: 1.000000\n",
      "epoch 0, iter 1676, loss: 3.774597, acc: 0.875000\n",
      "epoch 0, iter 1677, loss: 3.431745, acc: 1.000000\n",
      "epoch 0, iter 1678, loss: 3.010025, acc: 1.000000\n",
      "epoch 0, iter 1679, loss: 3.039148, acc: 1.000000\n",
      "epoch 0, iter 1680, loss: 2.794341, acc: 1.000000\n",
      "epoch 0, iter 1681, loss: 2.519374, acc: 1.000000\n",
      "epoch 0, iter 1682, loss: 2.598074, acc: 1.000000\n",
      "epoch 0, iter 1683, loss: 2.542918, acc: 1.000000\n",
      "epoch 0, iter 1684, loss: 2.653990, acc: 1.000000\n",
      "epoch 0, iter 1685, loss: 2.457037, acc: 1.000000\n",
      "epoch 0, iter 1686, loss: 2.462484, acc: 1.000000\n",
      "epoch 0, iter 1687, loss: 2.388361, acc: 1.000000\n",
      "epoch 0, iter 1688, loss: 1.894577, acc: 1.000000\n",
      "epoch 0, iter 1689, loss: 3.440720, acc: 0.750000\n",
      "epoch 0, iter 1690, loss: 3.467700, acc: 0.875000\n",
      "epoch 0, iter 1691, loss: 4.714968, acc: 0.750000\n",
      "epoch 0, iter 1692, loss: 4.145191, acc: 1.000000\n",
      "epoch 0, iter 1693, loss: 4.247339, acc: 0.875000\n",
      "epoch 0, iter 1694, loss: 3.818756, acc: 1.000000\n",
      "epoch 0, iter 1695, loss: 3.512283, acc: 1.000000\n",
      "epoch 0, iter 1696, loss: 3.212846, acc: 1.000000\n",
      "epoch 0, iter 1697, loss: 3.290871, acc: 0.875000\n",
      "epoch 0, iter 1698, loss: 3.317569, acc: 1.000000\n",
      "epoch 0, iter 1699, loss: 2.972019, acc: 1.000000\n",
      "epoch 0, iter 1700, loss: 2.631403, acc: 1.000000\n",
      "epoch 0, iter 1701, loss: 2.655010, acc: 1.000000\n",
      "epoch 0, iter 1702, loss: 2.587173, acc: 1.000000\n",
      "epoch 0, iter 1703, loss: 2.637012, acc: 1.000000\n",
      "epoch 0, iter 1704, loss: 2.494263, acc: 1.000000\n",
      "epoch 0, iter 1705, loss: 2.401721, acc: 1.000000\n",
      "epoch 0, iter 1706, loss: 2.036421, acc: 1.000000\n",
      "epoch 0, iter 1707, loss: 2.214562, acc: 0.875000\n",
      "epoch 0, iter 1708, loss: 1.961540, acc: 1.000000\n",
      "epoch 0, iter 1709, loss: 2.465436, acc: 0.875000\n",
      "epoch 0, iter 1710, loss: 2.344955, acc: 1.000000\n",
      "epoch 0, iter 1711, loss: 2.949449, acc: 0.875000\n",
      "epoch 0, iter 1712, loss: 2.988913, acc: 1.000000\n",
      "epoch 0, iter 1713, loss: 2.603882, acc: 1.000000\n",
      "epoch 0, iter 1714, loss: 2.606311, acc: 0.875000\n",
      "epoch 0, iter 1715, loss: 2.959435, acc: 1.000000\n",
      "epoch 0, iter 1716, loss: 2.690157, acc: 1.000000\n",
      "epoch 0, iter 1717, loss: 2.274529, acc: 1.000000\n",
      "epoch 0, iter 1718, loss: 2.511506, acc: 0.875000\n",
      "epoch 0, iter 1719, loss: 2.297534, acc: 1.000000\n",
      "epoch 0, iter 1720, loss: 2.064479, acc: 1.000000\n",
      "epoch 0, iter 1721, loss: 1.876116, acc: 1.000000\n",
      "epoch 0, iter 1722, loss: 1.735347, acc: 1.000000\n",
      "epoch 0, iter 1723, loss: 1.632429, acc: 1.000000\n",
      "epoch 0, iter 1724, loss: 1.557359, acc: 1.000000\n",
      "epoch 0, iter 1725, loss: 1.930043, acc: 1.000000\n",
      "epoch 0, iter 1726, loss: 2.338884, acc: 0.875000\n",
      "epoch 0, iter 1727, loss: 2.197279, acc: 1.000000\n",
      "epoch 0, iter 1728, loss: 2.003701, acc: 1.000000\n",
      "epoch 0, iter 1729, loss: 2.204669, acc: 1.000000\n",
      "epoch 0, iter 1730, loss: 2.075668, acc: 1.000000\n",
      "epoch 0, iter 1731, loss: 1.895146, acc: 1.000000\n",
      "epoch 0, iter 1732, loss: 1.740562, acc: 1.000000\n",
      "epoch 0, iter 1733, loss: 1.987712, acc: 1.000000\n",
      "epoch 0, iter 1734, loss: 1.914424, acc: 1.000000\n",
      "epoch 0, iter 1735, loss: 1.951227, acc: 1.000000\n",
      "epoch 0, iter 1736, loss: 1.942373, acc: 1.000000\n",
      "epoch 0, iter 1737, loss: 1.927027, acc: 1.000000\n",
      "epoch 0, iter 1738, loss: 2.871203, acc: 0.875000\n",
      "epoch 0, iter 1739, loss: 2.652874, acc: 1.000000\n",
      "epoch 0, iter 1740, loss: 3.357132, acc: 1.000000\n",
      "epoch 0, iter 1741, loss: 3.255941, acc: 1.000000\n",
      "epoch 0, iter 1742, loss: 2.716804, acc: 1.000000\n",
      "epoch 0, iter 1743, loss: 2.304065, acc: 1.000000\n",
      "epoch 0, iter 1744, loss: 2.002007, acc: 1.000000\n",
      "epoch 0, iter 1745, loss: 2.208886, acc: 1.000000\n",
      "epoch 0, iter 1746, loss: 2.932350, acc: 0.875000\n",
      "epoch 0, iter 1747, loss: 2.865516, acc: 1.000000\n",
      "epoch 0, iter 1748, loss: 2.479386, acc: 1.000000\n",
      "epoch 0, iter 1749, loss: 3.753412, acc: 0.875000\n",
      "epoch 0, iter 1750, loss: 3.363021, acc: 1.000000\n",
      "epoch 0, iter 1751, loss: 2.859800, acc: 1.000000\n",
      "epoch 0, iter 1752, loss: 2.839434, acc: 1.000000\n",
      "epoch 0, iter 1753, loss: 3.408641, acc: 0.875000\n",
      "epoch 0, iter 1754, loss: 3.352069, acc: 1.000000\n",
      "epoch 0, iter 1755, loss: 3.719822, acc: 0.875000\n",
      "epoch 0, iter 1756, loss: 4.332584, acc: 0.875000\n",
      "epoch 0, iter 1757, loss: 4.654797, acc: 1.000000\n",
      "epoch 0, iter 1758, loss: 4.779869, acc: 0.750000\n",
      "epoch 0, iter 1759, loss: 4.738841, acc: 0.875000\n",
      "epoch 0, iter 1760, loss: 4.281527, acc: 1.000000\n",
      "epoch 0, iter 1761, loss: 3.688369, acc: 1.000000\n",
      "epoch 0, iter 1762, loss: 3.058011, acc: 1.000000\n",
      "epoch 0, iter 1763, loss: 2.541541, acc: 1.000000\n",
      "epoch 0, iter 1764, loss: 2.615601, acc: 0.875000\n",
      "epoch 0, iter 1765, loss: 2.307283, acc: 1.000000\n",
      "epoch 0, iter 1766, loss: 2.534591, acc: 0.875000\n",
      "epoch 0, iter 1767, loss: 2.592125, acc: 1.000000\n",
      "epoch 0, iter 1768, loss: 2.367565, acc: 1.000000\n",
      "epoch 0, iter 1769, loss: 2.079882, acc: 1.000000\n",
      "epoch 0, iter 1770, loss: 1.840032, acc: 1.000000\n",
      "epoch 0, iter 1771, loss: 1.659325, acc: 1.000000\n",
      "epoch 0, iter 1772, loss: 1.527297, acc: 1.000000\n",
      "epoch 0, iter 1773, loss: 1.431609, acc: 1.000000\n",
      "epoch 0, iter 1774, loss: 1.361999, acc: 1.000000\n",
      "epoch 0, iter 1775, loss: 1.310416, acc: 1.000000\n",
      "epoch 0, iter 1776, loss: 1.269026, acc: 1.000000\n",
      "epoch 0, iter 1777, loss: 1.864151, acc: 1.000000\n",
      "epoch 0, iter 1778, loss: 2.295641, acc: 0.875000\n",
      "epoch 0, iter 1779, loss: 2.336724, acc: 1.000000\n",
      "epoch 0, iter 1780, loss: 2.053842, acc: 1.000000\n",
      "epoch 0, iter 1781, loss: 1.813662, acc: 1.000000\n",
      "epoch 0, iter 1782, loss: 1.630389, acc: 1.000000\n",
      "epoch 0, iter 1783, loss: 1.495590, acc: 1.000000\n",
      "epoch 0, iter 1784, loss: 1.873087, acc: 0.875000\n",
      "epoch 0, iter 1785, loss: 1.780933, acc: 1.000000\n",
      "epoch 0, iter 1786, loss: 2.804482, acc: 0.875000\n",
      "epoch 0, iter 1787, loss: 2.683088, acc: 1.000000\n",
      "epoch 0, iter 1788, loss: 4.127554, acc: 1.000000\n",
      "epoch 0, iter 1789, loss: 3.850214, acc: 1.000000\n",
      "epoch 0, iter 1790, loss: 3.448571, acc: 1.000000\n",
      "epoch 0, iter 1791, loss: 3.172423, acc: 1.000000\n",
      "epoch 0, iter 1792, loss: 2.871005, acc: 1.000000\n",
      "epoch 0, iter 1793, loss: 4.228948, acc: 0.750000\n",
      "epoch 0, iter 1794, loss: 3.553862, acc: 1.000000\n",
      "epoch 0, iter 1795, loss: 3.398134, acc: 1.000000\n",
      "epoch 0, iter 1796, loss: 3.028202, acc: 1.000000\n",
      "epoch 0, iter 1797, loss: 2.605446, acc: 1.000000\n",
      "epoch 0, iter 1798, loss: 2.264945, acc: 1.000000\n",
      "epoch 0, iter 1799, loss: 2.970086, acc: 0.875000\n",
      "epoch 0, iter 1800, loss: 2.660329, acc: 1.000000\n",
      "epoch 0, iter 1801, loss: 2.318608, acc: 1.000000\n",
      "epoch 0, iter 1802, loss: 3.716698, acc: 0.750000\n",
      "epoch 0, iter 1803, loss: 3.356054, acc: 1.000000\n",
      "epoch 0, iter 1804, loss: 3.506784, acc: 0.875000\n",
      "epoch 0, iter 1805, loss: 3.073451, acc: 1.000000\n",
      "epoch 0, iter 1806, loss: 2.809649, acc: 1.000000\n",
      "epoch 0, iter 1807, loss: 3.886814, acc: 0.875000\n",
      "epoch 0, iter 1808, loss: 3.675157, acc: 1.000000\n",
      "epoch 0, iter 1809, loss: 3.058802, acc: 1.000000\n",
      "epoch 0, iter 1810, loss: 3.788141, acc: 0.625000\n",
      "epoch 0, iter 1811, loss: 5.495271, acc: 0.750000\n",
      "epoch 0, iter 1812, loss: 4.371795, acc: 1.000000\n",
      "epoch 0, iter 1813, loss: 3.807239, acc: 1.000000\n",
      "epoch 0, iter 1814, loss: 4.062931, acc: 0.500000\n",
      "epoch 0, iter 1815, loss: 3.714388, acc: 0.875000\n",
      "epoch 0, iter 1816, loss: 3.101370, acc: 1.000000\n",
      "epoch 0, iter 1817, loss: 2.618164, acc: 1.000000\n",
      "epoch 0, iter 1818, loss: 2.679105, acc: 1.000000\n",
      "epoch 0, iter 1819, loss: 2.615072, acc: 1.000000\n",
      "epoch 0, iter 1820, loss: 2.475501, acc: 1.000000\n",
      "epoch 0, iter 1821, loss: 2.328548, acc: 1.000000\n",
      "epoch 0, iter 1822, loss: 2.291213, acc: 1.000000\n",
      "epoch 0, iter 1823, loss: 2.386844, acc: 1.000000\n",
      "epoch 0, iter 1824, loss: 2.270463, acc: 1.000000\n",
      "epoch 0, iter 1825, loss: 2.222226, acc: 1.000000\n",
      "epoch 0, iter 1826, loss: 2.128005, acc: 1.000000\n",
      "epoch 0, iter 1827, loss: 2.109622, acc: 1.000000\n",
      "epoch 0, iter 1828, loss: 1.951380, acc: 1.000000\n",
      "epoch 0, iter 1829, loss: 1.791656, acc: 1.000000\n",
      "epoch 0, iter 1830, loss: 1.662919, acc: 1.000000\n",
      "epoch 0, iter 1831, loss: 1.974815, acc: 1.000000\n",
      "epoch 0, iter 1832, loss: 2.112644, acc: 1.000000\n",
      "epoch 0, iter 1833, loss: 2.152579, acc: 1.000000\n",
      "epoch 0, iter 1834, loss: 1.980687, acc: 1.000000\n",
      "epoch 0, iter 1835, loss: 1.804566, acc: 1.000000\n",
      "epoch 0, iter 1836, loss: 2.139551, acc: 0.875000\n",
      "epoch 0, iter 1837, loss: 2.832726, acc: 0.875000\n",
      "epoch 0, iter 1838, loss: 3.202110, acc: 1.000000\n",
      "epoch 0, iter 1839, loss: 4.626656, acc: 0.500000\n",
      "epoch 0, iter 1840, loss: 4.950046, acc: 0.750000\n",
      "epoch 0, iter 1841, loss: 4.435200, acc: 0.750000\n",
      "epoch 0, iter 1842, loss: 3.986275, acc: 1.000000\n",
      "epoch 0, iter 1843, loss: 3.284745, acc: 1.000000\n",
      "epoch 0, iter 1844, loss: 2.700643, acc: 1.000000\n",
      "epoch 0, iter 1845, loss: 2.718737, acc: 1.000000\n",
      "epoch 0, iter 1846, loss: 2.471010, acc: 1.000000\n",
      "epoch 0, iter 1847, loss: 2.467633, acc: 1.000000\n",
      "epoch 0, iter 1848, loss: 2.214882, acc: 1.000000\n",
      "epoch 0, iter 1849, loss: 2.102302, acc: 1.000000\n",
      "epoch 0, iter 1850, loss: 1.828862, acc: 1.000000\n",
      "epoch 0, iter 1851, loss: 2.754181, acc: 0.750000\n",
      "epoch 0, iter 1852, loss: 2.792658, acc: 0.750000\n",
      "epoch 0, iter 1853, loss: 3.187134, acc: 0.875000\n",
      "epoch 0, iter 1854, loss: 2.922595, acc: 1.000000\n",
      "epoch 0, iter 1855, loss: 3.325590, acc: 0.875000\n",
      "epoch 0, iter 1856, loss: 3.591586, acc: 1.000000\n",
      "epoch 0, iter 1857, loss: 3.039472, acc: 1.000000\n",
      "epoch 0, iter 1858, loss: 3.232353, acc: 1.000000\n",
      "epoch 0, iter 1859, loss: 3.180506, acc: 1.000000\n",
      "epoch 0, iter 1860, loss: 2.513504, acc: 1.000000\n",
      "epoch 0, iter 1861, loss: 3.011977, acc: 1.000000\n",
      "epoch 0, iter 1862, loss: 2.910862, acc: 1.000000\n",
      "epoch 0, iter 1863, loss: 2.509508, acc: 1.000000\n",
      "epoch 0, iter 1864, loss: 3.049281, acc: 0.875000\n",
      "epoch 0, iter 1865, loss: 3.226034, acc: 1.000000\n",
      "epoch 0, iter 1866, loss: 2.693036, acc: 1.000000\n",
      "epoch 0, iter 1867, loss: 2.215122, acc: 1.000000\n",
      "epoch 0, iter 1868, loss: 1.814488, acc: 1.000000\n",
      "epoch 0, iter 1869, loss: 2.247923, acc: 0.875000\n",
      "epoch 0, iter 1870, loss: 2.150983, acc: 1.000000\n",
      "epoch 0, iter 1871, loss: 2.051726, acc: 1.000000\n",
      "epoch 0, iter 1872, loss: 1.773297, acc: 1.000000\n",
      "epoch 0, iter 1873, loss: 2.255586, acc: 0.875000\n",
      "epoch 0, iter 1874, loss: 2.959083, acc: 0.750000\n",
      "epoch 0, iter 1875, loss: 2.768191, acc: 1.000000\n",
      "epoch 0, iter 1876, loss: 2.384467, acc: 1.000000\n",
      "epoch 0, iter 1877, loss: 2.394658, acc: 0.875000\n",
      "epoch 0, iter 1878, loss: 2.172013, acc: 1.000000\n",
      "epoch 0, iter 1879, loss: 2.242525, acc: 1.000000\n",
      "epoch 0, iter 1880, loss: 2.254959, acc: 1.000000\n",
      "epoch 0, iter 1881, loss: 3.204707, acc: 0.875000\n",
      "epoch 0, iter 1882, loss: 3.224397, acc: 1.000000\n",
      "epoch 0, iter 1883, loss: 3.712116, acc: 0.875000\n",
      "epoch 0, iter 1884, loss: 3.467809, acc: 0.875000\n",
      "epoch 0, iter 1885, loss: 3.386291, acc: 1.000000\n",
      "epoch 0, iter 1886, loss: 2.923000, acc: 1.000000\n",
      "epoch 0, iter 1887, loss: 2.457508, acc: 1.000000\n",
      "epoch 0, iter 1888, loss: 2.488788, acc: 1.000000\n",
      "epoch 0, iter 1889, loss: 2.226557, acc: 1.000000\n",
      "epoch 0, iter 1890, loss: 1.942040, acc: 1.000000\n",
      "epoch 0, iter 1891, loss: 1.701557, acc: 1.000000\n",
      "epoch 0, iter 1892, loss: 2.012934, acc: 0.875000\n",
      "epoch 0, iter 1893, loss: 1.840322, acc: 1.000000\n",
      "epoch 0, iter 1894, loss: 1.986762, acc: 1.000000\n",
      "epoch 0, iter 1895, loss: 2.191383, acc: 1.000000\n",
      "epoch 0, iter 1896, loss: 2.813070, acc: 0.875000\n",
      "epoch 0, iter 1897, loss: 2.554193, acc: 1.000000\n",
      "epoch 0, iter 1898, loss: 3.925265, acc: 0.375000\n",
      "epoch 0, iter 1899, loss: 3.544763, acc: 1.000000\n",
      "epoch 0, iter 1900, loss: 3.104479, acc: 1.000000\n",
      "epoch 0, iter 1901, loss: 3.686431, acc: 0.875000\n",
      "epoch 0, iter 1902, loss: 3.147296, acc: 1.000000\n",
      "epoch 0, iter 1903, loss: 2.604979, acc: 1.000000\n",
      "epoch 0, iter 1904, loss: 2.870028, acc: 1.000000\n",
      "epoch 0, iter 1905, loss: 2.560488, acc: 1.000000\n",
      "epoch 0, iter 1906, loss: 3.257855, acc: 0.875000\n",
      "epoch 0, iter 1907, loss: 2.777249, acc: 1.000000\n",
      "epoch 0, iter 1908, loss: 3.741448, acc: 0.750000\n",
      "epoch 0, iter 1909, loss: 3.417291, acc: 0.875000\n",
      "epoch 0, iter 1910, loss: 3.942895, acc: 0.875000\n",
      "epoch 0, iter 1911, loss: 5.216855, acc: 1.000000\n",
      "epoch 0, iter 1912, loss: 4.166589, acc: 1.000000\n",
      "epoch 0, iter 1913, loss: 4.014565, acc: 1.000000\n",
      "epoch 0, iter 1914, loss: 3.886067, acc: 0.875000\n",
      "epoch 0, iter 1915, loss: 4.189177, acc: 0.500000\n",
      "epoch 0, iter 1916, loss: 4.402899, acc: 1.000000\n",
      "epoch 0, iter 1917, loss: 3.568264, acc: 1.000000\n",
      "epoch 0, iter 1918, loss: 3.381728, acc: 0.875000\n",
      "epoch 0, iter 1919, loss: 2.887789, acc: 1.000000\n",
      "epoch 0, iter 1920, loss: 2.605846, acc: 1.000000\n",
      "epoch 0, iter 1921, loss: 2.549069, acc: 1.000000\n",
      "epoch 0, iter 1922, loss: 2.392883, acc: 1.000000\n",
      "epoch 0, iter 1923, loss: 2.082543, acc: 1.000000\n",
      "epoch 0, iter 1924, loss: 2.177589, acc: 0.875000\n",
      "epoch 0, iter 1925, loss: 2.012563, acc: 1.000000\n",
      "epoch 0, iter 1926, loss: 2.688773, acc: 1.000000\n",
      "epoch 0, iter 1927, loss: 2.386722, acc: 1.000000\n",
      "epoch 0, iter 1928, loss: 2.067540, acc: 1.000000\n",
      "epoch 0, iter 1929, loss: 2.320262, acc: 0.875000\n",
      "epoch 0, iter 1930, loss: 2.135984, acc: 1.000000\n",
      "epoch 0, iter 1931, loss: 2.076307, acc: 1.000000\n",
      "epoch 0, iter 1932, loss: 1.974957, acc: 1.000000\n",
      "epoch 0, iter 1933, loss: 1.770346, acc: 1.000000\n",
      "epoch 0, iter 1934, loss: 1.575617, acc: 1.000000\n",
      "epoch 0, iter 1935, loss: 1.799290, acc: 1.000000\n",
      "epoch 0, iter 1936, loss: 2.660739, acc: 0.875000\n",
      "epoch 0, iter 1937, loss: 2.578685, acc: 1.000000\n",
      "epoch 0, iter 1938, loss: 2.513565, acc: 1.000000\n",
      "epoch 0, iter 1939, loss: 2.270864, acc: 1.000000\n",
      "epoch 0, iter 1940, loss: 1.969284, acc: 1.000000\n",
      "epoch 0, iter 1941, loss: 2.039252, acc: 1.000000\n",
      "epoch 0, iter 1942, loss: 1.871386, acc: 1.000000\n",
      "epoch 0, iter 1943, loss: 3.395875, acc: 0.875000\n",
      "epoch 0, iter 1944, loss: 3.810040, acc: 1.000000\n",
      "epoch 0, iter 1945, loss: 3.407441, acc: 1.000000\n",
      "epoch 0, iter 1946, loss: 3.249488, acc: 0.875000\n",
      "epoch 0, iter 1947, loss: 2.777851, acc: 1.000000\n",
      "epoch 0, iter 1948, loss: 2.317281, acc: 1.000000\n",
      "epoch 0, iter 1949, loss: 2.289607, acc: 1.000000\n",
      "epoch 0, iter 1950, loss: 2.042832, acc: 1.000000\n",
      "epoch 0, iter 1951, loss: 2.258959, acc: 0.875000\n",
      "epoch 0, iter 1952, loss: 2.123408, acc: 1.000000\n",
      "epoch 0, iter 1953, loss: 2.283865, acc: 1.000000\n",
      "epoch 0, iter 1954, loss: 2.308765, acc: 1.000000\n",
      "epoch 0, iter 1955, loss: 2.812456, acc: 0.875000\n",
      "epoch 0, iter 1956, loss: 3.253707, acc: 0.750000\n",
      "epoch 0, iter 1957, loss: 2.757804, acc: 1.000000\n",
      "epoch 0, iter 1958, loss: 3.699250, acc: 0.875000\n",
      "epoch 0, iter 1959, loss: 3.183973, acc: 1.000000\n",
      "epoch 0, iter 1960, loss: 2.851356, acc: 1.000000\n",
      "epoch 0, iter 1961, loss: 2.701684, acc: 1.000000\n",
      "epoch 0, iter 1962, loss: 2.330484, acc: 1.000000\n",
      "epoch 0, iter 1963, loss: 1.979420, acc: 1.000000\n",
      "epoch 0, iter 1964, loss: 1.696721, acc: 1.000000\n",
      "epoch 0, iter 1965, loss: 1.839077, acc: 1.000000\n",
      "epoch 0, iter 1966, loss: 1.701380, acc: 1.000000\n",
      "epoch 0, iter 1967, loss: 2.117156, acc: 0.875000\n",
      "epoch 0, iter 1968, loss: 2.060302, acc: 1.000000\n",
      "epoch 0, iter 1969, loss: 3.958966, acc: 0.750000\n",
      "epoch 0, iter 1970, loss: 3.354480, acc: 1.000000\n",
      "epoch 0, iter 1971, loss: 2.924928, acc: 1.000000\n",
      "epoch 0, iter 1972, loss: 2.471178, acc: 1.000000\n",
      "epoch 0, iter 1973, loss: 2.101935, acc: 1.000000\n",
      "epoch 0, iter 1974, loss: 1.823271, acc: 1.000000\n",
      "epoch 0, iter 1975, loss: 2.043273, acc: 0.875000\n",
      "epoch 0, iter 1976, loss: 1.880127, acc: 1.000000\n",
      "epoch 0, iter 1977, loss: 2.096884, acc: 1.000000\n",
      "epoch 0, iter 1978, loss: 2.500504, acc: 1.000000\n",
      "epoch 0, iter 1979, loss: 2.309477, acc: 1.000000\n",
      "epoch 0, iter 1980, loss: 2.391842, acc: 0.875000\n",
      "epoch 0, iter 1981, loss: 2.863745, acc: 1.000000\n",
      "epoch 0, iter 1982, loss: 2.533419, acc: 1.000000\n",
      "epoch 0, iter 1983, loss: 4.476189, acc: 0.625000\n",
      "epoch 0, iter 1984, loss: 4.520638, acc: 0.875000\n",
      "epoch 0, iter 1985, loss: 4.540823, acc: 0.875000\n",
      "epoch 0, iter 1986, loss: 4.343931, acc: 1.000000\n",
      "epoch 0, iter 1987, loss: 3.516777, acc: 1.000000\n",
      "epoch 0, iter 1988, loss: 2.829010, acc: 1.000000\n",
      "epoch 0, iter 1989, loss: 2.304522, acc: 1.000000\n",
      "epoch 0, iter 1990, loss: 2.403300, acc: 0.875000\n",
      "epoch 0, iter 1991, loss: 3.549987, acc: 0.625000\n",
      "epoch 0, iter 1992, loss: 3.060178, acc: 1.000000\n",
      "epoch 0, iter 1993, loss: 2.401800, acc: 1.000000\n",
      "epoch 0, iter 1994, loss: 1.913075, acc: 1.000000\n",
      "epoch 0, iter 1995, loss: 2.021578, acc: 0.875000\n",
      "epoch 0, iter 1996, loss: 2.582238, acc: 0.875000\n",
      "epoch 0, iter 1997, loss: 2.161037, acc: 1.000000\n",
      "epoch 0, iter 1998, loss: 1.712774, acc: 1.000000\n",
      "epoch 0, iter 1999, loss: 1.366028, acc: 1.000000\n",
      "epoch 0, acc: 0.772687\n",
      "epoch 1, iter 0, loss: 15.146197, acc: 0.375000\n",
      "epoch 1, iter 1, loss: 36.070038, acc: 0.000000\n",
      "epoch 1, iter 2, loss: 36.018669, acc: 0.500000\n",
      "epoch 1, iter 3, loss: 43.645524, acc: 0.000000\n",
      "epoch 1, iter 4, loss: 41.527938, acc: 0.125000\n",
      "epoch 1, iter 5, loss: 36.114020, acc: 0.250000\n",
      "epoch 1, iter 6, loss: 29.508226, acc: 0.625000\n",
      "epoch 1, iter 7, loss: 27.484149, acc: 0.250000\n",
      "epoch 1, iter 8, loss: 22.312842, acc: 0.250000\n",
      "epoch 1, iter 9, loss: 19.211339, acc: 0.250000\n",
      "epoch 1, iter 10, loss: 17.090038, acc: 0.250000\n",
      "epoch 1, iter 11, loss: 15.715869, acc: 0.500000\n",
      "epoch 1, iter 12, loss: 13.986947, acc: 0.500000\n",
      "epoch 1, iter 13, loss: 12.149500, acc: 0.375000\n",
      "epoch 1, iter 14, loss: 9.682874, acc: 0.875000\n",
      "epoch 1, iter 15, loss: 8.157895, acc: 0.750000\n",
      "epoch 1, iter 16, loss: 7.721211, acc: 0.625000\n",
      "epoch 1, iter 17, loss: 6.907922, acc: 0.875000\n",
      "epoch 1, iter 18, loss: 6.638172, acc: 0.625000\n",
      "epoch 1, iter 19, loss: 6.185011, acc: 0.625000\n",
      "epoch 1, iter 20, loss: 5.630268, acc: 0.625000\n",
      "epoch 1, iter 21, loss: 5.135288, acc: 0.750000\n",
      "epoch 1, iter 22, loss: 5.200121, acc: 0.500000\n",
      "epoch 1, iter 23, loss: 4.864977, acc: 0.750000\n",
      "epoch 1, iter 24, loss: 4.894330, acc: 0.625000\n",
      "epoch 1, iter 25, loss: 5.108991, acc: 0.750000\n",
      "epoch 1, iter 26, loss: 5.012040, acc: 0.750000\n",
      "epoch 1, iter 27, loss: 4.758603, acc: 0.875000\n",
      "epoch 1, iter 28, loss: 4.561831, acc: 0.750000\n",
      "epoch 1, iter 29, loss: 4.404783, acc: 0.750000\n",
      "epoch 1, iter 30, loss: 4.501161, acc: 0.750000\n",
      "epoch 1, iter 31, loss: 4.172970, acc: 1.000000\n",
      "epoch 1, iter 32, loss: 4.408784, acc: 0.875000\n",
      "epoch 1, iter 33, loss: 4.330345, acc: 0.875000\n",
      "epoch 1, iter 34, loss: 4.217911, acc: 0.875000\n",
      "epoch 1, iter 35, loss: 4.119043, acc: 0.750000\n",
      "epoch 1, iter 36, loss: 4.038872, acc: 0.750000\n",
      "epoch 1, iter 37, loss: 4.213573, acc: 0.875000\n",
      "epoch 1, iter 38, loss: 4.061487, acc: 0.750000\n",
      "epoch 1, iter 39, loss: 3.805240, acc: 1.000000\n",
      "epoch 1, iter 40, loss: 3.852206, acc: 0.875000\n",
      "epoch 1, iter 41, loss: 3.705835, acc: 0.875000\n",
      "epoch 1, iter 42, loss: 4.146154, acc: 0.750000\n",
      "epoch 1, iter 43, loss: 3.966444, acc: 1.000000\n",
      "epoch 1, iter 44, loss: 4.671353, acc: 0.875000\n",
      "epoch 1, iter 45, loss: 4.614953, acc: 0.875000\n",
      "epoch 1, iter 46, loss: 4.541280, acc: 0.750000\n",
      "epoch 1, iter 47, loss: 4.627049, acc: 0.875000\n",
      "epoch 1, iter 48, loss: 5.087863, acc: 0.875000\n",
      "epoch 1, iter 49, loss: 5.081582, acc: 0.875000\n",
      "epoch 1, iter 50, loss: 5.056581, acc: 0.875000\n",
      "epoch 1, iter 51, loss: 4.778700, acc: 0.875000\n",
      "epoch 1, iter 52, loss: 4.702271, acc: 1.000000\n",
      "epoch 1, iter 53, loss: 4.824743, acc: 0.875000\n",
      "epoch 1, iter 54, loss: 4.544866, acc: 0.875000\n",
      "epoch 1, iter 55, loss: 4.188637, acc: 1.000000\n",
      "epoch 1, iter 56, loss: 4.226769, acc: 0.875000\n",
      "epoch 1, iter 57, loss: 4.192058, acc: 0.750000\n",
      "epoch 1, iter 58, loss: 3.939706, acc: 1.000000\n",
      "epoch 1, iter 59, loss: 3.495529, acc: 1.000000\n",
      "epoch 1, iter 60, loss: 3.287176, acc: 1.000000\n",
      "epoch 1, iter 61, loss: 3.014088, acc: 1.000000\n",
      "epoch 1, iter 62, loss: 2.725157, acc: 1.000000\n",
      "epoch 1, iter 63, loss: 2.490969, acc: 1.000000\n",
      "epoch 1, iter 64, loss: 2.808514, acc: 0.875000\n",
      "epoch 1, iter 65, loss: 2.601988, acc: 1.000000\n",
      "epoch 1, iter 66, loss: 2.403116, acc: 1.000000\n",
      "epoch 1, iter 67, loss: 2.536762, acc: 1.000000\n",
      "epoch 1, iter 68, loss: 3.022339, acc: 1.000000\n",
      "epoch 1, iter 69, loss: 2.910347, acc: 1.000000\n",
      "epoch 1, iter 70, loss: 2.629361, acc: 1.000000\n",
      "epoch 1, iter 71, loss: 2.659666, acc: 1.000000\n",
      "epoch 1, iter 72, loss: 2.906962, acc: 1.000000\n",
      "epoch 1, iter 73, loss: 2.692099, acc: 1.000000\n",
      "epoch 1, iter 74, loss: 2.791965, acc: 0.875000\n",
      "epoch 1, iter 75, loss: 2.509806, acc: 1.000000\n",
      "epoch 1, iter 76, loss: 3.821248, acc: 0.750000\n",
      "epoch 1, iter 77, loss: 3.241353, acc: 1.000000\n",
      "epoch 1, iter 78, loss: 3.147307, acc: 1.000000\n",
      "epoch 1, iter 79, loss: 3.036457, acc: 0.875000\n",
      "epoch 1, iter 80, loss: 3.673029, acc: 0.875000\n",
      "epoch 1, iter 81, loss: 3.357082, acc: 1.000000\n",
      "epoch 1, iter 82, loss: 2.942963, acc: 1.000000\n",
      "epoch 1, iter 83, loss: 3.172002, acc: 1.000000\n",
      "epoch 1, iter 84, loss: 3.075866, acc: 1.000000\n",
      "epoch 1, iter 85, loss: 2.925116, acc: 1.000000\n",
      "epoch 1, iter 86, loss: 3.313508, acc: 1.000000\n",
      "epoch 1, iter 87, loss: 3.310866, acc: 1.000000\n",
      "epoch 1, iter 88, loss: 3.231603, acc: 1.000000\n",
      "epoch 1, iter 89, loss: 3.265528, acc: 0.875000\n",
      "epoch 1, iter 90, loss: 2.928007, acc: 1.000000\n",
      "epoch 1, iter 91, loss: 2.760266, acc: 1.000000\n",
      "epoch 1, iter 92, loss: 3.369977, acc: 1.000000\n",
      "epoch 1, iter 93, loss: 3.098276, acc: 1.000000\n",
      "epoch 1, iter 94, loss: 3.056485, acc: 0.875000\n",
      "epoch 1, iter 95, loss: 2.684454, acc: 1.000000\n",
      "epoch 1, iter 96, loss: 2.629736, acc: 0.875000\n",
      "epoch 1, iter 97, loss: 2.429397, acc: 1.000000\n",
      "epoch 1, iter 98, loss: 2.681384, acc: 1.000000\n",
      "epoch 1, iter 99, loss: 2.660652, acc: 1.000000\n",
      "epoch 1, iter 100, loss: 2.608232, acc: 1.000000\n",
      "epoch 1, iter 101, loss: 3.448071, acc: 1.000000\n",
      "epoch 1, iter 102, loss: 4.187289, acc: 0.875000\n",
      "epoch 1, iter 103, loss: 3.662619, acc: 1.000000\n",
      "epoch 1, iter 104, loss: 3.321523, acc: 1.000000\n",
      "epoch 1, iter 105, loss: 2.981956, acc: 1.000000\n",
      "epoch 1, iter 106, loss: 2.716886, acc: 1.000000\n",
      "epoch 1, iter 107, loss: 3.472474, acc: 0.875000\n",
      "epoch 1, iter 108, loss: 3.343691, acc: 0.875000\n",
      "epoch 1, iter 109, loss: 3.144222, acc: 1.000000\n",
      "epoch 1, iter 110, loss: 3.021427, acc: 1.000000\n",
      "epoch 1, iter 111, loss: 2.871270, acc: 1.000000\n",
      "epoch 1, iter 112, loss: 2.574713, acc: 1.000000\n",
      "epoch 1, iter 113, loss: 2.321328, acc: 1.000000\n",
      "epoch 1, iter 114, loss: 2.128559, acc: 1.000000\n",
      "epoch 1, iter 115, loss: 1.982727, acc: 1.000000\n",
      "epoch 1, iter 116, loss: 2.200371, acc: 1.000000\n",
      "epoch 1, iter 117, loss: 2.053605, acc: 1.000000\n",
      "epoch 1, iter 118, loss: 1.850200, acc: 1.000000\n",
      "epoch 1, iter 119, loss: 2.097423, acc: 0.875000\n",
      "epoch 1, iter 120, loss: 2.316825, acc: 1.000000\n",
      "epoch 1, iter 121, loss: 1.988692, acc: 1.000000\n",
      "epoch 1, iter 122, loss: 2.534851, acc: 0.875000\n",
      "epoch 1, iter 123, loss: 2.654162, acc: 1.000000\n",
      "epoch 1, iter 124, loss: 3.392920, acc: 0.875000\n",
      "epoch 1, iter 125, loss: 3.379921, acc: 1.000000\n",
      "epoch 1, iter 126, loss: 3.601620, acc: 1.000000\n",
      "epoch 1, iter 127, loss: 3.543559, acc: 1.000000\n",
      "epoch 1, iter 128, loss: 3.028538, acc: 1.000000\n",
      "epoch 1, iter 129, loss: 3.223416, acc: 1.000000\n",
      "epoch 1, iter 130, loss: 3.146667, acc: 0.875000\n",
      "epoch 1, iter 131, loss: 2.976203, acc: 1.000000\n",
      "epoch 1, iter 132, loss: 2.746981, acc: 1.000000\n",
      "epoch 1, iter 133, loss: 2.314733, acc: 1.000000\n",
      "epoch 1, iter 134, loss: 3.333724, acc: 0.750000\n",
      "epoch 1, iter 135, loss: 3.205228, acc: 1.000000\n",
      "epoch 1, iter 136, loss: 3.617032, acc: 0.875000\n",
      "epoch 1, iter 137, loss: 3.424197, acc: 1.000000\n",
      "epoch 1, iter 138, loss: 3.088710, acc: 1.000000\n",
      "epoch 1, iter 139, loss: 2.629441, acc: 1.000000\n",
      "epoch 1, iter 140, loss: 2.607839, acc: 0.875000\n",
      "epoch 1, iter 141, loss: 2.338423, acc: 1.000000\n",
      "epoch 1, iter 142, loss: 2.330601, acc: 0.875000\n",
      "epoch 1, iter 143, loss: 2.169432, acc: 1.000000\n",
      "epoch 1, iter 144, loss: 2.188097, acc: 1.000000\n",
      "epoch 1, iter 145, loss: 2.078054, acc: 1.000000\n",
      "epoch 1, iter 146, loss: 1.874399, acc: 1.000000\n",
      "epoch 1, iter 147, loss: 1.684950, acc: 1.000000\n",
      "epoch 1, iter 148, loss: 1.528368, acc: 1.000000\n",
      "epoch 1, iter 149, loss: 1.403848, acc: 1.000000\n",
      "epoch 1, iter 150, loss: 2.825348, acc: 0.875000\n",
      "epoch 1, iter 151, loss: 2.762830, acc: 1.000000\n",
      "epoch 1, iter 152, loss: 2.828372, acc: 1.000000\n",
      "epoch 1, iter 153, loss: 2.824786, acc: 1.000000\n",
      "epoch 1, iter 154, loss: 2.849433, acc: 1.000000\n",
      "epoch 1, iter 155, loss: 2.599432, acc: 1.000000\n",
      "epoch 1, iter 156, loss: 2.235372, acc: 1.000000\n",
      "epoch 1, iter 157, loss: 2.370899, acc: 1.000000\n",
      "epoch 1, iter 158, loss: 2.687022, acc: 0.875000\n",
      "epoch 1, iter 159, loss: 2.369553, acc: 1.000000\n",
      "epoch 1, iter 160, loss: 2.384475, acc: 0.875000\n",
      "epoch 1, iter 161, loss: 3.556189, acc: 1.000000\n",
      "epoch 1, iter 162, loss: 3.245671, acc: 1.000000\n",
      "epoch 1, iter 163, loss: 3.899420, acc: 0.875000\n",
      "epoch 1, iter 164, loss: 3.728504, acc: 0.875000\n",
      "epoch 1, iter 165, loss: 3.731261, acc: 1.000000\n",
      "epoch 1, iter 166, loss: 3.175818, acc: 1.000000\n",
      "epoch 1, iter 167, loss: 2.634675, acc: 1.000000\n",
      "epoch 1, iter 168, loss: 3.659083, acc: 0.875000\n",
      "epoch 1, iter 169, loss: 3.937442, acc: 0.875000\n",
      "epoch 1, iter 170, loss: 3.268288, acc: 1.000000\n",
      "epoch 1, iter 171, loss: 2.687838, acc: 1.000000\n",
      "epoch 1, iter 172, loss: 2.599488, acc: 1.000000\n",
      "epoch 1, iter 173, loss: 2.205639, acc: 1.000000\n",
      "epoch 1, iter 174, loss: 1.822334, acc: 1.000000\n",
      "epoch 1, iter 175, loss: 2.497330, acc: 0.750000\n",
      "epoch 1, iter 176, loss: 2.566250, acc: 0.875000\n",
      "epoch 1, iter 177, loss: 2.476825, acc: 1.000000\n",
      "epoch 1, iter 178, loss: 2.160170, acc: 1.000000\n",
      "epoch 1, iter 179, loss: 3.235037, acc: 0.750000\n",
      "epoch 1, iter 180, loss: 3.581699, acc: 1.000000\n",
      "epoch 1, iter 181, loss: 3.050749, acc: 1.000000\n",
      "epoch 1, iter 182, loss: 2.525485, acc: 1.000000\n",
      "epoch 1, iter 183, loss: 2.510519, acc: 1.000000\n",
      "epoch 1, iter 184, loss: 4.347056, acc: 0.500000\n",
      "epoch 1, iter 185, loss: 3.841474, acc: 1.000000\n",
      "epoch 1, iter 186, loss: 3.073894, acc: 1.000000\n",
      "epoch 1, iter 187, loss: 2.966492, acc: 1.000000\n",
      "epoch 1, iter 188, loss: 4.562071, acc: 0.625000\n",
      "epoch 1, iter 189, loss: 4.765026, acc: 0.750000\n",
      "epoch 1, iter 190, loss: 4.390680, acc: 1.000000\n",
      "epoch 1, iter 191, loss: 4.378232, acc: 0.875000\n",
      "epoch 1, iter 192, loss: 5.370115, acc: 0.625000\n",
      "epoch 1, iter 193, loss: 5.607575, acc: 0.625000\n",
      "epoch 1, iter 194, loss: 5.034174, acc: 1.000000\n",
      "epoch 1, iter 195, loss: 4.597938, acc: 0.875000\n",
      "epoch 1, iter 196, loss: 4.502982, acc: 0.750000\n",
      "epoch 1, iter 197, loss: 3.957377, acc: 1.000000\n",
      "epoch 1, iter 198, loss: 3.334352, acc: 1.000000\n",
      "epoch 1, iter 199, loss: 3.755798, acc: 0.875000\n",
      "epoch 1, iter 200, loss: 3.298907, acc: 1.000000\n",
      "epoch 1, iter 201, loss: 3.568730, acc: 0.875000\n",
      "epoch 1, iter 202, loss: 3.477116, acc: 0.875000\n",
      "epoch 1, iter 203, loss: 3.635152, acc: 0.875000\n",
      "epoch 1, iter 204, loss: 3.742741, acc: 1.000000\n",
      "epoch 1, iter 205, loss: 3.433527, acc: 1.000000\n",
      "epoch 1, iter 206, loss: 3.777377, acc: 0.875000\n",
      "epoch 1, iter 207, loss: 4.300684, acc: 0.875000\n",
      "epoch 1, iter 208, loss: 4.075600, acc: 0.875000\n",
      "epoch 1, iter 209, loss: 5.006853, acc: 0.750000\n",
      "epoch 1, iter 210, loss: 4.238786, acc: 1.000000\n",
      "epoch 1, iter 211, loss: 4.243540, acc: 0.875000\n",
      "epoch 1, iter 212, loss: 4.181823, acc: 0.875000\n",
      "epoch 1, iter 213, loss: 4.179764, acc: 1.000000\n",
      "epoch 1, iter 214, loss: 3.740486, acc: 1.000000\n",
      "epoch 1, iter 215, loss: 3.888955, acc: 0.875000\n",
      "epoch 1, iter 216, loss: 4.378094, acc: 0.750000\n",
      "epoch 1, iter 217, loss: 4.601840, acc: 0.875000\n",
      "epoch 1, iter 218, loss: 4.155238, acc: 1.000000\n",
      "epoch 1, iter 219, loss: 3.803563, acc: 1.000000\n",
      "epoch 1, iter 220, loss: 4.312452, acc: 0.625000\n",
      "epoch 1, iter 221, loss: 3.949018, acc: 1.000000\n",
      "epoch 1, iter 222, loss: 3.645752, acc: 1.000000\n",
      "epoch 1, iter 223, loss: 3.823797, acc: 0.875000\n",
      "epoch 1, iter 224, loss: 4.269550, acc: 0.750000\n",
      "epoch 1, iter 225, loss: 4.261576, acc: 0.875000\n",
      "epoch 1, iter 226, loss: 4.586716, acc: 1.000000\n",
      "epoch 1, iter 227, loss: 4.356307, acc: 1.000000\n",
      "epoch 1, iter 228, loss: 4.643725, acc: 0.875000\n",
      "epoch 1, iter 229, loss: 4.365555, acc: 0.875000\n",
      "epoch 1, iter 230, loss: 3.768485, acc: 1.000000\n",
      "epoch 1, iter 231, loss: 3.146904, acc: 1.000000\n",
      "epoch 1, iter 232, loss: 3.305654, acc: 0.875000\n",
      "epoch 1, iter 233, loss: 3.567908, acc: 0.875000\n",
      "epoch 1, iter 234, loss: 3.361199, acc: 1.000000\n",
      "epoch 1, iter 235, loss: 3.414964, acc: 0.875000\n",
      "epoch 1, iter 236, loss: 3.288603, acc: 1.000000\n",
      "epoch 1, iter 237, loss: 3.287275, acc: 1.000000\n",
      "epoch 1, iter 238, loss: 3.079681, acc: 1.000000\n",
      "epoch 1, iter 239, loss: 3.116349, acc: 0.875000\n",
      "epoch 1, iter 240, loss: 3.821520, acc: 0.875000\n",
      "epoch 1, iter 241, loss: 3.766728, acc: 0.875000\n",
      "epoch 1, iter 242, loss: 3.510294, acc: 1.000000\n",
      "epoch 1, iter 243, loss: 3.543658, acc: 1.000000\n",
      "epoch 1, iter 244, loss: 3.251381, acc: 1.000000\n",
      "epoch 1, iter 245, loss: 3.039768, acc: 1.000000\n",
      "epoch 1, iter 246, loss: 2.794394, acc: 1.000000\n",
      "epoch 1, iter 247, loss: 3.875242, acc: 0.750000\n",
      "epoch 1, iter 248, loss: 3.623537, acc: 0.875000\n",
      "epoch 1, iter 249, loss: 4.424402, acc: 0.875000\n",
      "epoch 1, iter 250, loss: 4.180881, acc: 0.875000\n",
      "epoch 1, iter 251, loss: 4.707011, acc: 0.750000\n",
      "epoch 1, iter 252, loss: 4.185277, acc: 1.000000\n",
      "epoch 1, iter 253, loss: 4.093205, acc: 0.875000\n",
      "epoch 1, iter 254, loss: 3.528723, acc: 1.000000\n",
      "epoch 1, iter 255, loss: 3.518835, acc: 0.875000\n",
      "epoch 1, iter 256, loss: 3.203891, acc: 1.000000\n",
      "epoch 1, iter 257, loss: 2.952038, acc: 1.000000\n",
      "epoch 1, iter 258, loss: 2.738852, acc: 1.000000\n",
      "epoch 1, iter 259, loss: 3.172787, acc: 0.875000\n",
      "epoch 1, iter 260, loss: 3.799814, acc: 0.875000\n",
      "epoch 1, iter 261, loss: 3.517061, acc: 1.000000\n",
      "epoch 1, iter 262, loss: 3.558769, acc: 1.000000\n",
      "epoch 1, iter 263, loss: 3.841222, acc: 0.875000\n",
      "epoch 1, iter 264, loss: 3.264826, acc: 1.000000\n",
      "epoch 1, iter 265, loss: 3.406143, acc: 0.875000\n",
      "epoch 1, iter 266, loss: 3.508003, acc: 0.875000\n",
      "epoch 1, iter 267, loss: 3.594150, acc: 1.000000\n",
      "epoch 1, iter 268, loss: 3.768053, acc: 0.875000\n",
      "epoch 1, iter 269, loss: 3.833325, acc: 0.875000\n",
      "epoch 1, iter 270, loss: 3.535619, acc: 1.000000\n",
      "epoch 1, iter 271, loss: 3.253520, acc: 1.000000\n",
      "epoch 1, iter 272, loss: 3.954121, acc: 1.000000\n",
      "epoch 1, iter 273, loss: 5.716553, acc: 1.000000\n",
      "epoch 1, iter 274, loss: 5.230103, acc: 1.000000\n",
      "epoch 1, iter 275, loss: 4.314161, acc: 1.000000\n",
      "epoch 1, iter 276, loss: 3.948832, acc: 0.875000\n",
      "epoch 1, iter 277, loss: 3.837563, acc: 0.875000\n",
      "epoch 1, iter 278, loss: 3.377510, acc: 1.000000\n",
      "epoch 1, iter 279, loss: 3.544747, acc: 0.875000\n",
      "epoch 1, iter 280, loss: 3.531847, acc: 0.875000\n",
      "epoch 1, iter 281, loss: 3.230567, acc: 1.000000\n",
      "epoch 1, iter 282, loss: 2.978447, acc: 1.000000\n",
      "epoch 1, iter 283, loss: 3.140450, acc: 1.000000\n",
      "epoch 1, iter 284, loss: 3.517555, acc: 0.875000\n",
      "epoch 1, iter 285, loss: 3.064152, acc: 1.000000\n",
      "epoch 1, iter 286, loss: 3.638420, acc: 0.875000\n",
      "epoch 1, iter 287, loss: 3.469938, acc: 1.000000\n",
      "epoch 1, iter 288, loss: 3.346482, acc: 1.000000\n",
      "epoch 1, iter 289, loss: 3.087549, acc: 1.000000\n",
      "epoch 1, iter 290, loss: 3.061893, acc: 0.875000\n",
      "epoch 1, iter 291, loss: 3.107025, acc: 0.875000\n",
      "epoch 1, iter 292, loss: 3.490001, acc: 0.875000\n",
      "epoch 1, iter 293, loss: 3.540311, acc: 1.000000\n",
      "epoch 1, iter 294, loss: 4.481647, acc: 1.000000\n",
      "epoch 1, iter 295, loss: 5.043148, acc: 0.750000\n",
      "epoch 1, iter 296, loss: 4.432222, acc: 1.000000\n",
      "epoch 1, iter 297, loss: 4.324370, acc: 1.000000\n",
      "epoch 1, iter 298, loss: 4.985238, acc: 0.500000\n",
      "epoch 1, iter 299, loss: 4.811269, acc: 1.000000\n",
      "epoch 1, iter 300, loss: 4.329187, acc: 1.000000\n",
      "epoch 1, iter 301, loss: 3.812910, acc: 1.000000\n",
      "epoch 1, iter 302, loss: 3.476113, acc: 1.000000\n",
      "epoch 1, iter 303, loss: 3.374386, acc: 0.875000\n",
      "epoch 1, iter 304, loss: 3.287526, acc: 1.000000\n",
      "epoch 1, iter 305, loss: 3.145460, acc: 1.000000\n",
      "epoch 1, iter 306, loss: 2.924296, acc: 1.000000\n",
      "epoch 1, iter 307, loss: 2.731456, acc: 1.000000\n",
      "epoch 1, iter 308, loss: 2.850653, acc: 1.000000\n",
      "epoch 1, iter 309, loss: 2.773891, acc: 1.000000\n",
      "epoch 1, iter 310, loss: 2.691740, acc: 1.000000\n",
      "epoch 1, iter 311, loss: 3.149066, acc: 0.875000\n",
      "epoch 1, iter 312, loss: 3.322396, acc: 1.000000\n",
      "epoch 1, iter 313, loss: 3.668299, acc: 0.875000\n",
      "epoch 1, iter 314, loss: 3.414046, acc: 1.000000\n",
      "epoch 1, iter 315, loss: 3.921565, acc: 0.875000\n",
      "epoch 1, iter 316, loss: 3.793219, acc: 0.875000\n",
      "epoch 1, iter 317, loss: 3.461512, acc: 1.000000\n",
      "epoch 1, iter 318, loss: 3.175979, acc: 1.000000\n",
      "epoch 1, iter 319, loss: 2.965608, acc: 1.000000\n",
      "epoch 1, iter 320, loss: 3.338215, acc: 0.875000\n",
      "epoch 1, iter 321, loss: 2.905709, acc: 1.000000\n",
      "epoch 1, iter 322, loss: 2.475900, acc: 1.000000\n",
      "epoch 1, iter 323, loss: 2.090300, acc: 1.000000\n",
      "epoch 1, iter 324, loss: 2.481081, acc: 1.000000\n",
      "epoch 1, iter 325, loss: 3.567924, acc: 0.750000\n",
      "epoch 1, iter 326, loss: 3.581936, acc: 1.000000\n",
      "epoch 1, iter 327, loss: 3.371153, acc: 1.000000\n",
      "epoch 1, iter 328, loss: 3.210779, acc: 1.000000\n",
      "epoch 1, iter 329, loss: 3.027569, acc: 1.000000\n",
      "epoch 1, iter 330, loss: 2.830690, acc: 1.000000\n",
      "epoch 1, iter 331, loss: 3.019751, acc: 0.875000\n",
      "epoch 1, iter 332, loss: 2.882308, acc: 1.000000\n",
      "epoch 1, iter 333, loss: 2.644967, acc: 1.000000\n",
      "epoch 1, iter 334, loss: 3.142246, acc: 0.875000\n",
      "epoch 1, iter 335, loss: 3.776617, acc: 0.750000\n",
      "epoch 1, iter 336, loss: 3.495859, acc: 1.000000\n",
      "epoch 1, iter 337, loss: 4.370844, acc: 0.750000\n",
      "epoch 1, iter 338, loss: 4.517441, acc: 1.000000\n",
      "epoch 1, iter 339, loss: 4.705057, acc: 0.875000\n",
      "epoch 1, iter 340, loss: 4.107355, acc: 1.000000\n",
      "epoch 1, iter 341, loss: 3.388395, acc: 1.000000\n",
      "epoch 1, iter 342, loss: 3.052028, acc: 0.875000\n",
      "epoch 1, iter 343, loss: 2.602039, acc: 1.000000\n",
      "epoch 1, iter 344, loss: 3.093958, acc: 0.750000\n",
      "epoch 1, iter 345, loss: 3.472210, acc: 0.875000\n",
      "epoch 1, iter 346, loss: 4.024467, acc: 0.875000\n",
      "epoch 1, iter 347, loss: 3.749036, acc: 0.875000\n",
      "epoch 1, iter 348, loss: 3.065994, acc: 1.000000\n",
      "epoch 1, iter 349, loss: 2.521442, acc: 1.000000\n",
      "epoch 1, iter 350, loss: 2.116370, acc: 1.000000\n",
      "epoch 1, iter 351, loss: 2.116240, acc: 1.000000\n",
      "epoch 1, iter 352, loss: 2.735506, acc: 0.875000\n",
      "epoch 1, iter 353, loss: 2.353067, acc: 1.000000\n",
      "epoch 1, iter 354, loss: 1.956036, acc: 1.000000\n",
      "epoch 1, iter 355, loss: 3.215681, acc: 0.750000\n",
      "epoch 1, iter 356, loss: 4.435632, acc: 0.875000\n",
      "epoch 1, iter 357, loss: 5.563544, acc: 0.625000\n",
      "epoch 1, iter 358, loss: 4.515939, acc: 1.000000\n",
      "epoch 1, iter 359, loss: 4.804282, acc: 0.750000\n",
      "epoch 1, iter 360, loss: 4.887546, acc: 0.750000\n",
      "epoch 1, iter 361, loss: 4.235010, acc: 1.000000\n",
      "epoch 1, iter 362, loss: 3.887098, acc: 1.000000\n",
      "epoch 1, iter 363, loss: 3.264905, acc: 1.000000\n",
      "epoch 1, iter 364, loss: 3.103284, acc: 1.000000\n",
      "epoch 1, iter 365, loss: 2.686939, acc: 1.000000\n",
      "epoch 1, iter 366, loss: 2.458438, acc: 1.000000\n",
      "epoch 1, iter 367, loss: 2.247447, acc: 1.000000\n",
      "epoch 1, iter 368, loss: 3.636847, acc: 0.875000\n",
      "epoch 1, iter 369, loss: 3.270124, acc: 1.000000\n",
      "epoch 1, iter 370, loss: 2.776000, acc: 1.000000\n",
      "epoch 1, iter 371, loss: 2.341019, acc: 1.000000\n",
      "epoch 1, iter 372, loss: 1.999329, acc: 1.000000\n",
      "epoch 1, iter 373, loss: 2.085825, acc: 1.000000\n",
      "epoch 1, iter 374, loss: 1.851362, acc: 1.000000\n",
      "epoch 1, iter 375, loss: 2.071671, acc: 0.875000\n",
      "epoch 1, iter 376, loss: 1.790978, acc: 1.000000\n",
      "epoch 1, iter 377, loss: 1.774526, acc: 1.000000\n",
      "epoch 1, iter 378, loss: 2.135029, acc: 0.875000\n",
      "epoch 1, iter 379, loss: 1.870715, acc: 1.000000\n",
      "epoch 1, iter 380, loss: 1.931125, acc: 0.875000\n",
      "epoch 1, iter 381, loss: 1.733848, acc: 1.000000\n",
      "epoch 1, iter 382, loss: 3.118986, acc: 0.750000\n",
      "epoch 1, iter 383, loss: 2.773625, acc: 1.000000\n",
      "epoch 1, iter 384, loss: 2.295732, acc: 1.000000\n",
      "epoch 1, iter 385, loss: 2.212231, acc: 0.875000\n",
      "epoch 1, iter 386, loss: 1.925614, acc: 1.000000\n",
      "epoch 1, iter 387, loss: 1.885343, acc: 1.000000\n",
      "epoch 1, iter 388, loss: 2.361141, acc: 0.875000\n",
      "epoch 1, iter 389, loss: 2.101737, acc: 1.000000\n",
      "epoch 1, iter 390, loss: 2.047796, acc: 1.000000\n",
      "epoch 1, iter 391, loss: 2.187357, acc: 0.875000\n",
      "epoch 1, iter 392, loss: 3.099136, acc: 1.000000\n",
      "epoch 1, iter 393, loss: 3.349007, acc: 0.875000\n",
      "epoch 1, iter 394, loss: 2.858672, acc: 1.000000\n",
      "epoch 1, iter 395, loss: 2.390944, acc: 1.000000\n",
      "epoch 1, iter 396, loss: 2.023005, acc: 1.000000\n",
      "epoch 1, iter 397, loss: 2.341758, acc: 0.875000\n",
      "epoch 1, iter 398, loss: 3.582175, acc: 0.750000\n",
      "epoch 1, iter 399, loss: 3.054136, acc: 1.000000\n",
      "epoch 1, iter 400, loss: 5.278092, acc: 0.500000\n",
      "epoch 1, iter 401, loss: 5.241965, acc: 0.875000\n",
      "epoch 1, iter 402, loss: 4.290989, acc: 1.000000\n",
      "epoch 1, iter 403, loss: 3.746743, acc: 1.000000\n",
      "epoch 1, iter 404, loss: 3.050175, acc: 1.000000\n",
      "epoch 1, iter 405, loss: 2.495982, acc: 1.000000\n",
      "epoch 1, iter 406, loss: 2.520698, acc: 0.875000\n",
      "epoch 1, iter 407, loss: 3.520226, acc: 0.875000\n",
      "epoch 1, iter 408, loss: 3.002041, acc: 1.000000\n",
      "epoch 1, iter 409, loss: 2.705922, acc: 1.000000\n",
      "epoch 1, iter 410, loss: 2.338415, acc: 1.000000\n",
      "epoch 1, iter 411, loss: 2.154620, acc: 1.000000\n",
      "epoch 1, iter 412, loss: 1.889067, acc: 1.000000\n",
      "epoch 1, iter 413, loss: 1.656355, acc: 1.000000\n",
      "epoch 1, iter 414, loss: 1.477575, acc: 1.000000\n",
      "epoch 1, iter 415, loss: 1.346221, acc: 1.000000\n",
      "epoch 1, iter 416, loss: 2.249410, acc: 0.750000\n",
      "epoch 1, iter 417, loss: 3.022641, acc: 0.875000\n",
      "epoch 1, iter 418, loss: 2.594731, acc: 1.000000\n",
      "epoch 1, iter 419, loss: 2.163728, acc: 1.000000\n",
      "epoch 1, iter 420, loss: 2.237411, acc: 0.875000\n",
      "epoch 1, iter 421, loss: 2.219700, acc: 1.000000\n",
      "epoch 1, iter 422, loss: 2.063068, acc: 1.000000\n",
      "epoch 1, iter 423, loss: 1.818281, acc: 1.000000\n",
      "epoch 1, iter 424, loss: 1.830499, acc: 1.000000\n",
      "epoch 1, iter 425, loss: 2.378103, acc: 0.875000\n",
      "epoch 1, iter 426, loss: 2.011186, acc: 1.000000\n",
      "epoch 1, iter 427, loss: 2.487607, acc: 0.875000\n",
      "epoch 1, iter 428, loss: 2.395774, acc: 1.000000\n",
      "epoch 1, iter 429, loss: 4.389268, acc: 0.750000\n",
      "epoch 1, iter 430, loss: 4.959670, acc: 0.750000\n",
      "epoch 1, iter 431, loss: 4.722582, acc: 1.000000\n",
      "epoch 1, iter 432, loss: 5.084820, acc: 0.750000\n",
      "epoch 1, iter 433, loss: 4.310267, acc: 1.000000\n",
      "epoch 1, iter 434, loss: 4.257511, acc: 1.000000\n",
      "epoch 1, iter 435, loss: 4.173362, acc: 0.875000\n",
      "epoch 1, iter 436, loss: 4.147937, acc: 0.875000\n",
      "epoch 1, iter 437, loss: 3.422317, acc: 1.000000\n",
      "epoch 1, iter 438, loss: 3.519676, acc: 1.000000\n",
      "epoch 1, iter 439, loss: 3.299534, acc: 1.000000\n",
      "epoch 1, iter 440, loss: 2.998823, acc: 1.000000\n",
      "epoch 1, iter 441, loss: 3.838120, acc: 0.750000\n",
      "epoch 1, iter 442, loss: 3.595277, acc: 1.000000\n",
      "epoch 1, iter 443, loss: 3.968918, acc: 0.875000\n",
      "epoch 1, iter 444, loss: 4.237616, acc: 1.000000\n",
      "epoch 1, iter 445, loss: 3.447028, acc: 1.000000\n",
      "epoch 1, iter 446, loss: 3.319909, acc: 0.875000\n",
      "epoch 1, iter 447, loss: 2.925651, acc: 1.000000\n",
      "epoch 1, iter 448, loss: 2.573186, acc: 1.000000\n",
      "epoch 1, iter 449, loss: 2.299681, acc: 1.000000\n",
      "epoch 1, iter 450, loss: 2.271428, acc: 1.000000\n",
      "epoch 1, iter 451, loss: 2.222815, acc: 1.000000\n",
      "epoch 1, iter 452, loss: 2.060298, acc: 1.000000\n",
      "epoch 1, iter 453, loss: 2.046113, acc: 1.000000\n",
      "epoch 1, iter 454, loss: 3.048843, acc: 0.875000\n",
      "epoch 1, iter 455, loss: 3.476215, acc: 0.875000\n",
      "epoch 1, iter 456, loss: 3.184212, acc: 1.000000\n",
      "epoch 1, iter 457, loss: 3.069519, acc: 1.000000\n",
      "epoch 1, iter 458, loss: 2.716597, acc: 1.000000\n",
      "epoch 1, iter 459, loss: 2.401657, acc: 1.000000\n",
      "epoch 1, iter 460, loss: 2.158259, acc: 1.000000\n",
      "epoch 1, iter 461, loss: 1.975368, acc: 1.000000\n",
      "epoch 1, iter 462, loss: 2.765406, acc: 0.875000\n",
      "epoch 1, iter 463, loss: 3.304302, acc: 0.875000\n",
      "epoch 1, iter 464, loss: 2.857796, acc: 1.000000\n",
      "epoch 1, iter 465, loss: 2.950044, acc: 0.875000\n",
      "epoch 1, iter 466, loss: 2.790312, acc: 1.000000\n",
      "epoch 1, iter 467, loss: 2.657020, acc: 1.000000\n",
      "epoch 1, iter 468, loss: 2.423811, acc: 1.000000\n",
      "epoch 1, iter 469, loss: 2.203314, acc: 1.000000\n",
      "epoch 1, iter 470, loss: 2.018921, acc: 1.000000\n",
      "epoch 1, iter 471, loss: 2.748659, acc: 0.750000\n",
      "epoch 1, iter 472, loss: 3.086638, acc: 1.000000\n",
      "epoch 1, iter 473, loss: 3.921268, acc: 0.875000\n",
      "epoch 1, iter 474, loss: 3.359582, acc: 1.000000\n",
      "epoch 1, iter 475, loss: 3.031370, acc: 1.000000\n",
      "epoch 1, iter 476, loss: 3.620910, acc: 0.750000\n",
      "epoch 1, iter 477, loss: 3.627536, acc: 1.000000\n",
      "epoch 1, iter 478, loss: 3.159830, acc: 1.000000\n",
      "epoch 1, iter 479, loss: 3.053628, acc: 1.000000\n",
      "epoch 1, iter 480, loss: 2.735594, acc: 1.000000\n",
      "epoch 1, iter 481, loss: 2.602990, acc: 1.000000\n",
      "epoch 1, iter 482, loss: 2.489060, acc: 1.000000\n",
      "epoch 1, iter 483, loss: 2.828593, acc: 0.875000\n",
      "epoch 1, iter 484, loss: 3.222417, acc: 0.750000\n",
      "epoch 1, iter 485, loss: 3.897683, acc: 0.500000\n",
      "epoch 1, iter 486, loss: 3.554263, acc: 1.000000\n",
      "epoch 1, iter 487, loss: 3.210272, acc: 1.000000\n",
      "epoch 1, iter 488, loss: 3.992237, acc: 0.875000\n",
      "epoch 1, iter 489, loss: 3.876340, acc: 1.000000\n",
      "epoch 1, iter 490, loss: 3.435763, acc: 1.000000\n",
      "epoch 1, iter 491, loss: 3.116016, acc: 1.000000\n",
      "epoch 1, iter 492, loss: 2.902293, acc: 1.000000\n",
      "epoch 1, iter 493, loss: 3.331887, acc: 1.000000\n",
      "epoch 1, iter 494, loss: 3.056730, acc: 1.000000\n",
      "epoch 1, iter 495, loss: 3.063227, acc: 1.000000\n",
      "epoch 1, iter 496, loss: 2.741381, acc: 1.000000\n",
      "epoch 1, iter 497, loss: 2.444986, acc: 1.000000\n",
      "epoch 1, iter 498, loss: 2.453610, acc: 1.000000\n",
      "epoch 1, iter 499, loss: 2.210481, acc: 1.000000\n",
      "epoch 1, iter 500, loss: 2.825939, acc: 0.750000\n",
      "epoch 1, iter 501, loss: 2.687928, acc: 1.000000\n",
      "epoch 1, iter 502, loss: 2.611871, acc: 1.000000\n",
      "epoch 1, iter 503, loss: 2.983043, acc: 1.000000\n",
      "epoch 1, iter 504, loss: 2.904617, acc: 1.000000\n",
      "epoch 1, iter 505, loss: 2.872364, acc: 1.000000\n",
      "epoch 1, iter 506, loss: 2.594341, acc: 1.000000\n",
      "epoch 1, iter 507, loss: 2.586161, acc: 1.000000\n",
      "epoch 1, iter 508, loss: 3.027921, acc: 1.000000\n",
      "epoch 1, iter 509, loss: 3.337782, acc: 1.000000\n",
      "epoch 1, iter 510, loss: 3.017920, acc: 1.000000\n",
      "epoch 1, iter 511, loss: 2.689175, acc: 1.000000\n",
      "epoch 1, iter 512, loss: 2.647462, acc: 1.000000\n",
      "epoch 1, iter 513, loss: 2.413281, acc: 1.000000\n",
      "epoch 1, iter 514, loss: 2.171571, acc: 1.000000\n",
      "epoch 1, iter 515, loss: 1.965900, acc: 1.000000\n",
      "epoch 1, iter 516, loss: 1.801251, acc: 1.000000\n",
      "epoch 1, iter 517, loss: 2.713745, acc: 1.000000\n",
      "epoch 1, iter 518, loss: 3.358456, acc: 0.875000\n",
      "epoch 1, iter 519, loss: 3.738252, acc: 0.875000\n",
      "epoch 1, iter 520, loss: 3.152144, acc: 1.000000\n",
      "epoch 1, iter 521, loss: 2.564908, acc: 1.000000\n",
      "epoch 1, iter 522, loss: 3.204128, acc: 0.875000\n",
      "epoch 1, iter 523, loss: 3.261966, acc: 0.875000\n",
      "epoch 1, iter 524, loss: 3.180419, acc: 1.000000\n",
      "epoch 1, iter 525, loss: 2.849944, acc: 1.000000\n",
      "epoch 1, iter 526, loss: 2.804698, acc: 1.000000\n",
      "epoch 1, iter 527, loss: 2.675092, acc: 1.000000\n",
      "epoch 1, iter 528, loss: 2.686727, acc: 1.000000\n",
      "epoch 1, iter 529, loss: 2.976999, acc: 0.875000\n",
      "epoch 1, iter 530, loss: 2.824430, acc: 1.000000\n",
      "epoch 1, iter 531, loss: 2.506604, acc: 1.000000\n",
      "epoch 1, iter 532, loss: 2.636104, acc: 0.875000\n",
      "epoch 1, iter 533, loss: 2.427031, acc: 1.000000\n",
      "epoch 1, iter 534, loss: 2.222563, acc: 1.000000\n",
      "epoch 1, iter 535, loss: 2.055629, acc: 1.000000\n",
      "epoch 1, iter 536, loss: 2.268507, acc: 1.000000\n",
      "epoch 1, iter 537, loss: 2.476918, acc: 1.000000\n",
      "epoch 1, iter 538, loss: 2.538859, acc: 1.000000\n",
      "epoch 1, iter 539, loss: 2.296852, acc: 1.000000\n",
      "epoch 1, iter 540, loss: 2.456797, acc: 0.875000\n",
      "epoch 1, iter 541, loss: 2.334683, acc: 1.000000\n",
      "epoch 1, iter 542, loss: 2.162404, acc: 1.000000\n",
      "epoch 1, iter 543, loss: 2.006462, acc: 1.000000\n",
      "epoch 1, iter 544, loss: 2.875996, acc: 0.625000\n",
      "epoch 1, iter 545, loss: 2.674624, acc: 1.000000\n",
      "epoch 1, iter 546, loss: 2.357352, acc: 1.000000\n",
      "epoch 1, iter 547, loss: 2.113731, acc: 1.000000\n",
      "epoch 1, iter 548, loss: 1.932496, acc: 1.000000\n",
      "epoch 1, iter 549, loss: 2.178207, acc: 0.875000\n",
      "epoch 1, iter 550, loss: 2.060331, acc: 1.000000\n",
      "epoch 1, iter 551, loss: 2.933043, acc: 1.000000\n",
      "epoch 1, iter 552, loss: 4.142036, acc: 0.875000\n",
      "epoch 1, iter 553, loss: 4.102154, acc: 1.000000\n",
      "epoch 1, iter 554, loss: 3.240913, acc: 1.000000\n",
      "epoch 1, iter 555, loss: 3.926795, acc: 0.625000\n",
      "epoch 1, iter 556, loss: 3.692913, acc: 1.000000\n",
      "epoch 1, iter 557, loss: 3.779235, acc: 1.000000\n",
      "epoch 1, iter 558, loss: 3.451242, acc: 1.000000\n",
      "epoch 1, iter 559, loss: 3.546095, acc: 0.875000\n",
      "epoch 1, iter 560, loss: 3.113358, acc: 1.000000\n",
      "epoch 1, iter 561, loss: 3.035068, acc: 1.000000\n",
      "epoch 1, iter 562, loss: 2.844346, acc: 1.000000\n",
      "epoch 1, iter 563, loss: 2.512197, acc: 1.000000\n",
      "epoch 1, iter 564, loss: 2.212468, acc: 1.000000\n",
      "epoch 1, iter 565, loss: 2.415528, acc: 1.000000\n",
      "epoch 1, iter 566, loss: 2.226665, acc: 1.000000\n",
      "epoch 1, iter 567, loss: 2.170552, acc: 1.000000\n",
      "epoch 1, iter 568, loss: 1.971337, acc: 1.000000\n",
      "epoch 1, iter 569, loss: 1.724302, acc: 1.000000\n",
      "epoch 1, iter 570, loss: 2.701029, acc: 1.000000\n",
      "epoch 1, iter 571, loss: 2.718642, acc: 1.000000\n",
      "epoch 1, iter 572, loss: 2.348423, acc: 1.000000\n",
      "epoch 1, iter 573, loss: 1.975158, acc: 1.000000\n",
      "epoch 1, iter 574, loss: 1.668088, acc: 1.000000\n",
      "epoch 1, iter 575, loss: 1.725696, acc: 1.000000\n",
      "epoch 1, iter 576, loss: 2.216465, acc: 0.875000\n",
      "epoch 1, iter 577, loss: 1.965764, acc: 1.000000\n",
      "epoch 1, iter 578, loss: 1.913139, acc: 0.875000\n",
      "epoch 1, iter 579, loss: 1.700916, acc: 1.000000\n",
      "epoch 1, iter 580, loss: 1.442128, acc: 1.000000\n",
      "epoch 1, iter 581, loss: 1.563215, acc: 0.875000\n",
      "epoch 1, iter 582, loss: 1.463903, acc: 1.000000\n",
      "epoch 1, iter 583, loss: 2.406570, acc: 0.875000\n",
      "epoch 1, iter 584, loss: 3.794893, acc: 0.750000\n",
      "epoch 1, iter 585, loss: 2.940361, acc: 1.000000\n",
      "epoch 1, iter 586, loss: 3.471467, acc: 0.750000\n",
      "epoch 1, iter 587, loss: 2.843951, acc: 1.000000\n",
      "epoch 1, iter 588, loss: 3.423594, acc: 0.875000\n",
      "epoch 1, iter 589, loss: 3.243016, acc: 0.875000\n",
      "epoch 1, iter 590, loss: 2.741365, acc: 1.000000\n",
      "epoch 1, iter 591, loss: 3.873195, acc: 0.875000\n",
      "epoch 1, iter 592, loss: 3.385491, acc: 1.000000\n",
      "epoch 1, iter 593, loss: 3.592391, acc: 0.875000\n",
      "epoch 1, iter 594, loss: 3.067848, acc: 1.000000\n",
      "epoch 1, iter 595, loss: 2.483595, acc: 1.000000\n",
      "epoch 1, iter 596, loss: 1.987501, acc: 1.000000\n",
      "epoch 1, iter 597, loss: 2.066603, acc: 0.875000\n",
      "epoch 1, iter 598, loss: 3.338956, acc: 0.750000\n",
      "epoch 1, iter 599, loss: 2.794191, acc: 1.000000\n",
      "epoch 1, iter 600, loss: 2.550532, acc: 0.875000\n",
      "epoch 1, iter 601, loss: 4.581494, acc: 0.750000\n",
      "epoch 1, iter 602, loss: 3.686360, acc: 1.000000\n",
      "epoch 1, iter 603, loss: 3.112929, acc: 1.000000\n",
      "epoch 1, iter 604, loss: 3.021270, acc: 0.875000\n",
      "epoch 1, iter 605, loss: 2.609329, acc: 1.000000\n",
      "epoch 1, iter 606, loss: 2.172713, acc: 1.000000\n",
      "epoch 1, iter 607, loss: 2.061876, acc: 1.000000\n",
      "epoch 1, iter 608, loss: 1.768108, acc: 1.000000\n",
      "epoch 1, iter 609, loss: 1.723623, acc: 1.000000\n",
      "epoch 1, iter 610, loss: 1.551428, acc: 1.000000\n",
      "epoch 1, iter 611, loss: 1.536217, acc: 1.000000\n",
      "epoch 1, iter 612, loss: 1.984369, acc: 0.875000\n",
      "epoch 1, iter 613, loss: 1.736698, acc: 1.000000\n",
      "epoch 1, iter 614, loss: 1.779146, acc: 0.875000\n",
      "epoch 1, iter 615, loss: 1.562899, acc: 1.000000\n",
      "epoch 1, iter 616, loss: 1.903607, acc: 0.875000\n",
      "epoch 1, iter 617, loss: 1.799276, acc: 1.000000\n",
      "epoch 1, iter 618, loss: 1.735358, acc: 1.000000\n",
      "epoch 1, iter 619, loss: 1.640575, acc: 1.000000\n",
      "epoch 1, iter 620, loss: 1.462685, acc: 1.000000\n",
      "epoch 1, iter 621, loss: 1.293292, acc: 1.000000\n",
      "epoch 1, iter 622, loss: 1.156318, acc: 1.000000\n",
      "epoch 1, iter 623, loss: 1.052143, acc: 1.000000\n",
      "epoch 1, iter 624, loss: 0.974972, acc: 1.000000\n",
      "epoch 1, iter 625, loss: 1.310471, acc: 0.875000\n",
      "epoch 1, iter 626, loss: 1.231019, acc: 1.000000\n",
      "epoch 1, iter 627, loss: 1.730885, acc: 0.875000\n",
      "epoch 1, iter 628, loss: 1.934970, acc: 0.875000\n",
      "epoch 1, iter 629, loss: 4.288638, acc: 0.875000\n",
      "epoch 1, iter 630, loss: 3.382695, acc: 1.000000\n",
      "epoch 1, iter 631, loss: 3.825825, acc: 0.875000\n",
      "epoch 1, iter 632, loss: 3.040590, acc: 1.000000\n",
      "epoch 1, iter 633, loss: 2.423894, acc: 1.000000\n",
      "epoch 1, iter 634, loss: 2.546350, acc: 0.875000\n",
      "epoch 1, iter 635, loss: 2.184502, acc: 1.000000\n",
      "epoch 1, iter 636, loss: 1.831918, acc: 1.000000\n",
      "epoch 1, iter 637, loss: 1.980710, acc: 0.875000\n",
      "epoch 1, iter 638, loss: 1.975230, acc: 1.000000\n",
      "epoch 1, iter 639, loss: 1.724541, acc: 1.000000\n",
      "epoch 1, iter 640, loss: 1.729123, acc: 0.875000\n",
      "epoch 1, iter 641, loss: 1.555669, acc: 1.000000\n",
      "epoch 1, iter 642, loss: 2.019881, acc: 0.875000\n",
      "epoch 1, iter 643, loss: 2.962316, acc: 0.875000\n",
      "epoch 1, iter 644, loss: 2.448985, acc: 1.000000\n",
      "epoch 1, iter 645, loss: 2.012758, acc: 1.000000\n",
      "epoch 1, iter 646, loss: 2.992903, acc: 0.875000\n",
      "epoch 1, iter 647, loss: 2.376420, acc: 1.000000\n",
      "epoch 1, iter 648, loss: 1.923634, acc: 1.000000\n",
      "epoch 1, iter 649, loss: 1.596378, acc: 1.000000\n",
      "epoch 1, iter 650, loss: 1.813200, acc: 0.875000\n",
      "epoch 1, iter 651, loss: 1.574197, acc: 1.000000\n",
      "epoch 1, iter 652, loss: 1.364101, acc: 1.000000\n",
      "epoch 1, iter 653, loss: 1.496887, acc: 1.000000\n",
      "epoch 1, iter 654, loss: 2.967647, acc: 0.750000\n",
      "epoch 1, iter 655, loss: 3.706515, acc: 0.875000\n",
      "epoch 1, iter 656, loss: 2.950993, acc: 1.000000\n",
      "epoch 1, iter 657, loss: 2.604488, acc: 0.875000\n",
      "epoch 1, iter 658, loss: 2.168283, acc: 1.000000\n",
      "epoch 1, iter 659, loss: 1.985692, acc: 1.000000\n",
      "epoch 1, iter 660, loss: 2.217836, acc: 0.875000\n",
      "epoch 1, iter 661, loss: 1.909617, acc: 1.000000\n",
      "epoch 1, iter 662, loss: 1.850030, acc: 1.000000\n",
      "epoch 1, iter 663, loss: 1.983186, acc: 0.875000\n",
      "epoch 1, iter 664, loss: 1.766786, acc: 1.000000\n",
      "epoch 1, iter 665, loss: 1.740297, acc: 1.000000\n",
      "epoch 1, iter 666, loss: 1.565022, acc: 1.000000\n",
      "epoch 1, iter 667, loss: 1.550420, acc: 1.000000\n",
      "epoch 1, iter 668, loss: 1.471291, acc: 1.000000\n",
      "epoch 1, iter 669, loss: 1.322023, acc: 1.000000\n",
      "epoch 1, iter 670, loss: 1.180595, acc: 1.000000\n",
      "epoch 1, iter 671, loss: 1.067000, acc: 1.000000\n",
      "epoch 1, iter 672, loss: 1.959843, acc: 0.875000\n",
      "epoch 1, iter 673, loss: 1.919375, acc: 1.000000\n",
      "epoch 1, iter 674, loss: 1.726163, acc: 1.000000\n",
      "epoch 1, iter 675, loss: 1.504703, acc: 1.000000\n",
      "epoch 1, iter 676, loss: 1.565152, acc: 1.000000\n",
      "epoch 1, iter 677, loss: 3.114767, acc: 0.625000\n",
      "epoch 1, iter 678, loss: 2.784685, acc: 1.000000\n",
      "epoch 1, iter 679, loss: 2.441235, acc: 1.000000\n",
      "epoch 1, iter 680, loss: 2.062299, acc: 1.000000\n",
      "epoch 1, iter 681, loss: 1.719914, acc: 1.000000\n",
      "epoch 1, iter 682, loss: 1.450711, acc: 1.000000\n",
      "epoch 1, iter 683, loss: 1.816717, acc: 0.875000\n",
      "epoch 1, iter 684, loss: 2.592058, acc: 0.875000\n",
      "epoch 1, iter 685, loss: 2.076542, acc: 1.000000\n",
      "epoch 1, iter 686, loss: 1.702010, acc: 1.000000\n",
      "epoch 1, iter 687, loss: 1.432378, acc: 1.000000\n",
      "epoch 1, iter 688, loss: 2.445340, acc: 0.750000\n",
      "epoch 1, iter 689, loss: 2.109545, acc: 1.000000\n",
      "epoch 1, iter 690, loss: 1.994343, acc: 1.000000\n",
      "epoch 1, iter 691, loss: 1.713741, acc: 1.000000\n",
      "epoch 1, iter 692, loss: 2.126646, acc: 0.875000\n",
      "epoch 1, iter 693, loss: 2.068539, acc: 0.875000\n",
      "epoch 1, iter 694, loss: 1.780157, acc: 1.000000\n",
      "epoch 1, iter 695, loss: 1.727603, acc: 1.000000\n",
      "epoch 1, iter 696, loss: 1.543201, acc: 1.000000\n",
      "epoch 1, iter 697, loss: 1.526028, acc: 1.000000\n",
      "epoch 1, iter 698, loss: 1.446531, acc: 1.000000\n",
      "epoch 1, iter 699, loss: 1.298501, acc: 1.000000\n",
      "epoch 1, iter 700, loss: 1.787621, acc: 0.875000\n",
      "epoch 1, iter 701, loss: 2.008052, acc: 0.875000\n",
      "epoch 1, iter 702, loss: 2.396010, acc: 0.875000\n",
      "epoch 1, iter 703, loss: 2.124644, acc: 1.000000\n",
      "epoch 1, iter 704, loss: 2.594249, acc: 0.875000\n",
      "epoch 1, iter 705, loss: 2.430000, acc: 1.000000\n",
      "epoch 1, iter 706, loss: 4.494531, acc: 0.750000\n",
      "epoch 1, iter 707, loss: 3.451785, acc: 1.000000\n",
      "epoch 1, iter 708, loss: 3.044576, acc: 0.875000\n",
      "epoch 1, iter 709, loss: 2.995558, acc: 0.875000\n",
      "epoch 1, iter 710, loss: 2.454247, acc: 1.000000\n",
      "epoch 1, iter 711, loss: 1.964065, acc: 1.000000\n",
      "epoch 1, iter 712, loss: 1.570996, acc: 1.000000\n",
      "epoch 1, iter 713, loss: 1.810923, acc: 0.875000\n",
      "epoch 1, iter 714, loss: 1.672311, acc: 1.000000\n",
      "epoch 1, iter 715, loss: 2.536354, acc: 0.875000\n",
      "epoch 1, iter 716, loss: 2.076202, acc: 1.000000\n",
      "epoch 1, iter 717, loss: 1.707779, acc: 1.000000\n",
      "epoch 1, iter 718, loss: 1.794548, acc: 0.875000\n",
      "epoch 1, iter 719, loss: 2.776723, acc: 0.875000\n",
      "epoch 1, iter 720, loss: 2.557453, acc: 0.875000\n",
      "epoch 1, iter 721, loss: 2.139794, acc: 1.000000\n",
      "epoch 1, iter 722, loss: 2.598043, acc: 0.875000\n",
      "epoch 1, iter 723, loss: 2.181810, acc: 1.000000\n",
      "epoch 1, iter 724, loss: 1.823255, acc: 1.000000\n",
      "epoch 1, iter 725, loss: 1.845424, acc: 1.000000\n",
      "epoch 1, iter 726, loss: 2.209446, acc: 0.875000\n",
      "epoch 1, iter 727, loss: 1.865399, acc: 1.000000\n",
      "epoch 1, iter 728, loss: 1.878019, acc: 0.875000\n",
      "epoch 1, iter 729, loss: 2.046106, acc: 0.875000\n",
      "epoch 1, iter 730, loss: 2.920466, acc: 0.875000\n",
      "epoch 1, iter 731, loss: 2.434276, acc: 1.000000\n",
      "epoch 1, iter 732, loss: 2.649296, acc: 0.875000\n",
      "epoch 1, iter 733, loss: 2.280829, acc: 1.000000\n",
      "epoch 1, iter 734, loss: 2.114666, acc: 0.875000\n",
      "epoch 1, iter 735, loss: 1.865639, acc: 1.000000\n",
      "epoch 1, iter 736, loss: 1.716564, acc: 1.000000\n",
      "epoch 1, iter 737, loss: 1.455746, acc: 1.000000\n",
      "epoch 1, iter 738, loss: 2.400573, acc: 0.875000\n",
      "epoch 1, iter 739, loss: 1.922455, acc: 1.000000\n",
      "epoch 1, iter 740, loss: 2.885593, acc: 0.875000\n",
      "epoch 1, iter 741, loss: 2.877752, acc: 0.875000\n",
      "epoch 1, iter 742, loss: 2.521034, acc: 1.000000\n",
      "epoch 1, iter 743, loss: 2.087704, acc: 1.000000\n",
      "epoch 1, iter 744, loss: 1.699004, acc: 1.000000\n",
      "epoch 1, iter 745, loss: 1.922747, acc: 0.875000\n",
      "epoch 1, iter 746, loss: 1.818618, acc: 1.000000\n",
      "epoch 1, iter 747, loss: 1.627682, acc: 1.000000\n",
      "epoch 1, iter 748, loss: 1.386750, acc: 1.000000\n",
      "epoch 1, iter 749, loss: 1.499255, acc: 0.875000\n",
      "epoch 1, iter 750, loss: 1.403693, acc: 1.000000\n",
      "epoch 1, iter 751, loss: 1.258088, acc: 1.000000\n",
      "epoch 1, iter 752, loss: 1.124845, acc: 1.000000\n",
      "epoch 1, iter 753, loss: 1.018850, acc: 1.000000\n",
      "epoch 1, iter 754, loss: 1.646641, acc: 0.875000\n",
      "epoch 1, iter 755, loss: 4.116989, acc: 0.625000\n",
      "epoch 1, iter 756, loss: 5.003366, acc: 1.000000\n",
      "epoch 1, iter 757, loss: 5.820881, acc: 0.875000\n",
      "epoch 1, iter 758, loss: 4.912089, acc: 1.000000\n",
      "epoch 1, iter 759, loss: 4.083524, acc: 1.000000\n",
      "epoch 1, iter 760, loss: 3.348040, acc: 1.000000\n",
      "epoch 1, iter 761, loss: 2.858966, acc: 1.000000\n",
      "epoch 1, iter 762, loss: 2.423797, acc: 1.000000\n",
      "epoch 1, iter 763, loss: 2.609468, acc: 0.875000\n",
      "epoch 1, iter 764, loss: 2.220900, acc: 1.000000\n",
      "epoch 1, iter 765, loss: 2.280343, acc: 0.875000\n",
      "epoch 1, iter 766, loss: 1.914811, acc: 1.000000\n",
      "epoch 1, iter 767, loss: 2.087376, acc: 0.875000\n",
      "epoch 1, iter 768, loss: 1.939234, acc: 1.000000\n",
      "epoch 1, iter 769, loss: 1.682688, acc: 1.000000\n",
      "epoch 1, iter 770, loss: 2.980692, acc: 0.875000\n",
      "epoch 1, iter 771, loss: 3.067880, acc: 1.000000\n",
      "epoch 1, iter 772, loss: 3.694699, acc: 0.875000\n",
      "epoch 1, iter 773, loss: 3.804041, acc: 0.875000\n",
      "epoch 1, iter 774, loss: 3.114039, acc: 1.000000\n",
      "epoch 1, iter 775, loss: 2.499480, acc: 1.000000\n",
      "epoch 1, iter 776, loss: 2.767949, acc: 0.875000\n",
      "epoch 1, iter 777, loss: 4.715997, acc: 0.625000\n",
      "epoch 1, iter 778, loss: 4.955879, acc: 1.000000\n",
      "epoch 1, iter 779, loss: 4.308188, acc: 1.000000\n",
      "epoch 1, iter 780, loss: 3.983344, acc: 1.000000\n",
      "epoch 1, iter 781, loss: 5.735314, acc: 0.625000\n",
      "epoch 1, iter 782, loss: 5.878625, acc: 0.750000\n",
      "epoch 1, iter 783, loss: 4.786358, acc: 1.000000\n",
      "epoch 1, iter 784, loss: 4.083218, acc: 1.000000\n",
      "epoch 1, iter 785, loss: 3.388631, acc: 1.000000\n",
      "epoch 1, iter 786, loss: 2.853188, acc: 1.000000\n",
      "epoch 1, iter 787, loss: 2.768551, acc: 1.000000\n",
      "epoch 1, iter 788, loss: 2.496328, acc: 1.000000\n",
      "epoch 1, iter 789, loss: 2.393379, acc: 1.000000\n",
      "epoch 1, iter 790, loss: 2.266712, acc: 1.000000\n",
      "epoch 1, iter 791, loss: 2.268961, acc: 1.000000\n",
      "epoch 1, iter 792, loss: 2.231268, acc: 1.000000\n",
      "epoch 1, iter 793, loss: 2.091169, acc: 1.000000\n",
      "epoch 1, iter 794, loss: 3.392330, acc: 0.875000\n",
      "epoch 1, iter 795, loss: 3.877482, acc: 0.750000\n",
      "epoch 1, iter 796, loss: 4.167086, acc: 0.875000\n",
      "epoch 1, iter 797, loss: 3.967371, acc: 1.000000\n",
      "epoch 1, iter 798, loss: 3.852157, acc: 1.000000\n",
      "epoch 1, iter 799, loss: 3.319054, acc: 1.000000\n",
      "epoch 1, iter 800, loss: 3.229337, acc: 1.000000\n",
      "epoch 1, iter 801, loss: 3.162585, acc: 0.875000\n",
      "epoch 1, iter 802, loss: 3.129438, acc: 1.000000\n",
      "epoch 1, iter 803, loss: 2.786759, acc: 1.000000\n",
      "epoch 1, iter 804, loss: 2.444413, acc: 1.000000\n",
      "epoch 1, iter 805, loss: 2.170254, acc: 1.000000\n",
      "epoch 1, iter 806, loss: 2.297814, acc: 0.875000\n",
      "epoch 1, iter 807, loss: 2.147338, acc: 1.000000\n",
      "epoch 1, iter 808, loss: 1.944492, acc: 1.000000\n",
      "epoch 1, iter 809, loss: 2.017821, acc: 1.000000\n",
      "epoch 1, iter 810, loss: 2.952585, acc: 0.750000\n",
      "epoch 1, iter 811, loss: 2.681140, acc: 1.000000\n",
      "epoch 1, iter 812, loss: 2.378372, acc: 1.000000\n",
      "epoch 1, iter 813, loss: 2.670865, acc: 1.000000\n",
      "epoch 1, iter 814, loss: 3.063737, acc: 0.875000\n",
      "epoch 1, iter 815, loss: 2.673588, acc: 1.000000\n",
      "epoch 1, iter 816, loss: 2.338546, acc: 1.000000\n",
      "epoch 1, iter 817, loss: 2.081454, acc: 1.000000\n",
      "epoch 1, iter 818, loss: 3.473411, acc: 0.625000\n",
      "epoch 1, iter 819, loss: 3.101498, acc: 1.000000\n",
      "epoch 1, iter 820, loss: 2.660182, acc: 1.000000\n",
      "epoch 1, iter 821, loss: 2.812979, acc: 0.875000\n",
      "epoch 1, iter 822, loss: 2.456086, acc: 1.000000\n",
      "epoch 1, iter 823, loss: 2.170443, acc: 1.000000\n",
      "epoch 1, iter 824, loss: 2.659326, acc: 0.875000\n",
      "epoch 1, iter 825, loss: 2.452983, acc: 1.000000\n",
      "epoch 1, iter 826, loss: 3.140680, acc: 0.875000\n",
      "epoch 1, iter 827, loss: 2.800476, acc: 1.000000\n",
      "epoch 1, iter 828, loss: 2.426512, acc: 1.000000\n",
      "epoch 1, iter 829, loss: 2.139921, acc: 1.000000\n",
      "epoch 1, iter 830, loss: 1.929680, acc: 1.000000\n",
      "epoch 1, iter 831, loss: 3.034163, acc: 0.750000\n",
      "epoch 1, iter 832, loss: 3.436813, acc: 0.875000\n",
      "epoch 1, iter 833, loss: 4.034056, acc: 1.000000\n",
      "epoch 1, iter 834, loss: 3.573213, acc: 1.000000\n",
      "epoch 1, iter 835, loss: 3.019912, acc: 1.000000\n",
      "epoch 1, iter 836, loss: 2.567625, acc: 1.000000\n",
      "epoch 1, iter 837, loss: 2.515252, acc: 1.000000\n",
      "epoch 1, iter 838, loss: 2.326060, acc: 1.000000\n",
      "epoch 1, iter 839, loss: 2.087172, acc: 1.000000\n",
      "epoch 1, iter 840, loss: 1.889235, acc: 1.000000\n",
      "epoch 1, iter 841, loss: 2.305099, acc: 0.875000\n",
      "epoch 1, iter 842, loss: 2.161416, acc: 1.000000\n",
      "epoch 1, iter 843, loss: 2.269384, acc: 1.000000\n",
      "epoch 1, iter 844, loss: 2.512274, acc: 0.875000\n",
      "epoch 1, iter 845, loss: 3.444964, acc: 0.750000\n",
      "epoch 1, iter 846, loss: 3.065925, acc: 1.000000\n",
      "epoch 1, iter 847, loss: 2.648136, acc: 1.000000\n",
      "epoch 1, iter 848, loss: 2.302977, acc: 1.000000\n",
      "epoch 1, iter 849, loss: 2.461127, acc: 1.000000\n",
      "epoch 1, iter 850, loss: 2.332114, acc: 1.000000\n",
      "epoch 1, iter 851, loss: 2.417155, acc: 0.875000\n",
      "epoch 1, iter 852, loss: 2.214778, acc: 1.000000\n",
      "epoch 1, iter 853, loss: 2.002503, acc: 1.000000\n",
      "epoch 1, iter 854, loss: 2.935030, acc: 0.875000\n",
      "epoch 1, iter 855, loss: 3.080502, acc: 0.875000\n",
      "epoch 1, iter 856, loss: 2.934117, acc: 1.000000\n",
      "epoch 1, iter 857, loss: 2.932581, acc: 0.875000\n",
      "epoch 1, iter 858, loss: 3.274897, acc: 1.000000\n",
      "epoch 1, iter 859, loss: 2.763892, acc: 1.000000\n",
      "epoch 1, iter 860, loss: 2.367855, acc: 1.000000\n",
      "epoch 1, iter 861, loss: 2.543276, acc: 0.875000\n",
      "epoch 1, iter 862, loss: 2.256116, acc: 1.000000\n",
      "epoch 1, iter 863, loss: 2.243597, acc: 1.000000\n",
      "epoch 1, iter 864, loss: 2.264363, acc: 1.000000\n",
      "epoch 1, iter 865, loss: 2.151320, acc: 1.000000\n",
      "epoch 1, iter 866, loss: 2.203105, acc: 0.875000\n",
      "epoch 1, iter 867, loss: 2.053209, acc: 1.000000\n",
      "epoch 1, iter 868, loss: 2.046860, acc: 1.000000\n",
      "epoch 1, iter 869, loss: 1.886532, acc: 1.000000\n",
      "epoch 1, iter 870, loss: 3.010893, acc: 0.875000\n",
      "epoch 1, iter 871, loss: 2.808881, acc: 1.000000\n",
      "epoch 1, iter 872, loss: 2.575491, acc: 1.000000\n",
      "epoch 1, iter 873, loss: 2.284485, acc: 1.000000\n",
      "epoch 1, iter 874, loss: 2.242790, acc: 1.000000\n",
      "epoch 1, iter 875, loss: 2.038770, acc: 1.000000\n",
      "epoch 1, iter 876, loss: 3.049751, acc: 0.625000\n",
      "epoch 1, iter 877, loss: 4.610793, acc: 0.875000\n",
      "epoch 1, iter 878, loss: 4.020560, acc: 0.875000\n",
      "epoch 1, iter 879, loss: 3.894548, acc: 1.000000\n",
      "epoch 1, iter 880, loss: 3.146408, acc: 1.000000\n",
      "epoch 1, iter 881, loss: 2.607075, acc: 1.000000\n",
      "epoch 1, iter 882, loss: 2.734222, acc: 1.000000\n",
      "epoch 1, iter 883, loss: 2.504981, acc: 1.000000\n",
      "epoch 1, iter 884, loss: 2.582372, acc: 0.875000\n",
      "epoch 1, iter 885, loss: 2.297512, acc: 1.000000\n",
      "epoch 1, iter 886, loss: 2.037099, acc: 1.000000\n",
      "epoch 1, iter 887, loss: 2.119472, acc: 1.000000\n",
      "epoch 1, iter 888, loss: 2.719730, acc: 0.875000\n",
      "epoch 1, iter 889, loss: 2.555655, acc: 1.000000\n",
      "epoch 1, iter 890, loss: 2.484547, acc: 1.000000\n",
      "epoch 1, iter 891, loss: 2.480446, acc: 1.000000\n",
      "epoch 1, iter 892, loss: 2.859980, acc: 1.000000\n",
      "epoch 1, iter 893, loss: 2.701247, acc: 1.000000\n",
      "epoch 1, iter 894, loss: 3.343978, acc: 1.000000\n",
      "epoch 1, iter 895, loss: 3.096418, acc: 0.875000\n",
      "epoch 1, iter 896, loss: 2.614551, acc: 1.000000\n",
      "epoch 1, iter 897, loss: 2.711937, acc: 0.875000\n",
      "epoch 1, iter 898, loss: 2.326105, acc: 1.000000\n",
      "epoch 1, iter 899, loss: 1.992737, acc: 1.000000\n",
      "epoch 1, iter 900, loss: 2.142128, acc: 0.875000\n",
      "epoch 1, iter 901, loss: 3.148160, acc: 0.875000\n",
      "epoch 1, iter 902, loss: 2.858857, acc: 1.000000\n",
      "epoch 1, iter 903, loss: 2.803312, acc: 0.875000\n",
      "epoch 1, iter 904, loss: 2.474530, acc: 1.000000\n",
      "epoch 1, iter 905, loss: 2.820941, acc: 1.000000\n",
      "epoch 1, iter 906, loss: 2.540437, acc: 1.000000\n",
      "epoch 1, iter 907, loss: 3.130930, acc: 1.000000\n",
      "epoch 1, iter 908, loss: 3.178146, acc: 1.000000\n",
      "epoch 1, iter 909, loss: 3.235105, acc: 0.875000\n",
      "epoch 1, iter 910, loss: 2.734153, acc: 1.000000\n",
      "epoch 1, iter 911, loss: 3.768263, acc: 0.750000\n",
      "epoch 1, iter 912, loss: 4.114210, acc: 0.875000\n",
      "epoch 1, iter 913, loss: 3.803588, acc: 0.875000\n",
      "epoch 1, iter 914, loss: 3.172611, acc: 1.000000\n",
      "epoch 1, iter 915, loss: 2.644743, acc: 1.000000\n",
      "epoch 1, iter 916, loss: 2.725447, acc: 0.875000\n",
      "epoch 1, iter 917, loss: 2.460881, acc: 1.000000\n",
      "epoch 1, iter 918, loss: 2.153915, acc: 1.000000\n",
      "epoch 1, iter 919, loss: 1.901828, acc: 1.000000\n",
      "epoch 1, iter 920, loss: 2.068443, acc: 1.000000\n",
      "epoch 1, iter 921, loss: 1.949907, acc: 1.000000\n",
      "epoch 1, iter 922, loss: 2.122517, acc: 0.875000\n",
      "epoch 1, iter 923, loss: 1.963253, acc: 1.000000\n",
      "epoch 1, iter 924, loss: 1.787415, acc: 1.000000\n",
      "epoch 1, iter 925, loss: 1.638700, acc: 1.000000\n",
      "epoch 1, iter 926, loss: 1.523757, acc: 1.000000\n",
      "epoch 1, iter 927, loss: 1.819757, acc: 0.875000\n",
      "epoch 1, iter 928, loss: 2.039865, acc: 1.000000\n",
      "epoch 1, iter 929, loss: 1.921289, acc: 1.000000\n",
      "epoch 1, iter 930, loss: 1.947215, acc: 1.000000\n",
      "epoch 1, iter 931, loss: 1.853808, acc: 1.000000\n",
      "epoch 1, iter 932, loss: 1.687216, acc: 1.000000\n",
      "epoch 1, iter 933, loss: 2.862193, acc: 0.750000\n",
      "epoch 1, iter 934, loss: 3.721211, acc: 0.875000\n",
      "epoch 1, iter 935, loss: 3.212852, acc: 1.000000\n",
      "epoch 1, iter 936, loss: 2.637864, acc: 1.000000\n",
      "epoch 1, iter 937, loss: 2.223101, acc: 1.000000\n",
      "epoch 1, iter 938, loss: 1.923788, acc: 1.000000\n",
      "epoch 1, iter 939, loss: 2.137871, acc: 0.875000\n",
      "epoch 1, iter 940, loss: 1.921732, acc: 1.000000\n",
      "epoch 1, iter 941, loss: 1.727659, acc: 1.000000\n",
      "epoch 1, iter 942, loss: 1.880734, acc: 0.875000\n",
      "epoch 1, iter 943, loss: 1.770592, acc: 1.000000\n",
      "epoch 1, iter 944, loss: 1.800474, acc: 1.000000\n",
      "epoch 1, iter 945, loss: 1.757487, acc: 1.000000\n",
      "epoch 1, iter 946, loss: 2.447924, acc: 0.875000\n",
      "epoch 1, iter 947, loss: 2.245832, acc: 1.000000\n",
      "epoch 1, iter 948, loss: 2.208236, acc: 1.000000\n",
      "epoch 1, iter 949, loss: 2.051952, acc: 1.000000\n",
      "epoch 1, iter 950, loss: 2.370658, acc: 0.875000\n",
      "epoch 1, iter 951, loss: 2.234166, acc: 1.000000\n",
      "epoch 1, iter 952, loss: 2.224600, acc: 1.000000\n",
      "epoch 1, iter 953, loss: 2.069156, acc: 1.000000\n",
      "epoch 1, iter 954, loss: 3.443058, acc: 0.875000\n",
      "epoch 1, iter 955, loss: 3.151040, acc: 1.000000\n",
      "epoch 1, iter 956, loss: 2.673940, acc: 1.000000\n",
      "epoch 1, iter 957, loss: 2.870844, acc: 0.875000\n",
      "epoch 1, iter 958, loss: 2.526504, acc: 1.000000\n",
      "epoch 1, iter 959, loss: 2.729654, acc: 0.875000\n",
      "epoch 1, iter 960, loss: 2.392985, acc: 1.000000\n",
      "epoch 1, iter 961, loss: 2.074833, acc: 1.000000\n",
      "epoch 1, iter 962, loss: 2.121330, acc: 0.875000\n",
      "epoch 1, iter 963, loss: 1.942977, acc: 1.000000\n",
      "epoch 1, iter 964, loss: 1.920411, acc: 1.000000\n",
      "epoch 1, iter 965, loss: 1.778377, acc: 1.000000\n",
      "epoch 1, iter 966, loss: 1.967936, acc: 0.875000\n",
      "epoch 1, iter 967, loss: 1.873308, acc: 1.000000\n",
      "epoch 1, iter 968, loss: 1.703575, acc: 1.000000\n",
      "epoch 1, iter 969, loss: 1.547228, acc: 1.000000\n",
      "epoch 1, iter 970, loss: 1.778280, acc: 1.000000\n",
      "epoch 1, iter 971, loss: 2.391625, acc: 0.875000\n",
      "epoch 1, iter 972, loss: 2.195609, acc: 1.000000\n",
      "epoch 1, iter 973, loss: 1.910531, acc: 1.000000\n",
      "epoch 1, iter 974, loss: 3.459235, acc: 0.875000\n",
      "epoch 1, iter 975, loss: 2.697056, acc: 1.000000\n",
      "epoch 1, iter 976, loss: 2.924558, acc: 0.875000\n",
      "epoch 1, iter 977, loss: 2.338166, acc: 1.000000\n",
      "epoch 1, iter 978, loss: 1.875962, acc: 1.000000\n",
      "epoch 1, iter 979, loss: 2.262411, acc: 0.875000\n",
      "epoch 1, iter 980, loss: 2.155530, acc: 1.000000\n",
      "epoch 1, iter 981, loss: 2.283070, acc: 0.875000\n",
      "epoch 1, iter 982, loss: 2.958189, acc: 0.875000\n",
      "epoch 1, iter 983, loss: 3.420519, acc: 0.875000\n",
      "epoch 1, iter 984, loss: 3.208778, acc: 0.875000\n",
      "epoch 1, iter 985, loss: 2.921567, acc: 1.000000\n",
      "epoch 1, iter 986, loss: 2.687509, acc: 1.000000\n",
      "epoch 1, iter 987, loss: 3.314852, acc: 0.875000\n",
      "epoch 1, iter 988, loss: 4.024763, acc: 0.500000\n",
      "epoch 1, iter 989, loss: 4.619421, acc: 0.625000\n",
      "epoch 1, iter 990, loss: 4.136446, acc: 0.875000\n",
      "epoch 1, iter 991, loss: 3.448140, acc: 1.000000\n",
      "epoch 1, iter 992, loss: 2.929697, acc: 1.000000\n",
      "epoch 1, iter 993, loss: 2.461935, acc: 1.000000\n",
      "epoch 1, iter 994, loss: 2.453587, acc: 0.875000\n",
      "epoch 1, iter 995, loss: 2.205044, acc: 1.000000\n",
      "epoch 1, iter 996, loss: 2.093444, acc: 1.000000\n",
      "epoch 1, iter 997, loss: 2.219861, acc: 0.875000\n",
      "epoch 1, iter 998, loss: 2.379288, acc: 1.000000\n",
      "epoch 1, iter 999, loss: 2.258766, acc: 1.000000\n",
      "epoch 1, iter 1000, loss: 2.139437, acc: 1.000000\n",
      "epoch 1, iter 1001, loss: 2.116832, acc: 1.000000\n",
      "epoch 1, iter 1002, loss: 2.066638, acc: 1.000000\n",
      "epoch 1, iter 1003, loss: 1.942187, acc: 1.000000\n",
      "epoch 1, iter 1004, loss: 1.736328, acc: 1.000000\n",
      "epoch 1, iter 1005, loss: 2.726976, acc: 0.875000\n",
      "epoch 1, iter 1006, loss: 2.384375, acc: 1.000000\n",
      "epoch 1, iter 1007, loss: 3.329907, acc: 0.875000\n",
      "epoch 1, iter 1008, loss: 2.795544, acc: 1.000000\n",
      "epoch 1, iter 1009, loss: 2.989334, acc: 1.000000\n",
      "epoch 1, iter 1010, loss: 4.612051, acc: 0.750000\n",
      "epoch 1, iter 1011, loss: 4.193609, acc: 1.000000\n",
      "epoch 1, iter 1012, loss: 3.389441, acc: 1.000000\n",
      "epoch 1, iter 1013, loss: 2.761188, acc: 1.000000\n",
      "epoch 1, iter 1014, loss: 2.852817, acc: 0.875000\n",
      "epoch 1, iter 1015, loss: 2.487340, acc: 1.000000\n",
      "epoch 1, iter 1016, loss: 2.567949, acc: 0.875000\n",
      "epoch 1, iter 1017, loss: 2.209299, acc: 1.000000\n",
      "epoch 1, iter 1018, loss: 1.913544, acc: 1.000000\n",
      "epoch 1, iter 1019, loss: 2.129868, acc: 0.875000\n",
      "epoch 1, iter 1020, loss: 2.003786, acc: 1.000000\n",
      "epoch 1, iter 1021, loss: 1.790853, acc: 1.000000\n",
      "epoch 1, iter 1022, loss: 1.584667, acc: 1.000000\n",
      "epoch 1, iter 1023, loss: 1.410361, acc: 1.000000\n",
      "epoch 1, iter 1024, loss: 1.740261, acc: 0.875000\n",
      "epoch 1, iter 1025, loss: 1.754414, acc: 1.000000\n",
      "epoch 1, iter 1026, loss: 1.648600, acc: 1.000000\n",
      "epoch 1, iter 1027, loss: 3.102603, acc: 0.750000\n",
      "epoch 1, iter 1028, loss: 3.132287, acc: 0.875000\n",
      "epoch 1, iter 1029, loss: 3.184732, acc: 1.000000\n",
      "epoch 1, iter 1030, loss: 3.108577, acc: 1.000000\n",
      "epoch 1, iter 1031, loss: 2.902947, acc: 1.000000\n",
      "epoch 1, iter 1032, loss: 2.552665, acc: 1.000000\n",
      "epoch 1, iter 1033, loss: 2.455235, acc: 1.000000\n",
      "epoch 1, iter 1034, loss: 2.308972, acc: 1.000000\n",
      "epoch 1, iter 1035, loss: 2.115796, acc: 1.000000\n",
      "epoch 1, iter 1036, loss: 2.010620, acc: 1.000000\n",
      "epoch 1, iter 1037, loss: 2.054831, acc: 0.875000\n",
      "epoch 1, iter 1038, loss: 1.976746, acc: 1.000000\n",
      "epoch 1, iter 1039, loss: 1.965293, acc: 1.000000\n",
      "epoch 1, iter 1040, loss: 4.247996, acc: 0.875000\n",
      "epoch 1, iter 1041, loss: 3.438899, acc: 1.000000\n",
      "epoch 1, iter 1042, loss: 4.544489, acc: 0.875000\n",
      "epoch 1, iter 1043, loss: 5.265814, acc: 0.750000\n",
      "epoch 1, iter 1044, loss: 4.516796, acc: 0.875000\n",
      "epoch 1, iter 1045, loss: 3.835518, acc: 1.000000\n",
      "epoch 1, iter 1046, loss: 3.163754, acc: 1.000000\n",
      "epoch 1, iter 1047, loss: 3.340883, acc: 1.000000\n",
      "epoch 1, iter 1048, loss: 3.179171, acc: 1.000000\n",
      "epoch 1, iter 1049, loss: 2.524712, acc: 1.000000\n",
      "epoch 1, iter 1050, loss: 2.523667, acc: 0.875000\n",
      "epoch 1, iter 1051, loss: 2.123692, acc: 1.000000\n",
      "epoch 1, iter 1052, loss: 3.091213, acc: 0.750000\n",
      "epoch 1, iter 1053, loss: 2.877054, acc: 1.000000\n",
      "epoch 1, iter 1054, loss: 2.481330, acc: 1.000000\n",
      "epoch 1, iter 1055, loss: 2.116195, acc: 1.000000\n",
      "epoch 1, iter 1056, loss: 1.828410, acc: 1.000000\n",
      "epoch 1, iter 1057, loss: 2.873129, acc: 0.875000\n",
      "epoch 1, iter 1058, loss: 2.986989, acc: 0.875000\n",
      "epoch 1, iter 1059, loss: 2.645607, acc: 1.000000\n",
      "epoch 1, iter 1060, loss: 2.255169, acc: 1.000000\n",
      "epoch 1, iter 1061, loss: 2.966942, acc: 0.750000\n",
      "epoch 1, iter 1062, loss: 2.597549, acc: 1.000000\n",
      "epoch 1, iter 1063, loss: 2.172272, acc: 1.000000\n",
      "epoch 1, iter 1064, loss: 3.121612, acc: 0.875000\n",
      "epoch 1, iter 1065, loss: 2.658710, acc: 1.000000\n",
      "epoch 1, iter 1066, loss: 2.248744, acc: 1.000000\n",
      "epoch 1, iter 1067, loss: 2.873843, acc: 0.875000\n",
      "epoch 1, iter 1068, loss: 2.412667, acc: 1.000000\n",
      "epoch 1, iter 1069, loss: 2.667466, acc: 0.875000\n",
      "epoch 1, iter 1070, loss: 3.285047, acc: 0.750000\n",
      "epoch 1, iter 1071, loss: 2.829223, acc: 1.000000\n",
      "epoch 1, iter 1072, loss: 2.348212, acc: 1.000000\n",
      "epoch 1, iter 1073, loss: 2.493295, acc: 0.875000\n",
      "epoch 1, iter 1074, loss: 2.147669, acc: 1.000000\n",
      "epoch 1, iter 1075, loss: 2.260818, acc: 0.875000\n",
      "epoch 1, iter 1076, loss: 2.033262, acc: 1.000000\n",
      "epoch 1, iter 1077, loss: 1.794768, acc: 1.000000\n",
      "epoch 1, iter 1078, loss: 1.599319, acc: 1.000000\n",
      "epoch 1, iter 1079, loss: 1.450586, acc: 1.000000\n",
      "epoch 1, iter 1080, loss: 1.766396, acc: 0.875000\n",
      "epoch 1, iter 1081, loss: 2.365970, acc: 0.875000\n",
      "epoch 1, iter 1082, loss: 2.035087, acc: 1.000000\n",
      "epoch 1, iter 1083, loss: 1.768066, acc: 1.000000\n",
      "epoch 1, iter 1084, loss: 1.568742, acc: 1.000000\n",
      "epoch 1, iter 1085, loss: 2.326766, acc: 0.875000\n",
      "epoch 1, iter 1086, loss: 2.080841, acc: 1.000000\n",
      "epoch 1, iter 1087, loss: 2.188495, acc: 0.875000\n",
      "epoch 1, iter 1088, loss: 1.956517, acc: 1.000000\n",
      "epoch 1, iter 1089, loss: 1.737933, acc: 1.000000\n",
      "epoch 1, iter 1090, loss: 1.559076, acc: 1.000000\n",
      "epoch 1, iter 1091, loss: 1.421154, acc: 1.000000\n",
      "epoch 1, iter 1092, loss: 2.105085, acc: 0.875000\n",
      "epoch 1, iter 1093, loss: 1.917931, acc: 1.000000\n",
      "epoch 1, iter 1094, loss: 1.713839, acc: 1.000000\n",
      "epoch 1, iter 1095, loss: 1.946536, acc: 0.875000\n",
      "epoch 1, iter 1096, loss: 1.851719, acc: 1.000000\n",
      "epoch 1, iter 1097, loss: 2.873387, acc: 0.625000\n",
      "epoch 1, iter 1098, loss: 2.624247, acc: 1.000000\n",
      "epoch 1, iter 1099, loss: 2.203069, acc: 1.000000\n",
      "epoch 1, iter 1100, loss: 1.878066, acc: 1.000000\n",
      "epoch 1, iter 1101, loss: 1.637174, acc: 1.000000\n",
      "epoch 1, iter 1102, loss: 1.893117, acc: 0.875000\n",
      "epoch 1, iter 1103, loss: 2.051854, acc: 0.875000\n",
      "epoch 1, iter 1104, loss: 1.962984, acc: 1.000000\n",
      "epoch 1, iter 1105, loss: 3.000582, acc: 0.875000\n",
      "epoch 1, iter 1106, loss: 2.791358, acc: 1.000000\n",
      "epoch 1, iter 1107, loss: 2.469691, acc: 1.000000\n",
      "epoch 1, iter 1108, loss: 3.486383, acc: 0.750000\n",
      "epoch 1, iter 1109, loss: 3.021656, acc: 1.000000\n",
      "epoch 1, iter 1110, loss: 2.945047, acc: 0.875000\n",
      "epoch 1, iter 1111, loss: 2.492680, acc: 1.000000\n",
      "epoch 1, iter 1112, loss: 3.475126, acc: 0.875000\n",
      "epoch 1, iter 1113, loss: 3.103390, acc: 1.000000\n",
      "epoch 1, iter 1114, loss: 2.790439, acc: 1.000000\n",
      "epoch 1, iter 1115, loss: 3.641130, acc: 0.875000\n",
      "epoch 1, iter 1116, loss: 2.975106, acc: 1.000000\n",
      "epoch 1, iter 1117, loss: 2.412721, acc: 1.000000\n",
      "epoch 1, iter 1118, loss: 3.638611, acc: 0.750000\n",
      "epoch 1, iter 1119, loss: 3.078658, acc: 1.000000\n",
      "epoch 1, iter 1120, loss: 3.588047, acc: 0.875000\n",
      "epoch 1, iter 1121, loss: 3.058065, acc: 1.000000\n",
      "epoch 1, iter 1122, loss: 2.805891, acc: 1.000000\n",
      "epoch 1, iter 1123, loss: 2.404528, acc: 1.000000\n",
      "epoch 1, iter 1124, loss: 2.225499, acc: 1.000000\n",
      "epoch 1, iter 1125, loss: 3.375743, acc: 0.750000\n",
      "epoch 1, iter 1126, loss: 3.135631, acc: 1.000000\n",
      "epoch 1, iter 1127, loss: 2.766996, acc: 1.000000\n",
      "epoch 1, iter 1128, loss: 2.456457, acc: 1.000000\n",
      "epoch 1, iter 1129, loss: 2.215973, acc: 1.000000\n",
      "epoch 1, iter 1130, loss: 2.045529, acc: 1.000000\n",
      "epoch 1, iter 1131, loss: 1.816825, acc: 1.000000\n",
      "epoch 1, iter 1132, loss: 1.611651, acc: 1.000000\n",
      "epoch 1, iter 1133, loss: 1.952193, acc: 0.875000\n",
      "epoch 1, iter 1134, loss: 2.437350, acc: 1.000000\n",
      "epoch 1, iter 1135, loss: 2.223615, acc: 1.000000\n",
      "epoch 1, iter 1136, loss: 1.943727, acc: 1.000000\n",
      "epoch 1, iter 1137, loss: 2.143776, acc: 1.000000\n",
      "epoch 1, iter 1138, loss: 2.198383, acc: 1.000000\n",
      "epoch 1, iter 1139, loss: 1.985376, acc: 1.000000\n",
      "epoch 1, iter 1140, loss: 1.729033, acc: 1.000000\n",
      "epoch 1, iter 1141, loss: 1.499640, acc: 1.000000\n",
      "epoch 1, iter 1142, loss: 1.312654, acc: 1.000000\n",
      "epoch 1, iter 1143, loss: 1.166104, acc: 1.000000\n",
      "epoch 1, iter 1144, loss: 1.053302, acc: 1.000000\n",
      "epoch 1, iter 1145, loss: 0.967145, acc: 1.000000\n",
      "epoch 1, iter 1146, loss: 1.562423, acc: 0.875000\n",
      "epoch 1, iter 1147, loss: 1.374077, acc: 1.000000\n",
      "epoch 1, iter 1148, loss: 1.220223, acc: 1.000000\n",
      "epoch 1, iter 1149, loss: 4.051190, acc: 0.750000\n",
      "epoch 1, iter 1150, loss: 4.108327, acc: 1.000000\n",
      "epoch 1, iter 1151, loss: 3.573533, acc: 0.875000\n",
      "epoch 1, iter 1152, loss: 4.637883, acc: 0.750000\n",
      "epoch 1, iter 1153, loss: 3.615492, acc: 1.000000\n",
      "epoch 1, iter 1154, loss: 3.480530, acc: 0.875000\n",
      "epoch 1, iter 1155, loss: 2.869075, acc: 1.000000\n",
      "epoch 1, iter 1156, loss: 2.711273, acc: 0.875000\n",
      "epoch 1, iter 1157, loss: 2.461847, acc: 1.000000\n",
      "epoch 1, iter 1158, loss: 2.262959, acc: 1.000000\n",
      "epoch 1, iter 1159, loss: 2.049978, acc: 1.000000\n",
      "epoch 1, iter 1160, loss: 2.520749, acc: 0.875000\n",
      "epoch 1, iter 1161, loss: 2.351851, acc: 1.000000\n",
      "epoch 1, iter 1162, loss: 2.058981, acc: 1.000000\n",
      "epoch 1, iter 1163, loss: 2.011341, acc: 1.000000\n",
      "epoch 1, iter 1164, loss: 1.891230, acc: 1.000000\n",
      "epoch 1, iter 1165, loss: 2.044804, acc: 0.875000\n",
      "epoch 1, iter 1166, loss: 1.836542, acc: 1.000000\n",
      "epoch 1, iter 1167, loss: 1.821615, acc: 1.000000\n",
      "epoch 1, iter 1168, loss: 3.802226, acc: 0.625000\n",
      "epoch 1, iter 1169, loss: 3.163702, acc: 1.000000\n",
      "epoch 1, iter 1170, loss: 2.584068, acc: 1.000000\n",
      "epoch 1, iter 1171, loss: 2.138954, acc: 1.000000\n",
      "epoch 1, iter 1172, loss: 1.810683, acc: 1.000000\n",
      "epoch 1, iter 1173, loss: 3.263360, acc: 0.750000\n",
      "epoch 1, iter 1174, loss: 3.373683, acc: 0.875000\n",
      "epoch 1, iter 1175, loss: 2.938733, acc: 1.000000\n",
      "epoch 1, iter 1176, loss: 2.629061, acc: 1.000000\n",
      "epoch 1, iter 1177, loss: 3.131178, acc: 0.875000\n",
      "epoch 1, iter 1178, loss: 3.690880, acc: 0.875000\n",
      "epoch 1, iter 1179, loss: 3.960343, acc: 0.875000\n",
      "epoch 1, iter 1180, loss: 4.000952, acc: 0.875000\n",
      "epoch 1, iter 1181, loss: 3.397649, acc: 1.000000\n",
      "epoch 1, iter 1182, loss: 4.273918, acc: 0.875000\n",
      "epoch 1, iter 1183, loss: 3.399271, acc: 1.000000\n",
      "epoch 1, iter 1184, loss: 2.722153, acc: 1.000000\n",
      "epoch 1, iter 1185, loss: 2.227562, acc: 1.000000\n",
      "epoch 1, iter 1186, loss: 1.871610, acc: 1.000000\n",
      "epoch 1, iter 1187, loss: 2.180508, acc: 0.875000\n",
      "epoch 1, iter 1188, loss: 2.946598, acc: 0.875000\n",
      "epoch 1, iter 1189, loss: 3.121209, acc: 1.000000\n",
      "epoch 1, iter 1190, loss: 2.639688, acc: 1.000000\n",
      "epoch 1, iter 1191, loss: 2.561538, acc: 0.875000\n",
      "epoch 1, iter 1192, loss: 2.250354, acc: 1.000000\n",
      "epoch 1, iter 1193, loss: 2.075206, acc: 1.000000\n",
      "epoch 1, iter 1194, loss: 2.092148, acc: 0.875000\n",
      "epoch 1, iter 1195, loss: 3.231467, acc: 0.875000\n",
      "epoch 1, iter 1196, loss: 2.674163, acc: 1.000000\n",
      "epoch 1, iter 1197, loss: 2.207518, acc: 1.000000\n",
      "epoch 1, iter 1198, loss: 2.339854, acc: 0.875000\n",
      "epoch 1, iter 1199, loss: 1.999567, acc: 1.000000\n",
      "epoch 1, iter 1200, loss: 2.804145, acc: 0.875000\n",
      "epoch 1, iter 1201, loss: 4.241226, acc: 0.875000\n",
      "epoch 1, iter 1202, loss: 4.505659, acc: 0.875000\n",
      "epoch 1, iter 1203, loss: 3.817806, acc: 1.000000\n",
      "epoch 1, iter 1204, loss: 3.022955, acc: 1.000000\n",
      "epoch 1, iter 1205, loss: 2.435895, acc: 1.000000\n",
      "epoch 1, iter 1206, loss: 2.011838, acc: 1.000000\n",
      "epoch 1, iter 1207, loss: 1.708621, acc: 1.000000\n",
      "epoch 1, iter 1208, loss: 3.111311, acc: 0.750000\n",
      "epoch 1, iter 1209, loss: 2.750126, acc: 1.000000\n",
      "epoch 1, iter 1210, loss: 2.308943, acc: 1.000000\n",
      "epoch 1, iter 1211, loss: 2.359627, acc: 0.875000\n",
      "epoch 1, iter 1212, loss: 2.763383, acc: 0.875000\n",
      "epoch 1, iter 1213, loss: 2.277251, acc: 1.000000\n",
      "epoch 1, iter 1214, loss: 3.477934, acc: 0.750000\n",
      "epoch 1, iter 1215, loss: 3.230036, acc: 0.875000\n",
      "epoch 1, iter 1216, loss: 2.728220, acc: 1.000000\n",
      "epoch 1, iter 1217, loss: 2.855133, acc: 0.875000\n",
      "epoch 1, iter 1218, loss: 2.733245, acc: 1.000000\n",
      "epoch 1, iter 1219, loss: 2.248336, acc: 1.000000\n",
      "epoch 1, iter 1220, loss: 2.320839, acc: 1.000000\n",
      "epoch 1, iter 1221, loss: 2.213637, acc: 1.000000\n",
      "epoch 1, iter 1222, loss: 2.061037, acc: 1.000000\n",
      "epoch 1, iter 1223, loss: 2.716100, acc: 1.000000\n",
      "epoch 1, iter 1224, loss: 2.741395, acc: 0.875000\n",
      "epoch 1, iter 1225, loss: 2.346941, acc: 1.000000\n",
      "epoch 1, iter 1226, loss: 1.996477, acc: 1.000000\n",
      "epoch 1, iter 1227, loss: 2.794487, acc: 0.875000\n",
      "epoch 1, iter 1228, loss: 2.860707, acc: 0.875000\n",
      "epoch 1, iter 1229, loss: 2.463189, acc: 1.000000\n",
      "epoch 1, iter 1230, loss: 2.076748, acc: 1.000000\n",
      "epoch 1, iter 1231, loss: 2.331942, acc: 0.875000\n",
      "epoch 1, iter 1232, loss: 3.083971, acc: 0.875000\n",
      "epoch 1, iter 1233, loss: 2.935334, acc: 0.875000\n",
      "epoch 1, iter 1234, loss: 2.486314, acc: 1.000000\n",
      "epoch 1, iter 1235, loss: 2.948897, acc: 0.875000\n",
      "epoch 1, iter 1236, loss: 2.717367, acc: 1.000000\n",
      "epoch 1, iter 1237, loss: 3.388530, acc: 1.000000\n",
      "epoch 1, iter 1238, loss: 3.031099, acc: 1.000000\n",
      "epoch 1, iter 1239, loss: 2.527764, acc: 1.000000\n",
      "epoch 1, iter 1240, loss: 2.655051, acc: 1.000000\n",
      "epoch 1, iter 1241, loss: 2.360590, acc: 1.000000\n",
      "epoch 1, iter 1242, loss: 1.995016, acc: 1.000000\n",
      "epoch 1, iter 1243, loss: 2.161408, acc: 0.875000\n",
      "epoch 1, iter 1244, loss: 2.042599, acc: 1.000000\n",
      "epoch 1, iter 1245, loss: 2.295993, acc: 0.875000\n",
      "epoch 1, iter 1246, loss: 2.123710, acc: 1.000000\n",
      "epoch 1, iter 1247, loss: 1.852932, acc: 1.000000\n",
      "epoch 1, iter 1248, loss: 3.834667, acc: 0.625000\n",
      "epoch 1, iter 1249, loss: 3.317678, acc: 1.000000\n",
      "epoch 1, iter 1250, loss: 2.661063, acc: 1.000000\n",
      "epoch 1, iter 1251, loss: 2.409056, acc: 0.875000\n",
      "epoch 1, iter 1252, loss: 2.935460, acc: 0.875000\n",
      "epoch 1, iter 1253, loss: 2.871018, acc: 0.875000\n",
      "epoch 1, iter 1254, loss: 2.546978, acc: 1.000000\n",
      "epoch 1, iter 1255, loss: 2.186623, acc: 1.000000\n",
      "epoch 1, iter 1256, loss: 2.860776, acc: 0.750000\n",
      "epoch 1, iter 1257, loss: 2.608459, acc: 1.000000\n",
      "epoch 1, iter 1258, loss: 2.434972, acc: 1.000000\n",
      "epoch 1, iter 1259, loss: 2.839197, acc: 0.875000\n",
      "epoch 1, iter 1260, loss: 2.418214, acc: 1.000000\n",
      "epoch 1, iter 1261, loss: 3.536050, acc: 0.875000\n",
      "epoch 1, iter 1262, loss: 3.009439, acc: 1.000000\n",
      "epoch 1, iter 1263, loss: 3.400661, acc: 0.875000\n",
      "epoch 1, iter 1264, loss: 3.194310, acc: 0.875000\n",
      "epoch 1, iter 1265, loss: 2.641395, acc: 1.000000\n",
      "epoch 1, iter 1266, loss: 2.194907, acc: 1.000000\n",
      "epoch 1, iter 1267, loss: 1.854746, acc: 1.000000\n",
      "epoch 1, iter 1268, loss: 1.602928, acc: 1.000000\n",
      "epoch 1, iter 1269, loss: 1.419308, acc: 1.000000\n",
      "epoch 1, iter 1270, loss: 1.286454, acc: 1.000000\n",
      "epoch 1, iter 1271, loss: 1.190638, acc: 1.000000\n",
      "epoch 1, iter 1272, loss: 1.121529, acc: 1.000000\n",
      "epoch 1, iter 1273, loss: 1.071545, acc: 1.000000\n",
      "epoch 1, iter 1274, loss: 1.035205, acc: 1.000000\n",
      "epoch 1, iter 1275, loss: 1.008579, acc: 1.000000\n",
      "epoch 1, iter 1276, loss: 1.725548, acc: 0.875000\n",
      "epoch 1, iter 1277, loss: 1.585409, acc: 1.000000\n",
      "epoch 1, iter 1278, loss: 1.431649, acc: 1.000000\n",
      "epoch 1, iter 1279, loss: 1.300145, acc: 1.000000\n",
      "epoch 1, iter 1280, loss: 1.196903, acc: 1.000000\n",
      "epoch 1, iter 1281, loss: 2.365731, acc: 0.750000\n",
      "epoch 1, iter 1282, loss: 2.715825, acc: 0.875000\n",
      "epoch 1, iter 1283, loss: 2.808676, acc: 0.875000\n",
      "epoch 1, iter 1284, loss: 2.311618, acc: 1.000000\n",
      "epoch 1, iter 1285, loss: 2.327255, acc: 0.875000\n",
      "epoch 1, iter 1286, loss: 2.086429, acc: 1.000000\n",
      "epoch 1, iter 1287, loss: 1.798122, acc: 1.000000\n",
      "epoch 1, iter 1288, loss: 1.538720, acc: 1.000000\n",
      "epoch 1, iter 1289, loss: 2.689080, acc: 0.750000\n",
      "epoch 1, iter 1290, loss: 3.134107, acc: 0.875000\n",
      "epoch 1, iter 1291, loss: 2.906872, acc: 1.000000\n",
      "epoch 1, iter 1292, loss: 2.509234, acc: 1.000000\n",
      "epoch 1, iter 1293, loss: 2.124937, acc: 1.000000\n",
      "epoch 1, iter 1294, loss: 3.258817, acc: 0.750000\n",
      "epoch 1, iter 1295, loss: 3.526647, acc: 0.875000\n",
      "epoch 1, iter 1296, loss: 3.305243, acc: 0.875000\n",
      "epoch 1, iter 1297, loss: 2.814171, acc: 1.000000\n",
      "epoch 1, iter 1298, loss: 3.250426, acc: 0.875000\n",
      "epoch 1, iter 1299, loss: 3.051235, acc: 1.000000\n",
      "epoch 1, iter 1300, loss: 4.404999, acc: 0.500000\n",
      "epoch 1, iter 1301, loss: 5.740170, acc: 0.500000\n",
      "epoch 1, iter 1302, loss: 5.857965, acc: 0.875000\n",
      "epoch 1, iter 1303, loss: 4.706727, acc: 1.000000\n",
      "epoch 1, iter 1304, loss: 3.816775, acc: 1.000000\n",
      "epoch 1, iter 1305, loss: 3.135468, acc: 1.000000\n",
      "epoch 1, iter 1306, loss: 2.993659, acc: 0.875000\n",
      "epoch 1, iter 1307, loss: 3.328339, acc: 1.000000\n",
      "epoch 1, iter 1308, loss: 3.306956, acc: 1.000000\n",
      "epoch 1, iter 1309, loss: 2.652315, acc: 1.000000\n",
      "epoch 1, iter 1310, loss: 2.813294, acc: 0.875000\n",
      "epoch 1, iter 1311, loss: 2.416451, acc: 1.000000\n",
      "epoch 1, iter 1312, loss: 2.288619, acc: 0.875000\n",
      "epoch 1, iter 1313, loss: 2.027500, acc: 1.000000\n",
      "epoch 1, iter 1314, loss: 2.289792, acc: 0.875000\n",
      "epoch 1, iter 1315, loss: 2.038513, acc: 1.000000\n",
      "epoch 1, iter 1316, loss: 1.766226, acc: 1.000000\n",
      "epoch 1, iter 1317, loss: 2.271326, acc: 0.875000\n",
      "epoch 1, iter 1318, loss: 2.738060, acc: 0.875000\n",
      "epoch 1, iter 1319, loss: 2.430275, acc: 1.000000\n",
      "epoch 1, iter 1320, loss: 2.152379, acc: 1.000000\n",
      "epoch 1, iter 1321, loss: 2.783362, acc: 0.875000\n",
      "epoch 1, iter 1322, loss: 2.695646, acc: 0.875000\n",
      "epoch 1, iter 1323, loss: 2.492398, acc: 1.000000\n",
      "epoch 1, iter 1324, loss: 2.144661, acc: 1.000000\n",
      "epoch 1, iter 1325, loss: 2.904984, acc: 0.875000\n",
      "epoch 1, iter 1326, loss: 2.631363, acc: 1.000000\n",
      "epoch 1, iter 1327, loss: 2.380385, acc: 1.000000\n",
      "epoch 1, iter 1328, loss: 2.247231, acc: 1.000000\n",
      "epoch 1, iter 1329, loss: 2.128375, acc: 1.000000\n",
      "epoch 1, iter 1330, loss: 1.819839, acc: 1.000000\n",
      "epoch 1, iter 1331, loss: 1.956924, acc: 1.000000\n",
      "epoch 1, iter 1332, loss: 1.817492, acc: 1.000000\n",
      "epoch 1, iter 1333, loss: 1.624190, acc: 1.000000\n",
      "epoch 1, iter 1334, loss: 2.428511, acc: 0.875000\n",
      "epoch 1, iter 1335, loss: 2.087256, acc: 1.000000\n",
      "epoch 1, iter 1336, loss: 2.996829, acc: 0.750000\n",
      "epoch 1, iter 1337, loss: 3.663239, acc: 0.875000\n",
      "epoch 1, iter 1338, loss: 3.426818, acc: 0.875000\n",
      "epoch 1, iter 1339, loss: 2.728014, acc: 1.000000\n",
      "epoch 1, iter 1340, loss: 2.941954, acc: 0.875000\n",
      "epoch 1, iter 1341, loss: 2.859950, acc: 0.875000\n",
      "epoch 1, iter 1342, loss: 3.804710, acc: 0.875000\n",
      "epoch 1, iter 1343, loss: 3.351905, acc: 1.000000\n",
      "epoch 1, iter 1344, loss: 2.642950, acc: 1.000000\n",
      "epoch 1, iter 1345, loss: 2.776819, acc: 0.875000\n",
      "epoch 1, iter 1346, loss: 3.049925, acc: 0.875000\n",
      "epoch 1, iter 1347, loss: 2.615381, acc: 1.000000\n",
      "epoch 1, iter 1348, loss: 2.394530, acc: 1.000000\n",
      "epoch 1, iter 1349, loss: 2.108714, acc: 1.000000\n",
      "epoch 1, iter 1350, loss: 2.016060, acc: 1.000000\n",
      "epoch 1, iter 1351, loss: 3.159741, acc: 0.875000\n",
      "epoch 1, iter 1352, loss: 2.885388, acc: 0.875000\n",
      "epoch 1, iter 1353, loss: 2.548033, acc: 1.000000\n",
      "epoch 1, iter 1354, loss: 2.299546, acc: 1.000000\n",
      "epoch 1, iter 1355, loss: 1.987980, acc: 1.000000\n",
      "epoch 1, iter 1356, loss: 1.947013, acc: 1.000000\n",
      "epoch 1, iter 1357, loss: 1.808799, acc: 1.000000\n",
      "epoch 1, iter 1358, loss: 1.902453, acc: 0.875000\n",
      "epoch 1, iter 1359, loss: 1.731620, acc: 1.000000\n",
      "epoch 1, iter 1360, loss: 1.541536, acc: 1.000000\n",
      "epoch 1, iter 1361, loss: 1.646402, acc: 0.875000\n",
      "epoch 1, iter 1362, loss: 1.534016, acc: 1.000000\n",
      "epoch 1, iter 1363, loss: 1.392892, acc: 1.000000\n",
      "epoch 1, iter 1364, loss: 3.665708, acc: 0.500000\n",
      "epoch 1, iter 1365, loss: 3.567156, acc: 0.875000\n",
      "epoch 1, iter 1366, loss: 2.944565, acc: 1.000000\n",
      "epoch 1, iter 1367, loss: 2.414344, acc: 1.000000\n",
      "epoch 1, iter 1368, loss: 2.376687, acc: 0.875000\n",
      "epoch 1, iter 1369, loss: 2.111589, acc: 1.000000\n",
      "epoch 1, iter 1370, loss: 1.940104, acc: 1.000000\n",
      "epoch 1, iter 1371, loss: 2.036417, acc: 0.875000\n",
      "epoch 1, iter 1372, loss: 1.913694, acc: 1.000000\n",
      "epoch 1, iter 1373, loss: 2.268993, acc: 0.875000\n",
      "epoch 1, iter 1374, loss: 2.176223, acc: 1.000000\n",
      "epoch 1, iter 1375, loss: 2.972335, acc: 0.750000\n",
      "epoch 1, iter 1376, loss: 2.492490, acc: 1.000000\n",
      "epoch 1, iter 1377, loss: 2.470377, acc: 0.875000\n",
      "epoch 1, iter 1378, loss: 2.273620, acc: 0.875000\n",
      "epoch 1, iter 1379, loss: 2.125518, acc: 1.000000\n",
      "epoch 1, iter 1380, loss: 1.994967, acc: 1.000000\n",
      "epoch 1, iter 1381, loss: 1.921194, acc: 0.875000\n",
      "epoch 1, iter 1382, loss: 1.859435, acc: 1.000000\n",
      "epoch 1, iter 1383, loss: 1.651018, acc: 1.000000\n",
      "epoch 1, iter 1384, loss: 1.430102, acc: 1.000000\n",
      "epoch 1, iter 1385, loss: 1.236620, acc: 1.000000\n",
      "epoch 1, iter 1386, loss: 1.471443, acc: 0.875000\n",
      "epoch 1, iter 1387, loss: 1.814167, acc: 0.875000\n",
      "epoch 1, iter 1388, loss: 1.724392, acc: 1.000000\n",
      "epoch 1, iter 1389, loss: 1.639735, acc: 1.000000\n",
      "epoch 1, iter 1390, loss: 1.535451, acc: 1.000000\n",
      "epoch 1, iter 1391, loss: 1.842123, acc: 0.875000\n",
      "epoch 1, iter 1392, loss: 1.693813, acc: 1.000000\n",
      "epoch 1, iter 1393, loss: 2.760347, acc: 0.875000\n",
      "epoch 1, iter 1394, loss: 2.415977, acc: 1.000000\n",
      "epoch 1, iter 1395, loss: 2.263464, acc: 1.000000\n",
      "epoch 1, iter 1396, loss: 1.966503, acc: 1.000000\n",
      "epoch 1, iter 1397, loss: 2.599498, acc: 0.875000\n",
      "epoch 1, iter 1398, loss: 3.604851, acc: 0.875000\n",
      "epoch 1, iter 1399, loss: 2.862522, acc: 1.000000\n",
      "epoch 1, iter 1400, loss: 2.273098, acc: 1.000000\n",
      "epoch 1, iter 1401, loss: 3.060677, acc: 0.875000\n",
      "epoch 1, iter 1402, loss: 2.825759, acc: 0.875000\n",
      "epoch 1, iter 1403, loss: 4.739788, acc: 0.625000\n",
      "epoch 1, iter 1404, loss: 4.413054, acc: 1.000000\n",
      "epoch 1, iter 1405, loss: 5.233683, acc: 1.000000\n",
      "epoch 1, iter 1406, loss: 4.351270, acc: 0.875000\n",
      "epoch 1, iter 1407, loss: 3.395618, acc: 1.000000\n",
      "epoch 1, iter 1408, loss: 2.903772, acc: 1.000000\n",
      "epoch 1, iter 1409, loss: 2.432008, acc: 1.000000\n",
      "epoch 1, iter 1410, loss: 2.896759, acc: 0.875000\n",
      "epoch 1, iter 1411, loss: 2.413692, acc: 1.000000\n",
      "epoch 1, iter 1412, loss: 2.006142, acc: 1.000000\n",
      "epoch 1, iter 1413, loss: 1.699001, acc: 1.000000\n",
      "epoch 1, iter 1414, loss: 1.473457, acc: 1.000000\n",
      "epoch 1, iter 1415, loss: 1.309889, acc: 1.000000\n",
      "epoch 1, iter 1416, loss: 1.192006, acc: 1.000000\n",
      "epoch 1, iter 1417, loss: 1.107254, acc: 1.000000\n",
      "epoch 1, iter 1418, loss: 1.046298, acc: 1.000000\n",
      "epoch 1, iter 1419, loss: 1.002331, acc: 1.000000\n",
      "epoch 1, iter 1420, loss: 0.970447, acc: 1.000000\n",
      "epoch 1, iter 1421, loss: 0.947135, acc: 1.000000\n",
      "epoch 1, iter 1422, loss: 0.929894, acc: 1.000000\n",
      "epoch 1, iter 1423, loss: 1.995571, acc: 0.875000\n",
      "epoch 1, iter 1424, loss: 2.309653, acc: 0.875000\n",
      "epoch 1, iter 1425, loss: 2.068020, acc: 1.000000\n",
      "epoch 1, iter 1426, loss: 2.353045, acc: 0.875000\n",
      "epoch 1, iter 1427, loss: 1.993174, acc: 1.000000\n",
      "epoch 1, iter 1428, loss: 1.698814, acc: 1.000000\n",
      "epoch 1, iter 1429, loss: 1.966502, acc: 0.875000\n",
      "epoch 1, iter 1430, loss: 1.698792, acc: 1.000000\n",
      "epoch 1, iter 1431, loss: 1.480615, acc: 1.000000\n",
      "epoch 1, iter 1432, loss: 1.646810, acc: 0.875000\n",
      "epoch 1, iter 1433, loss: 1.554988, acc: 1.000000\n",
      "epoch 1, iter 1434, loss: 1.528393, acc: 1.000000\n",
      "epoch 1, iter 1435, loss: 1.408326, acc: 1.000000\n",
      "epoch 1, iter 1436, loss: 1.277077, acc: 1.000000\n",
      "epoch 1, iter 1437, loss: 1.841078, acc: 0.875000\n",
      "epoch 1, iter 1438, loss: 2.725031, acc: 0.875000\n",
      "epoch 1, iter 1439, loss: 2.262828, acc: 1.000000\n",
      "epoch 1, iter 1440, loss: 1.888265, acc: 1.000000\n",
      "epoch 1, iter 1441, loss: 2.250393, acc: 0.875000\n",
      "epoch 1, iter 1442, loss: 2.801627, acc: 0.875000\n",
      "epoch 1, iter 1443, loss: 2.297692, acc: 1.000000\n",
      "epoch 1, iter 1444, loss: 2.993091, acc: 0.875000\n",
      "epoch 1, iter 1445, loss: 3.682388, acc: 0.875000\n",
      "epoch 1, iter 1446, loss: 3.494127, acc: 0.875000\n",
      "epoch 1, iter 1447, loss: 3.739482, acc: 0.750000\n",
      "epoch 1, iter 1448, loss: 3.228248, acc: 0.875000\n",
      "epoch 1, iter 1449, loss: 2.662970, acc: 1.000000\n",
      "epoch 1, iter 1450, loss: 2.167657, acc: 1.000000\n",
      "epoch 1, iter 1451, loss: 2.056141, acc: 0.875000\n",
      "epoch 1, iter 1452, loss: 2.890023, acc: 0.875000\n",
      "epoch 1, iter 1453, loss: 4.012031, acc: 0.875000\n",
      "epoch 1, iter 1454, loss: 3.372998, acc: 1.000000\n",
      "epoch 1, iter 1455, loss: 2.732578, acc: 1.000000\n",
      "epoch 1, iter 1456, loss: 4.521338, acc: 0.750000\n",
      "epoch 1, iter 1457, loss: 4.941908, acc: 0.750000\n",
      "epoch 1, iter 1458, loss: 4.131043, acc: 0.875000\n",
      "epoch 1, iter 1459, loss: 4.043407, acc: 0.875000\n",
      "epoch 1, iter 1460, loss: 3.843757, acc: 0.875000\n",
      "epoch 1, iter 1461, loss: 5.288896, acc: 1.000000\n",
      "epoch 1, iter 1462, loss: 5.795172, acc: 0.750000\n",
      "epoch 1, iter 1463, loss: 5.273326, acc: 0.875000\n",
      "epoch 1, iter 1464, loss: 4.045346, acc: 1.000000\n",
      "epoch 1, iter 1465, loss: 3.898385, acc: 0.875000\n",
      "epoch 1, iter 1466, loss: 3.137851, acc: 1.000000\n",
      "epoch 1, iter 1467, loss: 3.042140, acc: 0.875000\n",
      "epoch 1, iter 1468, loss: 3.252015, acc: 0.875000\n",
      "epoch 1, iter 1469, loss: 2.691078, acc: 1.000000\n",
      "epoch 1, iter 1470, loss: 2.217992, acc: 1.000000\n",
      "epoch 1, iter 1471, loss: 3.239990, acc: 0.875000\n",
      "epoch 1, iter 1472, loss: 3.330432, acc: 0.875000\n",
      "epoch 1, iter 1473, loss: 2.781425, acc: 1.000000\n",
      "epoch 1, iter 1474, loss: 2.845020, acc: 0.875000\n",
      "epoch 1, iter 1475, loss: 2.324034, acc: 1.000000\n",
      "epoch 1, iter 1476, loss: 1.923078, acc: 1.000000\n",
      "epoch 1, iter 1477, loss: 1.623390, acc: 1.000000\n",
      "epoch 1, iter 1478, loss: 2.866480, acc: 0.750000\n",
      "epoch 1, iter 1479, loss: 3.474211, acc: 0.875000\n",
      "epoch 1, iter 1480, loss: 2.872661, acc: 1.000000\n",
      "epoch 1, iter 1481, loss: 2.335722, acc: 1.000000\n",
      "epoch 1, iter 1482, loss: 3.052302, acc: 0.625000\n",
      "epoch 1, iter 1483, loss: 3.017565, acc: 1.000000\n",
      "epoch 1, iter 1484, loss: 3.049783, acc: 0.875000\n",
      "epoch 1, iter 1485, loss: 3.869693, acc: 0.875000\n",
      "epoch 1, iter 1486, loss: 3.103264, acc: 1.000000\n",
      "epoch 1, iter 1487, loss: 2.506118, acc: 1.000000\n",
      "epoch 1, iter 1488, loss: 2.057576, acc: 1.000000\n",
      "epoch 1, iter 1489, loss: 2.586424, acc: 0.875000\n",
      "epoch 1, iter 1490, loss: 2.632384, acc: 0.875000\n",
      "epoch 1, iter 1491, loss: 2.335552, acc: 1.000000\n",
      "epoch 1, iter 1492, loss: 2.642208, acc: 0.875000\n",
      "epoch 1, iter 1493, loss: 2.782477, acc: 0.875000\n",
      "epoch 1, iter 1494, loss: 4.747850, acc: 0.875000\n",
      "epoch 1, iter 1495, loss: 5.246006, acc: 0.750000\n",
      "epoch 1, iter 1496, loss: 4.141607, acc: 1.000000\n",
      "epoch 1, iter 1497, loss: 3.499427, acc: 1.000000\n",
      "epoch 1, iter 1498, loss: 5.247816, acc: 0.500000\n",
      "epoch 1, iter 1499, loss: 4.344343, acc: 1.000000\n",
      "epoch 1, iter 1500, loss: 3.381148, acc: 1.000000\n",
      "epoch 1, iter 1501, loss: 2.672661, acc: 1.000000\n",
      "epoch 1, iter 1502, loss: 2.625585, acc: 0.875000\n",
      "epoch 1, iter 1503, loss: 3.278263, acc: 0.875000\n",
      "epoch 1, iter 1504, loss: 2.682169, acc: 1.000000\n",
      "epoch 1, iter 1505, loss: 2.638066, acc: 0.875000\n",
      "epoch 1, iter 1506, loss: 2.330661, acc: 1.000000\n",
      "epoch 1, iter 1507, loss: 1.933809, acc: 1.000000\n",
      "epoch 1, iter 1508, loss: 1.991074, acc: 0.875000\n",
      "epoch 1, iter 1509, loss: 1.732576, acc: 1.000000\n",
      "epoch 1, iter 1510, loss: 2.006944, acc: 1.000000\n",
      "epoch 1, iter 1511, loss: 1.906570, acc: 1.000000\n",
      "epoch 1, iter 1512, loss: 1.708222, acc: 1.000000\n",
      "epoch 1, iter 1513, loss: 1.511782, acc: 1.000000\n",
      "epoch 1, iter 1514, loss: 1.347086, acc: 1.000000\n",
      "epoch 1, iter 1515, loss: 1.218273, acc: 1.000000\n",
      "epoch 1, iter 1516, loss: 1.512841, acc: 0.875000\n",
      "epoch 1, iter 1517, loss: 1.489946, acc: 1.000000\n",
      "epoch 1, iter 1518, loss: 1.466068, acc: 1.000000\n",
      "epoch 1, iter 1519, loss: 1.362003, acc: 1.000000\n",
      "epoch 1, iter 1520, loss: 1.248666, acc: 1.000000\n",
      "epoch 1, iter 1521, loss: 2.210794, acc: 0.875000\n",
      "epoch 1, iter 1522, loss: 2.200438, acc: 0.875000\n",
      "epoch 1, iter 1523, loss: 3.920105, acc: 0.750000\n",
      "epoch 1, iter 1524, loss: 4.065986, acc: 0.875000\n",
      "epoch 1, iter 1525, loss: 3.278134, acc: 1.000000\n",
      "epoch 1, iter 1526, loss: 2.640892, acc: 1.000000\n",
      "epoch 1, iter 1527, loss: 2.156916, acc: 1.000000\n",
      "epoch 1, iter 1528, loss: 2.295603, acc: 0.875000\n",
      "epoch 1, iter 1529, loss: 2.108893, acc: 1.000000\n",
      "epoch 1, iter 1530, loss: 1.877754, acc: 1.000000\n",
      "epoch 1, iter 1531, loss: 2.548322, acc: 0.875000\n",
      "epoch 1, iter 1532, loss: 2.523210, acc: 0.875000\n",
      "epoch 1, iter 1533, loss: 2.143586, acc: 1.000000\n",
      "epoch 1, iter 1534, loss: 2.025552, acc: 1.000000\n",
      "epoch 1, iter 1535, loss: 1.813745, acc: 1.000000\n",
      "epoch 1, iter 1536, loss: 2.182976, acc: 0.875000\n",
      "epoch 1, iter 1537, loss: 1.907798, acc: 1.000000\n",
      "epoch 1, iter 1538, loss: 1.651466, acc: 1.000000\n",
      "epoch 1, iter 1539, loss: 1.444988, acc: 1.000000\n",
      "epoch 1, iter 1540, loss: 2.036123, acc: 0.875000\n",
      "epoch 1, iter 1541, loss: 1.783900, acc: 1.000000\n",
      "epoch 1, iter 1542, loss: 1.556352, acc: 1.000000\n",
      "epoch 1, iter 1543, loss: 1.373051, acc: 1.000000\n",
      "epoch 1, iter 1544, loss: 2.781708, acc: 0.750000\n",
      "epoch 1, iter 1545, loss: 2.848507, acc: 0.875000\n",
      "epoch 1, iter 1546, loss: 3.689885, acc: 0.875000\n",
      "epoch 1, iter 1547, loss: 2.857692, acc: 1.000000\n",
      "epoch 1, iter 1548, loss: 2.257416, acc: 1.000000\n",
      "epoch 1, iter 1549, loss: 1.836073, acc: 1.000000\n",
      "epoch 1, iter 1550, loss: 1.540183, acc: 1.000000\n",
      "epoch 1, iter 1551, loss: 1.332231, acc: 1.000000\n",
      "epoch 1, iter 1552, loss: 1.185917, acc: 1.000000\n",
      "epoch 1, iter 1553, loss: 1.082800, acc: 1.000000\n",
      "epoch 1, iter 1554, loss: 1.707311, acc: 0.875000\n",
      "epoch 1, iter 1555, loss: 2.079269, acc: 0.875000\n",
      "epoch 1, iter 1556, loss: 1.768093, acc: 1.000000\n",
      "epoch 1, iter 1557, loss: 1.521353, acc: 1.000000\n",
      "epoch 1, iter 1558, loss: 1.333954, acc: 1.000000\n",
      "epoch 1, iter 1559, loss: 1.194935, acc: 1.000000\n",
      "epoch 1, iter 1560, loss: 1.093189, acc: 1.000000\n",
      "epoch 1, iter 1561, loss: 1.823659, acc: 0.875000\n",
      "epoch 1, iter 1562, loss: 2.525600, acc: 0.875000\n",
      "epoch 1, iter 1563, loss: 2.050418, acc: 1.000000\n",
      "epoch 1, iter 1564, loss: 2.035144, acc: 0.875000\n",
      "epoch 1, iter 1565, loss: 1.820526, acc: 1.000000\n",
      "epoch 1, iter 1566, loss: 1.538227, acc: 1.000000\n",
      "epoch 1, iter 1567, loss: 1.287934, acc: 1.000000\n",
      "epoch 1, iter 1568, loss: 2.742857, acc: 0.750000\n",
      "epoch 1, iter 1569, loss: 2.290474, acc: 1.000000\n",
      "epoch 1, iter 1570, loss: 2.179185, acc: 0.875000\n",
      "epoch 1, iter 1571, loss: 1.881473, acc: 1.000000\n",
      "epoch 1, iter 1572, loss: 2.038248, acc: 0.875000\n",
      "epoch 1, iter 1573, loss: 1.740608, acc: 1.000000\n",
      "epoch 1, iter 1574, loss: 1.476237, acc: 1.000000\n",
      "epoch 1, iter 1575, loss: 2.651439, acc: 0.875000\n",
      "epoch 1, iter 1576, loss: 2.225593, acc: 1.000000\n",
      "epoch 1, iter 1577, loss: 2.090237, acc: 0.875000\n",
      "epoch 1, iter 1578, loss: 1.830038, acc: 1.000000\n",
      "epoch 1, iter 1579, loss: 1.759044, acc: 1.000000\n",
      "epoch 1, iter 1580, loss: 2.048212, acc: 0.875000\n",
      "epoch 1, iter 1581, loss: 2.363162, acc: 1.000000\n",
      "epoch 1, iter 1582, loss: 4.602617, acc: 0.875000\n",
      "epoch 1, iter 1583, loss: 3.626769, acc: 1.000000\n",
      "epoch 1, iter 1584, loss: 2.858081, acc: 1.000000\n",
      "epoch 1, iter 1585, loss: 2.289540, acc: 1.000000\n",
      "epoch 1, iter 1586, loss: 2.263605, acc: 0.875000\n",
      "epoch 1, iter 1587, loss: 2.016188, acc: 1.000000\n",
      "epoch 1, iter 1588, loss: 1.729181, acc: 1.000000\n",
      "epoch 1, iter 1589, loss: 2.697870, acc: 0.875000\n",
      "epoch 1, iter 1590, loss: 4.126505, acc: 0.750000\n",
      "epoch 1, iter 1591, loss: 3.417354, acc: 1.000000\n",
      "epoch 1, iter 1592, loss: 2.930741, acc: 1.000000\n",
      "epoch 1, iter 1593, loss: 2.461510, acc: 1.000000\n",
      "epoch 1, iter 1594, loss: 2.195185, acc: 1.000000\n",
      "epoch 1, iter 1595, loss: 2.258889, acc: 0.875000\n",
      "epoch 1, iter 1596, loss: 1.983745, acc: 1.000000\n",
      "epoch 1, iter 1597, loss: 1.654352, acc: 1.000000\n",
      "epoch 1, iter 1598, loss: 3.183382, acc: 0.625000\n",
      "epoch 1, iter 1599, loss: 2.948301, acc: 1.000000\n",
      "epoch 1, iter 1600, loss: 3.980573, acc: 0.875000\n",
      "epoch 1, iter 1601, loss: 4.462673, acc: 0.875000\n",
      "epoch 1, iter 1602, loss: 3.640931, acc: 1.000000\n",
      "epoch 1, iter 1603, loss: 3.036199, acc: 1.000000\n",
      "epoch 1, iter 1604, loss: 4.871350, acc: 0.625000\n",
      "epoch 1, iter 1605, loss: 4.658977, acc: 0.875000\n",
      "epoch 1, iter 1606, loss: 3.581627, acc: 1.000000\n",
      "epoch 1, iter 1607, loss: 3.137159, acc: 0.875000\n",
      "epoch 1, iter 1608, loss: 2.559391, acc: 1.000000\n",
      "epoch 1, iter 1609, loss: 2.677849, acc: 0.875000\n",
      "epoch 1, iter 1610, loss: 2.432429, acc: 1.000000\n",
      "epoch 1, iter 1611, loss: 2.230758, acc: 1.000000\n",
      "epoch 1, iter 1612, loss: 2.108031, acc: 1.000000\n",
      "epoch 1, iter 1613, loss: 1.861524, acc: 1.000000\n",
      "epoch 1, iter 1614, loss: 3.151712, acc: 0.750000\n",
      "epoch 1, iter 1615, loss: 2.649746, acc: 1.000000\n",
      "epoch 1, iter 1616, loss: 4.072382, acc: 0.750000\n",
      "epoch 1, iter 1617, loss: 3.259164, acc: 1.000000\n",
      "epoch 1, iter 1618, loss: 3.077662, acc: 0.875000\n",
      "epoch 1, iter 1619, loss: 2.791492, acc: 1.000000\n",
      "epoch 1, iter 1620, loss: 2.327306, acc: 1.000000\n",
      "epoch 1, iter 1621, loss: 2.176432, acc: 0.875000\n",
      "epoch 1, iter 1622, loss: 1.910906, acc: 1.000000\n",
      "epoch 1, iter 1623, loss: 2.293107, acc: 0.875000\n",
      "epoch 1, iter 1624, loss: 2.039714, acc: 1.000000\n",
      "epoch 1, iter 1625, loss: 1.888205, acc: 1.000000\n",
      "epoch 1, iter 1626, loss: 1.643283, acc: 1.000000\n",
      "epoch 1, iter 1627, loss: 1.927127, acc: 0.875000\n",
      "epoch 1, iter 1628, loss: 2.671492, acc: 0.875000\n",
      "epoch 1, iter 1629, loss: 2.257222, acc: 1.000000\n",
      "epoch 1, iter 1630, loss: 1.895137, acc: 1.000000\n",
      "epoch 1, iter 1631, loss: 2.656812, acc: 0.875000\n",
      "epoch 1, iter 1632, loss: 2.672846, acc: 0.875000\n",
      "epoch 1, iter 1633, loss: 2.195341, acc: 1.000000\n",
      "epoch 1, iter 1634, loss: 3.357444, acc: 0.750000\n",
      "epoch 1, iter 1635, loss: 5.276173, acc: 0.750000\n",
      "epoch 1, iter 1636, loss: 4.241155, acc: 1.000000\n",
      "epoch 1, iter 1637, loss: 3.356713, acc: 1.000000\n",
      "epoch 1, iter 1638, loss: 2.671719, acc: 1.000000\n",
      "epoch 1, iter 1639, loss: 2.161359, acc: 1.000000\n",
      "epoch 1, iter 1640, loss: 1.788017, acc: 1.000000\n",
      "epoch 1, iter 1641, loss: 1.517521, acc: 1.000000\n",
      "epoch 1, iter 1642, loss: 2.451321, acc: 0.875000\n",
      "epoch 1, iter 1643, loss: 3.097390, acc: 0.750000\n",
      "epoch 1, iter 1644, loss: 2.577404, acc: 1.000000\n",
      "epoch 1, iter 1645, loss: 2.486220, acc: 0.875000\n",
      "epoch 1, iter 1646, loss: 4.085873, acc: 0.750000\n",
      "epoch 1, iter 1647, loss: 3.417439, acc: 1.000000\n",
      "epoch 1, iter 1648, loss: 2.763028, acc: 1.000000\n",
      "epoch 1, iter 1649, loss: 2.498769, acc: 1.000000\n",
      "epoch 1, iter 1650, loss: 2.132857, acc: 1.000000\n",
      "epoch 1, iter 1651, loss: 2.545815, acc: 0.875000\n",
      "epoch 1, iter 1652, loss: 2.159522, acc: 1.000000\n",
      "epoch 1, iter 1653, loss: 1.825933, acc: 1.000000\n",
      "epoch 1, iter 1654, loss: 1.864062, acc: 0.875000\n",
      "epoch 1, iter 1655, loss: 2.090540, acc: 0.875000\n",
      "epoch 1, iter 1656, loss: 2.666360, acc: 0.875000\n",
      "epoch 1, iter 1657, loss: 2.485392, acc: 1.000000\n",
      "epoch 1, iter 1658, loss: 3.473319, acc: 0.750000\n",
      "epoch 1, iter 1659, loss: 2.975062, acc: 1.000000\n",
      "epoch 1, iter 1660, loss: 2.712568, acc: 1.000000\n",
      "epoch 1, iter 1661, loss: 3.088188, acc: 0.875000\n",
      "epoch 1, iter 1662, loss: 2.855944, acc: 1.000000\n",
      "epoch 1, iter 1663, loss: 2.497232, acc: 1.000000\n",
      "epoch 1, iter 1664, loss: 2.102707, acc: 1.000000\n",
      "epoch 1, iter 1665, loss: 1.771292, acc: 1.000000\n",
      "epoch 1, iter 1666, loss: 1.827748, acc: 0.875000\n",
      "epoch 1, iter 1667, loss: 2.786319, acc: 0.875000\n",
      "epoch 1, iter 1668, loss: 2.308527, acc: 1.000000\n",
      "epoch 1, iter 1669, loss: 1.907444, acc: 1.000000\n",
      "epoch 1, iter 1670, loss: 2.287366, acc: 0.875000\n",
      "epoch 1, iter 1671, loss: 2.130292, acc: 1.000000\n",
      "epoch 1, iter 1672, loss: 1.901199, acc: 1.000000\n",
      "epoch 1, iter 1673, loss: 2.960040, acc: 0.750000\n",
      "epoch 1, iter 1674, loss: 2.579553, acc: 1.000000\n",
      "epoch 1, iter 1675, loss: 2.514013, acc: 0.875000\n",
      "epoch 1, iter 1676, loss: 3.299180, acc: 0.750000\n",
      "epoch 1, iter 1677, loss: 2.838199, acc: 1.000000\n",
      "epoch 1, iter 1678, loss: 2.297546, acc: 1.000000\n",
      "epoch 1, iter 1679, loss: 2.313196, acc: 0.875000\n",
      "epoch 1, iter 1680, loss: 1.940566, acc: 1.000000\n",
      "epoch 1, iter 1681, loss: 1.640857, acc: 1.000000\n",
      "epoch 1, iter 1682, loss: 1.723552, acc: 0.875000\n",
      "epoch 1, iter 1683, loss: 1.902059, acc: 0.875000\n",
      "epoch 1, iter 1684, loss: 1.758318, acc: 1.000000\n",
      "epoch 1, iter 1685, loss: 1.559584, acc: 1.000000\n",
      "epoch 1, iter 1686, loss: 1.692484, acc: 0.875000\n",
      "epoch 1, iter 1687, loss: 2.132858, acc: 0.875000\n",
      "epoch 1, iter 1688, loss: 1.974272, acc: 1.000000\n",
      "epoch 1, iter 1689, loss: 3.504550, acc: 0.750000\n",
      "epoch 1, iter 1690, loss: 2.968936, acc: 1.000000\n",
      "epoch 1, iter 1691, loss: 4.557159, acc: 0.750000\n",
      "epoch 1, iter 1692, loss: 3.637635, acc: 1.000000\n",
      "epoch 1, iter 1693, loss: 3.278330, acc: 0.875000\n",
      "epoch 1, iter 1694, loss: 2.669223, acc: 1.000000\n",
      "epoch 1, iter 1695, loss: 2.540074, acc: 1.000000\n",
      "epoch 1, iter 1696, loss: 2.186424, acc: 1.000000\n",
      "epoch 1, iter 1697, loss: 2.746460, acc: 0.875000\n",
      "epoch 1, iter 1698, loss: 2.651737, acc: 0.875000\n",
      "epoch 1, iter 1699, loss: 2.163360, acc: 1.000000\n",
      "epoch 1, iter 1700, loss: 1.792144, acc: 1.000000\n",
      "epoch 1, iter 1701, loss: 1.841634, acc: 0.875000\n",
      "epoch 1, iter 1702, loss: 2.050227, acc: 0.875000\n",
      "epoch 1, iter 1703, loss: 1.838524, acc: 1.000000\n",
      "epoch 1, iter 1704, loss: 1.773799, acc: 1.000000\n",
      "epoch 1, iter 1705, loss: 1.821684, acc: 0.875000\n",
      "epoch 1, iter 1706, loss: 1.621753, acc: 1.000000\n",
      "epoch 1, iter 1707, loss: 1.657842, acc: 1.000000\n",
      "epoch 1, iter 1708, loss: 1.497877, acc: 1.000000\n",
      "epoch 1, iter 1709, loss: 1.767015, acc: 0.875000\n",
      "epoch 1, iter 1710, loss: 1.706966, acc: 1.000000\n",
      "epoch 1, iter 1711, loss: 2.288140, acc: 0.875000\n",
      "epoch 1, iter 1712, loss: 2.016795, acc: 1.000000\n",
      "epoch 1, iter 1713, loss: 1.745538, acc: 1.000000\n",
      "epoch 1, iter 1714, loss: 1.857712, acc: 0.875000\n",
      "epoch 1, iter 1715, loss: 1.915759, acc: 1.000000\n",
      "epoch 1, iter 1716, loss: 1.747847, acc: 1.000000\n",
      "epoch 1, iter 1717, loss: 1.528135, acc: 1.000000\n",
      "epoch 1, iter 1718, loss: 1.625369, acc: 0.875000\n",
      "epoch 1, iter 1719, loss: 1.537478, acc: 1.000000\n",
      "epoch 1, iter 1720, loss: 1.395079, acc: 1.000000\n",
      "epoch 1, iter 1721, loss: 1.256189, acc: 1.000000\n",
      "epoch 1, iter 1722, loss: 1.139532, acc: 1.000000\n",
      "epoch 1, iter 1723, loss: 1.047796, acc: 1.000000\n",
      "epoch 1, iter 1724, loss: 0.978085, acc: 1.000000\n",
      "epoch 1, iter 1725, loss: 1.345936, acc: 0.875000\n",
      "epoch 1, iter 1726, loss: 1.908815, acc: 0.875000\n",
      "epoch 1, iter 1727, loss: 1.629596, acc: 1.000000\n",
      "epoch 1, iter 1728, loss: 1.405750, acc: 1.000000\n",
      "epoch 1, iter 1729, loss: 1.610768, acc: 0.875000\n",
      "epoch 1, iter 1730, loss: 1.441296, acc: 1.000000\n",
      "epoch 1, iter 1731, loss: 1.283774, acc: 1.000000\n",
      "epoch 1, iter 1732, loss: 1.154284, acc: 1.000000\n",
      "epoch 1, iter 1733, loss: 1.406913, acc: 0.875000\n",
      "epoch 1, iter 1734, loss: 1.299006, acc: 1.000000\n",
      "epoch 1, iter 1735, loss: 1.388873, acc: 1.000000\n",
      "epoch 1, iter 1736, loss: 1.332690, acc: 1.000000\n",
      "epoch 1, iter 1737, loss: 1.359953, acc: 1.000000\n",
      "epoch 1, iter 1738, loss: 2.767650, acc: 0.875000\n",
      "epoch 1, iter 1739, loss: 2.410240, acc: 1.000000\n",
      "epoch 1, iter 1740, loss: 3.527141, acc: 0.875000\n",
      "epoch 1, iter 1741, loss: 2.813919, acc: 1.000000\n",
      "epoch 1, iter 1742, loss: 2.256931, acc: 1.000000\n",
      "epoch 1, iter 1743, loss: 1.846057, acc: 1.000000\n",
      "epoch 1, iter 1744, loss: 1.546365, acc: 1.000000\n",
      "epoch 1, iter 1745, loss: 1.744174, acc: 0.875000\n",
      "epoch 1, iter 1746, loss: 2.360605, acc: 0.875000\n",
      "epoch 1, iter 1747, loss: 2.075697, acc: 1.000000\n",
      "epoch 1, iter 1748, loss: 1.777565, acc: 1.000000\n",
      "epoch 1, iter 1749, loss: 3.644025, acc: 0.750000\n",
      "epoch 1, iter 1750, loss: 3.136380, acc: 1.000000\n",
      "epoch 1, iter 1751, loss: 2.524124, acc: 1.000000\n",
      "epoch 1, iter 1752, loss: 2.354013, acc: 0.875000\n",
      "epoch 1, iter 1753, loss: 2.934439, acc: 0.875000\n",
      "epoch 1, iter 1754, loss: 2.732124, acc: 0.875000\n",
      "epoch 1, iter 1755, loss: 2.938418, acc: 0.875000\n",
      "epoch 1, iter 1756, loss: 2.694396, acc: 1.000000\n",
      "epoch 1, iter 1757, loss: 2.301269, acc: 1.000000\n",
      "epoch 1, iter 1758, loss: 3.701954, acc: 0.750000\n",
      "epoch 1, iter 1759, loss: 3.043929, acc: 1.000000\n",
      "epoch 1, iter 1760, loss: 2.467582, acc: 1.000000\n",
      "epoch 1, iter 1761, loss: 2.004297, acc: 1.000000\n",
      "epoch 1, iter 1762, loss: 1.647103, acc: 1.000000\n",
      "epoch 1, iter 1763, loss: 1.386363, acc: 1.000000\n",
      "epoch 1, iter 1764, loss: 1.682349, acc: 0.875000\n",
      "epoch 1, iter 1765, loss: 1.445735, acc: 1.000000\n",
      "epoch 1, iter 1766, loss: 2.056791, acc: 0.875000\n",
      "epoch 1, iter 1767, loss: 2.028400, acc: 0.875000\n",
      "epoch 1, iter 1768, loss: 1.742259, acc: 1.000000\n",
      "epoch 1, iter 1769, loss: 1.491575, acc: 1.000000\n",
      "epoch 1, iter 1770, loss: 1.291377, acc: 1.000000\n",
      "epoch 1, iter 1771, loss: 1.138508, acc: 1.000000\n",
      "epoch 1, iter 1772, loss: 1.024603, acc: 1.000000\n",
      "epoch 1, iter 1773, loss: 0.940912, acc: 1.000000\n",
      "epoch 1, iter 1774, loss: 0.879886, acc: 1.000000\n",
      "epoch 1, iter 1775, loss: 0.835514, acc: 1.000000\n",
      "epoch 1, iter 1776, loss: 0.803207, acc: 1.000000\n",
      "epoch 1, iter 1777, loss: 1.689406, acc: 0.875000\n",
      "epoch 1, iter 1778, loss: 2.263454, acc: 0.875000\n",
      "epoch 1, iter 1779, loss: 1.952115, acc: 1.000000\n",
      "epoch 1, iter 1780, loss: 1.651427, acc: 1.000000\n",
      "epoch 1, iter 1781, loss: 1.410074, acc: 1.000000\n",
      "epoch 1, iter 1782, loss: 1.224741, acc: 1.000000\n",
      "epoch 1, iter 1783, loss: 1.085529, acc: 1.000000\n",
      "epoch 1, iter 1784, loss: 1.481243, acc: 0.875000\n",
      "epoch 1, iter 1785, loss: 1.493121, acc: 1.000000\n",
      "epoch 1, iter 1786, loss: 3.069328, acc: 0.750000\n",
      "epoch 1, iter 1787, loss: 2.583197, acc: 1.000000\n",
      "epoch 1, iter 1788, loss: 4.086697, acc: 0.875000\n",
      "epoch 1, iter 1789, loss: 3.320447, acc: 1.000000\n",
      "epoch 1, iter 1790, loss: 2.785267, acc: 1.000000\n",
      "epoch 1, iter 1791, loss: 2.768559, acc: 0.875000\n",
      "epoch 1, iter 1792, loss: 2.310025, acc: 1.000000\n",
      "epoch 1, iter 1793, loss: 3.460242, acc: 0.875000\n",
      "epoch 1, iter 1794, loss: 2.873922, acc: 1.000000\n",
      "epoch 1, iter 1795, loss: 3.039248, acc: 0.875000\n",
      "epoch 1, iter 1796, loss: 2.525830, acc: 1.000000\n",
      "epoch 1, iter 1797, loss: 2.089264, acc: 1.000000\n",
      "epoch 1, iter 1798, loss: 1.745292, acc: 1.000000\n",
      "epoch 1, iter 1799, loss: 2.802530, acc: 0.750000\n",
      "epoch 1, iter 1800, loss: 2.307631, acc: 1.000000\n",
      "epoch 1, iter 1801, loss: 1.901637, acc: 1.000000\n",
      "epoch 1, iter 1802, loss: 3.830684, acc: 0.750000\n",
      "epoch 1, iter 1803, loss: 3.153235, acc: 1.000000\n",
      "epoch 1, iter 1804, loss: 3.190134, acc: 0.875000\n",
      "epoch 1, iter 1805, loss: 2.853697, acc: 0.875000\n",
      "epoch 1, iter 1806, loss: 2.361065, acc: 1.000000\n",
      "epoch 1, iter 1807, loss: 3.329786, acc: 0.875000\n",
      "epoch 1, iter 1808, loss: 2.795504, acc: 1.000000\n",
      "epoch 1, iter 1809, loss: 2.292585, acc: 1.000000\n",
      "epoch 1, iter 1810, loss: 3.208239, acc: 0.750000\n",
      "epoch 1, iter 1811, loss: 5.988100, acc: 0.500000\n",
      "epoch 1, iter 1812, loss: 5.006097, acc: 1.000000\n",
      "epoch 1, iter 1813, loss: 4.073050, acc: 0.875000\n",
      "epoch 1, iter 1814, loss: 4.359100, acc: 0.875000\n",
      "epoch 1, iter 1815, loss: 3.469797, acc: 1.000000\n",
      "epoch 1, iter 1816, loss: 2.870685, acc: 1.000000\n",
      "epoch 1, iter 1817, loss: 2.336580, acc: 1.000000\n",
      "epoch 1, iter 1818, loss: 2.435281, acc: 0.875000\n",
      "epoch 1, iter 1819, loss: 2.194604, acc: 1.000000\n",
      "epoch 1, iter 1820, loss: 1.943818, acc: 1.000000\n",
      "epoch 1, iter 1821, loss: 1.780821, acc: 1.000000\n",
      "epoch 1, iter 1822, loss: 1.874930, acc: 0.875000\n",
      "epoch 1, iter 1823, loss: 1.806053, acc: 1.000000\n",
      "epoch 1, iter 1824, loss: 1.690491, acc: 1.000000\n",
      "epoch 1, iter 1825, loss: 1.614620, acc: 1.000000\n",
      "epoch 1, iter 1826, loss: 1.522985, acc: 1.000000\n",
      "epoch 1, iter 1827, loss: 1.482610, acc: 1.000000\n",
      "epoch 1, iter 1828, loss: 1.360839, acc: 1.000000\n",
      "epoch 1, iter 1829, loss: 1.230137, acc: 1.000000\n",
      "epoch 1, iter 1830, loss: 1.116162, acc: 1.000000\n",
      "epoch 1, iter 1831, loss: 1.355141, acc: 0.875000\n",
      "epoch 1, iter 1832, loss: 1.702678, acc: 0.875000\n",
      "epoch 1, iter 1833, loss: 1.573255, acc: 1.000000\n",
      "epoch 1, iter 1834, loss: 1.406769, acc: 1.000000\n",
      "epoch 1, iter 1835, loss: 1.254587, acc: 1.000000\n",
      "epoch 1, iter 1836, loss: 1.946117, acc: 0.875000\n",
      "epoch 1, iter 1837, loss: 2.296643, acc: 0.875000\n",
      "epoch 1, iter 1838, loss: 2.581697, acc: 0.875000\n",
      "epoch 1, iter 1839, loss: 3.901565, acc: 0.875000\n",
      "epoch 1, iter 1840, loss: 4.631155, acc: 0.625000\n",
      "epoch 1, iter 1841, loss: 5.137872, acc: 0.875000\n",
      "epoch 1, iter 1842, loss: 4.044766, acc: 1.000000\n",
      "epoch 1, iter 1843, loss: 3.171134, acc: 1.000000\n",
      "epoch 1, iter 1844, loss: 2.510145, acc: 1.000000\n",
      "epoch 1, iter 1845, loss: 2.531650, acc: 0.875000\n",
      "epoch 1, iter 1846, loss: 2.106178, acc: 1.000000\n",
      "epoch 1, iter 1847, loss: 2.214826, acc: 0.875000\n",
      "epoch 1, iter 1848, loss: 1.856925, acc: 1.000000\n",
      "epoch 1, iter 1849, loss: 1.834711, acc: 0.875000\n",
      "epoch 1, iter 1850, loss: 1.652753, acc: 1.000000\n",
      "epoch 1, iter 1851, loss: 2.540569, acc: 0.875000\n",
      "epoch 1, iter 1852, loss: 2.177068, acc: 1.000000\n",
      "epoch 1, iter 1853, loss: 1.961287, acc: 1.000000\n",
      "epoch 1, iter 1854, loss: 1.708884, acc: 1.000000\n",
      "epoch 1, iter 1855, loss: 2.526634, acc: 0.875000\n",
      "epoch 1, iter 1856, loss: 3.472253, acc: 0.750000\n",
      "epoch 1, iter 1857, loss: 3.497504, acc: 0.875000\n",
      "epoch 1, iter 1858, loss: 3.059780, acc: 1.000000\n",
      "epoch 1, iter 1859, loss: 3.237775, acc: 0.875000\n",
      "epoch 1, iter 1860, loss: 2.850580, acc: 1.000000\n",
      "epoch 1, iter 1861, loss: 2.923844, acc: 0.875000\n",
      "epoch 1, iter 1862, loss: 2.490885, acc: 1.000000\n",
      "epoch 1, iter 1863, loss: 2.092471, acc: 1.000000\n",
      "epoch 1, iter 1864, loss: 2.286446, acc: 0.875000\n",
      "epoch 1, iter 1865, loss: 2.396966, acc: 0.875000\n",
      "epoch 1, iter 1866, loss: 2.147886, acc: 1.000000\n",
      "epoch 1, iter 1867, loss: 1.815418, acc: 1.000000\n",
      "epoch 1, iter 1868, loss: 1.505398, acc: 1.000000\n",
      "epoch 1, iter 1869, loss: 1.734758, acc: 0.875000\n",
      "epoch 1, iter 1870, loss: 1.660563, acc: 1.000000\n",
      "epoch 1, iter 1871, loss: 1.585148, acc: 1.000000\n",
      "epoch 1, iter 1872, loss: 1.392605, acc: 1.000000\n",
      "epoch 1, iter 1873, loss: 1.944133, acc: 0.875000\n",
      "epoch 1, iter 1874, loss: 2.466576, acc: 0.750000\n",
      "epoch 1, iter 1875, loss: 2.386062, acc: 1.000000\n",
      "epoch 1, iter 1876, loss: 2.096083, acc: 1.000000\n",
      "epoch 1, iter 1877, loss: 1.953570, acc: 1.000000\n",
      "epoch 1, iter 1878, loss: 1.728241, acc: 1.000000\n",
      "epoch 1, iter 1879, loss: 1.820657, acc: 0.875000\n",
      "epoch 1, iter 1880, loss: 1.779898, acc: 1.000000\n",
      "epoch 1, iter 1881, loss: 2.812201, acc: 0.875000\n",
      "epoch 1, iter 1882, loss: 2.361569, acc: 1.000000\n",
      "epoch 1, iter 1883, loss: 3.482760, acc: 0.875000\n",
      "epoch 1, iter 1884, loss: 3.444558, acc: 0.875000\n",
      "epoch 1, iter 1885, loss: 2.879967, acc: 1.000000\n",
      "epoch 1, iter 1886, loss: 2.366297, acc: 1.000000\n",
      "epoch 1, iter 1887, loss: 1.955517, acc: 1.000000\n",
      "epoch 1, iter 1888, loss: 1.934031, acc: 0.875000\n",
      "epoch 1, iter 1889, loss: 1.743133, acc: 1.000000\n",
      "epoch 1, iter 1890, loss: 1.514836, acc: 1.000000\n",
      "epoch 1, iter 1891, loss: 1.303465, acc: 1.000000\n",
      "epoch 1, iter 1892, loss: 1.479451, acc: 0.875000\n",
      "epoch 1, iter 1893, loss: 1.325295, acc: 1.000000\n",
      "epoch 1, iter 1894, loss: 1.682741, acc: 0.875000\n",
      "epoch 1, iter 1895, loss: 1.730349, acc: 0.875000\n",
      "epoch 1, iter 1896, loss: 2.643527, acc: 0.750000\n",
      "epoch 1, iter 1897, loss: 2.234217, acc: 1.000000\n",
      "epoch 1, iter 1898, loss: 3.290048, acc: 0.750000\n",
      "epoch 1, iter 1899, loss: 2.964554, acc: 0.875000\n",
      "epoch 1, iter 1900, loss: 2.438587, acc: 1.000000\n",
      "epoch 1, iter 1901, loss: 3.008082, acc: 0.875000\n",
      "epoch 1, iter 1902, loss: 2.393707, acc: 1.000000\n",
      "epoch 1, iter 1903, loss: 1.932516, acc: 1.000000\n",
      "epoch 1, iter 1904, loss: 2.571945, acc: 0.750000\n",
      "epoch 1, iter 1905, loss: 2.593683, acc: 0.875000\n",
      "epoch 1, iter 1906, loss: 3.104687, acc: 0.875000\n",
      "epoch 1, iter 1907, loss: 2.647193, acc: 1.000000\n",
      "epoch 1, iter 1908, loss: 3.747832, acc: 0.750000\n",
      "epoch 1, iter 1909, loss: 3.207601, acc: 0.875000\n",
      "epoch 1, iter 1910, loss: 3.778083, acc: 0.875000\n",
      "epoch 1, iter 1911, loss: 3.000326, acc: 1.000000\n",
      "epoch 1, iter 1912, loss: 2.396030, acc: 1.000000\n",
      "epoch 1, iter 1913, loss: 2.695569, acc: 0.875000\n",
      "epoch 1, iter 1914, loss: 2.982232, acc: 0.875000\n",
      "epoch 1, iter 1915, loss: 3.694611, acc: 0.875000\n",
      "epoch 1, iter 1916, loss: 2.885285, acc: 1.000000\n",
      "epoch 1, iter 1917, loss: 2.274600, acc: 1.000000\n",
      "epoch 1, iter 1918, loss: 2.268183, acc: 0.875000\n",
      "epoch 1, iter 1919, loss: 2.038612, acc: 1.000000\n",
      "epoch 1, iter 1920, loss: 1.790897, acc: 1.000000\n",
      "epoch 1, iter 1921, loss: 2.062525, acc: 0.875000\n",
      "epoch 1, iter 1922, loss: 1.896793, acc: 1.000000\n",
      "epoch 1, iter 1923, loss: 1.641404, acc: 1.000000\n",
      "epoch 1, iter 1924, loss: 1.636446, acc: 0.875000\n",
      "epoch 1, iter 1925, loss: 1.506371, acc: 1.000000\n",
      "epoch 1, iter 1926, loss: 2.582144, acc: 0.750000\n",
      "epoch 1, iter 1927, loss: 2.111031, acc: 1.000000\n",
      "epoch 1, iter 1928, loss: 1.745443, acc: 1.000000\n",
      "epoch 1, iter 1929, loss: 1.900968, acc: 0.875000\n",
      "epoch 1, iter 1930, loss: 1.784742, acc: 1.000000\n",
      "epoch 1, iter 1931, loss: 1.611944, acc: 1.000000\n",
      "epoch 1, iter 1932, loss: 1.537020, acc: 1.000000\n",
      "epoch 1, iter 1933, loss: 1.379110, acc: 1.000000\n",
      "epoch 1, iter 1934, loss: 1.210924, acc: 1.000000\n",
      "epoch 1, iter 1935, loss: 1.573025, acc: 0.875000\n",
      "epoch 1, iter 1936, loss: 2.768823, acc: 0.875000\n",
      "epoch 1, iter 1937, loss: 2.420013, acc: 1.000000\n",
      "epoch 1, iter 1938, loss: 2.200628, acc: 1.000000\n",
      "epoch 1, iter 1939, loss: 1.924098, acc: 1.000000\n",
      "epoch 1, iter 1940, loss: 1.637588, acc: 1.000000\n",
      "epoch 1, iter 1941, loss: 1.741499, acc: 0.875000\n",
      "epoch 1, iter 1942, loss: 1.532817, acc: 1.000000\n",
      "epoch 1, iter 1943, loss: 2.520664, acc: 0.875000\n",
      "epoch 1, iter 1944, loss: 2.113705, acc: 1.000000\n",
      "epoch 1, iter 1945, loss: 2.270424, acc: 0.875000\n",
      "epoch 1, iter 1946, loss: 2.210539, acc: 0.875000\n",
      "epoch 1, iter 1947, loss: 1.924116, acc: 1.000000\n",
      "epoch 1, iter 1948, loss: 1.635795, acc: 1.000000\n",
      "epoch 1, iter 1949, loss: 1.802552, acc: 0.875000\n",
      "epoch 1, iter 1950, loss: 1.563873, acc: 1.000000\n",
      "epoch 1, iter 1951, loss: 1.735064, acc: 0.875000\n",
      "epoch 1, iter 1952, loss: 1.670720, acc: 1.000000\n",
      "epoch 1, iter 1953, loss: 2.013551, acc: 0.875000\n",
      "epoch 1, iter 1954, loss: 2.060343, acc: 0.875000\n",
      "epoch 1, iter 1955, loss: 2.549119, acc: 0.875000\n",
      "epoch 1, iter 1956, loss: 3.568876, acc: 0.750000\n",
      "epoch 1, iter 1957, loss: 2.968094, acc: 1.000000\n",
      "epoch 1, iter 1958, loss: 3.766659, acc: 0.875000\n",
      "epoch 1, iter 1959, loss: 3.072981, acc: 1.000000\n",
      "epoch 1, iter 1960, loss: 2.726856, acc: 0.875000\n",
      "epoch 1, iter 1961, loss: 2.452431, acc: 1.000000\n",
      "epoch 1, iter 1962, loss: 2.091747, acc: 1.000000\n",
      "epoch 1, iter 1963, loss: 1.752360, acc: 1.000000\n",
      "epoch 1, iter 1964, loss: 1.466001, acc: 1.000000\n",
      "epoch 1, iter 1965, loss: 1.631647, acc: 0.875000\n",
      "epoch 1, iter 1966, loss: 1.426502, acc: 1.000000\n",
      "epoch 1, iter 1967, loss: 1.704621, acc: 0.875000\n",
      "epoch 1, iter 1968, loss: 1.723545, acc: 0.875000\n",
      "epoch 1, iter 1969, loss: 3.565182, acc: 0.875000\n",
      "epoch 1, iter 1970, loss: 2.879262, acc: 1.000000\n",
      "epoch 1, iter 1971, loss: 2.494010, acc: 0.875000\n",
      "epoch 1, iter 1972, loss: 2.110803, acc: 1.000000\n",
      "epoch 1, iter 1973, loss: 1.779403, acc: 1.000000\n",
      "epoch 1, iter 1974, loss: 1.503110, acc: 1.000000\n",
      "epoch 1, iter 1975, loss: 1.610431, acc: 0.875000\n",
      "epoch 1, iter 1976, loss: 1.434935, acc: 1.000000\n",
      "epoch 1, iter 1977, loss: 1.800743, acc: 0.875000\n",
      "epoch 1, iter 1978, loss: 2.411995, acc: 1.000000\n",
      "epoch 1, iter 1979, loss: 2.209501, acc: 1.000000\n",
      "epoch 1, iter 1980, loss: 2.071350, acc: 1.000000\n",
      "epoch 1, iter 1981, loss: 2.971451, acc: 0.875000\n",
      "epoch 1, iter 1982, loss: 2.481708, acc: 1.000000\n",
      "epoch 1, iter 1983, loss: 4.234250, acc: 0.750000\n",
      "epoch 1, iter 1984, loss: 4.207862, acc: 0.875000\n",
      "epoch 1, iter 1985, loss: 4.304983, acc: 1.000000\n",
      "epoch 1, iter 1986, loss: 3.917221, acc: 1.000000\n",
      "epoch 1, iter 1987, loss: 3.057512, acc: 1.000000\n",
      "epoch 1, iter 1988, loss: 2.418505, acc: 1.000000\n",
      "epoch 1, iter 1989, loss: 1.951418, acc: 1.000000\n",
      "epoch 1, iter 1990, loss: 2.078699, acc: 0.875000\n",
      "epoch 1, iter 1991, loss: 3.019754, acc: 0.875000\n",
      "epoch 1, iter 1992, loss: 2.396225, acc: 1.000000\n",
      "epoch 1, iter 1993, loss: 1.926172, acc: 1.000000\n",
      "epoch 1, iter 1994, loss: 1.588946, acc: 1.000000\n",
      "epoch 1, iter 1995, loss: 1.736407, acc: 0.875000\n",
      "epoch 1, iter 1996, loss: 2.039618, acc: 0.875000\n",
      "epoch 1, iter 1997, loss: 1.850320, acc: 1.000000\n",
      "epoch 1, iter 1998, loss: 1.605743, acc: 1.000000\n",
      "epoch 1, iter 1999, loss: 1.374378, acc: 1.000000\n",
      "epoch 1, acc: 0.936813\n"
     ]
    }
   ],
   "source": [
    "mWxh, mWhh, mWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
    "mbh, mby = np.zeros_like(bh), np.zeros_like(by) # memory variables for Adagrad\n",
    "smooth_loss = -np.log(1.0/num_problems)*num_timesteps # loss at iteration 0\n",
    "\n",
    "losses = []\n",
    "accuracies = []\n",
    "for e in xrange(epochs):\n",
    "    hprev = np.zeros((hidden_size,1)) # reset RNN memory\n",
    "    total_acc = 0.0\n",
    "    for i in xrange(num_train):\n",
    "        inputs = X_train[i,:,:].reshape((num_timesteps, num_problems * 2))\n",
    "        targets = y_train[i,:].reshape((num_timesteps,))\n",
    "        correctness_for_student = correctness[i,:].reshape((num_problems))\n",
    "\n",
    "        # forward num_timesteps characters through the net and fetch gradient\n",
    "        loss, dWxh, dWhh, dWhy, dbh, dby, hprev = lossFun(inputs, targets, correctness_for_student, hprev)\n",
    "        smooth_loss = smooth_loss * 0.7 + loss * 0.3\n",
    "        losses.append(smooth_loss)\n",
    "\n",
    "        # perform parameter update with Adagrad\n",
    "        for param, dparam, mem in zip([Wxh, Whh, Why, bh, by], \n",
    "                                      [dWxh, dWhh, dWhy, dbh, dby], \n",
    "                                      [mWxh, mWhh, mWhy, mbh, mby]):\n",
    "            mem += dparam * dparam\n",
    "            param += -learning_rate * dparam / np.sqrt(mem + 1e-8) # adagrad update\n",
    "        ps = forward_pass(inputs)\n",
    "        acc = accuracy(ps, targets, correctness_for_student) \n",
    "        accuracies.append(acc)\n",
    "        print ('epoch %d, iter %d, loss: %f, acc: %f' % (e, i, smooth_loss, acc)) # print progress\n",
    "        total_acc += acc\n",
    "    total_acc /= num_train\n",
    "    print ('epoch %d, acc: %f' % (e, total_acc)) # print progress\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaYAAAEPCAYAAAAJYmAlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109fc8c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "smooth_accs = []\n",
    "\n",
    "smooth_window = 100\n",
    "for i in xrange(len(accuracies)-smooth_window):\n",
    "    smooth_accs.append(np.mean(accuracies[i:i+smooth_window]))\n",
    "\n",
    "for i in xrange(len(accuracies)-smooth_window, len(accuracies)):\n",
    "    smooth_accs.append(np.mean(accuracies[i:len(accuracies)]))\n",
    "                    \n",
    "fig = plt.figure()\n",
    "\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.plot(xrange(len(smooth_accs)/2), smooth_accs[:len(smooth_accs)/2], 'b-')\n",
    "ax1.set_ylabel('accuracies', color='b')\n",
    "ax1.set_xlabel('iterations')\n",
    "for tl in ax1.get_yticklabels():\n",
    "    tl.set_color('b')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(xrange(len(losses)/2), losses[:len(losses)/2], 'r-')\n",
    "ax2.set_ylabel('losses', color='r')\n",
    "for tl in ax2.get_yticklabels():\n",
    "    tl.set_color('r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure_filename = \"loss_plots/test.png\"\n",
    "fig.savefig(figure_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
