{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from __future__ import print_function\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers.core import Dense, Activation, Dropout\n",
    "# from keras.layers.recurrent import LSTM\n",
    "# from keras.datasets.data_utils import get_file\n",
    "# from keras.callbacks import Callback\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "synthetic_data_set = \"syntheticDetailed/naive_c5_q50_s4000_v0.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 0 0 1 1 0 1 1 1 0 0 1 1 1 0 1 1 1 1 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 0\n",
      "  0 1 1 0 1 1 0 1 0 1 1 0 1]\n",
      " [1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
      "  1 0 0 0 1 0 1 0 0 1 0 0 0]\n",
      " [0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1 1 0 0 1\n",
      "  1 1 1 0 0 1 1 1 0 0 1 1 1]\n",
      " [0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 1 0 0 1 1\n",
      "  0 1 0 0 1 1 1 1 0 0 1 1 1]\n",
      " [0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1\n",
      "  1 1 1 0 0 0 1 0 1 1 1 1 1]\n",
      " [0 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1\n",
      "  1 1 0 0 0 0 1 0 0 0 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 1 1 1 0 0 1 1 1 0 0 1 1 0 1 1 0 1\n",
      "  1 1 1 0 0 1 1 1 1 1 1 1 1]\n",
      " [0 1 0 0 0 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 1 1 0 0 1 1 0 0 1 0 1 1 0 0\n",
      "  1 0 1 0 0 0 0 1 1 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 1\n",
      "  1 0 1 0 0 0 1 0 1 1 0 1 0]\n",
      " [0 0 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1\n",
      "  1 0 1 1 1 1 0 1 1 1 1 0 0]]\n",
      "(500, 50)\n",
      "(500, 50)\n",
      "Vectorization...\n",
      "Vectorization done!\n"
     ]
    }
   ],
   "source": [
    "# Read in the data set\n",
    "# This function can be moved to utils.py\n",
    "data_array = np.array(list(csv.reader(open(synthetic_data_set,\"rb\"),delimiter=','))).astype('int')\n",
    "print (data_array[0:10])\n",
    "data_array = data_array[:1000]\n",
    "num_samples = data_array.shape[0]\n",
    "num_problems = data_array.shape[1]\n",
    "\n",
    "# time steps is number of problems - 1 because we cannot predict on the last problem.\n",
    "num_timesteps = num_problems - 1 \n",
    "# Split data into train and test (half and half)\n",
    "train = data_array[0:num_samples/2,:]\n",
    "test = data_array[num_samples/2:num_samples,:]\n",
    "print (train.shape)\n",
    "print (test.shape)\n",
    "\n",
    "num_train = train.shape[0]\n",
    "num_test = test.shape[0]\n",
    "\n",
    "\n",
    "print('Vectorization...')\n",
    "X_train = np.zeros((num_train, num_timesteps, num_problems * 2), dtype=np.bool)\n",
    "y_train = np.zeros((num_train, num_timesteps), dtype=np.int)\n",
    "\n",
    "# Create 3-dimensional input tensor with one-hot encodings for each sample\n",
    "# the dimension of each vector for a student i and time t is 2 * num_problems\n",
    "# where the first half corresponds to the correctly answered problems and the\n",
    "# second half to the incorrectly answered ones.\n",
    "for i in xrange(num_train):\n",
    "    \n",
    "    # for the first time step. Done separately so we can populate the output \n",
    "    # tensor at the same time, which is shifted back by 1.\n",
    "\n",
    "    for t in xrange(0,num_timesteps):\n",
    "        p = t # since timestep t corresponds to problem p where t=p\n",
    "        if train[i,p] == 1:\n",
    "            X_train[i, t, p] = 1 \n",
    "        else:\n",
    "            X_train[i, t, num_problems + p] = 1\n",
    "        # this is a special case for the synthetic data set, where the next problem \n",
    "        # is just the current problem index + 1\n",
    "        y_train[i,t] = p + 1\n",
    "correctness = train\n",
    "\n",
    "print (\"Vectorization done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "hidden_size = 100 # size of hidden layer of neurons\n",
    "learning_rate = 1e-1\n",
    "epochs = 50\n",
    "\n",
    "# model parameters\n",
    "Wxh = np.random.randn(hidden_size, num_problems * 2)*0.01 # input to hidden\n",
    "Whh = np.random.randn(hidden_size, hidden_size)*0.01 # hidden to hidden\n",
    "Why = np.random.randn(num_problems, hidden_size)*0.01 # hidden to output\n",
    "bh = np.zeros((hidden_size, 1)) # hidden bias\n",
    "by = np.zeros((num_problems, 1)) # output bias\n",
    "\n",
    "def lossFun(inputs, targets, correctness, hprev):\n",
    "    \"\"\"\n",
    "    inputs,targets are both list of integers.\n",
    "    hprev is Hx1 array of initial hidden state\n",
    "    returns the loss, gradients on model parameters, and last hidden state\n",
    "    \"\"\"\n",
    "    xs, hs, ys, ps, ps_denom = {}, {}, {}, {}, {}\n",
    "    hs[-1] = np.copy(hprev)\n",
    "    loss = 0\n",
    "    # forward pass\n",
    "    for t in xrange(len(inputs)):\n",
    "        xs[t] = inputs[t,:].reshape((num_problems * 2, 1))\n",
    "        hs[t] = np.tanh(np.dot(Wxh, xs[t]) + np.dot(Whh, hs[t-1]) + bh) # hidden state\n",
    "        ys[t] = np.dot(Why, hs[t]) + by # unnormalized log probabilities for next chars\n",
    "        ps_denom[t] = np.sum(np.exp(ys[t]))\n",
    "        ps[t] = np.exp(ys[t]) / ps_denom[t] # probabilities for next chars\n",
    "\n",
    "        # softmax (cross-entropy loss)\n",
    "        if correctness[targets[t]] == 1:\n",
    "            loss += -np.log(ps[t][targets[t],0]) \n",
    "        else:\n",
    "            loss += -np.log(1-ps[t][targets[t],0]) \n",
    "        # backward pass: compute gradients going backwards\n",
    "        dWxh, dWhh, dWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
    "        dbh, dby = np.zeros_like(bh), np.zeros_like(by)\n",
    "        dhnext = np.zeros_like(hs[0])\n",
    "\n",
    "\n",
    "    for t in reversed(xrange(len(inputs))):\n",
    "        dy = np.copy(ps[t])\n",
    "        if correctness[targets[t]] == 1:\n",
    "            dy[targets[t]] -= 1 # backprop into y\n",
    "        else:\n",
    "            for p in xrange(num_problems):\n",
    "                if p != targets[t]:\n",
    "                    dy[p] -= np.exp(ys[t][p]) / (ps_denom[t] - np.exp(ys[t][targets[t]]))\n",
    "\n",
    "\n",
    "\n",
    "        dWhy += np.dot(dy, hs[t].T)\n",
    "        dby += dy\n",
    "        dh = np.dot(Why.T, dy) + dhnext # backprop into h\n",
    "        dhraw = (1 - hs[t] * hs[t]) * dh # backprop through tanh nonlinearity\n",
    "        dbh += dhraw\n",
    "        dWxh += np.dot(dhraw, xs[t].T)\n",
    "        dWhh += np.dot(dhraw, hs[t-1].T)\n",
    "        dhnext = np.dot(Whh.T, dhraw)\n",
    "        for dparam in [dWxh, dWhh, dWhy, dbh, dby]:\n",
    "            np.clip(dparam, -5, 5, out=dparam) # clip to mitigate exploding gradients\n",
    "    return loss, dWxh, dWhh, dWhy, dbh, dby, hs[len(inputs)-1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(ps, targets, correctness):\n",
    "    \"\"\"\n",
    "    Computes the accuracy using the predictions at each time step.\n",
    "    For each t, if probability of next problem is > 0.5 for correct, or <= 0.5 \n",
    "    for incorrect, then count this as correct prediction.\n",
    "    \"\"\"\n",
    "    num_correct = 0\n",
    "    for t in xrange(num_timesteps):\n",
    "        predicted_prob = ps[t][targets[t],0] \n",
    "        if (predicted_prob >= 0.5 and correctness[targets[t]] == 1) or (predicted_prob < 0.5 and correctness[targets[t]] == 0):\n",
    "            num_correct += 1\n",
    "    accuracy = num_correct / float(num_timesteps)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# def sample(h, seed_ix, n):\n",
    "#   \"\"\" \n",
    "#   sample a sequence of integers from the model \n",
    "#   h is memory state, seed_ix is seed letter for first time step\n",
    "#   \"\"\"\n",
    "#   x = np.zeros((num_problems, 1))\n",
    "#   x[seed_ix] = 1\n",
    "#   ixes = []\n",
    "#   for t in xrange(n):\n",
    "#     h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h) + bh)\n",
    "#     y = np.dot(Why, h) + by\n",
    "#     p = np.exp(y) / np.sum(np.exp(y))\n",
    "#     ix = np.random.choice(range(num_problems), p=p.ravel())\n",
    "#     x = np.zeros((num_problems, 1))\n",
    "#     x[ix] = 1\n",
    "#     ixes.append(ix)\n",
    "#   return ixes\n",
    "\n",
    "def forward_pass(inputs):\n",
    "    xs, hs, ys, ps, ps_denom = {}, {}, {}, {}, {}\n",
    "    hs[-1] = np.copy(hprev)\n",
    "    for t in xrange(len(inputs)):\n",
    "        xs[t] = inputs[t,:].reshape((num_problems * 2, 1))\n",
    "        hs[t] = np.tanh(np.dot(Wxh, xs[t]) + np.dot(Whh, hs[t-1]) + bh) # hidden state\n",
    "        ys[t] = np.dot(Why, hs[t]) + by # unnormalized log probabilities for next chars\n",
    "        ps_denom[t] = np.sum(np.exp(ys[t]))\n",
    "        ps[t] = np.exp(ys[t]) / ps_denom[t] # probabilities for next chars\n",
    "    return ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, iter 0, loss: 125.533393, acc: 0.346939\n",
      "epoch 0, iter 1, loss: 39.431083, acc: 0.816327\n",
      "epoch 0, iter 2, loss: 170.097497, acc: 0.306122\n",
      "epoch 0, iter 3, loss: 163.023807, acc: 0.571429\n",
      "epoch 0, iter 4, loss: 326.668227, acc: 0.285714\n",
      "epoch 0, iter 5, loss: 290.488278, acc: 0.387755\n",
      "epoch 0, iter 6, loss: 324.267898, acc: 0.244898\n",
      "epoch 0, iter 7, loss: 166.772631, acc: 0.489796\n",
      "epoch 0, iter 8, loss: 166.257124, acc: 0.653061\n",
      "epoch 0, iter 9, loss: 270.621781, acc: 0.244898\n",
      "epoch 0, iter 10, loss: 264.267423, acc: 0.387755\n",
      "epoch 0, iter 11, loss: 142.655729, acc: 0.632653\n",
      "epoch 0, iter 12, loss: 194.548714, acc: 0.224490\n",
      "epoch 0, iter 13, loss: 195.350284, acc: 0.346939\n",
      "epoch 0, iter 14, loss: 220.886382, acc: 0.306122\n",
      "epoch 0, iter 15, loss: 233.996487, acc: 0.102041\n",
      "epoch 0, iter 16, loss: 113.528345, acc: 0.571429\n",
      "epoch 0, iter 17, loss: 225.665717, acc: 0.224490\n",
      "epoch 0, iter 18, loss: 61.258655, acc: 0.734694\n",
      "epoch 0, iter 19, loss: 245.891783, acc: 0.040816\n",
      "epoch 0, iter 20, loss: 231.544930, acc: 0.102041\n",
      "epoch 0, iter 21, loss: 181.343143, acc: 0.326531\n",
      "epoch 0, iter 22, loss: 191.738628, acc: 0.204082\n",
      "epoch 0, iter 23, loss: 121.211140, acc: 0.510204\n",
      "epoch 0, iter 24, loss: 139.787444, acc: 0.408163\n",
      "epoch 0, iter 25, loss: 92.591897, acc: 0.571429\n",
      "epoch 0, iter 26, loss: 129.100071, acc: 0.448980\n",
      "epoch 0, iter 27, loss: 147.489276, acc: 0.387755\n",
      "epoch 0, iter 28, loss: 163.239850, acc: 0.306122\n",
      "epoch 0, iter 29, loss: 189.420577, acc: 0.204082\n",
      "epoch 0, iter 30, loss: 116.461534, acc: 0.489796\n",
      "epoch 0, iter 31, loss: 101.167925, acc: 0.571429\n",
      "epoch 0, iter 32, loss: 122.211382, acc: 0.408163\n",
      "epoch 0, iter 33, loss: 190.849505, acc: 0.183673\n",
      "epoch 0, iter 34, loss: 147.427506, acc: 0.387755\n",
      "epoch 0, iter 35, loss: 93.442854, acc: 0.571429\n",
      "epoch 0, iter 36, loss: 112.499458, acc: 0.469388\n",
      "epoch 0, iter 37, loss: 183.384482, acc: 0.163265\n",
      "epoch 0, iter 38, loss: 175.072030, acc: 0.265306\n",
      "epoch 0, iter 39, loss: 89.651234, acc: 0.591837\n",
      "epoch 0, iter 40, loss: 112.616982, acc: 0.448980\n",
      "epoch 0, iter 41, loss: 147.866118, acc: 0.285714\n",
      "epoch 0, iter 42, loss: 75.441515, acc: 0.693878\n",
      "epoch 0, iter 43, loss: 180.402581, acc: 0.142857\n",
      "epoch 0, iter 44, loss: 196.991198, acc: 0.122449\n",
      "epoch 0, iter 45, loss: 120.485490, acc: 0.489796\n",
      "epoch 0, iter 46, loss: 101.888388, acc: 0.530612\n",
      "epoch 0, iter 47, loss: 121.740675, acc: 0.387755\n",
      "epoch 0, iter 48, loss: 150.804989, acc: 0.367347\n",
      "epoch 0, iter 49, loss: 168.562606, acc: 0.244898\n",
      "epoch 0, iter 50, loss: 146.670183, acc: 0.306122\n",
      "epoch 0, iter 51, loss: 148.172448, acc: 0.367347\n",
      "epoch 0, iter 52, loss: 121.183527, acc: 0.469388\n",
      "epoch 0, iter 53, loss: 125.927982, acc: 0.408163\n",
      "epoch 0, iter 54, loss: 163.946266, acc: 0.244898\n",
      "epoch 0, iter 55, loss: 172.762293, acc: 0.224490\n",
      "epoch 0, iter 56, loss: 180.813351, acc: 0.204082\n",
      "epoch 0, iter 57, loss: 178.199903, acc: 0.204082\n",
      "epoch 0, iter 58, loss: 91.440990, acc: 0.591837\n",
      "epoch 0, iter 59, loss: 152.572777, acc: 0.285714\n",
      "epoch 0, iter 60, loss: 133.279926, acc: 0.346939\n",
      "epoch 0, iter 61, loss: 195.578115, acc: 0.142857\n",
      "epoch 0, iter 62, loss: 134.429844, acc: 0.387755\n",
      "epoch 0, iter 63, loss: 146.569782, acc: 0.265306\n",
      "epoch 0, iter 64, loss: 85.096644, acc: 0.612245\n",
      "epoch 0, iter 65, loss: 128.542497, acc: 0.448980\n",
      "epoch 0, iter 66, loss: 178.347958, acc: 0.204082\n",
      "epoch 0, iter 67, loss: 95.063814, acc: 0.571429\n",
      "epoch 0, iter 68, loss: 170.130319, acc: 0.163265\n",
      "epoch 0, iter 69, loss: 179.801035, acc: 0.122449\n",
      "epoch 0, iter 70, loss: 148.401669, acc: 0.346939\n",
      "epoch 0, iter 71, loss: 119.816415, acc: 0.387755\n",
      "epoch 0, iter 72, loss: 157.010521, acc: 0.367347\n",
      "epoch 0, iter 73, loss: 164.636073, acc: 0.224490\n",
      "epoch 0, iter 74, loss: 125.911486, acc: 0.469388\n",
      "epoch 0, iter 75, loss: 165.538575, acc: 0.265306\n",
      "epoch 0, iter 76, loss: 141.386526, acc: 0.346939\n",
      "epoch 0, iter 77, loss: 143.334679, acc: 0.367347\n",
      "epoch 0, iter 78, loss: 120.891940, acc: 0.408163\n",
      "epoch 0, iter 79, loss: 126.844250, acc: 0.408163\n",
      "epoch 0, iter 80, loss: 198.335182, acc: 0.061224\n",
      "epoch 0, iter 81, loss: 154.409804, acc: 0.326531\n",
      "epoch 0, iter 82, loss: 130.638239, acc: 0.387755\n",
      "epoch 0, iter 83, loss: 139.460675, acc: 0.306122\n",
      "epoch 0, iter 84, loss: 196.461752, acc: 0.122449\n",
      "epoch 0, iter 85, loss: 191.151982, acc: 0.102041\n",
      "epoch 0, iter 86, loss: 107.034343, acc: 0.510204\n",
      "epoch 0, iter 87, loss: 87.575802, acc: 0.571429\n",
      "epoch 0, iter 88, loss: 133.982363, acc: 0.326531\n",
      "epoch 0, iter 89, loss: 133.354066, acc: 0.387755\n",
      "epoch 0, iter 90, loss: 101.360816, acc: 0.510204\n",
      "epoch 0, iter 91, loss: 145.817639, acc: 0.285714\n",
      "epoch 0, iter 92, loss: 86.446708, acc: 0.591837\n",
      "epoch 0, iter 93, loss: 76.726036, acc: 0.632653\n",
      "epoch 0, iter 94, loss: 129.953152, acc: 0.346939\n",
      "epoch 0, iter 95, loss: 201.756872, acc: 0.040816\n",
      "epoch 0, iter 96, loss: 112.165357, acc: 0.489796\n",
      "epoch 0, iter 97, loss: 139.233281, acc: 0.326531\n",
      "epoch 0, iter 98, loss: 107.245366, acc: 0.469388\n",
      "epoch 0, iter 99, loss: 152.483611, acc: 0.244898\n",
      "epoch 0, iter 100, loss: 76.401167, acc: 0.612245\n",
      "epoch 0, iter 101, loss: 111.389045, acc: 0.448980\n",
      "epoch 0, iter 102, loss: 167.776990, acc: 0.183673\n",
      "epoch 0, iter 103, loss: 155.191202, acc: 0.265306\n",
      "epoch 0, iter 104, loss: 111.462530, acc: 0.469388\n",
      "epoch 0, iter 105, loss: 128.186234, acc: 0.285714\n",
      "epoch 0, iter 106, loss: 156.372570, acc: 0.204082\n",
      "epoch 0, iter 107, loss: 178.382512, acc: 0.163265\n",
      "epoch 0, iter 108, loss: 103.350970, acc: 0.530612\n",
      "epoch 0, iter 109, loss: 81.461716, acc: 0.551020\n",
      "epoch 0, iter 110, loss: 100.225267, acc: 0.489796\n",
      "epoch 0, iter 111, loss: 74.494525, acc: 0.591837\n",
      "epoch 0, iter 112, loss: 113.138945, acc: 0.306122\n",
      "epoch 0, iter 113, loss: 64.048090, acc: 0.653061\n",
      "epoch 0, iter 114, loss: 104.500928, acc: 0.530612\n",
      "epoch 0, iter 115, loss: 123.962691, acc: 0.326531\n",
      "epoch 0, iter 116, loss: 87.587800, acc: 0.612245\n",
      "epoch 0, iter 117, loss: 114.003370, acc: 0.408163\n",
      "epoch 0, iter 118, loss: 91.150582, acc: 0.530612\n",
      "epoch 0, iter 119, loss: 121.925235, acc: 0.387755\n",
      "epoch 0, iter 120, loss: 118.032447, acc: 0.387755\n",
      "epoch 0, iter 121, loss: 173.172648, acc: 0.204082\n",
      "epoch 0, iter 122, loss: 63.938172, acc: 0.714286\n",
      "epoch 0, iter 123, loss: 148.015385, acc: 0.285714\n",
      "epoch 0, iter 124, loss: 95.248031, acc: 0.571429\n",
      "epoch 0, iter 125, loss: 127.163404, acc: 0.387755\n",
      "epoch 0, iter 126, loss: 162.194523, acc: 0.204082\n",
      "epoch 0, iter 127, loss: 117.329070, acc: 0.469388\n",
      "epoch 0, iter 128, loss: 140.904292, acc: 0.326531\n",
      "epoch 0, iter 129, loss: 126.092412, acc: 0.326531\n",
      "epoch 0, iter 130, loss: 192.161717, acc: 0.102041\n",
      "epoch 0, iter 131, loss: 132.384179, acc: 0.367347\n",
      "epoch 0, iter 132, loss: 166.298693, acc: 0.224490\n",
      "epoch 0, iter 133, loss: 149.953583, acc: 0.265306\n",
      "epoch 0, iter 134, loss: 64.761830, acc: 0.693878\n",
      "epoch 0, iter 135, loss: 110.109905, acc: 0.448980\n",
      "epoch 0, iter 136, loss: 29.253355, acc: 0.857143\n",
      "epoch 0, iter 137, loss: 115.540662, acc: 0.448980\n",
      "epoch 0, iter 138, loss: 124.814136, acc: 0.346939\n",
      "epoch 0, iter 139, loss: 123.784653, acc: 0.346939\n",
      "epoch 0, iter 140, loss: 104.773485, acc: 0.469388\n",
      "epoch 0, iter 141, loss: 172.776124, acc: 0.081633\n",
      "epoch 0, iter 142, loss: 86.348908, acc: 0.551020\n",
      "epoch 0, iter 143, loss: 145.197206, acc: 0.306122\n",
      "epoch 0, iter 144, loss: 108.023820, acc: 0.428571\n",
      "epoch 0, iter 145, loss: 188.397576, acc: 0.040816\n",
      "epoch 0, iter 146, loss: 145.580592, acc: 0.306122\n",
      "epoch 0, iter 147, loss: 135.658032, acc: 0.326531\n",
      "epoch 0, iter 148, loss: 111.993863, acc: 0.408163\n",
      "epoch 0, iter 149, loss: 170.020276, acc: 0.102041\n",
      "epoch 0, iter 150, loss: 125.337093, acc: 0.346939\n",
      "epoch 0, iter 151, loss: 99.647037, acc: 0.469388\n",
      "epoch 0, iter 152, loss: 125.653168, acc: 0.306122\n",
      "epoch 0, iter 153, loss: 96.629785, acc: 0.489796\n",
      "epoch 0, iter 154, loss: 102.849237, acc: 0.510204\n",
      "epoch 0, iter 155, loss: 137.054446, acc: 0.285714\n",
      "epoch 0, iter 156, loss: 88.788859, acc: 0.530612\n",
      "epoch 0, iter 157, loss: 131.595333, acc: 0.326531\n",
      "epoch 0, iter 158, loss: 162.891303, acc: 0.163265\n",
      "epoch 0, iter 159, loss: 91.796126, acc: 0.530612\n",
      "epoch 0, iter 160, loss: 94.058236, acc: 0.530612\n",
      "epoch 0, iter 161, loss: 141.467370, acc: 0.285714\n",
      "epoch 0, iter 162, loss: 120.088573, acc: 0.367347\n",
      "epoch 0, iter 163, loss: 129.337122, acc: 0.346939\n",
      "epoch 0, iter 164, loss: 106.414133, acc: 0.510204\n",
      "epoch 0, iter 165, loss: 152.798094, acc: 0.224490\n",
      "epoch 0, iter 166, loss: 98.904870, acc: 0.448980\n",
      "epoch 0, iter 167, loss: 72.047815, acc: 0.612245\n",
      "epoch 0, iter 168, loss: 99.444357, acc: 0.489796\n",
      "epoch 0, iter 169, loss: 67.124230, acc: 0.612245\n",
      "epoch 0, iter 170, loss: 113.297616, acc: 0.387755\n",
      "epoch 0, iter 171, loss: 126.672800, acc: 0.306122\n",
      "epoch 0, iter 172, loss: 109.337553, acc: 0.428571\n",
      "epoch 0, iter 173, loss: 143.881966, acc: 0.265306\n",
      "epoch 0, iter 174, loss: 107.850977, acc: 0.387755\n",
      "epoch 0, iter 175, loss: 148.485812, acc: 0.204082\n",
      "epoch 0, iter 176, loss: 141.346705, acc: 0.244898\n",
      "epoch 0, iter 177, loss: 133.342030, acc: 0.306122\n",
      "epoch 0, iter 178, loss: 100.822875, acc: 0.489796\n",
      "epoch 0, iter 179, loss: 141.569450, acc: 0.224490\n",
      "epoch 0, iter 180, loss: 142.048787, acc: 0.204082\n",
      "epoch 0, iter 181, loss: 123.726667, acc: 0.306122\n",
      "epoch 0, iter 182, loss: 123.249359, acc: 0.346939\n",
      "epoch 0, iter 183, loss: 61.356391, acc: 0.653061\n",
      "epoch 0, iter 184, loss: 105.190940, acc: 0.428571\n",
      "epoch 0, iter 185, loss: 94.378585, acc: 0.448980\n",
      "epoch 0, iter 186, loss: 140.665801, acc: 0.163265\n",
      "epoch 0, iter 187, loss: 104.733969, acc: 0.428571\n",
      "epoch 0, iter 188, loss: 53.525351, acc: 0.755102\n",
      "epoch 0, iter 189, loss: 85.816704, acc: 0.530612\n",
      "epoch 0, iter 190, loss: 67.329315, acc: 0.591837\n",
      "epoch 0, iter 191, loss: 117.184232, acc: 0.346939\n",
      "epoch 0, iter 192, loss: 96.597566, acc: 0.489796\n",
      "epoch 0, iter 193, loss: 91.442562, acc: 0.489796\n",
      "epoch 0, iter 194, loss: 138.923415, acc: 0.204082\n",
      "epoch 0, iter 195, loss: 84.253392, acc: 0.510204\n",
      "epoch 0, iter 196, loss: 141.926106, acc: 0.244898\n",
      "epoch 0, iter 197, loss: 109.911379, acc: 0.408163\n",
      "epoch 0, iter 198, loss: 130.786526, acc: 0.265306\n",
      "epoch 0, iter 199, loss: 122.907636, acc: 0.408163\n",
      "epoch 0, iter 200, loss: 89.536371, acc: 0.551020\n",
      "epoch 0, iter 201, loss: 151.658394, acc: 0.142857\n",
      "epoch 0, iter 202, loss: 120.911419, acc: 0.326531\n",
      "epoch 0, iter 203, loss: 67.464824, acc: 0.673469\n",
      "epoch 0, iter 204, loss: 100.982518, acc: 0.551020\n",
      "epoch 0, iter 205, loss: 93.431906, acc: 0.448980\n",
      "epoch 0, iter 206, loss: 127.486636, acc: 0.224490\n",
      "epoch 0, iter 207, loss: 118.424751, acc: 0.408163\n",
      "epoch 0, iter 208, loss: 161.332420, acc: 0.163265\n",
      "epoch 0, iter 209, loss: 136.069729, acc: 0.224490\n",
      "epoch 0, iter 210, loss: 90.274193, acc: 0.489796\n",
      "epoch 0, iter 211, loss: 175.005927, acc: 0.081633\n",
      "epoch 0, iter 212, loss: 72.857201, acc: 0.632653\n",
      "epoch 0, iter 213, loss: 139.358975, acc: 0.163265\n",
      "epoch 0, iter 214, loss: 126.571874, acc: 0.224490\n",
      "epoch 0, iter 215, loss: 78.257459, acc: 0.571429\n",
      "epoch 0, iter 216, loss: 115.120584, acc: 0.367347\n",
      "epoch 0, iter 217, loss: 69.320427, acc: 0.571429\n",
      "epoch 0, iter 218, loss: 98.275049, acc: 0.367347\n",
      "epoch 0, iter 219, loss: 138.634214, acc: 0.142857\n",
      "epoch 0, iter 220, loss: 60.095936, acc: 0.653061\n",
      "epoch 0, iter 221, loss: 133.418373, acc: 0.224490\n",
      "epoch 0, iter 222, loss: 93.761739, acc: 0.428571\n",
      "epoch 0, iter 223, loss: 120.530396, acc: 0.244898\n",
      "epoch 0, iter 224, loss: 92.529512, acc: 0.428571\n",
      "epoch 0, iter 225, loss: 121.963205, acc: 0.326531\n",
      "epoch 0, iter 226, loss: 110.359294, acc: 0.326531\n",
      "epoch 0, iter 227, loss: 100.829532, acc: 0.346939\n",
      "epoch 0, iter 228, loss: 84.945553, acc: 0.428571\n",
      "epoch 0, iter 229, loss: 155.908074, acc: 0.020408\n",
      "epoch 0, iter 230, loss: 100.781410, acc: 0.408163\n",
      "epoch 0, iter 231, loss: 119.587207, acc: 0.244898\n",
      "epoch 0, iter 232, loss: 84.423633, acc: 0.448980\n",
      "epoch 0, iter 233, loss: 92.356276, acc: 0.387755\n",
      "epoch 0, iter 234, loss: 139.766675, acc: 0.081633\n",
      "epoch 0, iter 235, loss: 96.243359, acc: 0.387755\n",
      "epoch 0, iter 236, loss: 113.067852, acc: 0.265306\n",
      "epoch 0, iter 237, loss: 70.605819, acc: 0.510204\n",
      "epoch 0, iter 238, loss: 74.006635, acc: 0.530612\n",
      "epoch 0, iter 239, loss: 74.625619, acc: 0.489796\n",
      "epoch 0, iter 240, loss: 109.765096, acc: 0.265306\n",
      "epoch 0, iter 241, loss: 94.566852, acc: 0.346939\n",
      "epoch 0, iter 242, loss: 79.159519, acc: 0.510204\n",
      "epoch 0, iter 243, loss: 81.469065, acc: 0.469388\n",
      "epoch 0, iter 244, loss: 55.894790, acc: 0.591837\n",
      "epoch 0, iter 245, loss: 72.381174, acc: 0.469388\n",
      "epoch 0, iter 246, loss: 70.436034, acc: 0.510204\n",
      "epoch 0, iter 247, loss: 43.686886, acc: 0.673469\n",
      "epoch 0, iter 248, loss: 105.456594, acc: 0.244898\n",
      "epoch 0, iter 249, loss: 56.425064, acc: 0.612245\n",
      "epoch 0, iter 250, loss: 110.574699, acc: 0.244898\n",
      "epoch 0, iter 251, loss: 84.287656, acc: 0.408163\n",
      "epoch 0, iter 252, loss: 22.932014, acc: 0.836735\n",
      "epoch 0, iter 253, loss: 90.327319, acc: 0.387755\n",
      "epoch 0, iter 254, loss: 109.787827, acc: 0.142857\n",
      "epoch 0, iter 255, loss: 72.360383, acc: 0.408163\n",
      "epoch 0, iter 256, loss: 91.643873, acc: 0.408163\n",
      "epoch 0, iter 257, loss: 39.640920, acc: 0.734694\n",
      "epoch 0, iter 258, loss: 43.861581, acc: 0.653061\n",
      "epoch 0, iter 259, loss: 90.487975, acc: 0.224490\n",
      "epoch 0, iter 260, loss: 57.729194, acc: 0.612245\n",
      "epoch 0, iter 261, loss: 123.951923, acc: 0.142857\n",
      "epoch 0, iter 262, loss: 81.444111, acc: 0.346939\n",
      "epoch 0, iter 263, loss: 75.366075, acc: 0.408163\n",
      "epoch 0, iter 264, loss: 101.570698, acc: 0.224490\n",
      "epoch 0, iter 265, loss: 104.159820, acc: 0.183673\n",
      "epoch 0, iter 266, loss: 70.184456, acc: 0.551020\n",
      "epoch 0, iter 267, loss: 96.610259, acc: 0.346939\n",
      "epoch 0, iter 268, loss: 80.471844, acc: 0.367347\n",
      "epoch 0, iter 269, loss: 89.296589, acc: 0.244898\n",
      "epoch 0, iter 270, loss: 100.635184, acc: 0.224490\n",
      "epoch 0, iter 271, loss: 116.238063, acc: 0.142857\n",
      "epoch 0, iter 272, loss: 111.998667, acc: 0.163265\n",
      "epoch 0, iter 273, loss: 57.355951, acc: 0.551020\n",
      "epoch 0, iter 274, loss: 52.733765, acc: 0.591837\n",
      "epoch 0, iter 275, loss: 74.895377, acc: 0.448980\n",
      "epoch 0, iter 276, loss: 85.449218, acc: 0.183673\n",
      "epoch 0, iter 277, loss: 62.915451, acc: 0.489796\n",
      "epoch 0, iter 278, loss: 94.720176, acc: 0.244898\n",
      "epoch 0, iter 279, loss: 65.891911, acc: 0.428571\n",
      "epoch 0, iter 280, loss: 78.841902, acc: 0.346939\n",
      "epoch 0, iter 281, loss: 39.647229, acc: 0.714286\n",
      "epoch 0, iter 282, loss: 65.273657, acc: 0.469388\n",
      "epoch 0, iter 283, loss: 43.990580, acc: 0.632653\n",
      "epoch 0, iter 284, loss: 31.197494, acc: 0.714286\n",
      "epoch 0, iter 285, loss: 92.543018, acc: 0.183673\n",
      "epoch 0, iter 286, loss: 76.326669, acc: 0.306122\n",
      "epoch 0, iter 287, loss: 85.474339, acc: 0.285714\n",
      "epoch 0, iter 288, loss: 68.312036, acc: 0.408163\n",
      "epoch 0, iter 289, loss: 35.501025, acc: 0.693878\n",
      "epoch 0, iter 290, loss: 79.434927, acc: 0.244898\n",
      "epoch 0, iter 291, loss: 49.370019, acc: 0.510204\n",
      "epoch 0, iter 292, loss: 64.463132, acc: 0.387755\n",
      "epoch 0, iter 293, loss: 67.713189, acc: 0.387755\n",
      "epoch 0, iter 294, loss: 67.793011, acc: 0.306122\n",
      "epoch 0, iter 295, loss: 75.578057, acc: 0.367347\n",
      "epoch 0, iter 296, loss: 86.956642, acc: 0.285714\n",
      "epoch 0, iter 297, loss: 74.202648, acc: 0.306122\n",
      "epoch 0, iter 298, loss: 59.077749, acc: 0.448980\n",
      "epoch 0, iter 299, loss: 62.246948, acc: 0.387755\n",
      "epoch 0, iter 300, loss: 74.279256, acc: 0.244898\n",
      "epoch 0, iter 301, loss: 70.061970, acc: 0.285714\n",
      "epoch 0, iter 302, loss: 63.435570, acc: 0.387755\n",
      "epoch 0, iter 303, loss: 48.069779, acc: 0.510204\n",
      "epoch 0, iter 304, loss: 52.948290, acc: 0.469388\n",
      "epoch 0, iter 305, loss: 55.497989, acc: 0.448980\n",
      "epoch 0, iter 306, loss: 58.149404, acc: 0.408163\n",
      "epoch 0, iter 307, loss: 48.020405, acc: 0.530612\n",
      "epoch 0, iter 308, loss: 36.882424, acc: 0.591837\n",
      "epoch 0, iter 309, loss: 50.174028, acc: 0.510204\n",
      "epoch 0, iter 310, loss: 62.551584, acc: 0.204082\n",
      "epoch 0, iter 311, loss: 86.773679, acc: 0.081633\n",
      "epoch 0, iter 312, loss: 86.325512, acc: 0.244898\n",
      "epoch 0, iter 313, loss: 80.621150, acc: 0.306122\n",
      "epoch 0, iter 314, loss: 62.551060, acc: 0.387755\n",
      "epoch 0, iter 315, loss: 66.077594, acc: 0.387755\n",
      "epoch 0, iter 316, loss: 54.649739, acc: 0.387755\n",
      "epoch 0, iter 317, loss: 58.358922, acc: 0.346939\n",
      "epoch 0, iter 318, loss: 55.121660, acc: 0.551020\n",
      "epoch 0, iter 319, loss: 48.490624, acc: 0.510204\n",
      "epoch 0, iter 320, loss: 41.754268, acc: 0.551020\n",
      "epoch 0, iter 321, loss: 54.216450, acc: 0.387755\n",
      "epoch 0, iter 322, loss: 49.581647, acc: 0.510204\n",
      "epoch 0, iter 323, loss: 42.433632, acc: 0.571429\n",
      "epoch 0, iter 324, loss: 43.087469, acc: 0.469388\n",
      "epoch 0, iter 325, loss: 66.533228, acc: 0.244898\n",
      "epoch 0, iter 326, loss: 33.123875, acc: 0.734694\n",
      "epoch 0, iter 327, loss: 60.811097, acc: 0.387755\n",
      "epoch 0, iter 328, loss: 57.312522, acc: 0.408163\n",
      "epoch 0, iter 329, loss: 56.461421, acc: 0.367347\n",
      "epoch 0, iter 330, loss: 73.356067, acc: 0.367347\n",
      "epoch 0, iter 331, loss: 46.797169, acc: 0.591837\n",
      "epoch 0, iter 332, loss: 39.302014, acc: 0.612245\n",
      "epoch 0, iter 333, loss: 45.376255, acc: 0.408163\n",
      "epoch 0, iter 334, loss: 47.707832, acc: 0.510204\n",
      "epoch 0, iter 335, loss: 65.438943, acc: 0.265306\n",
      "epoch 0, iter 336, loss: 58.476204, acc: 0.346939\n",
      "epoch 0, iter 337, loss: 52.960228, acc: 0.469388\n",
      "epoch 0, iter 338, loss: 72.941345, acc: 0.285714\n",
      "epoch 0, iter 339, loss: 51.881946, acc: 0.408163\n",
      "epoch 0, iter 340, loss: 51.273453, acc: 0.551020\n",
      "epoch 0, iter 341, loss: 55.233692, acc: 0.428571\n",
      "epoch 0, iter 342, loss: 32.860893, acc: 0.755102\n",
      "epoch 0, iter 343, loss: 40.652070, acc: 0.489796\n",
      "epoch 0, iter 344, loss: 25.903569, acc: 0.775510\n",
      "epoch 0, iter 345, loss: 42.043332, acc: 0.469388\n",
      "epoch 0, iter 346, loss: 54.653631, acc: 0.448980\n",
      "epoch 0, iter 347, loss: 36.864221, acc: 0.448980\n",
      "epoch 0, iter 348, loss: 38.387969, acc: 0.612245\n",
      "epoch 0, iter 349, loss: 30.212848, acc: 0.714286\n",
      "epoch 0, iter 350, loss: 45.305954, acc: 0.489796\n",
      "epoch 0, iter 351, loss: 36.056614, acc: 0.510204\n",
      "epoch 0, iter 352, loss: 63.583148, acc: 0.551020\n",
      "epoch 0, iter 353, loss: 29.471650, acc: 0.714286\n",
      "epoch 0, iter 354, loss: 42.900837, acc: 0.571429\n",
      "epoch 0, iter 355, loss: 43.937170, acc: 0.367347\n",
      "epoch 0, iter 356, loss: 47.206851, acc: 0.428571\n",
      "epoch 0, iter 357, loss: 43.901714, acc: 0.612245\n",
      "epoch 0, iter 358, loss: 35.082726, acc: 0.530612\n",
      "epoch 0, iter 359, loss: 38.285765, acc: 0.428571\n",
      "epoch 0, iter 360, loss: 42.462512, acc: 0.551020\n",
      "epoch 0, iter 361, loss: 38.513900, acc: 0.530612\n",
      "epoch 0, iter 362, loss: 48.883474, acc: 0.510204\n",
      "epoch 0, iter 363, loss: 46.337587, acc: 0.489796\n",
      "epoch 0, iter 364, loss: 36.194173, acc: 0.551020\n",
      "epoch 0, iter 365, loss: 42.675954, acc: 0.448980\n",
      "epoch 0, iter 366, loss: 32.883051, acc: 0.673469\n",
      "epoch 0, iter 367, loss: 30.257133, acc: 0.693878\n",
      "epoch 0, iter 368, loss: 43.665529, acc: 0.510204\n",
      "epoch 0, iter 369, loss: 36.861574, acc: 0.448980\n",
      "epoch 0, iter 370, loss: 40.547009, acc: 0.530612\n",
      "epoch 0, iter 371, loss: 36.068515, acc: 0.571429\n",
      "epoch 0, iter 372, loss: 33.303465, acc: 0.632653\n",
      "epoch 0, iter 373, loss: 32.432350, acc: 0.591837\n",
      "epoch 0, iter 374, loss: 41.371216, acc: 0.510204\n",
      "epoch 0, iter 375, loss: 50.318908, acc: 0.367347\n",
      "epoch 0, iter 376, loss: 42.892730, acc: 0.530612\n",
      "epoch 0, iter 377, loss: 36.423345, acc: 0.489796\n",
      "epoch 0, iter 378, loss: 47.102296, acc: 0.530612\n",
      "epoch 0, iter 379, loss: 26.283406, acc: 0.714286\n",
      "epoch 0, iter 380, loss: 46.286297, acc: 0.530612\n",
      "epoch 0, iter 381, loss: 46.134947, acc: 0.306122\n",
      "epoch 0, iter 382, loss: 53.216283, acc: 0.448980\n",
      "epoch 0, iter 383, loss: 43.481558, acc: 0.326531\n",
      "epoch 0, iter 384, loss: 47.382494, acc: 0.632653\n",
      "epoch 0, iter 385, loss: 43.688758, acc: 0.469388\n",
      "epoch 0, iter 386, loss: 30.323080, acc: 0.714286\n",
      "epoch 0, iter 387, loss: 31.847198, acc: 0.530612\n",
      "epoch 0, iter 388, loss: 53.908641, acc: 0.632653\n",
      "epoch 0, iter 389, loss: 38.135065, acc: 0.571429\n",
      "epoch 0, iter 390, loss: 46.086333, acc: 0.469388\n",
      "epoch 0, iter 391, loss: 37.259588, acc: 0.489796\n",
      "epoch 0, iter 392, loss: 36.321198, acc: 0.673469\n",
      "epoch 0, iter 393, loss: 34.894895, acc: 0.510204\n",
      "epoch 0, iter 394, loss: 45.542413, acc: 0.448980\n",
      "epoch 0, iter 395, loss: 34.534193, acc: 0.591837\n",
      "epoch 0, iter 396, loss: 40.162752, acc: 0.591837\n",
      "epoch 0, iter 397, loss: 31.526503, acc: 0.530612\n",
      "epoch 0, iter 398, loss: 39.873655, acc: 0.428571\n",
      "epoch 0, iter 399, loss: 41.713160, acc: 0.571429\n",
      "epoch 0, iter 400, loss: 37.040399, acc: 0.428571\n",
      "epoch 0, iter 401, loss: 40.825326, acc: 0.469388\n",
      "epoch 0, iter 402, loss: 40.305596, acc: 0.673469\n",
      "epoch 0, iter 403, loss: 37.298091, acc: 0.673469\n",
      "epoch 0, iter 404, loss: 38.352141, acc: 0.591837\n",
      "epoch 0, iter 405, loss: 32.136559, acc: 0.489796\n",
      "epoch 0, iter 406, loss: 36.510102, acc: 0.571429\n",
      "epoch 0, iter 407, loss: 39.624275, acc: 0.510204\n",
      "epoch 0, iter 408, loss: 36.290943, acc: 0.571429\n",
      "epoch 0, iter 409, loss: 31.423781, acc: 0.591837\n",
      "epoch 0, iter 410, loss: 37.969232, acc: 0.632653\n",
      "epoch 0, iter 411, loss: 31.535177, acc: 0.612245\n",
      "epoch 0, iter 412, loss: 51.111390, acc: 0.571429\n",
      "epoch 0, iter 413, loss: 30.077396, acc: 0.469388\n",
      "epoch 0, iter 414, loss: 32.003104, acc: 0.612245\n",
      "epoch 0, iter 415, loss: 38.526317, acc: 0.489796\n",
      "epoch 0, iter 416, loss: 35.662549, acc: 0.612245\n",
      "epoch 0, iter 417, loss: 30.060360, acc: 0.612245\n",
      "epoch 0, iter 418, loss: 40.857733, acc: 0.612245\n",
      "epoch 0, iter 419, loss: 33.088862, acc: 0.591837\n",
      "epoch 0, iter 420, loss: 31.787013, acc: 0.653061\n",
      "epoch 0, iter 421, loss: 40.511115, acc: 0.489796\n",
      "epoch 0, iter 422, loss: 35.701217, acc: 0.612245\n",
      "epoch 0, iter 423, loss: 33.257066, acc: 0.632653\n",
      "epoch 0, iter 424, loss: 38.003761, acc: 0.673469\n",
      "epoch 0, iter 425, loss: 34.052510, acc: 0.530612\n",
      "epoch 0, iter 426, loss: 35.748557, acc: 0.632653\n",
      "epoch 0, iter 427, loss: 40.194903, acc: 0.571429\n",
      "epoch 0, iter 428, loss: 33.024958, acc: 0.653061\n",
      "epoch 0, iter 429, loss: 33.710289, acc: 0.489796\n",
      "epoch 0, iter 430, loss: 32.126177, acc: 0.612245\n",
      "epoch 0, iter 431, loss: 51.332653, acc: 0.510204\n",
      "epoch 0, iter 432, loss: 30.323090, acc: 0.714286\n",
      "epoch 0, iter 433, loss: 32.936802, acc: 0.408163\n",
      "epoch 0, iter 434, loss: 30.799002, acc: 0.632653\n",
      "epoch 0, iter 435, loss: 33.416776, acc: 0.653061\n",
      "epoch 0, iter 436, loss: 32.776246, acc: 0.734694\n",
      "epoch 0, iter 437, loss: 41.276458, acc: 0.551020\n",
      "epoch 0, iter 438, loss: 35.575494, acc: 0.612245\n",
      "epoch 0, iter 439, loss: 32.421382, acc: 0.571429\n",
      "epoch 0, iter 440, loss: 33.688000, acc: 0.653061\n",
      "epoch 0, iter 441, loss: 30.294753, acc: 0.530612\n",
      "epoch 0, iter 442, loss: 35.186023, acc: 0.653061\n",
      "epoch 0, iter 443, loss: 33.083148, acc: 0.653061\n",
      "epoch 0, iter 444, loss: 32.233335, acc: 0.755102\n",
      "epoch 0, iter 445, loss: 43.476284, acc: 0.551020\n",
      "epoch 0, iter 446, loss: 34.315501, acc: 0.591837\n",
      "epoch 0, iter 447, loss: 33.262499, acc: 0.714286\n",
      "epoch 0, iter 448, loss: 34.505187, acc: 0.632653\n",
      "epoch 0, iter 449, loss: 34.945850, acc: 0.510204\n",
      "epoch 0, iter 450, loss: 34.122247, acc: 0.693878\n",
      "epoch 0, iter 451, loss: 28.591674, acc: 0.653061\n",
      "epoch 0, iter 452, loss: 31.895138, acc: 0.795918\n",
      "epoch 0, iter 453, loss: 31.109768, acc: 0.428571\n",
      "epoch 0, iter 454, loss: 37.081177, acc: 0.591837\n",
      "epoch 0, iter 455, loss: 28.738041, acc: 0.612245\n",
      "epoch 0, iter 456, loss: 29.977773, acc: 0.530612\n",
      "epoch 0, iter 457, loss: 31.788144, acc: 0.653061\n",
      "epoch 0, iter 458, loss: 33.936562, acc: 0.653061\n",
      "epoch 0, iter 459, loss: 33.667550, acc: 0.448980\n",
      "epoch 0, iter 460, loss: 37.986485, acc: 0.530612\n",
      "epoch 0, iter 461, loss: 30.451505, acc: 0.551020\n",
      "epoch 0, iter 462, loss: 33.726642, acc: 0.530612\n",
      "epoch 0, iter 463, loss: 36.136562, acc: 0.653061\n",
      "epoch 0, iter 464, loss: 43.027334, acc: 0.612245\n",
      "epoch 0, iter 465, loss: 31.130719, acc: 0.591837\n",
      "epoch 0, iter 466, loss: 33.162388, acc: 0.673469\n",
      "epoch 0, iter 467, loss: 38.471862, acc: 0.653061\n",
      "epoch 0, iter 468, loss: 37.027293, acc: 0.653061\n",
      "epoch 0, iter 469, loss: 32.679022, acc: 0.612245\n",
      "epoch 0, iter 470, loss: 38.342454, acc: 0.571429\n",
      "epoch 0, iter 471, loss: 41.120031, acc: 0.673469\n",
      "epoch 0, iter 472, loss: 27.227206, acc: 0.673469\n",
      "epoch 0, iter 473, loss: 35.891174, acc: 0.530612\n",
      "epoch 0, iter 474, loss: 38.168267, acc: 0.612245\n",
      "epoch 0, iter 475, loss: 37.519904, acc: 0.428571\n",
      "epoch 0, iter 476, loss: 30.349141, acc: 0.571429\n",
      "epoch 0, iter 477, loss: 38.107701, acc: 0.530612\n",
      "epoch 0, iter 478, loss: 32.188340, acc: 0.755102\n",
      "epoch 0, iter 479, loss: 35.075330, acc: 0.673469\n",
      "epoch 0, iter 480, loss: 28.642282, acc: 0.632653\n",
      "epoch 0, iter 481, loss: 26.977087, acc: 0.653061\n",
      "epoch 0, iter 482, loss: 32.858981, acc: 0.795918\n",
      "epoch 0, iter 483, loss: 31.005771, acc: 0.591837\n",
      "epoch 0, iter 484, loss: 33.960586, acc: 0.653061\n",
      "epoch 0, iter 485, loss: 28.593193, acc: 0.693878\n",
      "epoch 0, iter 486, loss: 34.287628, acc: 0.530612\n",
      "epoch 0, iter 487, loss: 28.091873, acc: 0.653061\n",
      "epoch 0, iter 488, loss: 31.463384, acc: 0.653061\n",
      "epoch 0, iter 489, loss: 35.970646, acc: 0.734694\n",
      "epoch 0, iter 490, loss: 34.987361, acc: 0.591837\n",
      "epoch 0, iter 491, loss: 35.898118, acc: 0.632653\n",
      "epoch 0, iter 492, loss: 34.022107, acc: 0.571429\n",
      "epoch 0, iter 493, loss: 24.809244, acc: 0.530612\n",
      "epoch 0, iter 494, loss: 38.498029, acc: 0.510204\n",
      "epoch 0, iter 495, loss: 37.896131, acc: 0.489796\n",
      "epoch 0, iter 496, loss: 27.381104, acc: 0.693878\n",
      "epoch 0, iter 497, loss: 38.876009, acc: 0.428571\n",
      "epoch 0, iter 498, loss: 35.493672, acc: 0.469388\n",
      "epoch 0, iter 499, loss: 40.904461, acc: 0.591837\n",
      "epoch 0, acc: 0.447020\n",
      "epoch 1, iter 0, loss: 35.544799, acc: 0.448980\n",
      "epoch 1, iter 1, loss: 28.549893, acc: 0.469388\n",
      "epoch 1, iter 2, loss: 40.573144, acc: 0.551020\n",
      "epoch 1, iter 3, loss: 39.268192, acc: 0.653061\n",
      "epoch 1, iter 4, loss: 39.138818, acc: 0.489796\n",
      "epoch 1, iter 5, loss: 38.044482, acc: 0.673469\n",
      "epoch 1, iter 6, loss: 30.710835, acc: 0.673469\n",
      "epoch 1, iter 7, loss: 34.721674, acc: 0.632653\n",
      "epoch 1, iter 8, loss: 34.541862, acc: 0.632653\n",
      "epoch 1, iter 9, loss: 37.907877, acc: 0.653061\n",
      "epoch 1, iter 10, loss: 36.734766, acc: 0.612245\n",
      "epoch 1, iter 11, loss: 32.739028, acc: 0.551020\n",
      "epoch 1, iter 12, loss: 31.679977, acc: 0.734694\n",
      "epoch 1, iter 13, loss: 33.125472, acc: 0.653061\n",
      "epoch 1, iter 14, loss: 29.381050, acc: 0.551020\n",
      "epoch 1, iter 15, loss: 33.613703, acc: 0.755102\n",
      "epoch 1, iter 16, loss: 35.328717, acc: 0.571429\n",
      "epoch 1, iter 17, loss: 36.438170, acc: 0.795918\n",
      "epoch 1, iter 18, loss: 43.584052, acc: 0.612245\n",
      "epoch 1, iter 19, loss: 31.733024, acc: 0.714286\n",
      "epoch 1, iter 20, loss: 28.746271, acc: 0.612245\n",
      "epoch 1, iter 21, loss: 32.064781, acc: 0.734694\n",
      "epoch 1, iter 22, loss: 24.585690, acc: 0.714286\n",
      "epoch 1, iter 23, loss: 34.838234, acc: 0.591837\n",
      "epoch 1, iter 24, loss: 32.325037, acc: 0.612245\n",
      "epoch 1, iter 25, loss: 33.100353, acc: 0.510204\n",
      "epoch 1, iter 26, loss: 36.281296, acc: 0.489796\n",
      "epoch 1, iter 27, loss: 34.016078, acc: 0.530612\n",
      "epoch 1, iter 28, loss: 32.347466, acc: 0.510204\n",
      "epoch 1, iter 29, loss: 28.154603, acc: 0.775510\n",
      "epoch 1, iter 30, loss: 34.292229, acc: 0.571429\n",
      "epoch 1, iter 31, loss: 35.375493, acc: 0.346939\n",
      "epoch 1, iter 32, loss: 31.795905, acc: 0.612245\n",
      "epoch 1, iter 33, loss: 26.752745, acc: 0.612245\n",
      "epoch 1, iter 34, loss: 31.130260, acc: 0.551020\n",
      "epoch 1, iter 35, loss: 40.393930, acc: 0.530612\n",
      "epoch 1, iter 36, loss: 32.236092, acc: 0.653061\n",
      "epoch 1, iter 37, loss: 31.390871, acc: 0.734694\n",
      "epoch 1, iter 38, loss: 43.485284, acc: 0.408163\n",
      "epoch 1, iter 39, loss: 31.315043, acc: 0.571429\n",
      "epoch 1, iter 40, loss: 37.396498, acc: 0.612245\n",
      "epoch 1, iter 41, loss: 27.487068, acc: 0.632653\n",
      "epoch 1, iter 42, loss: 35.818440, acc: 0.673469\n",
      "epoch 1, iter 43, loss: 40.324445, acc: 0.755102\n",
      "epoch 1, iter 44, loss: 31.244496, acc: 0.816327\n",
      "epoch 1, iter 45, loss: 38.043294, acc: 0.693878\n",
      "epoch 1, iter 46, loss: 34.389915, acc: 0.469388\n",
      "epoch 1, iter 47, loss: 32.524897, acc: 0.571429\n",
      "epoch 1, iter 48, loss: 31.350723, acc: 0.591837\n",
      "epoch 1, iter 49, loss: 29.455889, acc: 0.571429\n",
      "epoch 1, iter 50, loss: 34.092520, acc: 0.632653\n",
      "epoch 1, iter 51, loss: 33.719156, acc: 0.653061\n",
      "epoch 1, iter 52, loss: 36.427581, acc: 0.591837\n",
      "epoch 1, iter 53, loss: 37.932189, acc: 0.653061\n",
      "epoch 1, iter 54, loss: 35.036427, acc: 0.632653\n",
      "epoch 1, iter 55, loss: 32.353770, acc: 0.714286\n",
      "epoch 1, iter 56, loss: 26.197420, acc: 0.734694\n",
      "epoch 1, iter 57, loss: 32.699666, acc: 0.653061\n",
      "epoch 1, iter 58, loss: 32.599663, acc: 0.612245\n",
      "epoch 1, iter 59, loss: 36.849196, acc: 0.673469\n",
      "epoch 1, iter 60, loss: 30.124130, acc: 0.734694\n",
      "epoch 1, iter 61, loss: 27.653370, acc: 0.653061\n",
      "epoch 1, iter 62, loss: 33.164826, acc: 0.530612\n",
      "epoch 1, iter 63, loss: 28.730046, acc: 0.755102\n",
      "epoch 1, iter 64, loss: 35.660523, acc: 0.551020\n",
      "epoch 1, iter 65, loss: 34.931681, acc: 0.612245\n",
      "epoch 1, iter 66, loss: 34.237065, acc: 0.877551\n",
      "epoch 1, iter 67, loss: 35.400459, acc: 0.489796\n",
      "epoch 1, iter 68, loss: 34.262212, acc: 0.734694\n",
      "epoch 1, iter 69, loss: 24.101375, acc: 0.714286\n",
      "epoch 1, iter 70, loss: 28.699816, acc: 0.714286\n",
      "epoch 1, iter 71, loss: 33.355423, acc: 0.673469\n",
      "epoch 1, iter 72, loss: 24.082997, acc: 0.673469\n",
      "epoch 1, iter 73, loss: 28.271452, acc: 0.653061\n",
      "epoch 1, iter 74, loss: 31.783506, acc: 0.551020\n",
      "epoch 1, iter 75, loss: 33.381179, acc: 0.816327\n",
      "epoch 1, iter 76, loss: 30.183081, acc: 0.693878\n",
      "epoch 1, iter 77, loss: 34.317583, acc: 0.448980\n",
      "epoch 1, iter 78, loss: 35.012485, acc: 0.714286\n",
      "epoch 1, iter 79, loss: 31.405879, acc: 0.693878\n",
      "epoch 1, iter 80, loss: 24.586441, acc: 0.897959\n",
      "epoch 1, iter 81, loss: 28.698617, acc: 0.612245\n",
      "epoch 1, iter 82, loss: 35.115942, acc: 0.571429\n",
      "epoch 1, iter 83, loss: 35.046312, acc: 0.591837\n",
      "epoch 1, iter 84, loss: 22.392336, acc: 0.734694\n",
      "epoch 1, iter 85, loss: 24.643820, acc: 0.795918\n",
      "epoch 1, iter 86, loss: 32.284787, acc: 0.489796\n",
      "epoch 1, iter 87, loss: 41.324072, acc: 0.387755\n",
      "epoch 1, iter 88, loss: 26.174288, acc: 0.836735\n",
      "epoch 1, iter 89, loss: 30.971577, acc: 0.632653\n",
      "epoch 1, iter 90, loss: 32.276009, acc: 0.387755\n",
      "epoch 1, iter 91, loss: 35.337875, acc: 0.714286\n",
      "epoch 1, iter 92, loss: 42.091976, acc: 0.551020\n",
      "epoch 1, iter 93, loss: 42.401193, acc: 0.489796\n",
      "epoch 1, iter 94, loss: 39.788284, acc: 0.653061\n",
      "epoch 1, iter 95, loss: 26.270489, acc: 0.816327\n",
      "epoch 1, iter 96, loss: 29.305851, acc: 0.612245\n",
      "epoch 1, iter 97, loss: 37.780139, acc: 0.551020\n",
      "epoch 1, iter 98, loss: 37.023562, acc: 0.632653\n",
      "epoch 1, iter 99, loss: 29.363041, acc: 0.775510\n",
      "epoch 1, iter 100, loss: 44.109645, acc: 0.612245\n",
      "epoch 1, iter 101, loss: 30.732052, acc: 0.673469\n",
      "epoch 1, iter 102, loss: 28.769144, acc: 0.734694\n",
      "epoch 1, iter 103, loss: 25.634661, acc: 0.734694\n",
      "epoch 1, iter 104, loss: 36.170806, acc: 0.591837\n",
      "epoch 1, iter 105, loss: 29.289735, acc: 0.612245\n",
      "epoch 1, iter 106, loss: 24.230522, acc: 0.755102\n",
      "epoch 1, iter 107, loss: 24.439406, acc: 0.755102\n",
      "epoch 1, iter 108, loss: 34.165259, acc: 0.448980\n",
      "epoch 1, iter 109, loss: 31.765325, acc: 0.612245\n",
      "epoch 1, iter 110, loss: 30.197068, acc: 0.673469\n",
      "epoch 1, iter 111, loss: 42.829972, acc: 0.551020\n",
      "epoch 1, iter 112, loss: 48.887009, acc: 0.591837\n",
      "epoch 1, iter 113, loss: 43.445031, acc: 0.448980\n",
      "epoch 1, iter 114, loss: 28.360498, acc: 0.551020\n",
      "epoch 1, iter 115, loss: 33.443970, acc: 0.530612\n",
      "epoch 1, iter 116, loss: 41.067100, acc: 0.469388\n",
      "epoch 1, iter 117, loss: 33.101565, acc: 0.755102\n",
      "epoch 1, iter 118, loss: 36.668107, acc: 0.693878\n",
      "epoch 1, iter 119, loss: 34.042675, acc: 0.693878\n",
      "epoch 1, iter 120, loss: 31.384294, acc: 0.530612\n",
      "epoch 1, iter 121, loss: 36.021808, acc: 0.653061\n",
      "epoch 1, iter 122, loss: 30.762268, acc: 0.510204\n",
      "epoch 1, iter 123, loss: 34.017186, acc: 0.632653\n",
      "epoch 1, iter 124, loss: 36.573962, acc: 0.632653\n",
      "epoch 1, iter 125, loss: 35.235580, acc: 0.510204\n",
      "epoch 1, iter 126, loss: 28.764215, acc: 0.795918\n",
      "epoch 1, iter 127, loss: 44.563804, acc: 0.510204\n",
      "epoch 1, iter 128, loss: 32.411939, acc: 0.693878\n",
      "epoch 1, iter 129, loss: 26.211593, acc: 0.653061\n",
      "epoch 1, iter 130, loss: 29.131333, acc: 0.816327\n",
      "epoch 1, iter 131, loss: 28.831585, acc: 0.775510\n",
      "epoch 1, iter 132, loss: 36.573625, acc: 0.693878\n",
      "epoch 1, iter 133, loss: 25.411935, acc: 0.755102\n",
      "epoch 1, iter 134, loss: 40.312230, acc: 0.510204\n",
      "epoch 1, iter 135, loss: 36.123050, acc: 0.571429\n",
      "epoch 1, iter 136, loss: 39.621511, acc: 0.591837\n",
      "epoch 1, iter 137, loss: 34.948212, acc: 0.591837\n",
      "epoch 1, iter 138, loss: 30.970558, acc: 0.714286\n",
      "epoch 1, iter 139, loss: 29.642309, acc: 0.551020\n",
      "epoch 1, iter 140, loss: 29.405907, acc: 0.673469\n",
      "epoch 1, iter 141, loss: 23.606104, acc: 0.816327\n",
      "epoch 1, iter 142, loss: 35.470702, acc: 0.530612\n",
      "epoch 1, iter 143, loss: 31.118761, acc: 0.632653\n",
      "epoch 1, iter 144, loss: 32.262938, acc: 0.591837\n",
      "epoch 1, iter 145, loss: 20.043608, acc: 0.755102\n",
      "epoch 1, iter 146, loss: 29.357786, acc: 0.612245\n",
      "epoch 1, iter 147, loss: 31.896670, acc: 0.551020\n",
      "epoch 1, iter 148, loss: 30.249313, acc: 0.632653\n",
      "epoch 1, iter 149, loss: 23.668380, acc: 0.795918\n",
      "epoch 1, iter 150, loss: 29.108912, acc: 0.673469\n",
      "epoch 1, iter 151, loss: 31.952284, acc: 0.795918\n",
      "epoch 1, iter 152, loss: 32.465462, acc: 0.693878\n",
      "epoch 1, iter 153, loss: 39.866507, acc: 0.571429\n",
      "epoch 1, iter 154, loss: 36.456446, acc: 0.551020\n",
      "epoch 1, iter 155, loss: 31.892091, acc: 0.591837\n",
      "epoch 1, iter 156, loss: 31.594102, acc: 0.408163\n",
      "epoch 1, iter 157, loss: 30.844351, acc: 0.632653\n",
      "epoch 1, iter 158, loss: 25.244279, acc: 0.693878\n",
      "epoch 1, iter 159, loss: 39.853740, acc: 0.469388\n",
      "epoch 1, iter 160, loss: 28.864447, acc: 0.448980\n",
      "epoch 1, iter 161, loss: 30.830964, acc: 0.734694\n",
      "epoch 1, iter 162, loss: 30.845064, acc: 0.693878\n",
      "epoch 1, iter 163, loss: 39.137183, acc: 0.551020\n",
      "epoch 1, iter 164, loss: 33.675433, acc: 0.612245\n",
      "epoch 1, iter 165, loss: 27.214305, acc: 0.755102\n",
      "epoch 1, iter 166, loss: 26.788216, acc: 0.571429\n",
      "epoch 1, iter 167, loss: 32.010492, acc: 0.551020\n",
      "epoch 1, iter 168, loss: 31.692004, acc: 0.714286\n",
      "epoch 1, iter 169, loss: 38.506721, acc: 0.571429\n",
      "epoch 1, iter 170, loss: 38.186285, acc: 0.693878\n",
      "epoch 1, iter 171, loss: 31.428518, acc: 0.469388\n",
      "epoch 1, iter 172, loss: 35.009494, acc: 0.612245\n",
      "epoch 1, iter 173, loss: 33.796549, acc: 0.632653\n",
      "epoch 1, iter 174, loss: 31.565473, acc: 0.551020\n",
      "epoch 1, iter 175, loss: 22.762731, acc: 0.551020\n",
      "epoch 1, iter 176, loss: 29.514606, acc: 0.755102\n",
      "epoch 1, iter 177, loss: 31.454548, acc: 0.591837\n",
      "epoch 1, iter 178, loss: 43.447771, acc: 0.530612\n",
      "epoch 1, iter 179, loss: 26.008743, acc: 0.653061\n",
      "epoch 1, iter 180, loss: 26.699062, acc: 0.795918\n",
      "epoch 1, iter 181, loss: 35.237064, acc: 0.673469\n",
      "epoch 1, iter 182, loss: 32.528898, acc: 0.653061\n",
      "epoch 1, iter 183, loss: 40.135918, acc: 0.591837\n",
      "epoch 1, iter 184, loss: 37.790848, acc: 0.653061\n",
      "epoch 1, iter 185, loss: 39.478566, acc: 0.612245\n",
      "epoch 1, iter 186, loss: 27.259122, acc: 0.836735\n",
      "epoch 1, iter 187, loss: 34.578688, acc: 0.612245\n",
      "epoch 1, iter 188, loss: 46.876122, acc: 0.510204\n",
      "epoch 1, iter 189, loss: 40.906876, acc: 0.551020\n",
      "epoch 1, iter 190, loss: 34.567645, acc: 0.551020\n",
      "epoch 1, iter 191, loss: 39.515952, acc: 0.755102\n",
      "epoch 1, iter 192, loss: 33.024768, acc: 0.612245\n",
      "epoch 1, iter 193, loss: 35.533934, acc: 0.632653\n",
      "epoch 1, iter 194, loss: 29.062677, acc: 0.693878\n",
      "epoch 1, iter 195, loss: 40.076497, acc: 0.591837\n",
      "epoch 1, iter 196, loss: 31.354175, acc: 0.734694\n",
      "epoch 1, iter 197, loss: 35.376154, acc: 0.571429\n",
      "epoch 1, iter 198, loss: 31.387058, acc: 0.714286\n",
      "epoch 1, iter 199, loss: 41.214064, acc: 0.653061\n",
      "epoch 1, iter 200, loss: 34.349125, acc: 0.571429\n",
      "epoch 1, iter 201, loss: 31.252106, acc: 0.836735\n",
      "epoch 1, iter 202, loss: 30.864074, acc: 0.591837\n",
      "epoch 1, iter 203, loss: 35.478849, acc: 0.530612\n",
      "epoch 1, iter 204, loss: 34.838109, acc: 0.469388\n",
      "epoch 1, iter 205, loss: 39.400273, acc: 0.346939\n",
      "epoch 1, iter 206, loss: 34.203943, acc: 0.530612\n",
      "epoch 1, iter 207, loss: 37.392189, acc: 0.591837\n",
      "epoch 1, iter 208, loss: 34.396281, acc: 0.714286\n",
      "epoch 1, iter 209, loss: 30.340131, acc: 0.673469\n",
      "epoch 1, iter 210, loss: 34.323079, acc: 0.632653\n",
      "epoch 1, iter 211, loss: 29.316032, acc: 0.775510\n",
      "epoch 1, iter 212, loss: 31.974899, acc: 0.530612\n",
      "epoch 1, iter 213, loss: 23.038925, acc: 0.816327\n",
      "epoch 1, iter 214, loss: 24.855876, acc: 0.673469\n",
      "epoch 1, iter 215, loss: 37.552592, acc: 0.612245\n",
      "epoch 1, iter 216, loss: 31.457854, acc: 0.693878\n",
      "epoch 1, iter 217, loss: 40.989377, acc: 0.551020\n",
      "epoch 1, iter 218, loss: 31.228531, acc: 0.612245\n",
      "epoch 1, iter 219, loss: 26.190087, acc: 0.755102\n",
      "epoch 1, iter 220, loss: 35.951988, acc: 0.530612\n",
      "epoch 1, iter 221, loss: 27.179364, acc: 0.795918\n",
      "epoch 1, iter 222, loss: 37.045944, acc: 0.612245\n",
      "epoch 1, iter 223, loss: 25.355498, acc: 0.734694\n",
      "epoch 1, iter 224, loss: 25.127601, acc: 0.571429\n",
      "epoch 1, iter 225, loss: 29.338702, acc: 0.755102\n",
      "epoch 1, iter 226, loss: 30.174087, acc: 0.612245\n",
      "epoch 1, iter 227, loss: 28.535417, acc: 0.653061\n",
      "epoch 1, iter 228, loss: 28.618226, acc: 0.591837\n",
      "epoch 1, iter 229, loss: 20.215133, acc: 0.897959\n",
      "epoch 1, iter 230, loss: 33.223747, acc: 0.714286\n",
      "epoch 1, iter 231, loss: 24.397015, acc: 0.755102\n",
      "epoch 1, iter 232, loss: 32.393961, acc: 0.510204\n",
      "epoch 1, iter 233, loss: 34.707657, acc: 0.591837\n",
      "epoch 1, iter 234, loss: 23.806528, acc: 0.816327\n",
      "epoch 1, iter 235, loss: 32.099351, acc: 0.653061\n",
      "epoch 1, iter 236, loss: 25.266798, acc: 0.734694\n",
      "epoch 1, iter 237, loss: 35.656243, acc: 0.612245\n",
      "epoch 1, iter 238, loss: 39.238887, acc: 0.591837\n",
      "epoch 1, iter 239, loss: 36.392820, acc: 0.448980\n",
      "epoch 1, iter 240, loss: 34.773606, acc: 0.714286\n",
      "epoch 1, iter 241, loss: 27.743504, acc: 0.653061\n",
      "epoch 1, iter 242, loss: 38.563821, acc: 0.551020\n",
      "epoch 1, iter 243, loss: 28.697007, acc: 0.551020\n",
      "epoch 1, iter 244, loss: 39.617465, acc: 0.632653\n",
      "epoch 1, iter 245, loss: 33.196795, acc: 0.612245\n",
      "epoch 1, iter 246, loss: 38.863745, acc: 0.591837\n",
      "epoch 1, iter 247, loss: 31.212799, acc: 0.551020\n",
      "epoch 1, iter 248, loss: 38.015139, acc: 0.632653\n",
      "epoch 1, iter 249, loss: 43.973985, acc: 0.653061\n",
      "epoch 1, iter 250, loss: 35.182039, acc: 0.755102\n",
      "epoch 1, iter 251, loss: 36.291301, acc: 0.693878\n",
      "epoch 1, iter 252, loss: 37.974563, acc: 0.591837\n",
      "epoch 1, iter 253, loss: 35.532822, acc: 0.673469\n",
      "epoch 1, iter 254, loss: 22.674335, acc: 0.734694\n",
      "epoch 1, iter 255, loss: 29.958243, acc: 0.571429\n",
      "epoch 1, iter 256, loss: 32.319627, acc: 0.653061\n",
      "epoch 1, iter 257, loss: 40.604198, acc: 0.551020\n",
      "epoch 1, iter 258, loss: 39.257351, acc: 0.551020\n",
      "epoch 1, iter 259, loss: 28.351021, acc: 0.714286\n",
      "epoch 1, iter 260, loss: 42.758339, acc: 0.367347\n",
      "epoch 1, iter 261, loss: 35.215163, acc: 0.755102\n",
      "epoch 1, iter 262, loss: 31.140285, acc: 0.693878\n",
      "epoch 1, iter 263, loss: 33.184677, acc: 0.612245\n",
      "epoch 1, iter 264, loss: 28.209664, acc: 0.775510\n",
      "epoch 1, iter 265, loss: 24.918928, acc: 0.857143\n",
      "epoch 1, iter 266, loss: 37.089799, acc: 0.489796\n",
      "epoch 1, iter 267, loss: 39.167110, acc: 0.530612\n",
      "epoch 1, iter 268, loss: 29.224142, acc: 0.612245\n",
      "epoch 1, iter 269, loss: 26.222844, acc: 0.653061\n",
      "epoch 1, iter 270, loss: 30.115956, acc: 0.734694\n",
      "epoch 1, iter 271, loss: 26.651980, acc: 0.734694\n",
      "epoch 1, iter 272, loss: 22.197855, acc: 0.877551\n",
      "epoch 1, iter 273, loss: 36.546852, acc: 0.489796\n",
      "epoch 1, iter 274, loss: 30.832989, acc: 0.571429\n",
      "epoch 1, iter 275, loss: 36.866124, acc: 0.510204\n",
      "epoch 1, iter 276, loss: 22.028367, acc: 0.795918\n",
      "epoch 1, iter 277, loss: 31.359143, acc: 0.714286\n",
      "epoch 1, iter 278, loss: 33.272469, acc: 0.693878\n",
      "epoch 1, iter 279, loss: 30.807785, acc: 0.510204\n",
      "epoch 1, iter 280, loss: 38.634128, acc: 0.653061\n",
      "epoch 1, iter 281, loss: 38.484118, acc: 0.387755\n",
      "epoch 1, iter 282, loss: 38.593773, acc: 0.714286\n",
      "epoch 1, iter 283, loss: 37.343430, acc: 0.551020\n",
      "epoch 1, iter 284, loss: 25.310525, acc: 0.632653\n",
      "epoch 1, iter 285, loss: 44.651671, acc: 0.775510\n",
      "epoch 1, iter 286, loss: 27.979115, acc: 0.653061\n",
      "epoch 1, iter 287, loss: 31.290199, acc: 0.591837\n",
      "epoch 1, iter 288, loss: 24.643658, acc: 0.693878\n",
      "epoch 1, iter 289, loss: 30.961441, acc: 0.632653\n",
      "epoch 1, iter 290, loss: 31.973220, acc: 0.693878\n",
      "epoch 1, iter 291, loss: 33.853076, acc: 0.612245\n",
      "epoch 1, iter 292, loss: 29.929096, acc: 0.673469\n",
      "epoch 1, iter 293, loss: 30.386313, acc: 0.653061\n",
      "epoch 1, iter 294, loss: 25.643817, acc: 0.775510\n",
      "epoch 1, iter 295, loss: 34.299249, acc: 0.612245\n",
      "epoch 1, iter 296, loss: 38.392856, acc: 0.714286\n",
      "epoch 1, iter 297, loss: 30.806696, acc: 0.795918\n",
      "epoch 1, iter 298, loss: 30.754165, acc: 0.571429\n",
      "epoch 1, iter 299, loss: 29.935614, acc: 0.632653\n",
      "epoch 1, iter 300, loss: 22.220834, acc: 0.836735\n",
      "epoch 1, iter 301, loss: 27.147669, acc: 0.734694\n",
      "epoch 1, iter 302, loss: 31.957713, acc: 0.591837\n",
      "epoch 1, iter 303, loss: 33.332699, acc: 0.591837\n",
      "epoch 1, iter 304, loss: 31.949258, acc: 0.591837\n",
      "epoch 1, iter 305, loss: 38.858882, acc: 0.551020\n",
      "epoch 1, iter 306, loss: 37.680481, acc: 0.612245\n",
      "epoch 1, iter 307, loss: 36.675813, acc: 0.632653\n",
      "epoch 1, iter 308, loss: 39.374538, acc: 0.469388\n",
      "epoch 1, iter 309, loss: 30.784505, acc: 0.612245\n",
      "epoch 1, iter 310, loss: 27.520254, acc: 0.653061\n",
      "epoch 1, iter 311, loss: 26.728993, acc: 0.795918\n",
      "epoch 1, iter 312, loss: 23.207856, acc: 0.734694\n",
      "epoch 1, iter 313, loss: 26.215259, acc: 0.816327\n",
      "epoch 1, iter 314, loss: 27.619889, acc: 0.612245\n",
      "epoch 1, iter 315, loss: 28.725337, acc: 0.632653\n",
      "epoch 1, iter 316, loss: 24.951076, acc: 0.714286\n",
      "epoch 1, iter 317, loss: 23.540326, acc: 0.693878\n",
      "epoch 1, iter 318, loss: 40.253663, acc: 0.510204\n",
      "epoch 1, iter 319, loss: 37.640526, acc: 0.530612\n",
      "epoch 1, iter 320, loss: 31.835167, acc: 0.530612\n",
      "epoch 1, iter 321, loss: 29.033921, acc: 0.693878\n",
      "epoch 1, iter 322, loss: 39.393857, acc: 0.551020\n",
      "epoch 1, iter 323, loss: 29.514560, acc: 0.591837\n",
      "epoch 1, iter 324, loss: 27.120334, acc: 0.612245\n",
      "epoch 1, iter 325, loss: 25.395769, acc: 0.734694\n",
      "epoch 1, iter 326, loss: 41.738829, acc: 0.551020\n",
      "epoch 1, iter 327, loss: 27.717616, acc: 0.775510\n",
      "epoch 1, iter 328, loss: 27.367957, acc: 0.714286\n",
      "epoch 1, iter 329, loss: 35.517339, acc: 0.591837\n",
      "epoch 1, iter 330, loss: 32.884370, acc: 0.632653\n",
      "epoch 1, iter 331, loss: 37.877693, acc: 0.469388\n",
      "epoch 1, iter 332, loss: 37.719125, acc: 0.530612\n",
      "epoch 1, iter 333, loss: 39.031127, acc: 0.510204\n",
      "epoch 1, iter 334, loss: 30.808062, acc: 0.632653\n",
      "epoch 1, iter 335, loss: 28.657328, acc: 0.836735\n",
      "epoch 1, iter 336, loss: 26.590592, acc: 0.755102\n",
      "epoch 1, iter 337, loss: 30.850671, acc: 0.591837\n",
      "epoch 1, iter 338, loss: 27.268270, acc: 0.775510\n",
      "epoch 1, iter 339, loss: 26.361152, acc: 0.755102\n",
      "epoch 1, iter 340, loss: 40.888767, acc: 0.612245\n",
      "epoch 1, iter 341, loss: 29.396993, acc: 0.836735\n",
      "epoch 1, iter 342, loss: 47.721714, acc: 0.448980\n",
      "epoch 1, iter 343, loss: 35.014205, acc: 0.591837\n",
      "epoch 1, iter 344, loss: 42.252719, acc: 0.530612\n",
      "epoch 1, iter 345, loss: 29.828086, acc: 0.591837\n",
      "epoch 1, iter 346, loss: 29.307000, acc: 0.734694\n",
      "epoch 1, iter 347, loss: 27.158463, acc: 0.489796\n",
      "epoch 1, iter 348, loss: 34.342800, acc: 0.571429\n",
      "epoch 1, iter 349, loss: 38.008726, acc: 0.591837\n",
      "epoch 1, iter 350, loss: 30.608314, acc: 0.551020\n",
      "epoch 1, iter 351, loss: 35.385244, acc: 0.632653\n",
      "epoch 1, iter 352, loss: 38.924594, acc: 0.551020\n",
      "epoch 1, iter 353, loss: 41.050745, acc: 0.571429\n",
      "epoch 1, iter 354, loss: 31.865229, acc: 0.612245\n",
      "epoch 1, iter 355, loss: 29.619319, acc: 0.551020\n",
      "epoch 1, iter 356, loss: 32.342828, acc: 0.755102\n",
      "epoch 1, iter 357, loss: 36.350417, acc: 0.530612\n",
      "epoch 1, iter 358, loss: 34.671258, acc: 0.612245\n",
      "epoch 1, iter 359, loss: 29.002848, acc: 0.673469\n",
      "epoch 1, iter 360, loss: 28.503326, acc: 0.653061\n",
      "epoch 1, iter 361, loss: 36.094797, acc: 0.591837\n",
      "epoch 1, iter 362, loss: 39.513563, acc: 0.530612\n",
      "epoch 1, iter 363, loss: 30.812171, acc: 0.571429\n",
      "epoch 1, iter 364, loss: 42.392623, acc: 0.551020\n",
      "epoch 1, iter 365, loss: 30.378486, acc: 0.673469\n",
      "epoch 1, iter 366, loss: 44.700595, acc: 0.469388\n",
      "epoch 1, iter 367, loss: 39.494710, acc: 0.469388\n",
      "epoch 1, iter 368, loss: 34.400705, acc: 0.571429\n",
      "epoch 1, iter 369, loss: 32.215229, acc: 0.571429\n",
      "epoch 1, iter 370, loss: 35.838608, acc: 0.469388\n",
      "epoch 1, iter 371, loss: 31.439624, acc: 0.653061\n",
      "epoch 1, iter 372, loss: 42.137351, acc: 0.591837\n",
      "epoch 1, iter 373, loss: 33.529037, acc: 0.591837\n",
      "epoch 1, iter 374, loss: 33.160568, acc: 0.346939\n",
      "epoch 1, iter 375, loss: 36.810334, acc: 0.714286\n",
      "epoch 1, iter 376, loss: 31.457178, acc: 0.591837\n",
      "epoch 1, iter 377, loss: 25.423281, acc: 0.693878\n",
      "epoch 1, iter 378, loss: 32.812984, acc: 0.693878\n",
      "epoch 1, iter 379, loss: 40.694075, acc: 0.530612\n",
      "epoch 1, iter 380, loss: 37.660326, acc: 0.653061\n",
      "epoch 1, iter 381, loss: 42.476667, acc: 0.591837\n",
      "epoch 1, iter 382, loss: 28.220188, acc: 0.795918\n",
      "epoch 1, iter 383, loss: 25.310150, acc: 0.734694\n",
      "epoch 1, iter 384, loss: 34.223137, acc: 0.673469\n",
      "epoch 1, iter 385, loss: 22.730435, acc: 0.877551\n",
      "epoch 1, iter 386, loss: 39.488191, acc: 0.551020\n",
      "epoch 1, iter 387, loss: 33.522145, acc: 0.530612\n",
      "epoch 1, iter 388, loss: 33.605052, acc: 0.673469\n",
      "epoch 1, iter 389, loss: 34.722578, acc: 0.612245\n",
      "epoch 1, iter 390, loss: 31.479309, acc: 0.551020\n",
      "epoch 1, iter 391, loss: 31.021648, acc: 0.775510\n",
      "epoch 1, iter 392, loss: 25.715623, acc: 0.897959\n",
      "epoch 1, iter 393, loss: 32.370492, acc: 0.551020\n",
      "epoch 1, iter 394, loss: 26.636672, acc: 0.653061\n",
      "epoch 1, iter 395, loss: 32.950873, acc: 0.469388\n",
      "epoch 1, iter 396, loss: 32.193496, acc: 0.612245\n",
      "epoch 1, iter 397, loss: 22.229499, acc: 0.775510\n",
      "epoch 1, iter 398, loss: 38.280908, acc: 0.571429\n",
      "epoch 1, iter 399, loss: 29.254989, acc: 0.775510\n",
      "epoch 1, iter 400, loss: 38.629869, acc: 0.530612\n",
      "epoch 1, iter 401, loss: 32.680388, acc: 0.653061\n",
      "epoch 1, iter 402, loss: 33.736421, acc: 0.693878\n",
      "epoch 1, iter 403, loss: 36.990708, acc: 0.612245\n",
      "epoch 1, iter 404, loss: 36.230780, acc: 0.551020\n",
      "epoch 1, iter 405, loss: 34.302337, acc: 0.693878\n",
      "epoch 1, iter 406, loss: 26.733671, acc: 0.612245\n",
      "epoch 1, iter 407, loss: 36.969445, acc: 0.591837\n",
      "epoch 1, iter 408, loss: 34.526347, acc: 0.551020\n",
      "epoch 1, iter 409, loss: 22.652375, acc: 0.632653\n",
      "epoch 1, iter 410, loss: 40.002167, acc: 0.632653\n",
      "epoch 1, iter 411, loss: 31.040064, acc: 0.551020\n",
      "epoch 1, iter 412, loss: 33.267230, acc: 0.816327\n",
      "epoch 1, iter 413, loss: 27.908651, acc: 0.571429\n",
      "epoch 1, iter 414, loss: 35.470570, acc: 0.632653\n",
      "epoch 1, iter 415, loss: 38.464521, acc: 0.591837\n",
      "epoch 1, iter 416, loss: 30.842984, acc: 0.755102\n",
      "epoch 1, iter 417, loss: 38.948089, acc: 0.632653\n",
      "epoch 1, iter 418, loss: 34.732643, acc: 0.653061\n",
      "epoch 1, iter 419, loss: 29.436569, acc: 0.734694\n",
      "epoch 1, iter 420, loss: 35.086332, acc: 0.530612\n",
      "epoch 1, iter 421, loss: 35.085465, acc: 0.612245\n",
      "epoch 1, iter 422, loss: 29.308153, acc: 0.693878\n",
      "epoch 1, iter 423, loss: 36.242374, acc: 0.510204\n",
      "epoch 1, iter 424, loss: 26.663585, acc: 0.734694\n",
      "epoch 1, iter 425, loss: 28.982978, acc: 0.693878\n",
      "epoch 1, iter 426, loss: 31.496997, acc: 0.571429\n",
      "epoch 1, iter 427, loss: 36.738702, acc: 0.510204\n",
      "epoch 1, iter 428, loss: 29.337635, acc: 0.734694\n",
      "epoch 1, iter 429, loss: 30.884429, acc: 0.448980\n",
      "epoch 1, iter 430, loss: 31.902387, acc: 0.673469\n",
      "epoch 1, iter 431, loss: 38.700685, acc: 0.673469\n",
      "epoch 1, iter 432, loss: 25.888435, acc: 0.755102\n",
      "epoch 1, iter 433, loss: 27.830806, acc: 0.530612\n",
      "epoch 1, iter 434, loss: 27.702484, acc: 0.653061\n",
      "epoch 1, iter 435, loss: 28.450335, acc: 0.734694\n",
      "epoch 1, iter 436, loss: 28.631212, acc: 0.673469\n",
      "epoch 1, iter 437, loss: 43.347694, acc: 0.551020\n",
      "epoch 1, iter 438, loss: 37.298472, acc: 0.612245\n",
      "epoch 1, iter 439, loss: 32.313791, acc: 0.571429\n",
      "epoch 1, iter 440, loss: 33.445397, acc: 0.612245\n",
      "epoch 1, iter 441, loss: 26.995509, acc: 0.653061\n",
      "epoch 1, iter 442, loss: 33.163503, acc: 0.632653\n",
      "epoch 1, iter 443, loss: 27.278716, acc: 0.836735\n",
      "epoch 1, iter 444, loss: 30.052512, acc: 0.693878\n",
      "epoch 1, iter 445, loss: 46.109489, acc: 0.489796\n",
      "epoch 1, iter 446, loss: 33.166608, acc: 0.673469\n",
      "epoch 1, iter 447, loss: 34.912555, acc: 0.755102\n",
      "epoch 1, iter 448, loss: 32.684075, acc: 0.571429\n",
      "epoch 1, iter 449, loss: 23.674241, acc: 0.775510\n",
      "epoch 1, iter 450, loss: 33.892781, acc: 0.693878\n",
      "epoch 1, iter 451, loss: 28.982892, acc: 0.795918\n",
      "epoch 1, iter 452, loss: 27.962515, acc: 0.714286\n",
      "epoch 1, iter 453, loss: 34.618390, acc: 0.530612\n",
      "epoch 1, iter 454, loss: 28.820220, acc: 0.653061\n",
      "epoch 1, iter 455, loss: 30.938145, acc: 0.632653\n",
      "epoch 1, iter 456, loss: 32.264225, acc: 0.591837\n",
      "epoch 1, iter 457, loss: 34.291111, acc: 0.734694\n",
      "epoch 1, iter 458, loss: 23.352428, acc: 0.693878\n",
      "epoch 1, iter 459, loss: 33.467789, acc: 0.632653\n",
      "epoch 1, iter 460, loss: 35.705578, acc: 0.551020\n",
      "epoch 1, iter 461, loss: 30.728254, acc: 0.612245\n",
      "epoch 1, iter 462, loss: 33.436484, acc: 0.530612\n",
      "epoch 1, iter 463, loss: 34.267840, acc: 0.571429\n",
      "epoch 1, iter 464, loss: 33.486696, acc: 0.816327\n",
      "epoch 1, iter 465, loss: 31.141878, acc: 0.571429\n",
      "epoch 1, iter 466, loss: 35.708992, acc: 0.591837\n",
      "epoch 1, iter 467, loss: 38.654962, acc: 0.551020\n",
      "epoch 1, iter 468, loss: 29.883195, acc: 0.755102\n",
      "epoch 1, iter 469, loss: 31.847169, acc: 0.612245\n",
      "epoch 1, iter 470, loss: 42.706684, acc: 0.653061\n",
      "epoch 1, iter 471, loss: 41.864748, acc: 0.693878\n",
      "epoch 1, iter 472, loss: 28.108863, acc: 0.632653\n",
      "epoch 1, iter 473, loss: 30.208628, acc: 0.632653\n",
      "epoch 1, iter 474, loss: 37.534523, acc: 0.591837\n",
      "epoch 1, iter 475, loss: 35.809366, acc: 0.489796\n",
      "epoch 1, iter 476, loss: 24.822375, acc: 0.632653\n",
      "epoch 1, iter 477, loss: 35.565398, acc: 0.571429\n",
      "epoch 1, iter 478, loss: 34.272627, acc: 0.714286\n",
      "epoch 1, iter 479, loss: 33.199197, acc: 0.632653\n",
      "epoch 1, iter 480, loss: 29.358154, acc: 0.673469\n",
      "epoch 1, iter 481, loss: 28.934770, acc: 0.591837\n",
      "epoch 1, iter 482, loss: 31.177869, acc: 0.816327\n",
      "epoch 1, iter 483, loss: 28.536065, acc: 0.734694\n",
      "epoch 1, iter 484, loss: 30.132890, acc: 0.612245\n",
      "epoch 1, iter 485, loss: 26.427251, acc: 0.734694\n",
      "epoch 1, iter 486, loss: 32.675731, acc: 0.571429\n",
      "epoch 1, iter 487, loss: 28.020978, acc: 0.836735\n",
      "epoch 1, iter 488, loss: 26.349986, acc: 0.734694\n",
      "epoch 1, iter 489, loss: 31.067188, acc: 0.734694\n",
      "epoch 1, iter 490, loss: 33.344662, acc: 0.551020\n",
      "epoch 1, iter 491, loss: 32.797055, acc: 0.714286\n",
      "epoch 1, iter 492, loss: 33.269896, acc: 0.673469\n",
      "epoch 1, iter 493, loss: 23.912078, acc: 0.632653\n",
      "epoch 1, iter 494, loss: 35.377620, acc: 0.551020\n",
      "epoch 1, iter 495, loss: 38.136552, acc: 0.367347\n",
      "epoch 1, iter 496, loss: 24.101205, acc: 0.714286\n",
      "epoch 1, iter 497, loss: 36.070531, acc: 0.530612\n",
      "epoch 1, iter 498, loss: 35.904107, acc: 0.551020\n",
      "epoch 1, iter 499, loss: 37.113899, acc: 0.551020\n",
      "epoch 1, acc: 0.633918\n",
      "epoch 2, iter 0, loss: 40.313999, acc: 0.551020\n",
      "epoch 2, iter 1, loss: 43.869973, acc: 0.448980\n",
      "epoch 2, iter 2, loss: 35.544571, acc: 0.571429\n",
      "epoch 2, iter 3, loss: 36.787238, acc: 0.571429\n",
      "epoch 2, iter 4, loss: 32.560280, acc: 0.673469\n",
      "epoch 2, iter 5, loss: 30.965927, acc: 0.734694\n",
      "epoch 2, iter 6, loss: 30.083029, acc: 0.612245\n",
      "epoch 2, iter 7, loss: 37.315479, acc: 0.591837\n",
      "epoch 2, iter 8, loss: 37.133439, acc: 0.653061\n",
      "epoch 2, iter 9, loss: 29.953548, acc: 0.693878\n",
      "epoch 2, iter 10, loss: 38.965913, acc: 0.612245\n",
      "epoch 2, iter 11, loss: 37.836028, acc: 0.530612\n",
      "epoch 2, iter 12, loss: 29.627067, acc: 0.816327\n",
      "epoch 2, iter 13, loss: 32.930225, acc: 0.612245\n",
      "epoch 2, iter 14, loss: 30.223050, acc: 0.571429\n",
      "epoch 2, iter 15, loss: 26.773544, acc: 0.836735\n",
      "epoch 2, iter 16, loss: 36.235931, acc: 0.591837\n",
      "epoch 2, iter 17, loss: 28.023901, acc: 0.775510\n",
      "epoch 2, iter 18, loss: 44.871192, acc: 0.489796\n",
      "epoch 2, iter 19, loss: 24.409719, acc: 0.714286\n",
      "epoch 2, iter 20, loss: 25.397447, acc: 0.673469\n",
      "epoch 2, iter 21, loss: 28.963440, acc: 0.673469\n",
      "epoch 2, iter 22, loss: 21.942215, acc: 0.775510\n",
      "epoch 2, iter 23, loss: 38.233275, acc: 0.551020\n",
      "epoch 2, iter 24, loss: 35.676505, acc: 0.632653\n",
      "epoch 2, iter 25, loss: 37.933235, acc: 0.571429\n",
      "epoch 2, iter 26, loss: 39.064546, acc: 0.489796\n",
      "epoch 2, iter 27, loss: 33.926915, acc: 0.653061\n",
      "epoch 2, iter 28, loss: 31.379547, acc: 0.591837\n",
      "epoch 2, iter 29, loss: 23.376925, acc: 0.714286\n",
      "epoch 2, iter 30, loss: 35.921414, acc: 0.612245\n",
      "epoch 2, iter 31, loss: 35.604093, acc: 0.367347\n",
      "epoch 2, iter 32, loss: 30.902189, acc: 0.612245\n",
      "epoch 2, iter 33, loss: 25.565768, acc: 0.775510\n",
      "epoch 2, iter 34, loss: 33.344495, acc: 0.632653\n",
      "epoch 2, iter 35, loss: 39.653415, acc: 0.591837\n",
      "epoch 2, iter 36, loss: 31.023354, acc: 0.551020\n",
      "epoch 2, iter 37, loss: 26.927340, acc: 0.795918\n",
      "epoch 2, iter 38, loss: 38.718827, acc: 0.428571\n",
      "epoch 2, iter 39, loss: 33.448233, acc: 0.591837\n",
      "epoch 2, iter 40, loss: 35.388715, acc: 0.612245\n",
      "epoch 2, iter 41, loss: 28.617321, acc: 0.714286\n",
      "epoch 2, iter 42, loss: 37.400822, acc: 0.612245\n",
      "epoch 2, iter 43, loss: 29.133454, acc: 0.755102\n",
      "epoch 2, iter 44, loss: 27.691766, acc: 0.795918\n",
      "epoch 2, iter 45, loss: 35.975081, acc: 0.693878\n",
      "epoch 2, iter 46, loss: 33.308334, acc: 0.530612\n",
      "epoch 2, iter 47, loss: 31.947440, acc: 0.632653\n",
      "epoch 2, iter 48, loss: 29.277005, acc: 0.673469\n",
      "epoch 2, iter 49, loss: 28.020069, acc: 0.612245\n",
      "epoch 2, iter 50, loss: 30.785682, acc: 0.673469\n",
      "epoch 2, iter 51, loss: 33.713515, acc: 0.571429\n",
      "epoch 2, iter 52, loss: 36.196492, acc: 0.653061\n",
      "epoch 2, iter 53, loss: 35.611749, acc: 0.632653\n",
      "epoch 2, iter 54, loss: 30.011994, acc: 0.673469\n",
      "epoch 2, iter 55, loss: 29.478083, acc: 0.693878\n",
      "epoch 2, iter 56, loss: 22.388394, acc: 0.714286\n",
      "epoch 2, iter 57, loss: 30.445129, acc: 0.673469\n",
      "epoch 2, iter 58, loss: 34.342527, acc: 0.591837\n",
      "epoch 2, iter 59, loss: 29.287176, acc: 0.714286\n",
      "epoch 2, iter 60, loss: 30.004344, acc: 0.714286\n",
      "epoch 2, iter 61, loss: 24.653319, acc: 0.755102\n",
      "epoch 2, iter 62, loss: 33.070692, acc: 0.591837\n",
      "epoch 2, iter 63, loss: 26.529541, acc: 0.734694\n",
      "epoch 2, iter 64, loss: 36.309357, acc: 0.551020\n",
      "epoch 2, iter 65, loss: 32.170547, acc: 0.612245\n",
      "epoch 2, iter 66, loss: 31.380550, acc: 0.918367\n",
      "epoch 2, iter 67, loss: 38.530777, acc: 0.571429\n",
      "epoch 2, iter 68, loss: 26.829441, acc: 0.755102\n",
      "epoch 2, iter 69, loss: 20.594379, acc: 0.755102\n",
      "epoch 2, iter 70, loss: 29.316659, acc: 0.673469\n",
      "epoch 2, iter 71, loss: 31.805989, acc: 0.693878\n",
      "epoch 2, iter 72, loss: 26.246037, acc: 0.693878\n",
      "epoch 2, iter 73, loss: 25.555612, acc: 0.734694\n",
      "epoch 2, iter 74, loss: 31.646727, acc: 0.591837\n",
      "epoch 2, iter 75, loss: 30.513158, acc: 0.795918\n",
      "epoch 2, iter 76, loss: 29.287495, acc: 0.632653\n",
      "epoch 2, iter 77, loss: 36.616713, acc: 0.571429\n",
      "epoch 2, iter 78, loss: 34.322750, acc: 0.673469\n",
      "epoch 2, iter 79, loss: 28.839448, acc: 0.653061\n",
      "epoch 2, iter 80, loss: 22.861673, acc: 0.918367\n",
      "epoch 2, iter 81, loss: 30.281044, acc: 0.673469\n",
      "epoch 2, iter 82, loss: 33.044342, acc: 0.551020\n",
      "epoch 2, iter 83, loss: 33.205268, acc: 0.632653\n",
      "epoch 2, iter 84, loss: 20.751076, acc: 0.816327\n",
      "epoch 2, iter 85, loss: 20.591411, acc: 0.857143\n",
      "epoch 2, iter 86, loss: 33.522097, acc: 0.591837\n",
      "epoch 2, iter 87, loss: 42.898102, acc: 0.367347\n",
      "epoch 2, iter 88, loss: 25.785933, acc: 0.836735\n",
      "epoch 2, iter 89, loss: 29.018653, acc: 0.530612\n",
      "epoch 2, iter 90, loss: 31.201723, acc: 0.448980\n",
      "epoch 2, iter 91, loss: 31.151313, acc: 0.734694\n",
      "epoch 2, iter 92, loss: 42.393873, acc: 0.571429\n",
      "epoch 2, iter 93, loss: 45.550880, acc: 0.469388\n",
      "epoch 2, iter 94, loss: 36.665296, acc: 0.673469\n",
      "epoch 2, iter 95, loss: 22.423631, acc: 0.918367\n",
      "epoch 2, iter 96, loss: 26.873895, acc: 0.612245\n",
      "epoch 2, iter 97, loss: 33.377386, acc: 0.714286\n",
      "epoch 2, iter 98, loss: 35.286529, acc: 0.571429\n",
      "epoch 2, iter 99, loss: 27.743247, acc: 0.775510\n",
      "epoch 2, iter 100, loss: 45.478913, acc: 0.571429\n",
      "epoch 2, iter 101, loss: 31.400884, acc: 0.653061\n",
      "epoch 2, iter 102, loss: 27.405845, acc: 0.795918\n",
      "epoch 2, iter 103, loss: 24.706235, acc: 0.795918\n",
      "epoch 2, iter 104, loss: 37.984195, acc: 0.530612\n",
      "epoch 2, iter 105, loss: 30.478966, acc: 0.632653\n",
      "epoch 2, iter 106, loss: 23.163030, acc: 0.816327\n",
      "epoch 2, iter 107, loss: 20.882224, acc: 0.816327\n",
      "epoch 2, iter 108, loss: 32.946716, acc: 0.612245\n",
      "epoch 2, iter 109, loss: 29.480802, acc: 0.591837\n",
      "epoch 2, iter 110, loss: 33.254276, acc: 0.632653\n",
      "epoch 2, iter 111, loss: 41.540499, acc: 0.469388\n",
      "epoch 2, iter 112, loss: 38.003677, acc: 0.632653\n",
      "epoch 2, iter 113, loss: 44.452044, acc: 0.489796\n",
      "epoch 2, iter 114, loss: 34.119590, acc: 0.489796\n",
      "epoch 2, iter 115, loss: 29.452883, acc: 0.530612\n",
      "epoch 2, iter 116, loss: 41.595858, acc: 0.530612\n",
      "epoch 2, iter 117, loss: 31.590251, acc: 0.714286\n",
      "epoch 2, iter 118, loss: 36.032331, acc: 0.653061\n",
      "epoch 2, iter 119, loss: 33.477363, acc: 0.795918\n",
      "epoch 2, iter 120, loss: 29.475768, acc: 0.489796\n",
      "epoch 2, iter 121, loss: 34.023092, acc: 0.693878\n",
      "epoch 2, iter 122, loss: 30.375883, acc: 0.530612\n",
      "epoch 2, iter 123, loss: 32.555605, acc: 0.673469\n",
      "epoch 2, iter 124, loss: 38.257249, acc: 0.571429\n",
      "epoch 2, iter 125, loss: 35.473117, acc: 0.510204\n",
      "epoch 2, iter 126, loss: 25.912811, acc: 0.857143\n",
      "epoch 2, iter 127, loss: 40.381200, acc: 0.530612\n",
      "epoch 2, iter 128, loss: 31.341452, acc: 0.653061\n",
      "epoch 2, iter 129, loss: 26.502220, acc: 0.673469\n",
      "epoch 2, iter 130, loss: 26.009233, acc: 0.877551\n",
      "epoch 2, iter 131, loss: 28.879120, acc: 0.755102\n",
      "epoch 2, iter 132, loss: 35.939989, acc: 0.673469\n",
      "epoch 2, iter 133, loss: 23.600403, acc: 0.775510\n",
      "epoch 2, iter 134, loss: 40.639973, acc: 0.489796\n",
      "epoch 2, iter 135, loss: 34.984221, acc: 0.510204\n",
      "epoch 2, iter 136, loss: 36.849465, acc: 0.530612\n",
      "epoch 2, iter 137, loss: 32.982794, acc: 0.591837\n",
      "epoch 2, iter 138, loss: 32.713197, acc: 0.755102\n",
      "epoch 2, iter 139, loss: 27.745648, acc: 0.653061\n",
      "epoch 2, iter 140, loss: 31.432908, acc: 0.693878\n",
      "epoch 2, iter 141, loss: 20.630967, acc: 0.836735\n",
      "epoch 2, iter 142, loss: 34.680271, acc: 0.571429\n",
      "epoch 2, iter 143, loss: 29.338794, acc: 0.714286\n",
      "epoch 2, iter 144, loss: 34.994295, acc: 0.632653\n",
      "epoch 2, iter 145, loss: 19.440996, acc: 0.775510\n",
      "epoch 2, iter 146, loss: 28.932391, acc: 0.632653\n",
      "epoch 2, iter 147, loss: 30.425618, acc: 0.632653\n",
      "epoch 2, iter 148, loss: 28.863946, acc: 0.632653\n",
      "epoch 2, iter 149, loss: 22.202209, acc: 0.816327\n",
      "epoch 2, iter 150, loss: 29.742534, acc: 0.755102\n",
      "epoch 2, iter 151, loss: 34.044674, acc: 0.714286\n",
      "epoch 2, iter 152, loss: 33.121470, acc: 0.693878\n",
      "epoch 2, iter 153, loss: 38.517032, acc: 0.591837\n",
      "epoch 2, iter 154, loss: 36.378425, acc: 0.591837\n",
      "epoch 2, iter 155, loss: 29.541510, acc: 0.591837\n",
      "epoch 2, iter 156, loss: 29.980776, acc: 0.510204\n",
      "epoch 2, iter 157, loss: 32.077292, acc: 0.653061\n",
      "epoch 2, iter 158, loss: 22.996861, acc: 0.714286\n",
      "epoch 2, iter 159, loss: 38.636551, acc: 0.448980\n",
      "epoch 2, iter 160, loss: 31.146145, acc: 0.551020\n",
      "epoch 2, iter 161, loss: 27.558425, acc: 0.693878\n",
      "epoch 2, iter 162, loss: 32.265375, acc: 0.653061\n",
      "epoch 2, iter 163, loss: 34.993342, acc: 0.551020\n",
      "epoch 2, iter 164, loss: 33.934350, acc: 0.673469\n",
      "epoch 2, iter 165, loss: 25.639871, acc: 0.775510\n",
      "epoch 2, iter 166, loss: 25.995169, acc: 0.571429\n",
      "epoch 2, iter 167, loss: 28.700588, acc: 0.612245\n",
      "epoch 2, iter 168, loss: 29.952335, acc: 0.714286\n",
      "epoch 2, iter 169, loss: 37.130131, acc: 0.612245\n",
      "epoch 2, iter 170, loss: 37.641435, acc: 0.673469\n",
      "epoch 2, iter 171, loss: 31.586712, acc: 0.489796\n",
      "epoch 2, iter 172, loss: 32.723118, acc: 0.714286\n",
      "epoch 2, iter 173, loss: 36.260239, acc: 0.591837\n",
      "epoch 2, iter 174, loss: 31.663809, acc: 0.612245\n",
      "epoch 2, iter 175, loss: 22.461138, acc: 0.551020\n",
      "epoch 2, iter 176, loss: 27.794532, acc: 0.755102\n",
      "epoch 2, iter 177, loss: 29.873195, acc: 0.612245\n",
      "epoch 2, iter 178, loss: 44.156210, acc: 0.510204\n",
      "epoch 2, iter 179, loss: 26.067568, acc: 0.653061\n",
      "epoch 2, iter 180, loss: 25.691432, acc: 0.816327\n",
      "epoch 2, iter 181, loss: 35.388944, acc: 0.673469\n",
      "epoch 2, iter 182, loss: 31.515668, acc: 0.612245\n",
      "epoch 2, iter 183, loss: 37.032821, acc: 0.653061\n",
      "epoch 2, iter 184, loss: 36.674086, acc: 0.693878\n",
      "epoch 2, iter 185, loss: 38.652713, acc: 0.591837\n",
      "epoch 2, iter 186, loss: 24.953252, acc: 0.816327\n",
      "epoch 2, iter 187, loss: 33.547954, acc: 0.551020\n",
      "epoch 2, iter 188, loss: 46.798623, acc: 0.428571\n",
      "epoch 2, iter 189, loss: 40.553887, acc: 0.551020\n",
      "epoch 2, iter 190, loss: 31.520761, acc: 0.653061\n",
      "epoch 2, iter 191, loss: 29.124947, acc: 0.714286\n",
      "epoch 2, iter 192, loss: 31.877842, acc: 0.612245\n",
      "epoch 2, iter 193, loss: 33.977887, acc: 0.571429\n",
      "epoch 2, iter 194, loss: 27.356648, acc: 0.734694\n",
      "epoch 2, iter 195, loss: 38.142137, acc: 0.530612\n",
      "epoch 2, iter 196, loss: 28.055128, acc: 0.714286\n",
      "epoch 2, iter 197, loss: 34.973601, acc: 0.551020\n",
      "epoch 2, iter 198, loss: 29.559117, acc: 0.653061\n",
      "epoch 2, iter 199, loss: 39.115839, acc: 0.551020\n",
      "epoch 2, iter 200, loss: 33.485500, acc: 0.510204\n",
      "epoch 2, iter 201, loss: 27.407779, acc: 0.877551\n",
      "epoch 2, iter 202, loss: 28.334410, acc: 0.571429\n",
      "epoch 2, iter 203, loss: 35.724860, acc: 0.530612\n",
      "epoch 2, iter 204, loss: 32.737307, acc: 0.510204\n",
      "epoch 2, iter 205, loss: 38.149611, acc: 0.326531\n",
      "epoch 2, iter 206, loss: 34.068023, acc: 0.653061\n",
      "epoch 2, iter 207, loss: 37.194527, acc: 0.673469\n",
      "epoch 2, iter 208, loss: 31.165958, acc: 0.795918\n",
      "epoch 2, iter 209, loss: 28.945604, acc: 0.734694\n",
      "epoch 2, iter 210, loss: 34.514341, acc: 0.551020\n",
      "epoch 2, iter 211, loss: 24.343675, acc: 0.795918\n",
      "epoch 2, iter 212, loss: 29.111016, acc: 0.551020\n",
      "epoch 2, iter 213, loss: 22.805225, acc: 0.795918\n",
      "epoch 2, iter 214, loss: 23.821206, acc: 0.734694\n",
      "epoch 2, iter 215, loss: 38.050142, acc: 0.591837\n",
      "epoch 2, iter 216, loss: 31.414896, acc: 0.734694\n",
      "epoch 2, iter 217, loss: 38.136674, acc: 0.551020\n",
      "epoch 2, iter 218, loss: 29.936325, acc: 0.714286\n",
      "epoch 2, iter 219, loss: 27.356679, acc: 0.734694\n",
      "epoch 2, iter 220, loss: 32.805751, acc: 0.489796\n",
      "epoch 2, iter 221, loss: 24.914831, acc: 0.816327\n",
      "epoch 2, iter 222, loss: 38.611308, acc: 0.551020\n",
      "epoch 2, iter 223, loss: 25.237217, acc: 0.734694\n",
      "epoch 2, iter 224, loss: 25.761489, acc: 0.591837\n",
      "epoch 2, iter 225, loss: 29.921895, acc: 0.693878\n",
      "epoch 2, iter 226, loss: 28.152855, acc: 0.591837\n",
      "epoch 2, iter 227, loss: 29.290136, acc: 0.632653\n",
      "epoch 2, iter 228, loss: 28.593285, acc: 0.632653\n",
      "epoch 2, iter 229, loss: 17.974292, acc: 0.938776\n",
      "epoch 2, iter 230, loss: 32.400772, acc: 0.632653\n",
      "epoch 2, iter 231, loss: 24.686147, acc: 0.795918\n",
      "epoch 2, iter 232, loss: 33.989728, acc: 0.551020\n",
      "epoch 2, iter 233, loss: 35.066540, acc: 0.551020\n",
      "epoch 2, iter 234, loss: 25.506713, acc: 0.795918\n",
      "epoch 2, iter 235, loss: 29.734781, acc: 0.632653\n",
      "epoch 2, iter 236, loss: 25.752957, acc: 0.734694\n",
      "epoch 2, iter 237, loss: 34.884413, acc: 0.612245\n",
      "epoch 2, iter 238, loss: 39.605108, acc: 0.571429\n",
      "epoch 2, iter 239, loss: 35.275852, acc: 0.489796\n",
      "epoch 2, iter 240, loss: 31.053607, acc: 0.734694\n",
      "epoch 2, iter 241, loss: 28.495703, acc: 0.693878\n",
      "epoch 2, iter 242, loss: 37.774239, acc: 0.571429\n",
      "epoch 2, iter 243, loss: 30.398858, acc: 0.591837\n",
      "epoch 2, iter 244, loss: 37.154633, acc: 0.591837\n",
      "epoch 2, iter 245, loss: 33.807571, acc: 0.612245\n",
      "epoch 2, iter 246, loss: 37.674818, acc: 0.530612\n",
      "epoch 2, iter 247, loss: 33.224253, acc: 0.693878\n",
      "epoch 2, iter 248, loss: 36.262775, acc: 0.673469\n",
      "epoch 2, iter 249, loss: 42.544660, acc: 0.653061\n",
      "epoch 2, iter 250, loss: 32.491032, acc: 0.755102\n",
      "epoch 2, iter 251, loss: 33.796349, acc: 0.632653\n",
      "epoch 2, iter 252, loss: 34.506994, acc: 0.571429\n",
      "epoch 2, iter 253, loss: 32.326532, acc: 0.673469\n",
      "epoch 2, iter 254, loss: 22.157939, acc: 0.714286\n",
      "epoch 2, iter 255, loss: 30.778000, acc: 0.632653\n",
      "epoch 2, iter 256, loss: 32.732646, acc: 0.693878\n",
      "epoch 2, iter 257, loss: 33.640799, acc: 0.591837\n",
      "epoch 2, iter 258, loss: 36.584769, acc: 0.551020\n",
      "epoch 2, iter 259, loss: 26.728679, acc: 0.714286\n",
      "epoch 2, iter 260, loss: 40.589212, acc: 0.408163\n",
      "epoch 2, iter 261, loss: 33.043773, acc: 0.795918\n",
      "epoch 2, iter 262, loss: 29.718857, acc: 0.571429\n",
      "epoch 2, iter 263, loss: 36.329856, acc: 0.632653\n",
      "epoch 2, iter 264, loss: 27.974372, acc: 0.795918\n",
      "epoch 2, iter 265, loss: 24.752894, acc: 0.877551\n",
      "epoch 2, iter 266, loss: 37.414416, acc: 0.632653\n",
      "epoch 2, iter 267, loss: 36.724421, acc: 0.591837\n",
      "epoch 2, iter 268, loss: 28.731459, acc: 0.612245\n",
      "epoch 2, iter 269, loss: 24.562913, acc: 0.632653\n",
      "epoch 2, iter 270, loss: 30.780647, acc: 0.755102\n",
      "epoch 2, iter 271, loss: 24.896605, acc: 0.775510\n",
      "epoch 2, iter 272, loss: 20.994597, acc: 0.897959\n",
      "epoch 2, iter 273, loss: 38.653266, acc: 0.489796\n",
      "epoch 2, iter 274, loss: 31.965270, acc: 0.612245\n",
      "epoch 2, iter 275, loss: 35.344218, acc: 0.530612\n",
      "epoch 2, iter 276, loss: 20.581683, acc: 0.857143\n",
      "epoch 2, iter 277, loss: 32.919793, acc: 0.775510\n",
      "epoch 2, iter 278, loss: 27.790208, acc: 0.673469\n",
      "epoch 2, iter 279, loss: 30.103756, acc: 0.551020\n",
      "epoch 2, iter 280, loss: 39.562413, acc: 0.693878\n",
      "epoch 2, iter 281, loss: 35.473679, acc: 0.469388\n",
      "epoch 2, iter 282, loss: 37.776294, acc: 0.653061\n",
      "epoch 2, iter 283, loss: 38.167826, acc: 0.489796\n",
      "epoch 2, iter 284, loss: 29.427202, acc: 0.714286\n",
      "epoch 2, iter 285, loss: 35.135782, acc: 0.734694\n",
      "epoch 2, iter 286, loss: 28.979367, acc: 0.693878\n",
      "epoch 2, iter 287, loss: 30.011605, acc: 0.632653\n",
      "epoch 2, iter 288, loss: 25.395863, acc: 0.714286\n",
      "epoch 2, iter 289, loss: 30.245966, acc: 0.653061\n",
      "epoch 2, iter 290, loss: 31.268598, acc: 0.693878\n",
      "epoch 2, iter 291, loss: 30.203391, acc: 0.551020\n",
      "epoch 2, iter 292, loss: 28.318747, acc: 0.734694\n",
      "epoch 2, iter 293, loss: 28.002617, acc: 0.693878\n",
      "epoch 2, iter 294, loss: 24.565957, acc: 0.775510\n",
      "epoch 2, iter 295, loss: 36.609310, acc: 0.673469\n",
      "epoch 2, iter 296, loss: 35.603288, acc: 0.734694\n",
      "epoch 2, iter 297, loss: 31.632203, acc: 0.734694\n",
      "epoch 2, iter 298, loss: 30.459682, acc: 0.489796\n",
      "epoch 2, iter 299, loss: 31.568717, acc: 0.653061\n",
      "epoch 2, iter 300, loss: 21.904604, acc: 0.816327\n",
      "epoch 2, iter 301, loss: 25.840498, acc: 0.693878\n",
      "epoch 2, iter 302, loss: 32.337646, acc: 0.591837\n",
      "epoch 2, iter 303, loss: 32.121610, acc: 0.551020\n",
      "epoch 2, iter 304, loss: 31.719491, acc: 0.571429\n",
      "epoch 2, iter 305, loss: 38.537726, acc: 0.571429\n",
      "epoch 2, iter 306, loss: 35.283264, acc: 0.612245\n",
      "epoch 2, iter 307, loss: 32.588608, acc: 0.632653\n",
      "epoch 2, iter 308, loss: 39.174218, acc: 0.571429\n",
      "epoch 2, iter 309, loss: 31.640184, acc: 0.632653\n",
      "epoch 2, iter 310, loss: 26.468751, acc: 0.673469\n",
      "epoch 2, iter 311, loss: 24.342135, acc: 0.714286\n",
      "epoch 2, iter 312, loss: 22.466870, acc: 0.795918\n",
      "epoch 2, iter 313, loss: 24.958414, acc: 0.795918\n",
      "epoch 2, iter 314, loss: 26.635461, acc: 0.632653\n",
      "epoch 2, iter 315, loss: 28.915609, acc: 0.612245\n",
      "epoch 2, iter 316, loss: 24.983942, acc: 0.714286\n",
      "epoch 2, iter 317, loss: 24.177948, acc: 0.734694\n",
      "epoch 2, iter 318, loss: 39.869403, acc: 0.571429\n",
      "epoch 2, iter 319, loss: 38.598573, acc: 0.530612\n",
      "epoch 2, iter 320, loss: 28.086834, acc: 0.530612\n",
      "epoch 2, iter 321, loss: 29.764193, acc: 0.734694\n",
      "epoch 2, iter 322, loss: 39.461516, acc: 0.489796\n",
      "epoch 2, iter 323, loss: 30.399725, acc: 0.551020\n",
      "epoch 2, iter 324, loss: 27.303104, acc: 0.673469\n",
      "epoch 2, iter 325, loss: 23.147638, acc: 0.795918\n",
      "epoch 2, iter 326, loss: 37.610326, acc: 0.510204\n",
      "epoch 2, iter 327, loss: 25.938286, acc: 0.836735\n",
      "epoch 2, iter 328, loss: 28.950180, acc: 0.714286\n",
      "epoch 2, iter 329, loss: 33.640569, acc: 0.632653\n",
      "epoch 2, iter 330, loss: 31.806887, acc: 0.653061\n",
      "epoch 2, iter 331, loss: 35.562769, acc: 0.489796\n",
      "epoch 2, iter 332, loss: 41.686142, acc: 0.510204\n",
      "epoch 2, iter 333, loss: 31.004382, acc: 0.551020\n",
      "epoch 2, iter 334, loss: 31.502574, acc: 0.673469\n",
      "epoch 2, iter 335, loss: 25.422870, acc: 0.836735\n",
      "epoch 2, iter 336, loss: 25.146432, acc: 0.775510\n",
      "epoch 2, iter 337, loss: 32.100070, acc: 0.591837\n",
      "epoch 2, iter 338, loss: 26.870554, acc: 0.836735\n",
      "epoch 2, iter 339, loss: 27.016334, acc: 0.693878\n",
      "epoch 2, iter 340, loss: 41.077259, acc: 0.612245\n",
      "epoch 2, iter 341, loss: 26.209135, acc: 0.877551\n",
      "epoch 2, iter 342, loss: 44.153715, acc: 0.489796\n",
      "epoch 2, iter 343, loss: 36.179450, acc: 0.714286\n",
      "epoch 2, iter 344, loss: 38.123619, acc: 0.571429\n",
      "epoch 2, iter 345, loss: 33.477087, acc: 0.551020\n",
      "epoch 2, iter 346, loss: 30.451591, acc: 0.795918\n",
      "epoch 2, iter 347, loss: 23.590949, acc: 0.612245\n",
      "epoch 2, iter 348, loss: 32.926837, acc: 0.551020\n",
      "epoch 2, iter 349, loss: 37.538053, acc: 0.612245\n",
      "epoch 2, iter 350, loss: 29.454976, acc: 0.530612\n",
      "epoch 2, iter 351, loss: 33.344273, acc: 0.612245\n",
      "epoch 2, iter 352, loss: 39.340411, acc: 0.591837\n",
      "epoch 2, iter 353, loss: 38.948268, acc: 0.551020\n",
      "epoch 2, iter 354, loss: 32.445191, acc: 0.653061\n",
      "epoch 2, iter 355, loss: 29.875782, acc: 0.632653\n",
      "epoch 2, iter 356, loss: 29.279678, acc: 0.734694\n",
      "epoch 2, iter 357, loss: 34.563353, acc: 0.551020\n",
      "epoch 2, iter 358, loss: 32.495588, acc: 0.612245\n",
      "epoch 2, iter 359, loss: 26.834236, acc: 0.693878\n",
      "epoch 2, iter 360, loss: 27.500537, acc: 0.632653\n",
      "epoch 2, iter 361, loss: 32.862683, acc: 0.510204\n",
      "epoch 2, iter 362, loss: 37.093416, acc: 0.530612\n",
      "epoch 2, iter 363, loss: 33.608302, acc: 0.571429\n",
      "epoch 2, iter 364, loss: 40.821607, acc: 0.571429\n",
      "epoch 2, iter 365, loss: 29.248336, acc: 0.632653\n",
      "epoch 2, iter 366, loss: 42.967179, acc: 0.489796\n",
      "epoch 2, iter 367, loss: 40.131668, acc: 0.469388\n",
      "epoch 2, iter 368, loss: 31.746725, acc: 0.530612\n",
      "epoch 2, iter 369, loss: 32.040474, acc: 0.469388\n",
      "epoch 2, iter 370, loss: 37.025347, acc: 0.489796\n",
      "epoch 2, iter 371, loss: 32.107759, acc: 0.714286\n",
      "epoch 2, iter 372, loss: 34.877494, acc: 0.571429\n",
      "epoch 2, iter 373, loss: 31.620194, acc: 0.591837\n",
      "epoch 2, iter 374, loss: 37.939735, acc: 0.387755\n",
      "epoch 2, iter 375, loss: 34.189022, acc: 0.673469\n",
      "epoch 2, iter 376, loss: 30.205619, acc: 0.571429\n",
      "epoch 2, iter 377, loss: 25.428343, acc: 0.693878\n",
      "epoch 2, iter 378, loss: 31.810968, acc: 0.714286\n",
      "epoch 2, iter 379, loss: 39.203465, acc: 0.591837\n",
      "epoch 2, iter 380, loss: 36.561975, acc: 0.693878\n",
      "epoch 2, iter 381, loss: 34.767230, acc: 0.612245\n",
      "epoch 2, iter 382, loss: 24.732627, acc: 0.836735\n",
      "epoch 2, iter 383, loss: 25.257022, acc: 0.714286\n",
      "epoch 2, iter 384, loss: 32.584002, acc: 0.632653\n",
      "epoch 2, iter 385, loss: 20.922818, acc: 0.897959\n",
      "epoch 2, iter 386, loss: 39.980268, acc: 0.571429\n",
      "epoch 2, iter 387, loss: 33.101671, acc: 0.571429\n",
      "epoch 2, iter 388, loss: 29.400846, acc: 0.653061\n",
      "epoch 2, iter 389, loss: 32.919995, acc: 0.632653\n",
      "epoch 2, iter 390, loss: 30.617942, acc: 0.551020\n",
      "epoch 2, iter 391, loss: 28.041585, acc: 0.734694\n",
      "epoch 2, iter 392, loss: 27.928793, acc: 0.857143\n",
      "epoch 2, iter 393, loss: 32.275756, acc: 0.551020\n",
      "epoch 2, iter 394, loss: 25.783813, acc: 0.693878\n",
      "epoch 2, iter 395, loss: 33.165709, acc: 0.551020\n",
      "epoch 2, iter 396, loss: 27.943473, acc: 0.591837\n",
      "epoch 2, iter 397, loss: 21.917714, acc: 0.775510\n",
      "epoch 2, iter 398, loss: 37.266682, acc: 0.591837\n",
      "epoch 2, iter 399, loss: 27.780319, acc: 0.816327\n",
      "epoch 2, iter 400, loss: 39.011241, acc: 0.469388\n",
      "epoch 2, iter 401, loss: 32.175176, acc: 0.693878\n",
      "epoch 2, iter 402, loss: 33.234389, acc: 0.734694\n",
      "epoch 2, iter 403, loss: 37.967659, acc: 0.612245\n",
      "epoch 2, iter 404, loss: 36.842977, acc: 0.551020\n",
      "epoch 2, iter 405, loss: 31.935154, acc: 0.632653\n",
      "epoch 2, iter 406, loss: 27.215021, acc: 0.693878\n",
      "epoch 2, iter 407, loss: 34.195070, acc: 0.510204\n",
      "epoch 2, iter 408, loss: 32.044699, acc: 0.489796\n",
      "epoch 2, iter 409, loss: 24.718322, acc: 0.734694\n",
      "epoch 2, iter 410, loss: 36.335198, acc: 0.551020\n",
      "epoch 2, iter 411, loss: 32.631595, acc: 0.612245\n",
      "epoch 2, iter 412, loss: 30.939893, acc: 0.816327\n",
      "epoch 2, iter 413, loss: 27.049589, acc: 0.632653\n",
      "epoch 2, iter 414, loss: 34.714134, acc: 0.571429\n",
      "epoch 2, iter 415, loss: 32.501104, acc: 0.591837\n",
      "epoch 2, iter 416, loss: 27.582398, acc: 0.734694\n",
      "epoch 2, iter 417, loss: 33.784624, acc: 0.571429\n",
      "epoch 2, iter 418, loss: 34.451261, acc: 0.714286\n",
      "epoch 2, iter 419, loss: 30.658215, acc: 0.591837\n",
      "epoch 2, iter 420, loss: 37.417971, acc: 0.591837\n",
      "epoch 2, iter 421, loss: 27.212917, acc: 0.673469\n",
      "epoch 2, iter 422, loss: 29.309479, acc: 0.734694\n",
      "epoch 2, iter 423, loss: 36.170866, acc: 0.551020\n",
      "epoch 2, iter 424, loss: 29.796196, acc: 0.816327\n",
      "epoch 2, iter 425, loss: 28.294606, acc: 0.693878\n",
      "epoch 2, iter 426, loss: 31.246645, acc: 0.653061\n",
      "epoch 2, iter 427, loss: 37.646462, acc: 0.632653\n",
      "epoch 2, iter 428, loss: 28.696822, acc: 0.673469\n",
      "epoch 2, iter 429, loss: 29.579328, acc: 0.551020\n",
      "epoch 2, iter 430, loss: 30.592068, acc: 0.612245\n",
      "epoch 2, iter 431, loss: 35.531337, acc: 0.714286\n",
      "epoch 2, iter 432, loss: 25.392185, acc: 0.632653\n",
      "epoch 2, iter 433, loss: 29.130974, acc: 0.571429\n",
      "epoch 2, iter 434, loss: 27.107533, acc: 0.591837\n",
      "epoch 2, iter 435, loss: 28.384832, acc: 0.693878\n",
      "epoch 2, iter 436, loss: 28.611727, acc: 0.734694\n",
      "epoch 2, iter 437, loss: 43.660438, acc: 0.530612\n",
      "epoch 2, iter 438, loss: 34.863729, acc: 0.571429\n",
      "epoch 2, iter 439, loss: 31.367918, acc: 0.530612\n",
      "epoch 2, iter 440, loss: 34.660150, acc: 0.612245\n",
      "epoch 2, iter 441, loss: 28.157141, acc: 0.632653\n",
      "epoch 2, iter 442, loss: 31.976699, acc: 0.591837\n",
      "epoch 2, iter 443, loss: 26.863718, acc: 0.836735\n",
      "epoch 2, iter 444, loss: 28.878138, acc: 0.714286\n",
      "epoch 2, iter 445, loss: 46.057066, acc: 0.551020\n",
      "epoch 2, iter 446, loss: 30.249054, acc: 0.632653\n",
      "epoch 2, iter 447, loss: 34.231110, acc: 0.693878\n",
      "epoch 2, iter 448, loss: 33.286953, acc: 0.469388\n",
      "epoch 2, iter 449, loss: 20.230997, acc: 0.795918\n",
      "epoch 2, iter 450, loss: 35.799698, acc: 0.653061\n",
      "epoch 2, iter 451, loss: 27.827895, acc: 0.775510\n",
      "epoch 2, iter 452, loss: 28.440853, acc: 0.734694\n",
      "epoch 2, iter 453, loss: 32.648763, acc: 0.510204\n",
      "epoch 2, iter 454, loss: 29.212326, acc: 0.653061\n",
      "epoch 2, iter 455, loss: 30.183103, acc: 0.693878\n",
      "epoch 2, iter 456, loss: 31.606925, acc: 0.571429\n",
      "epoch 2, iter 457, loss: 31.583009, acc: 0.693878\n",
      "epoch 2, iter 458, loss: 22.245746, acc: 0.775510\n",
      "epoch 2, iter 459, loss: 33.581840, acc: 0.571429\n",
      "epoch 2, iter 460, loss: 34.862998, acc: 0.530612\n",
      "epoch 2, iter 461, loss: 29.965178, acc: 0.591837\n",
      "epoch 2, iter 462, loss: 34.038947, acc: 0.612245\n",
      "epoch 2, iter 463, loss: 32.702753, acc: 0.571429\n",
      "epoch 2, iter 464, loss: 31.297715, acc: 0.857143\n",
      "epoch 2, iter 465, loss: 31.637173, acc: 0.653061\n",
      "epoch 2, iter 466, loss: 36.876226, acc: 0.653061\n",
      "epoch 2, iter 467, loss: 35.174449, acc: 0.612245\n",
      "epoch 2, iter 468, loss: 32.532481, acc: 0.693878\n",
      "epoch 2, iter 469, loss: 34.398994, acc: 0.571429\n",
      "epoch 2, iter 470, loss: 38.992596, acc: 0.489796\n",
      "epoch 2, iter 471, loss: 32.704250, acc: 0.755102\n",
      "epoch 2, iter 472, loss: 28.559320, acc: 0.571429\n",
      "epoch 2, iter 473, loss: 29.829264, acc: 0.612245\n",
      "epoch 2, iter 474, loss: 33.864277, acc: 0.673469\n",
      "epoch 2, iter 475, loss: 36.236334, acc: 0.489796\n",
      "epoch 2, iter 476, loss: 25.022084, acc: 0.693878\n",
      "epoch 2, iter 477, loss: 37.581567, acc: 0.551020\n",
      "epoch 2, iter 478, loss: 31.910671, acc: 0.693878\n",
      "epoch 2, iter 479, loss: 31.171130, acc: 0.612245\n",
      "epoch 2, iter 480, loss: 28.483319, acc: 0.693878\n",
      "epoch 2, iter 481, loss: 25.932981, acc: 0.612245\n",
      "epoch 2, iter 482, loss: 27.742726, acc: 0.857143\n",
      "epoch 2, iter 483, loss: 28.659108, acc: 0.734694\n",
      "epoch 2, iter 484, loss: 30.000151, acc: 0.673469\n",
      "epoch 2, iter 485, loss: 27.562881, acc: 0.693878\n",
      "epoch 2, iter 486, loss: 32.703585, acc: 0.591837\n",
      "epoch 2, iter 487, loss: 27.939328, acc: 0.734694\n",
      "epoch 2, iter 488, loss: 24.178518, acc: 0.714286\n",
      "epoch 2, iter 489, loss: 31.779179, acc: 0.775510\n",
      "epoch 2, iter 490, loss: 33.528746, acc: 0.653061\n",
      "epoch 2, iter 491, loss: 32.134172, acc: 0.734694\n",
      "epoch 2, iter 492, loss: 32.208031, acc: 0.612245\n",
      "epoch 2, iter 493, loss: 23.838627, acc: 0.591837\n",
      "epoch 2, iter 494, loss: 33.950059, acc: 0.530612\n",
      "epoch 2, iter 495, loss: 34.023806, acc: 0.489796\n",
      "epoch 2, iter 496, loss: 26.545837, acc: 0.693878\n",
      "epoch 2, iter 497, loss: 34.965217, acc: 0.530612\n",
      "epoch 2, iter 498, loss: 34.602348, acc: 0.510204\n",
      "epoch 2, iter 499, loss: 35.084307, acc: 0.571429\n",
      "epoch 2, acc: 0.644245\n",
      "epoch 3, iter 0, loss: 37.137102, acc: 0.612245\n",
      "epoch 3, iter 1, loss: 41.012382, acc: 0.653061\n",
      "epoch 3, iter 2, loss: 40.053546, acc: 0.632653\n",
      "epoch 3, iter 3, loss: 30.853059, acc: 0.510204\n",
      "epoch 3, iter 4, loss: 28.642091, acc: 0.591837\n",
      "epoch 3, iter 5, loss: 29.338179, acc: 0.755102\n",
      "epoch 3, iter 6, loss: 28.788152, acc: 0.755102\n",
      "epoch 3, iter 7, loss: 31.512803, acc: 0.714286\n",
      "epoch 3, iter 8, loss: 35.976140, acc: 0.612245\n",
      "epoch 3, iter 9, loss: 27.696692, acc: 0.714286\n",
      "epoch 3, iter 10, loss: 34.096075, acc: 0.591837\n",
      "epoch 3, iter 11, loss: 40.573618, acc: 0.489796\n",
      "epoch 3, iter 12, loss: 27.724212, acc: 0.734694\n",
      "epoch 3, iter 13, loss: 34.698484, acc: 0.632653\n",
      "epoch 3, iter 14, loss: 29.445489, acc: 0.632653\n",
      "epoch 3, iter 15, loss: 22.572707, acc: 0.755102\n",
      "epoch 3, iter 16, loss: 35.706127, acc: 0.551020\n",
      "epoch 3, iter 17, loss: 25.694299, acc: 0.734694\n",
      "epoch 3, iter 18, loss: 40.606580, acc: 0.551020\n",
      "epoch 3, iter 19, loss: 21.787711, acc: 0.795918\n",
      "epoch 3, iter 20, loss: 25.210240, acc: 0.734694\n",
      "epoch 3, iter 21, loss: 30.380325, acc: 0.693878\n",
      "epoch 3, iter 22, loss: 23.438641, acc: 0.714286\n",
      "epoch 3, iter 23, loss: 37.975253, acc: 0.530612\n",
      "epoch 3, iter 24, loss: 35.810571, acc: 0.612245\n",
      "epoch 3, iter 25, loss: 35.493067, acc: 0.489796\n",
      "epoch 3, iter 26, loss: 36.012617, acc: 0.510204\n",
      "epoch 3, iter 27, loss: 33.010236, acc: 0.653061\n",
      "epoch 3, iter 28, loss: 31.639754, acc: 0.612245\n",
      "epoch 3, iter 29, loss: 22.476427, acc: 0.775510\n",
      "epoch 3, iter 30, loss: 31.752935, acc: 0.551020\n",
      "epoch 3, iter 31, loss: 35.169525, acc: 0.428571\n",
      "epoch 3, iter 32, loss: 30.913464, acc: 0.591837\n",
      "epoch 3, iter 33, loss: 23.351814, acc: 0.632653\n",
      "epoch 3, iter 34, loss: 30.455371, acc: 0.632653\n",
      "epoch 3, iter 35, loss: 40.169985, acc: 0.551020\n",
      "epoch 3, iter 36, loss: 31.465202, acc: 0.571429\n",
      "epoch 3, iter 37, loss: 25.663076, acc: 0.816327\n",
      "epoch 3, iter 38, loss: 39.206991, acc: 0.428571\n",
      "epoch 3, iter 39, loss: 34.600218, acc: 0.693878\n",
      "epoch 3, iter 40, loss: 33.965859, acc: 0.571429\n",
      "epoch 3, iter 41, loss: 29.912387, acc: 0.653061\n",
      "epoch 3, iter 42, loss: 37.510060, acc: 0.571429\n",
      "epoch 3, iter 43, loss: 25.563593, acc: 0.775510\n",
      "epoch 3, iter 44, loss: 26.513695, acc: 0.795918\n",
      "epoch 3, iter 45, loss: 33.449763, acc: 0.755102\n",
      "epoch 3, iter 46, loss: 31.371671, acc: 0.489796\n",
      "epoch 3, iter 47, loss: 31.802796, acc: 0.653061\n",
      "epoch 3, iter 48, loss: 29.396892, acc: 0.734694\n",
      "epoch 3, iter 49, loss: 24.903690, acc: 0.591837\n",
      "epoch 3, iter 50, loss: 29.739270, acc: 0.673469\n",
      "epoch 3, iter 51, loss: 34.385676, acc: 0.551020\n",
      "epoch 3, iter 52, loss: 33.824942, acc: 0.653061\n",
      "epoch 3, iter 53, loss: 35.504660, acc: 0.734694\n",
      "epoch 3, iter 54, loss: 30.302410, acc: 0.693878\n",
      "epoch 3, iter 55, loss: 27.402296, acc: 0.693878\n",
      "epoch 3, iter 56, loss: 21.795497, acc: 0.795918\n",
      "epoch 3, iter 57, loss: 27.913304, acc: 0.714286\n",
      "epoch 3, iter 58, loss: 32.724217, acc: 0.591837\n",
      "epoch 3, iter 59, loss: 28.125789, acc: 0.755102\n",
      "epoch 3, iter 60, loss: 30.752166, acc: 0.693878\n",
      "epoch 3, iter 61, loss: 23.547572, acc: 0.755102\n",
      "epoch 3, iter 62, loss: 34.711175, acc: 0.530612\n",
      "epoch 3, iter 63, loss: 25.232400, acc: 0.755102\n",
      "epoch 3, iter 64, loss: 33.478190, acc: 0.530612\n",
      "epoch 3, iter 65, loss: 31.625819, acc: 0.653061\n",
      "epoch 3, iter 66, loss: 27.715258, acc: 0.877551\n",
      "epoch 3, iter 67, loss: 36.359776, acc: 0.591837\n",
      "epoch 3, iter 68, loss: 26.612723, acc: 0.714286\n",
      "epoch 3, iter 69, loss: 21.326462, acc: 0.775510\n",
      "epoch 3, iter 70, loss: 26.968610, acc: 0.653061\n",
      "epoch 3, iter 71, loss: 31.010309, acc: 0.734694\n",
      "epoch 3, iter 72, loss: 26.283318, acc: 0.693878\n",
      "epoch 3, iter 73, loss: 24.599635, acc: 0.653061\n",
      "epoch 3, iter 74, loss: 29.843068, acc: 0.653061\n",
      "epoch 3, iter 75, loss: 29.364096, acc: 0.816327\n",
      "epoch 3, iter 76, loss: 29.941418, acc: 0.714286\n",
      "epoch 3, iter 77, loss: 34.693869, acc: 0.469388\n",
      "epoch 3, iter 78, loss: 34.422650, acc: 0.653061\n",
      "epoch 3, iter 79, loss: 28.714885, acc: 0.653061\n",
      "epoch 3, iter 80, loss: 21.891973, acc: 0.918367\n",
      "epoch 3, iter 81, loss: 29.099242, acc: 0.653061\n",
      "epoch 3, iter 82, loss: 33.044777, acc: 0.653061\n",
      "epoch 3, iter 83, loss: 32.022228, acc: 0.612245\n",
      "epoch 3, iter 84, loss: 21.304052, acc: 0.816327\n",
      "epoch 3, iter 85, loss: 20.492330, acc: 0.857143\n",
      "epoch 3, iter 86, loss: 29.771655, acc: 0.489796\n",
      "epoch 3, iter 87, loss: 43.618589, acc: 0.408163\n",
      "epoch 3, iter 88, loss: 24.082085, acc: 0.775510\n",
      "epoch 3, iter 89, loss: 30.418244, acc: 0.571429\n",
      "epoch 3, iter 90, loss: 30.944945, acc: 0.530612\n",
      "epoch 3, iter 91, loss: 29.383008, acc: 0.755102\n",
      "epoch 3, iter 92, loss: 40.337154, acc: 0.551020\n",
      "epoch 3, iter 93, loss: 42.425321, acc: 0.448980\n",
      "epoch 3, iter 94, loss: 36.678494, acc: 0.693878\n",
      "epoch 3, iter 95, loss: 18.864326, acc: 0.877551\n",
      "epoch 3, iter 96, loss: 27.309093, acc: 0.612245\n",
      "epoch 3, iter 97, loss: 32.977163, acc: 0.632653\n",
      "epoch 3, iter 98, loss: 33.614063, acc: 0.612245\n",
      "epoch 3, iter 99, loss: 26.150204, acc: 0.734694\n",
      "epoch 3, iter 100, loss: 41.691703, acc: 0.530612\n",
      "epoch 3, iter 101, loss: 28.904868, acc: 0.653061\n",
      "epoch 3, iter 102, loss: 27.815445, acc: 0.795918\n",
      "epoch 3, iter 103, loss: 24.874862, acc: 0.775510\n",
      "epoch 3, iter 104, loss: 37.063031, acc: 0.591837\n",
      "epoch 3, iter 105, loss: 31.556629, acc: 0.673469\n",
      "epoch 3, iter 106, loss: 24.450227, acc: 0.795918\n",
      "epoch 3, iter 107, loss: 20.491404, acc: 0.755102\n",
      "epoch 3, iter 108, loss: 31.589742, acc: 0.510204\n",
      "epoch 3, iter 109, loss: 27.759605, acc: 0.632653\n",
      "epoch 3, iter 110, loss: 30.333043, acc: 0.591837\n",
      "epoch 3, iter 111, loss: 41.342559, acc: 0.510204\n",
      "epoch 3, iter 112, loss: 34.310714, acc: 0.632653\n",
      "epoch 3, iter 113, loss: 42.664727, acc: 0.489796\n",
      "epoch 3, iter 114, loss: 33.494738, acc: 0.469388\n",
      "epoch 3, iter 115, loss: 29.944962, acc: 0.612245\n",
      "epoch 3, iter 116, loss: 41.239622, acc: 0.632653\n",
      "epoch 3, iter 117, loss: 28.984226, acc: 0.734694\n",
      "epoch 3, iter 118, loss: 34.289366, acc: 0.673469\n",
      "epoch 3, iter 119, loss: 32.219511, acc: 0.816327\n",
      "epoch 3, iter 120, loss: 28.983068, acc: 0.489796\n",
      "epoch 3, iter 121, loss: 32.170426, acc: 0.632653\n",
      "epoch 3, iter 122, loss: 28.584773, acc: 0.571429\n",
      "epoch 3, iter 123, loss: 32.115094, acc: 0.714286\n",
      "epoch 3, iter 124, loss: 37.552873, acc: 0.632653\n",
      "epoch 3, iter 125, loss: 34.415360, acc: 0.571429\n",
      "epoch 3, iter 126, loss: 25.675214, acc: 0.857143\n",
      "epoch 3, iter 127, loss: 40.145493, acc: 0.551020\n",
      "epoch 3, iter 128, loss: 31.534734, acc: 0.653061\n",
      "epoch 3, iter 129, loss: 25.523932, acc: 0.734694\n",
      "epoch 3, iter 130, loss: 25.632770, acc: 0.816327\n",
      "epoch 3, iter 131, loss: 27.328259, acc: 0.734694\n",
      "epoch 3, iter 132, loss: 34.408650, acc: 0.571429\n",
      "epoch 3, iter 133, loss: 23.263757, acc: 0.795918\n",
      "epoch 3, iter 134, loss: 37.941169, acc: 0.489796\n",
      "epoch 3, iter 135, loss: 34.740104, acc: 0.591837\n",
      "epoch 3, iter 136, loss: 34.752025, acc: 0.469388\n",
      "epoch 3, iter 137, loss: 32.156719, acc: 0.734694\n",
      "epoch 3, iter 138, loss: 29.116392, acc: 0.755102\n",
      "epoch 3, iter 139, loss: 27.042893, acc: 0.714286\n",
      "epoch 3, iter 140, loss: 31.283943, acc: 0.632653\n",
      "epoch 3, iter 141, loss: 21.842796, acc: 0.836735\n",
      "epoch 3, iter 142, loss: 32.787809, acc: 0.530612\n",
      "epoch 3, iter 143, loss: 28.957990, acc: 0.714286\n",
      "epoch 3, iter 144, loss: 32.996430, acc: 0.653061\n",
      "epoch 3, iter 145, loss: 18.773578, acc: 0.714286\n",
      "epoch 3, iter 146, loss: 28.250990, acc: 0.673469\n",
      "epoch 3, iter 147, loss: 28.604010, acc: 0.653061\n",
      "epoch 3, iter 148, loss: 29.143533, acc: 0.653061\n",
      "epoch 3, iter 149, loss: 22.178545, acc: 0.816327\n",
      "epoch 3, iter 150, loss: 29.803295, acc: 0.734694\n",
      "epoch 3, iter 151, loss: 32.777575, acc: 0.653061\n",
      "epoch 3, iter 152, loss: 31.916394, acc: 0.653061\n",
      "epoch 3, iter 153, loss: 35.616478, acc: 0.591837\n",
      "epoch 3, iter 154, loss: 34.539409, acc: 0.591837\n",
      "epoch 3, iter 155, loss: 30.408587, acc: 0.612245\n",
      "epoch 3, iter 156, loss: 29.240035, acc: 0.551020\n",
      "epoch 3, iter 157, loss: 31.375565, acc: 0.632653\n",
      "epoch 3, iter 158, loss: 22.074647, acc: 0.795918\n",
      "epoch 3, iter 159, loss: 37.059456, acc: 0.551020\n",
      "epoch 3, iter 160, loss: 29.162226, acc: 0.530612\n",
      "epoch 3, iter 161, loss: 25.998423, acc: 0.714286\n",
      "epoch 3, iter 162, loss: 31.322448, acc: 0.693878\n",
      "epoch 3, iter 163, loss: 34.398262, acc: 0.530612\n",
      "epoch 3, iter 164, loss: 32.315779, acc: 0.612245\n",
      "epoch 3, iter 165, loss: 24.089929, acc: 0.795918\n",
      "epoch 3, iter 166, loss: 25.799409, acc: 0.632653\n",
      "epoch 3, iter 167, loss: 27.363120, acc: 0.632653\n",
      "epoch 3, iter 168, loss: 29.292875, acc: 0.714286\n",
      "epoch 3, iter 169, loss: 36.865713, acc: 0.673469\n",
      "epoch 3, iter 170, loss: 36.197554, acc: 0.755102\n",
      "epoch 3, iter 171, loss: 30.096485, acc: 0.551020\n",
      "epoch 3, iter 172, loss: 30.765640, acc: 0.734694\n",
      "epoch 3, iter 173, loss: 36.357538, acc: 0.571429\n",
      "epoch 3, iter 174, loss: 30.844674, acc: 0.510204\n",
      "epoch 3, iter 175, loss: 23.228597, acc: 0.612245\n",
      "epoch 3, iter 176, loss: 28.212889, acc: 0.734694\n",
      "epoch 3, iter 177, loss: 28.804389, acc: 0.653061\n",
      "epoch 3, iter 178, loss: 42.071946, acc: 0.510204\n",
      "epoch 3, iter 179, loss: 25.751527, acc: 0.653061\n",
      "epoch 3, iter 180, loss: 24.919771, acc: 0.795918\n",
      "epoch 3, iter 181, loss: 35.904094, acc: 0.673469\n",
      "epoch 3, iter 182, loss: 30.643803, acc: 0.571429\n",
      "epoch 3, iter 183, loss: 34.466934, acc: 0.632653\n",
      "epoch 3, iter 184, loss: 33.426300, acc: 0.653061\n",
      "epoch 3, iter 185, loss: 36.666080, acc: 0.530612\n",
      "epoch 3, iter 186, loss: 23.288238, acc: 0.836735\n",
      "epoch 3, iter 187, loss: 33.722811, acc: 0.591837\n",
      "epoch 3, iter 188, loss: 42.575287, acc: 0.408163\n",
      "epoch 3, iter 189, loss: 38.789238, acc: 0.571429\n",
      "epoch 3, iter 190, loss: 30.555574, acc: 0.693878\n",
      "epoch 3, iter 191, loss: 28.650555, acc: 0.714286\n",
      "epoch 3, iter 192, loss: 31.437845, acc: 0.653061\n",
      "epoch 3, iter 193, loss: 33.731456, acc: 0.591837\n",
      "epoch 3, iter 194, loss: 26.414286, acc: 0.755102\n",
      "epoch 3, iter 195, loss: 37.115820, acc: 0.530612\n",
      "epoch 3, iter 196, loss: 26.739665, acc: 0.714286\n",
      "epoch 3, iter 197, loss: 33.852841, acc: 0.612245\n",
      "epoch 3, iter 198, loss: 29.413102, acc: 0.734694\n",
      "epoch 3, iter 199, loss: 40.611299, acc: 0.551020\n",
      "epoch 3, iter 200, loss: 33.123906, acc: 0.530612\n",
      "epoch 3, iter 201, loss: 25.273813, acc: 0.857143\n",
      "epoch 3, iter 202, loss: 27.123740, acc: 0.612245\n",
      "epoch 3, iter 203, loss: 35.758168, acc: 0.510204\n",
      "epoch 3, iter 204, loss: 31.854848, acc: 0.571429\n",
      "epoch 3, iter 205, loss: 36.666795, acc: 0.367347\n",
      "epoch 3, iter 206, loss: 33.926395, acc: 0.612245\n",
      "epoch 3, iter 207, loss: 38.921084, acc: 0.571429\n",
      "epoch 3, iter 208, loss: 30.582422, acc: 0.795918\n",
      "epoch 3, iter 209, loss: 29.437014, acc: 0.693878\n",
      "epoch 3, iter 210, loss: 34.668297, acc: 0.571429\n",
      "epoch 3, iter 211, loss: 23.060287, acc: 0.795918\n",
      "epoch 3, iter 212, loss: 26.020492, acc: 0.571429\n",
      "epoch 3, iter 213, loss: 22.816115, acc: 0.795918\n",
      "epoch 3, iter 214, loss: 22.715465, acc: 0.775510\n",
      "epoch 3, iter 215, loss: 39.739422, acc: 0.632653\n",
      "epoch 3, iter 216, loss: 31.211996, acc: 0.734694\n",
      "epoch 3, iter 217, loss: 34.778360, acc: 0.489796\n",
      "epoch 3, iter 218, loss: 29.517920, acc: 0.734694\n",
      "epoch 3, iter 219, loss: 26.141315, acc: 0.714286\n",
      "epoch 3, iter 220, loss: 31.626742, acc: 0.551020\n",
      "epoch 3, iter 221, loss: 23.403668, acc: 0.755102\n",
      "epoch 3, iter 222, loss: 36.885637, acc: 0.530612\n",
      "epoch 3, iter 223, loss: 25.122248, acc: 0.653061\n",
      "epoch 3, iter 224, loss: 24.238717, acc: 0.632653\n",
      "epoch 3, iter 225, loss: 29.358014, acc: 0.714286\n",
      "epoch 3, iter 226, loss: 28.225427, acc: 0.571429\n",
      "epoch 3, iter 227, loss: 28.124581, acc: 0.612245\n",
      "epoch 3, iter 228, loss: 28.030736, acc: 0.612245\n",
      "epoch 3, iter 229, loss: 17.207405, acc: 0.897959\n",
      "epoch 3, iter 230, loss: 31.782756, acc: 0.734694\n",
      "epoch 3, iter 231, loss: 24.643273, acc: 0.755102\n",
      "epoch 3, iter 232, loss: 34.623201, acc: 0.551020\n",
      "epoch 3, iter 233, loss: 33.490155, acc: 0.653061\n",
      "epoch 3, iter 234, loss: 24.335694, acc: 0.795918\n",
      "epoch 3, iter 235, loss: 29.201237, acc: 0.714286\n",
      "epoch 3, iter 236, loss: 24.320919, acc: 0.755102\n",
      "epoch 3, iter 237, loss: 35.116557, acc: 0.673469\n",
      "epoch 3, iter 238, loss: 37.772846, acc: 0.510204\n",
      "epoch 3, iter 239, loss: 34.691705, acc: 0.469388\n",
      "epoch 3, iter 240, loss: 29.847998, acc: 0.775510\n",
      "epoch 3, iter 241, loss: 29.065577, acc: 0.714286\n",
      "epoch 3, iter 242, loss: 36.651702, acc: 0.510204\n",
      "epoch 3, iter 243, loss: 30.235847, acc: 0.448980\n",
      "epoch 3, iter 244, loss: 36.017816, acc: 0.530612\n",
      "epoch 3, iter 245, loss: 34.498955, acc: 0.612245\n",
      "epoch 3, iter 246, loss: 36.879823, acc: 0.530612\n",
      "epoch 3, iter 247, loss: 35.391222, acc: 0.714286\n",
      "epoch 3, iter 248, loss: 33.007499, acc: 0.775510\n",
      "epoch 3, iter 249, loss: 40.221930, acc: 0.632653\n",
      "epoch 3, iter 250, loss: 31.398534, acc: 0.755102\n",
      "epoch 3, iter 251, loss: 32.544087, acc: 0.632653\n",
      "epoch 3, iter 252, loss: 32.441191, acc: 0.551020\n",
      "epoch 3, iter 253, loss: 30.127075, acc: 0.673469\n",
      "epoch 3, iter 254, loss: 22.218115, acc: 0.734694\n",
      "epoch 3, iter 255, loss: 30.013957, acc: 0.612245\n",
      "epoch 3, iter 256, loss: 31.417761, acc: 0.734694\n",
      "epoch 3, iter 257, loss: 32.594403, acc: 0.734694\n",
      "epoch 3, iter 258, loss: 35.051555, acc: 0.510204\n",
      "epoch 3, iter 259, loss: 24.377515, acc: 0.734694\n",
      "epoch 3, iter 260, loss: 39.892643, acc: 0.408163\n",
      "epoch 3, iter 261, loss: 30.122387, acc: 0.836735\n",
      "epoch 3, iter 262, loss: 29.215254, acc: 0.632653\n",
      "epoch 3, iter 263, loss: 35.318652, acc: 0.693878\n",
      "epoch 3, iter 264, loss: 26.820603, acc: 0.795918\n",
      "epoch 3, iter 265, loss: 24.271466, acc: 0.877551\n",
      "epoch 3, iter 266, loss: 35.964196, acc: 0.551020\n",
      "epoch 3, iter 267, loss: 34.945879, acc: 0.551020\n",
      "epoch 3, iter 268, loss: 29.424428, acc: 0.591837\n",
      "epoch 3, iter 269, loss: 24.640545, acc: 0.673469\n",
      "epoch 3, iter 270, loss: 31.543043, acc: 0.755102\n",
      "epoch 3, iter 271, loss: 23.120643, acc: 0.795918\n",
      "epoch 3, iter 272, loss: 20.379967, acc: 0.897959\n",
      "epoch 3, iter 273, loss: 36.279572, acc: 0.571429\n",
      "epoch 3, iter 274, loss: 31.865319, acc: 0.612245\n",
      "epoch 3, iter 275, loss: 34.126357, acc: 0.551020\n",
      "epoch 3, iter 276, loss: 19.798029, acc: 0.877551\n",
      "epoch 3, iter 277, loss: 31.283542, acc: 0.836735\n",
      "epoch 3, iter 278, loss: 27.004391, acc: 0.673469\n",
      "epoch 3, iter 279, loss: 28.858224, acc: 0.591837\n",
      "epoch 3, iter 280, loss: 39.032705, acc: 0.653061\n",
      "epoch 3, iter 281, loss: 34.379330, acc: 0.489796\n",
      "epoch 3, iter 282, loss: 37.008315, acc: 0.673469\n",
      "epoch 3, iter 283, loss: 36.117005, acc: 0.510204\n",
      "epoch 3, iter 284, loss: 28.435747, acc: 0.734694\n",
      "epoch 3, iter 285, loss: 28.816092, acc: 0.693878\n",
      "epoch 3, iter 286, loss: 27.801802, acc: 0.693878\n",
      "epoch 3, iter 287, loss: 29.155379, acc: 0.653061\n",
      "epoch 3, iter 288, loss: 25.434162, acc: 0.673469\n",
      "epoch 3, iter 289, loss: 29.573279, acc: 0.653061\n",
      "epoch 3, iter 290, loss: 30.684650, acc: 0.673469\n",
      "epoch 3, iter 291, loss: 30.214905, acc: 0.653061\n",
      "epoch 3, iter 292, loss: 26.134931, acc: 0.714286\n",
      "epoch 3, iter 293, loss: 27.056131, acc: 0.693878\n",
      "epoch 3, iter 294, loss: 23.991536, acc: 0.795918\n",
      "epoch 3, iter 295, loss: 34.610144, acc: 0.673469\n",
      "epoch 3, iter 296, loss: 35.028909, acc: 0.734694\n",
      "epoch 3, iter 297, loss: 30.915369, acc: 0.714286\n",
      "epoch 3, iter 298, loss: 30.473164, acc: 0.489796\n",
      "epoch 3, iter 299, loss: 32.305803, acc: 0.653061\n",
      "epoch 3, iter 300, loss: 21.079214, acc: 0.775510\n",
      "epoch 3, iter 301, loss: 26.407084, acc: 0.673469\n",
      "epoch 3, iter 302, loss: 33.049777, acc: 0.591837\n",
      "epoch 3, iter 303, loss: 32.330749, acc: 0.571429\n",
      "epoch 3, iter 304, loss: 31.256041, acc: 0.551020\n",
      "epoch 3, iter 305, loss: 36.452256, acc: 0.551020\n",
      "epoch 3, iter 306, loss: 34.713268, acc: 0.612245\n",
      "epoch 3, iter 307, loss: 30.812106, acc: 0.632653\n",
      "epoch 3, iter 308, loss: 38.200344, acc: 0.530612\n",
      "epoch 3, iter 309, loss: 31.244263, acc: 0.612245\n",
      "epoch 3, iter 310, loss: 25.977593, acc: 0.714286\n",
      "epoch 3, iter 311, loss: 23.844686, acc: 0.755102\n",
      "epoch 3, iter 312, loss: 21.705718, acc: 0.775510\n",
      "epoch 3, iter 313, loss: 25.285941, acc: 0.795918\n",
      "epoch 3, iter 314, loss: 26.273758, acc: 0.673469\n",
      "epoch 3, iter 315, loss: 28.828076, acc: 0.571429\n",
      "epoch 3, iter 316, loss: 25.453546, acc: 0.775510\n",
      "epoch 3, iter 317, loss: 22.216438, acc: 0.714286\n",
      "epoch 3, iter 318, loss: 39.026538, acc: 0.612245\n",
      "epoch 3, iter 319, loss: 38.011357, acc: 0.510204\n",
      "epoch 3, iter 320, loss: 25.898173, acc: 0.571429\n",
      "epoch 3, iter 321, loss: 28.541014, acc: 0.755102\n",
      "epoch 3, iter 322, loss: 38.560390, acc: 0.489796\n",
      "epoch 3, iter 323, loss: 29.965093, acc: 0.530612\n",
      "epoch 3, iter 324, loss: 28.035602, acc: 0.591837\n",
      "epoch 3, iter 325, loss: 22.666979, acc: 0.816327\n",
      "epoch 3, iter 326, loss: 34.578486, acc: 0.530612\n",
      "epoch 3, iter 327, loss: 24.478961, acc: 0.795918\n",
      "epoch 3, iter 328, loss: 28.770225, acc: 0.714286\n",
      "epoch 3, iter 329, loss: 32.225619, acc: 0.653061\n",
      "epoch 3, iter 330, loss: 31.360613, acc: 0.653061\n",
      "epoch 3, iter 331, loss: 34.620505, acc: 0.428571\n",
      "epoch 3, iter 332, loss: 39.039180, acc: 0.530612\n",
      "epoch 3, iter 333, loss: 31.665310, acc: 0.489796\n",
      "epoch 3, iter 334, loss: 32.805719, acc: 0.653061\n",
      "epoch 3, iter 335, loss: 23.441158, acc: 0.836735\n",
      "epoch 3, iter 336, loss: 25.207382, acc: 0.795918\n",
      "epoch 3, iter 337, loss: 31.579374, acc: 0.632653\n",
      "epoch 3, iter 338, loss: 26.871247, acc: 0.857143\n",
      "epoch 3, iter 339, loss: 26.526417, acc: 0.673469\n",
      "epoch 3, iter 340, loss: 39.784818, acc: 0.653061\n",
      "epoch 3, iter 341, loss: 26.230370, acc: 0.857143\n",
      "epoch 3, iter 342, loss: 41.886061, acc: 0.489796\n",
      "epoch 3, iter 343, loss: 34.824131, acc: 0.714286\n",
      "epoch 3, iter 344, loss: 32.980361, acc: 0.551020\n",
      "epoch 3, iter 345, loss: 32.743639, acc: 0.571429\n",
      "epoch 3, iter 346, loss: 29.339531, acc: 0.795918\n",
      "epoch 3, iter 347, loss: 24.253214, acc: 0.632653\n",
      "epoch 3, iter 348, loss: 30.800704, acc: 0.591837\n",
      "epoch 3, iter 349, loss: 34.747232, acc: 0.612245\n",
      "epoch 3, iter 350, loss: 30.620367, acc: 0.530612\n",
      "epoch 3, iter 351, loss: 32.312032, acc: 0.571429\n",
      "epoch 3, iter 352, loss: 36.861227, acc: 0.591837\n",
      "epoch 3, iter 353, loss: 38.462289, acc: 0.591837\n",
      "epoch 3, iter 354, loss: 31.739410, acc: 0.653061\n",
      "epoch 3, iter 355, loss: 30.532162, acc: 0.653061\n",
      "epoch 3, iter 356, loss: 29.392409, acc: 0.714286\n",
      "epoch 3, iter 357, loss: 33.514049, acc: 0.571429\n",
      "epoch 3, iter 358, loss: 34.705636, acc: 0.591837\n",
      "epoch 3, iter 359, loss: 26.905520, acc: 0.673469\n",
      "epoch 3, iter 360, loss: 26.386971, acc: 0.673469\n",
      "epoch 3, iter 361, loss: 32.382982, acc: 0.591837\n",
      "epoch 3, iter 362, loss: 37.025279, acc: 0.530612\n",
      "epoch 3, iter 363, loss: 29.872600, acc: 0.591837\n",
      "epoch 3, iter 364, loss: 40.387939, acc: 0.530612\n",
      "epoch 3, iter 365, loss: 27.973398, acc: 0.632653\n",
      "epoch 3, iter 366, loss: 38.935598, acc: 0.489796\n",
      "epoch 3, iter 367, loss: 39.452800, acc: 0.530612\n",
      "epoch 3, iter 368, loss: 31.312108, acc: 0.489796\n",
      "epoch 3, iter 369, loss: 31.118530, acc: 0.510204\n",
      "epoch 3, iter 370, loss: 33.129771, acc: 0.448980\n",
      "epoch 3, iter 371, loss: 30.116208, acc: 0.734694\n",
      "epoch 3, iter 372, loss: 38.531512, acc: 0.530612\n",
      "epoch 3, iter 373, loss: 30.961882, acc: 0.673469\n",
      "epoch 3, iter 374, loss: 37.602035, acc: 0.428571\n",
      "epoch 3, iter 375, loss: 31.714298, acc: 0.714286\n",
      "epoch 3, iter 376, loss: 31.065679, acc: 0.591837\n",
      "epoch 3, iter 377, loss: 25.080851, acc: 0.714286\n",
      "epoch 3, iter 378, loss: 28.674347, acc: 0.734694\n",
      "epoch 3, iter 379, loss: 37.450936, acc: 0.612245\n",
      "epoch 3, iter 380, loss: 37.776681, acc: 0.653061\n",
      "epoch 3, iter 381, loss: 35.412123, acc: 0.632653\n",
      "epoch 3, iter 382, loss: 25.375259, acc: 0.816327\n",
      "epoch 3, iter 383, loss: 24.968325, acc: 0.653061\n",
      "epoch 3, iter 384, loss: 32.073041, acc: 0.653061\n",
      "epoch 3, iter 385, loss: 20.267736, acc: 0.897959\n",
      "epoch 3, iter 386, loss: 38.939843, acc: 0.551020\n",
      "epoch 3, iter 387, loss: 32.005159, acc: 0.591837\n",
      "epoch 3, iter 388, loss: 28.566501, acc: 0.653061\n",
      "epoch 3, iter 389, loss: 31.570762, acc: 0.673469\n",
      "epoch 3, iter 390, loss: 32.401557, acc: 0.612245\n",
      "epoch 3, iter 391, loss: 27.556499, acc: 0.714286\n",
      "epoch 3, iter 392, loss: 27.327734, acc: 0.857143\n",
      "epoch 3, iter 393, loss: 31.302762, acc: 0.632653\n",
      "epoch 3, iter 394, loss: 25.135817, acc: 0.734694\n",
      "epoch 3, iter 395, loss: 32.759322, acc: 0.530612\n",
      "epoch 3, iter 396, loss: 27.406854, acc: 0.571429\n",
      "epoch 3, iter 397, loss: 20.718853, acc: 0.755102\n",
      "epoch 3, iter 398, loss: 36.099278, acc: 0.591837\n",
      "epoch 3, iter 399, loss: 26.739601, acc: 0.714286\n",
      "epoch 3, iter 400, loss: 38.592148, acc: 0.530612\n",
      "epoch 3, iter 401, loss: 31.714173, acc: 0.673469\n",
      "epoch 3, iter 402, loss: 34.300663, acc: 0.734694\n",
      "epoch 3, iter 403, loss: 37.166694, acc: 0.632653\n",
      "epoch 3, iter 404, loss: 35.947264, acc: 0.551020\n",
      "epoch 3, iter 405, loss: 31.138818, acc: 0.612245\n",
      "epoch 3, iter 406, loss: 27.295001, acc: 0.673469\n",
      "epoch 3, iter 407, loss: 33.019934, acc: 0.530612\n",
      "epoch 3, iter 408, loss: 31.451185, acc: 0.612245\n",
      "epoch 3, iter 409, loss: 23.607842, acc: 0.714286\n",
      "epoch 3, iter 410, loss: 35.218120, acc: 0.448980\n",
      "epoch 3, iter 411, loss: 31.240871, acc: 0.612245\n",
      "epoch 3, iter 412, loss: 30.193045, acc: 0.816327\n",
      "epoch 3, iter 413, loss: 26.498416, acc: 0.714286\n",
      "epoch 3, iter 414, loss: 33.888913, acc: 0.530612\n",
      "epoch 3, iter 415, loss: 31.480983, acc: 0.591837\n",
      "epoch 3, iter 416, loss: 27.333189, acc: 0.714286\n",
      "epoch 3, iter 417, loss: 33.058638, acc: 0.612245\n",
      "epoch 3, iter 418, loss: 32.545113, acc: 0.693878\n",
      "epoch 3, iter 419, loss: 29.916840, acc: 0.632653\n",
      "epoch 3, iter 420, loss: 36.399252, acc: 0.612245\n",
      "epoch 3, iter 421, loss: 25.720042, acc: 0.714286\n",
      "epoch 3, iter 422, loss: 28.071934, acc: 0.714286\n",
      "epoch 3, iter 423, loss: 36.889274, acc: 0.551020\n",
      "epoch 3, iter 424, loss: 28.507378, acc: 0.775510\n",
      "epoch 3, iter 425, loss: 27.040551, acc: 0.653061\n",
      "epoch 3, iter 426, loss: 31.002128, acc: 0.612245\n",
      "epoch 3, iter 427, loss: 37.058422, acc: 0.591837\n",
      "epoch 3, iter 428, loss: 28.776972, acc: 0.734694\n",
      "epoch 3, iter 429, loss: 29.447324, acc: 0.571429\n",
      "epoch 3, iter 430, loss: 28.571418, acc: 0.632653\n",
      "epoch 3, iter 431, loss: 33.998943, acc: 0.714286\n",
      "epoch 3, iter 432, loss: 25.570367, acc: 0.653061\n",
      "epoch 3, iter 433, loss: 28.977028, acc: 0.571429\n",
      "epoch 3, iter 434, loss: 26.950920, acc: 0.571429\n",
      "epoch 3, iter 435, loss: 28.999973, acc: 0.734694\n",
      "epoch 3, iter 436, loss: 28.099451, acc: 0.714286\n",
      "epoch 3, iter 437, loss: 43.719183, acc: 0.591837\n",
      "epoch 3, iter 438, loss: 33.770641, acc: 0.591837\n",
      "epoch 3, iter 439, loss: 31.459012, acc: 0.591837\n",
      "epoch 3, iter 440, loss: 32.359019, acc: 0.632653\n",
      "epoch 3, iter 441, loss: 27.873125, acc: 0.673469\n",
      "epoch 3, iter 442, loss: 31.756555, acc: 0.591837\n",
      "epoch 3, iter 443, loss: 26.017966, acc: 0.816327\n",
      "epoch 3, iter 444, loss: 28.385342, acc: 0.714286\n",
      "epoch 3, iter 445, loss: 45.260983, acc: 0.632653\n",
      "epoch 3, iter 446, loss: 29.929884, acc: 0.632653\n",
      "epoch 3, iter 447, loss: 32.608437, acc: 0.693878\n",
      "epoch 3, iter 448, loss: 32.991972, acc: 0.489796\n",
      "epoch 3, iter 449, loss: 19.374602, acc: 0.795918\n",
      "epoch 3, iter 450, loss: 34.544147, acc: 0.612245\n",
      "epoch 3, iter 451, loss: 27.407030, acc: 0.755102\n",
      "epoch 3, iter 452, loss: 28.206787, acc: 0.714286\n",
      "epoch 3, iter 453, loss: 33.177598, acc: 0.510204\n",
      "epoch 3, iter 454, loss: 27.577471, acc: 0.632653\n",
      "epoch 3, iter 455, loss: 30.251896, acc: 0.612245\n",
      "epoch 3, iter 456, loss: 28.651632, acc: 0.591837\n",
      "epoch 3, iter 457, loss: 30.705315, acc: 0.714286\n",
      "epoch 3, iter 458, loss: 22.546202, acc: 0.775510\n",
      "epoch 3, iter 459, loss: 33.264217, acc: 0.591837\n",
      "epoch 3, iter 460, loss: 33.666476, acc: 0.530612\n",
      "epoch 3, iter 461, loss: 29.399338, acc: 0.612245\n",
      "epoch 3, iter 462, loss: 32.990467, acc: 0.632653\n",
      "epoch 3, iter 463, loss: 32.826631, acc: 0.571429\n",
      "epoch 3, iter 464, loss: 29.347782, acc: 0.795918\n",
      "epoch 3, iter 465, loss: 31.834158, acc: 0.653061\n",
      "epoch 3, iter 466, loss: 36.234414, acc: 0.591837\n",
      "epoch 3, iter 467, loss: 33.981412, acc: 0.591837\n",
      "epoch 3, iter 468, loss: 31.885247, acc: 0.734694\n",
      "epoch 3, iter 469, loss: 32.756363, acc: 0.551020\n",
      "epoch 3, iter 470, loss: 39.096515, acc: 0.448980\n",
      "epoch 3, iter 471, loss: 29.692086, acc: 0.795918\n",
      "epoch 3, iter 472, loss: 28.570646, acc: 0.591837\n",
      "epoch 3, iter 473, loss: 28.556048, acc: 0.693878\n",
      "epoch 3, iter 474, loss: 32.086444, acc: 0.632653\n",
      "epoch 3, iter 475, loss: 33.147230, acc: 0.571429\n",
      "epoch 3, iter 476, loss: 25.097407, acc: 0.632653\n",
      "epoch 3, iter 477, loss: 37.053179, acc: 0.571429\n",
      "epoch 3, iter 478, loss: 30.454279, acc: 0.714286\n",
      "epoch 3, iter 479, loss: 32.054672, acc: 0.693878\n",
      "epoch 3, iter 480, loss: 27.865084, acc: 0.673469\n",
      "epoch 3, iter 481, loss: 26.066992, acc: 0.632653\n",
      "epoch 3, iter 482, loss: 26.445937, acc: 0.775510\n",
      "epoch 3, iter 483, loss: 29.448753, acc: 0.673469\n",
      "epoch 3, iter 484, loss: 28.648262, acc: 0.653061\n",
      "epoch 3, iter 485, loss: 27.203185, acc: 0.673469\n",
      "epoch 3, iter 486, loss: 34.051693, acc: 0.571429\n",
      "epoch 3, iter 487, loss: 26.577767, acc: 0.714286\n",
      "epoch 3, iter 488, loss: 23.665727, acc: 0.755102\n",
      "epoch 3, iter 489, loss: 30.996107, acc: 0.816327\n",
      "epoch 3, iter 490, loss: 32.240360, acc: 0.673469\n",
      "epoch 3, iter 491, loss: 30.854282, acc: 0.775510\n",
      "epoch 3, iter 492, loss: 31.621114, acc: 0.632653\n",
      "epoch 3, iter 493, loss: 23.958293, acc: 0.612245\n",
      "epoch 3, iter 494, loss: 32.277187, acc: 0.591837\n",
      "epoch 3, iter 495, loss: 33.079273, acc: 0.448980\n",
      "epoch 3, iter 496, loss: 26.174027, acc: 0.673469\n",
      "epoch 3, iter 497, loss: 35.039939, acc: 0.530612\n",
      "epoch 3, iter 498, loss: 35.750278, acc: 0.530612\n",
      "epoch 3, iter 499, loss: 34.734920, acc: 0.591837\n",
      "epoch 3, acc: 0.648980\n",
      "epoch 4, iter 0, loss: 36.791121, acc: 0.612245\n",
      "epoch 4, iter 1, loss: 39.368544, acc: 0.673469\n",
      "epoch 4, iter 2, loss: 37.688354, acc: 0.612245\n",
      "epoch 4, iter 3, loss: 28.948890, acc: 0.571429\n",
      "epoch 4, iter 4, loss: 27.718361, acc: 0.632653\n",
      "epoch 4, iter 5, loss: 29.622452, acc: 0.693878\n",
      "epoch 4, iter 6, loss: 28.717904, acc: 0.734694\n",
      "epoch 4, iter 7, loss: 31.187652, acc: 0.693878\n",
      "epoch 4, iter 8, loss: 34.301997, acc: 0.551020\n",
      "epoch 4, iter 9, loss: 25.498902, acc: 0.714286\n",
      "epoch 4, iter 10, loss: 34.251677, acc: 0.591837\n",
      "epoch 4, iter 11, loss: 39.797822, acc: 0.530612\n",
      "epoch 4, iter 12, loss: 27.731923, acc: 0.775510\n",
      "epoch 4, iter 13, loss: 34.229722, acc: 0.632653\n",
      "epoch 4, iter 14, loss: 29.321576, acc: 0.551020\n",
      "epoch 4, iter 15, loss: 21.873888, acc: 0.775510\n",
      "epoch 4, iter 16, loss: 35.091409, acc: 0.551020\n",
      "epoch 4, iter 17, loss: 24.967990, acc: 0.693878\n",
      "epoch 4, iter 18, loss: 38.515023, acc: 0.571429\n",
      "epoch 4, iter 19, loss: 21.081895, acc: 0.836735\n",
      "epoch 4, iter 20, loss: 23.160975, acc: 0.755102\n",
      "epoch 4, iter 21, loss: 29.804684, acc: 0.693878\n",
      "epoch 4, iter 22, loss: 23.189877, acc: 0.693878\n",
      "epoch 4, iter 23, loss: 38.636378, acc: 0.571429\n",
      "epoch 4, iter 24, loss: 34.577715, acc: 0.632653\n",
      "epoch 4, iter 25, loss: 33.707608, acc: 0.530612\n",
      "epoch 4, iter 26, loss: 34.807615, acc: 0.489796\n",
      "epoch 4, iter 27, loss: 32.946378, acc: 0.714286\n",
      "epoch 4, iter 28, loss: 31.716704, acc: 0.612245\n",
      "epoch 4, iter 29, loss: 22.416224, acc: 0.816327\n",
      "epoch 4, iter 30, loss: 30.895325, acc: 0.571429\n",
      "epoch 4, iter 31, loss: 34.511126, acc: 0.489796\n",
      "epoch 4, iter 32, loss: 30.619482, acc: 0.632653\n",
      "epoch 4, iter 33, loss: 22.668269, acc: 0.775510\n",
      "epoch 4, iter 34, loss: 30.273424, acc: 0.632653\n",
      "epoch 4, iter 35, loss: 38.147546, acc: 0.612245\n",
      "epoch 4, iter 36, loss: 32.269502, acc: 0.653061\n",
      "epoch 4, iter 37, loss: 25.587550, acc: 0.795918\n",
      "epoch 4, iter 38, loss: 38.698166, acc: 0.510204\n",
      "epoch 4, iter 39, loss: 33.298150, acc: 0.714286\n",
      "epoch 4, iter 40, loss: 33.101008, acc: 0.530612\n",
      "epoch 4, iter 41, loss: 29.384156, acc: 0.693878\n",
      "epoch 4, iter 42, loss: 35.955782, acc: 0.571429\n",
      "epoch 4, iter 43, loss: 27.223249, acc: 0.755102\n",
      "epoch 4, iter 44, loss: 26.822735, acc: 0.755102\n",
      "epoch 4, iter 45, loss: 32.931055, acc: 0.632653\n",
      "epoch 4, iter 46, loss: 33.653953, acc: 0.530612\n",
      "epoch 4, iter 47, loss: 31.370736, acc: 0.653061\n",
      "epoch 4, iter 48, loss: 28.228455, acc: 0.714286\n",
      "epoch 4, iter 49, loss: 24.131491, acc: 0.653061\n",
      "epoch 4, iter 50, loss: 29.199674, acc: 0.714286\n",
      "epoch 4, iter 51, loss: 34.634861, acc: 0.612245\n",
      "epoch 4, iter 52, loss: 32.535514, acc: 0.653061\n",
      "epoch 4, iter 53, loss: 34.267931, acc: 0.693878\n",
      "epoch 4, iter 54, loss: 29.963749, acc: 0.673469\n",
      "epoch 4, iter 55, loss: 26.743133, acc: 0.693878\n",
      "epoch 4, iter 56, loss: 20.453485, acc: 0.836735\n",
      "epoch 4, iter 57, loss: 27.470556, acc: 0.714286\n",
      "epoch 4, iter 58, loss: 30.998342, acc: 0.591837\n",
      "epoch 4, iter 59, loss: 28.120863, acc: 0.755102\n",
      "epoch 4, iter 60, loss: 31.086747, acc: 0.673469\n",
      "epoch 4, iter 61, loss: 23.961009, acc: 0.755102\n",
      "epoch 4, iter 62, loss: 34.973518, acc: 0.571429\n",
      "epoch 4, iter 63, loss: 25.184218, acc: 0.816327\n",
      "epoch 4, iter 64, loss: 32.243382, acc: 0.591837\n",
      "epoch 4, iter 65, loss: 30.559197, acc: 0.632653\n",
      "epoch 4, iter 66, loss: 27.082418, acc: 0.897959\n",
      "epoch 4, iter 67, loss: 34.791478, acc: 0.571429\n",
      "epoch 4, iter 68, loss: 25.213432, acc: 0.693878\n",
      "epoch 4, iter 69, loss: 21.368686, acc: 0.734694\n",
      "epoch 4, iter 70, loss: 25.919602, acc: 0.714286\n",
      "epoch 4, iter 71, loss: 30.515274, acc: 0.734694\n",
      "epoch 4, iter 72, loss: 26.469153, acc: 0.714286\n",
      "epoch 4, iter 73, loss: 23.959813, acc: 0.693878\n",
      "epoch 4, iter 74, loss: 29.489917, acc: 0.632653\n",
      "epoch 4, iter 75, loss: 28.550195, acc: 0.857143\n",
      "epoch 4, iter 76, loss: 29.502620, acc: 0.775510\n",
      "epoch 4, iter 77, loss: 33.448033, acc: 0.469388\n",
      "epoch 4, iter 78, loss: 33.526126, acc: 0.653061\n",
      "epoch 4, iter 79, loss: 29.392503, acc: 0.673469\n",
      "epoch 4, iter 80, loss: 21.813095, acc: 0.918367\n",
      "epoch 4, iter 81, loss: 27.830859, acc: 0.673469\n",
      "epoch 4, iter 82, loss: 31.814872, acc: 0.612245\n",
      "epoch 4, iter 83, loss: 31.028656, acc: 0.632653\n",
      "epoch 4, iter 84, loss: 21.524344, acc: 0.836735\n",
      "epoch 4, iter 85, loss: 20.696262, acc: 0.836735\n",
      "epoch 4, iter 86, loss: 28.314420, acc: 0.632653\n",
      "epoch 4, iter 87, loss: 43.296130, acc: 0.428571\n",
      "epoch 4, iter 88, loss: 24.466304, acc: 0.775510\n",
      "epoch 4, iter 89, loss: 30.917864, acc: 0.551020\n",
      "epoch 4, iter 90, loss: 30.564469, acc: 0.591837\n",
      "epoch 4, iter 91, loss: 28.744806, acc: 0.734694\n",
      "epoch 4, iter 92, loss: 39.003068, acc: 0.571429\n",
      "epoch 4, iter 93, loss: 41.000169, acc: 0.448980\n",
      "epoch 4, iter 94, loss: 34.839275, acc: 0.714286\n",
      "epoch 4, iter 95, loss: 19.228595, acc: 0.877551\n",
      "epoch 4, iter 96, loss: 26.062817, acc: 0.653061\n",
      "epoch 4, iter 97, loss: 32.027795, acc: 0.653061\n",
      "epoch 4, iter 98, loss: 32.299805, acc: 0.632653\n",
      "epoch 4, iter 99, loss: 25.510475, acc: 0.755102\n",
      "epoch 4, iter 100, loss: 40.615294, acc: 0.591837\n",
      "epoch 4, iter 101, loss: 27.612574, acc: 0.734694\n",
      "epoch 4, iter 102, loss: 26.372711, acc: 0.816327\n",
      "epoch 4, iter 103, loss: 24.181214, acc: 0.755102\n",
      "epoch 4, iter 104, loss: 37.451745, acc: 0.612245\n",
      "epoch 4, iter 105, loss: 31.167084, acc: 0.693878\n",
      "epoch 4, iter 106, loss: 24.355074, acc: 0.755102\n",
      "epoch 4, iter 107, loss: 20.411800, acc: 0.775510\n",
      "epoch 4, iter 108, loss: 30.634665, acc: 0.530612\n",
      "epoch 4, iter 109, loss: 27.486802, acc: 0.653061\n",
      "epoch 4, iter 110, loss: 30.291413, acc: 0.612245\n",
      "epoch 4, iter 111, loss: 39.818567, acc: 0.489796\n",
      "epoch 4, iter 112, loss: 33.203398, acc: 0.632653\n",
      "epoch 4, iter 113, loss: 42.774476, acc: 0.469388\n",
      "epoch 4, iter 114, loss: 32.813676, acc: 0.489796\n",
      "epoch 4, iter 115, loss: 29.874404, acc: 0.612245\n",
      "epoch 4, iter 116, loss: 39.225928, acc: 0.591837\n",
      "epoch 4, iter 117, loss: 27.074079, acc: 0.755102\n",
      "epoch 4, iter 118, loss: 35.501410, acc: 0.632653\n",
      "epoch 4, iter 119, loss: 31.222025, acc: 0.775510\n",
      "epoch 4, iter 120, loss: 29.456509, acc: 0.551020\n",
      "epoch 4, iter 121, loss: 31.360700, acc: 0.632653\n",
      "epoch 4, iter 122, loss: 29.760051, acc: 0.591837\n",
      "epoch 4, iter 123, loss: 31.552358, acc: 0.673469\n",
      "epoch 4, iter 124, loss: 35.544518, acc: 0.591837\n",
      "epoch 4, iter 125, loss: 33.399550, acc: 0.510204\n",
      "epoch 4, iter 126, loss: 24.605481, acc: 0.857143\n",
      "epoch 4, iter 127, loss: 39.297833, acc: 0.612245\n",
      "epoch 4, iter 128, loss: 31.311875, acc: 0.612245\n",
      "epoch 4, iter 129, loss: 24.964721, acc: 0.673469\n",
      "epoch 4, iter 130, loss: 24.669948, acc: 0.857143\n",
      "epoch 4, iter 131, loss: 27.591255, acc: 0.795918\n",
      "epoch 4, iter 132, loss: 32.694758, acc: 0.551020\n",
      "epoch 4, iter 133, loss: 23.215553, acc: 0.775510\n",
      "epoch 4, iter 134, loss: 36.953316, acc: 0.469388\n",
      "epoch 4, iter 135, loss: 34.023313, acc: 0.591837\n",
      "epoch 4, iter 136, loss: 33.438489, acc: 0.489796\n",
      "epoch 4, iter 137, loss: 31.442518, acc: 0.714286\n",
      "epoch 4, iter 138, loss: 27.880781, acc: 0.714286\n",
      "epoch 4, iter 139, loss: 25.705847, acc: 0.673469\n",
      "epoch 4, iter 140, loss: 30.848613, acc: 0.673469\n",
      "epoch 4, iter 141, loss: 20.938610, acc: 0.836735\n",
      "epoch 4, iter 142, loss: 32.663923, acc: 0.591837\n",
      "epoch 4, iter 143, loss: 27.555535, acc: 0.693878\n",
      "epoch 4, iter 144, loss: 32.699467, acc: 0.693878\n",
      "epoch 4, iter 145, loss: 18.095321, acc: 0.714286\n",
      "epoch 4, iter 146, loss: 28.075926, acc: 0.591837\n",
      "epoch 4, iter 147, loss: 26.959162, acc: 0.632653\n",
      "epoch 4, iter 148, loss: 29.315154, acc: 0.673469\n",
      "epoch 4, iter 149, loss: 22.656585, acc: 0.857143\n",
      "epoch 4, iter 150, loss: 29.839753, acc: 0.734694\n",
      "epoch 4, iter 151, loss: 31.435325, acc: 0.693878\n",
      "epoch 4, iter 152, loss: 31.532891, acc: 0.653061\n",
      "epoch 4, iter 153, loss: 35.371176, acc: 0.591837\n",
      "epoch 4, iter 154, loss: 33.438840, acc: 0.612245\n",
      "epoch 4, iter 155, loss: 30.743269, acc: 0.653061\n",
      "epoch 4, iter 156, loss: 28.771184, acc: 0.551020\n",
      "epoch 4, iter 157, loss: 30.888869, acc: 0.591837\n",
      "epoch 4, iter 158, loss: 21.528811, acc: 0.816327\n",
      "epoch 4, iter 159, loss: 36.477325, acc: 0.530612\n",
      "epoch 4, iter 160, loss: 30.098926, acc: 0.571429\n",
      "epoch 4, iter 161, loss: 26.015165, acc: 0.673469\n",
      "epoch 4, iter 162, loss: 30.085226, acc: 0.734694\n",
      "epoch 4, iter 163, loss: 35.247332, acc: 0.571429\n",
      "epoch 4, iter 164, loss: 31.344385, acc: 0.551020\n",
      "epoch 4, iter 165, loss: 23.704433, acc: 0.816327\n",
      "epoch 4, iter 166, loss: 26.289008, acc: 0.714286\n",
      "epoch 4, iter 167, loss: 28.343171, acc: 0.571429\n",
      "epoch 4, iter 168, loss: 29.392065, acc: 0.734694\n",
      "epoch 4, iter 169, loss: 35.667932, acc: 0.612245\n",
      "epoch 4, iter 170, loss: 35.965061, acc: 0.714286\n",
      "epoch 4, iter 171, loss: 28.486366, acc: 0.612245\n",
      "epoch 4, iter 172, loss: 29.212632, acc: 0.714286\n",
      "epoch 4, iter 173, loss: 34.491140, acc: 0.591837\n",
      "epoch 4, iter 174, loss: 29.563728, acc: 0.530612\n",
      "epoch 4, iter 175, loss: 23.118589, acc: 0.591837\n",
      "epoch 4, iter 176, loss: 28.844632, acc: 0.734694\n",
      "epoch 4, iter 177, loss: 27.614308, acc: 0.632653\n",
      "epoch 4, iter 178, loss: 41.094483, acc: 0.530612\n",
      "epoch 4, iter 179, loss: 27.060398, acc: 0.653061\n",
      "epoch 4, iter 180, loss: 24.279852, acc: 0.795918\n",
      "epoch 4, iter 181, loss: 35.430758, acc: 0.653061\n",
      "epoch 4, iter 182, loss: 31.154458, acc: 0.591837\n",
      "epoch 4, iter 183, loss: 33.487713, acc: 0.591837\n",
      "epoch 4, iter 184, loss: 31.525820, acc: 0.653061\n",
      "epoch 4, iter 185, loss: 36.468867, acc: 0.489796\n",
      "epoch 4, iter 186, loss: 22.120013, acc: 0.816327\n",
      "epoch 4, iter 187, loss: 33.280864, acc: 0.612245\n",
      "epoch 4, iter 188, loss: 39.992809, acc: 0.346939\n",
      "epoch 4, iter 189, loss: 37.723198, acc: 0.510204\n",
      "epoch 4, iter 190, loss: 29.158828, acc: 0.673469\n",
      "epoch 4, iter 191, loss: 28.233439, acc: 0.693878\n",
      "epoch 4, iter 192, loss: 31.234710, acc: 0.591837\n",
      "epoch 4, iter 193, loss: 31.259742, acc: 0.530612\n",
      "epoch 4, iter 194, loss: 25.418559, acc: 0.755102\n",
      "epoch 4, iter 195, loss: 36.552333, acc: 0.551020\n",
      "epoch 4, iter 196, loss: 26.808942, acc: 0.734694\n",
      "epoch 4, iter 197, loss: 33.193476, acc: 0.632653\n",
      "epoch 4, iter 198, loss: 29.122194, acc: 0.693878\n",
      "epoch 4, iter 199, loss: 41.411122, acc: 0.530612\n",
      "epoch 4, iter 200, loss: 31.640575, acc: 0.489796\n",
      "epoch 4, iter 201, loss: 24.529169, acc: 0.857143\n",
      "epoch 4, iter 202, loss: 26.532074, acc: 0.571429\n",
      "epoch 4, iter 203, loss: 34.840351, acc: 0.510204\n",
      "epoch 4, iter 204, loss: 34.694965, acc: 0.612245\n",
      "epoch 4, iter 205, loss: 36.969601, acc: 0.448980\n",
      "epoch 4, iter 206, loss: 31.052484, acc: 0.632653\n",
      "epoch 4, iter 207, loss: 38.845568, acc: 0.591837\n",
      "epoch 4, iter 208, loss: 30.573828, acc: 0.775510\n",
      "epoch 4, iter 209, loss: 30.884443, acc: 0.734694\n",
      "epoch 4, iter 210, loss: 33.854065, acc: 0.612245\n",
      "epoch 4, iter 211, loss: 21.990802, acc: 0.795918\n",
      "epoch 4, iter 212, loss: 25.957271, acc: 0.571429\n",
      "epoch 4, iter 213, loss: 22.713908, acc: 0.795918\n",
      "epoch 4, iter 214, loss: 22.154955, acc: 0.795918\n",
      "epoch 4, iter 215, loss: 39.604130, acc: 0.612245\n",
      "epoch 4, iter 216, loss: 31.785388, acc: 0.714286\n",
      "epoch 4, iter 217, loss: 33.729510, acc: 0.530612\n",
      "epoch 4, iter 218, loss: 28.411146, acc: 0.734694\n",
      "epoch 4, iter 219, loss: 25.660135, acc: 0.714286\n",
      "epoch 4, iter 220, loss: 31.077981, acc: 0.571429\n",
      "epoch 4, iter 221, loss: 22.973191, acc: 0.755102\n",
      "epoch 4, iter 222, loss: 34.603981, acc: 0.571429\n",
      "epoch 4, iter 223, loss: 24.565393, acc: 0.693878\n",
      "epoch 4, iter 224, loss: 22.950792, acc: 0.653061\n",
      "epoch 4, iter 225, loss: 30.566332, acc: 0.673469\n",
      "epoch 4, iter 226, loss: 28.193859, acc: 0.571429\n",
      "epoch 4, iter 227, loss: 27.425309, acc: 0.632653\n",
      "epoch 4, iter 228, loss: 28.400251, acc: 0.612245\n",
      "epoch 4, iter 229, loss: 17.576506, acc: 0.857143\n",
      "epoch 4, iter 230, loss: 31.134518, acc: 0.734694\n",
      "epoch 4, iter 231, loss: 24.529817, acc: 0.775510\n",
      "epoch 4, iter 232, loss: 35.296766, acc: 0.510204\n",
      "epoch 4, iter 233, loss: 33.650169, acc: 0.653061\n",
      "epoch 4, iter 234, loss: 23.284337, acc: 0.795918\n",
      "epoch 4, iter 235, loss: 28.235628, acc: 0.693878\n",
      "epoch 4, iter 236, loss: 23.813047, acc: 0.775510\n",
      "epoch 4, iter 237, loss: 33.578681, acc: 0.632653\n",
      "epoch 4, iter 238, loss: 36.507068, acc: 0.489796\n",
      "epoch 4, iter 239, loss: 35.193717, acc: 0.489796\n",
      "epoch 4, iter 240, loss: 28.680010, acc: 0.755102\n",
      "epoch 4, iter 241, loss: 29.474887, acc: 0.714286\n",
      "epoch 4, iter 242, loss: 36.623379, acc: 0.571429\n",
      "epoch 4, iter 243, loss: 29.985479, acc: 0.469388\n",
      "epoch 4, iter 244, loss: 36.206093, acc: 0.571429\n",
      "epoch 4, iter 245, loss: 35.017918, acc: 0.612245\n",
      "epoch 4, iter 246, loss: 35.616191, acc: 0.571429\n",
      "epoch 4, iter 247, loss: 36.971416, acc: 0.673469\n",
      "epoch 4, iter 248, loss: 28.870909, acc: 0.775510\n",
      "epoch 4, iter 249, loss: 38.718600, acc: 0.673469\n",
      "epoch 4, iter 250, loss: 30.718812, acc: 0.755102\n",
      "epoch 4, iter 251, loss: 32.183714, acc: 0.653061\n",
      "epoch 4, iter 252, loss: 30.596146, acc: 0.571429\n",
      "epoch 4, iter 253, loss: 29.197486, acc: 0.693878\n",
      "epoch 4, iter 254, loss: 21.158045, acc: 0.816327\n",
      "epoch 4, iter 255, loss: 30.793667, acc: 0.591837\n",
      "epoch 4, iter 256, loss: 30.999207, acc: 0.673469\n",
      "epoch 4, iter 257, loss: 31.652561, acc: 0.673469\n",
      "epoch 4, iter 258, loss: 36.474572, acc: 0.530612\n",
      "epoch 4, iter 259, loss: 23.122578, acc: 0.734694\n",
      "epoch 4, iter 260, loss: 37.838520, acc: 0.469388\n",
      "epoch 4, iter 261, loss: 30.421617, acc: 0.816327\n",
      "epoch 4, iter 262, loss: 28.397013, acc: 0.632653\n",
      "epoch 4, iter 263, loss: 35.289342, acc: 0.673469\n",
      "epoch 4, iter 264, loss: 25.946837, acc: 0.795918\n",
      "epoch 4, iter 265, loss: 23.420634, acc: 0.836735\n",
      "epoch 4, iter 266, loss: 37.017663, acc: 0.571429\n",
      "epoch 4, iter 267, loss: 35.093512, acc: 0.571429\n",
      "epoch 4, iter 268, loss: 29.768291, acc: 0.632653\n",
      "epoch 4, iter 269, loss: 23.974113, acc: 0.693878\n",
      "epoch 4, iter 270, loss: 31.775217, acc: 0.734694\n",
      "epoch 4, iter 271, loss: 22.399994, acc: 0.816327\n",
      "epoch 4, iter 272, loss: 20.043704, acc: 0.897959\n",
      "epoch 4, iter 273, loss: 35.308378, acc: 0.571429\n",
      "epoch 4, iter 274, loss: 32.321118, acc: 0.632653\n",
      "epoch 4, iter 275, loss: 33.522936, acc: 0.571429\n",
      "epoch 4, iter 276, loss: 19.288658, acc: 0.877551\n",
      "epoch 4, iter 277, loss: 31.417732, acc: 0.836735\n",
      "epoch 4, iter 278, loss: 24.980160, acc: 0.673469\n",
      "epoch 4, iter 279, loss: 29.115532, acc: 0.591837\n",
      "epoch 4, iter 280, loss: 36.701639, acc: 0.673469\n",
      "epoch 4, iter 281, loss: 34.720505, acc: 0.489796\n",
      "epoch 4, iter 282, loss: 35.850150, acc: 0.693878\n",
      "epoch 4, iter 283, loss: 33.999167, acc: 0.571429\n",
      "epoch 4, iter 284, loss: 27.030736, acc: 0.734694\n",
      "epoch 4, iter 285, loss: 28.246486, acc: 0.693878\n",
      "epoch 4, iter 286, loss: 26.914030, acc: 0.693878\n",
      "epoch 4, iter 287, loss: 29.135849, acc: 0.653061\n",
      "epoch 4, iter 288, loss: 25.985110, acc: 0.693878\n",
      "epoch 4, iter 289, loss: 27.782412, acc: 0.714286\n",
      "epoch 4, iter 290, loss: 29.735425, acc: 0.693878\n",
      "epoch 4, iter 291, loss: 29.795220, acc: 0.653061\n",
      "epoch 4, iter 292, loss: 25.393514, acc: 0.734694\n",
      "epoch 4, iter 293, loss: 26.659918, acc: 0.673469\n",
      "epoch 4, iter 294, loss: 23.805002, acc: 0.795918\n",
      "epoch 4, iter 295, loss: 33.425126, acc: 0.571429\n",
      "epoch 4, iter 296, loss: 33.595291, acc: 0.693878\n",
      "epoch 4, iter 297, loss: 30.037100, acc: 0.734694\n",
      "epoch 4, iter 298, loss: 30.321988, acc: 0.510204\n",
      "epoch 4, iter 299, loss: 32.942578, acc: 0.653061\n",
      "epoch 4, iter 300, loss: 21.482140, acc: 0.755102\n",
      "epoch 4, iter 301, loss: 26.006396, acc: 0.693878\n",
      "epoch 4, iter 302, loss: 32.500724, acc: 0.591837\n",
      "epoch 4, iter 303, loss: 32.356758, acc: 0.612245\n",
      "epoch 4, iter 304, loss: 30.805338, acc: 0.653061\n",
      "epoch 4, iter 305, loss: 34.706377, acc: 0.530612\n",
      "epoch 4, iter 306, loss: 34.546597, acc: 0.591837\n",
      "epoch 4, iter 307, loss: 29.674162, acc: 0.653061\n",
      "epoch 4, iter 308, loss: 37.666791, acc: 0.510204\n",
      "epoch 4, iter 309, loss: 30.705900, acc: 0.632653\n",
      "epoch 4, iter 310, loss: 26.346700, acc: 0.693878\n",
      "epoch 4, iter 311, loss: 24.089141, acc: 0.775510\n",
      "epoch 4, iter 312, loss: 21.559766, acc: 0.816327\n",
      "epoch 4, iter 313, loss: 25.125914, acc: 0.775510\n",
      "epoch 4, iter 314, loss: 26.346454, acc: 0.693878\n",
      "epoch 4, iter 315, loss: 28.311617, acc: 0.632653\n",
      "epoch 4, iter 316, loss: 25.565187, acc: 0.755102\n",
      "epoch 4, iter 317, loss: 21.226087, acc: 0.734694\n",
      "epoch 4, iter 318, loss: 39.633588, acc: 0.632653\n",
      "epoch 4, iter 319, loss: 36.142692, acc: 0.489796\n",
      "epoch 4, iter 320, loss: 26.617398, acc: 0.591837\n",
      "epoch 4, iter 321, loss: 27.308434, acc: 0.714286\n",
      "epoch 4, iter 322, loss: 38.710750, acc: 0.551020\n",
      "epoch 4, iter 323, loss: 28.919230, acc: 0.530612\n",
      "epoch 4, iter 324, loss: 28.009856, acc: 0.673469\n",
      "epoch 4, iter 325, loss: 21.231583, acc: 0.836735\n",
      "epoch 4, iter 326, loss: 32.755983, acc: 0.469388\n",
      "epoch 4, iter 327, loss: 24.518778, acc: 0.795918\n",
      "epoch 4, iter 328, loss: 27.723231, acc: 0.673469\n",
      "epoch 4, iter 329, loss: 32.313111, acc: 0.632653\n",
      "epoch 4, iter 330, loss: 31.768501, acc: 0.632653\n",
      "epoch 4, iter 331, loss: 35.209568, acc: 0.530612\n",
      "epoch 4, iter 332, loss: 38.698413, acc: 0.489796\n",
      "epoch 4, iter 333, loss: 31.057309, acc: 0.612245\n",
      "epoch 4, iter 334, loss: 33.061487, acc: 0.591837\n",
      "epoch 4, iter 335, loss: 23.685915, acc: 0.795918\n",
      "epoch 4, iter 336, loss: 24.736878, acc: 0.775510\n",
      "epoch 4, iter 337, loss: 31.937782, acc: 0.571429\n",
      "epoch 4, iter 338, loss: 27.155158, acc: 0.836735\n",
      "epoch 4, iter 339, loss: 26.816495, acc: 0.693878\n",
      "epoch 4, iter 340, loss: 39.151105, acc: 0.632653\n",
      "epoch 4, iter 341, loss: 26.525885, acc: 0.877551\n",
      "epoch 4, iter 342, loss: 39.489282, acc: 0.469388\n",
      "epoch 4, iter 343, loss: 32.808025, acc: 0.714286\n",
      "epoch 4, iter 344, loss: 32.388276, acc: 0.653061\n",
      "epoch 4, iter 345, loss: 31.293136, acc: 0.673469\n",
      "epoch 4, iter 346, loss: 28.495439, acc: 0.775510\n",
      "epoch 4, iter 347, loss: 22.943356, acc: 0.571429\n",
      "epoch 4, iter 348, loss: 30.011623, acc: 0.612245\n",
      "epoch 4, iter 349, loss: 35.277198, acc: 0.571429\n",
      "epoch 4, iter 350, loss: 30.480641, acc: 0.571429\n",
      "epoch 4, iter 351, loss: 31.919863, acc: 0.551020\n",
      "epoch 4, iter 352, loss: 34.082392, acc: 0.653061\n",
      "epoch 4, iter 353, loss: 37.554828, acc: 0.591837\n",
      "epoch 4, iter 354, loss: 31.470323, acc: 0.653061\n",
      "epoch 4, iter 355, loss: 30.375700, acc: 0.693878\n",
      "epoch 4, iter 356, loss: 28.129761, acc: 0.755102\n",
      "epoch 4, iter 357, loss: 33.493053, acc: 0.653061\n",
      "epoch 4, iter 358, loss: 34.567944, acc: 0.591837\n",
      "epoch 4, iter 359, loss: 25.704655, acc: 0.693878\n",
      "epoch 4, iter 360, loss: 27.364868, acc: 0.673469\n",
      "epoch 4, iter 361, loss: 30.249618, acc: 0.469388\n",
      "epoch 4, iter 362, loss: 35.015059, acc: 0.571429\n",
      "epoch 4, iter 363, loss: 28.068635, acc: 0.591837\n",
      "epoch 4, iter 364, loss: 41.999781, acc: 0.510204\n",
      "epoch 4, iter 365, loss: 28.410756, acc: 0.673469\n",
      "epoch 4, iter 366, loss: 37.514923, acc: 0.551020\n",
      "epoch 4, iter 367, loss: 41.159164, acc: 0.448980\n",
      "epoch 4, iter 368, loss: 30.285802, acc: 0.489796\n",
      "epoch 4, iter 369, loss: 31.697871, acc: 0.448980\n",
      "epoch 4, iter 370, loss: 34.927308, acc: 0.530612\n",
      "epoch 4, iter 371, loss: 29.521398, acc: 0.714286\n",
      "epoch 4, iter 372, loss: 37.127257, acc: 0.469388\n",
      "epoch 4, iter 373, loss: 32.608005, acc: 0.673469\n",
      "epoch 4, iter 374, loss: 37.832218, acc: 0.408163\n",
      "epoch 4, iter 375, loss: 26.610083, acc: 0.714286\n",
      "epoch 4, iter 376, loss: 30.325514, acc: 0.571429\n",
      "epoch 4, iter 377, loss: 24.490066, acc: 0.714286\n",
      "epoch 4, iter 378, loss: 29.384151, acc: 0.734694\n",
      "epoch 4, iter 379, loss: 36.673366, acc: 0.612245\n",
      "epoch 4, iter 380, loss: 38.358124, acc: 0.673469\n",
      "epoch 4, iter 381, loss: 33.360859, acc: 0.653061\n",
      "epoch 4, iter 382, loss: 24.791935, acc: 0.795918\n",
      "epoch 4, iter 383, loss: 23.970703, acc: 0.734694\n",
      "epoch 4, iter 384, loss: 31.381285, acc: 0.653061\n",
      "epoch 4, iter 385, loss: 20.263047, acc: 0.877551\n",
      "epoch 4, iter 386, loss: 39.322883, acc: 0.551020\n",
      "epoch 4, iter 387, loss: 30.988419, acc: 0.612245\n",
      "epoch 4, iter 388, loss: 28.467134, acc: 0.734694\n",
      "epoch 4, iter 389, loss: 30.843266, acc: 0.693878\n",
      "epoch 4, iter 390, loss: 31.813712, acc: 0.571429\n",
      "epoch 4, iter 391, loss: 28.007855, acc: 0.734694\n",
      "epoch 4, iter 392, loss: 27.222401, acc: 0.836735\n",
      "epoch 4, iter 393, loss: 31.564541, acc: 0.571429\n",
      "epoch 4, iter 394, loss: 24.371726, acc: 0.714286\n",
      "epoch 4, iter 395, loss: 30.631218, acc: 0.510204\n",
      "epoch 4, iter 396, loss: 26.494437, acc: 0.551020\n",
      "epoch 4, iter 397, loss: 21.075778, acc: 0.714286\n",
      "epoch 4, iter 398, loss: 34.443855, acc: 0.591837\n",
      "epoch 4, iter 399, loss: 25.988079, acc: 0.714286\n",
      "epoch 4, iter 400, loss: 38.224878, acc: 0.551020\n",
      "epoch 4, iter 401, loss: 31.772521, acc: 0.693878\n",
      "epoch 4, iter 402, loss: 34.841896, acc: 0.734694\n",
      "epoch 4, iter 403, loss: 35.051690, acc: 0.673469\n",
      "epoch 4, iter 404, loss: 35.818389, acc: 0.591837\n",
      "epoch 4, iter 405, loss: 31.303466, acc: 0.591837\n",
      "epoch 4, iter 406, loss: 26.190111, acc: 0.653061\n",
      "epoch 4, iter 407, loss: 31.457226, acc: 0.530612\n",
      "epoch 4, iter 408, loss: 30.861110, acc: 0.653061\n",
      "epoch 4, iter 409, loss: 23.633010, acc: 0.693878\n",
      "epoch 4, iter 410, loss: 35.061246, acc: 0.469388\n",
      "epoch 4, iter 411, loss: 30.042566, acc: 0.632653\n",
      "epoch 4, iter 412, loss: 28.522664, acc: 0.857143\n",
      "epoch 4, iter 413, loss: 26.021950, acc: 0.673469\n",
      "epoch 4, iter 414, loss: 34.702548, acc: 0.530612\n",
      "epoch 4, iter 415, loss: 31.610946, acc: 0.612245\n",
      "epoch 4, iter 416, loss: 28.676418, acc: 0.714286\n",
      "epoch 4, iter 417, loss: 34.370771, acc: 0.591837\n",
      "epoch 4, iter 418, loss: 31.189798, acc: 0.673469\n",
      "epoch 4, iter 419, loss: 30.301492, acc: 0.632653\n",
      "epoch 4, iter 420, loss: 36.888500, acc: 0.591837\n",
      "epoch 4, iter 421, loss: 24.561438, acc: 0.775510\n",
      "epoch 4, iter 422, loss: 27.125268, acc: 0.755102\n",
      "epoch 4, iter 423, loss: 36.010715, acc: 0.653061\n",
      "epoch 4, iter 424, loss: 27.958854, acc: 0.795918\n",
      "epoch 4, iter 425, loss: 26.974604, acc: 0.653061\n",
      "epoch 4, iter 426, loss: 30.867450, acc: 0.653061\n",
      "epoch 4, iter 427, loss: 36.185329, acc: 0.632653\n",
      "epoch 4, iter 428, loss: 28.607546, acc: 0.714286\n",
      "epoch 4, iter 429, loss: 28.915365, acc: 0.632653\n",
      "epoch 4, iter 430, loss: 28.344940, acc: 0.591837\n",
      "epoch 4, iter 431, loss: 33.765396, acc: 0.714286\n",
      "epoch 4, iter 432, loss: 25.299627, acc: 0.714286\n",
      "epoch 4, iter 433, loss: 28.283949, acc: 0.612245\n",
      "epoch 4, iter 434, loss: 25.591728, acc: 0.653061\n",
      "epoch 4, iter 435, loss: 29.268746, acc: 0.734694\n",
      "epoch 4, iter 436, loss: 28.738914, acc: 0.673469\n",
      "epoch 4, iter 437, loss: 45.754066, acc: 0.571429\n",
      "epoch 4, iter 438, loss: 35.881845, acc: 0.571429\n",
      "epoch 4, iter 439, loss: 32.573078, acc: 0.591837\n",
      "epoch 4, iter 440, loss: 32.302012, acc: 0.591837\n",
      "epoch 4, iter 441, loss: 27.967259, acc: 0.673469\n",
      "epoch 4, iter 442, loss: 32.769130, acc: 0.653061\n",
      "epoch 4, iter 443, loss: 24.468562, acc: 0.836735\n",
      "epoch 4, iter 444, loss: 28.424403, acc: 0.693878\n",
      "epoch 4, iter 445, loss: 46.951349, acc: 0.612245\n",
      "epoch 4, iter 446, loss: 30.510912, acc: 0.653061\n",
      "epoch 4, iter 447, loss: 32.181737, acc: 0.755102\n",
      "epoch 4, iter 448, loss: 33.376824, acc: 0.571429\n",
      "epoch 4, iter 449, loss: 17.207467, acc: 0.816327\n",
      "epoch 4, iter 450, loss: 32.724513, acc: 0.612245\n",
      "epoch 4, iter 451, loss: 27.302468, acc: 0.816327\n",
      "epoch 4, iter 452, loss: 28.728494, acc: 0.755102\n",
      "epoch 4, iter 453, loss: 31.744562, acc: 0.469388\n",
      "epoch 4, iter 454, loss: 28.378728, acc: 0.591837\n",
      "epoch 4, iter 455, loss: 29.877357, acc: 0.632653\n",
      "epoch 4, iter 456, loss: 30.659782, acc: 0.632653\n",
      "epoch 4, iter 457, loss: 31.074435, acc: 0.734694\n",
      "epoch 4, iter 458, loss: 22.154310, acc: 0.795918\n",
      "epoch 4, iter 459, loss: 32.116956, acc: 0.612245\n",
      "epoch 4, iter 460, loss: 34.080268, acc: 0.530612\n",
      "epoch 4, iter 461, loss: 29.557763, acc: 0.571429\n",
      "epoch 4, iter 462, loss: 34.018892, acc: 0.612245\n",
      "epoch 4, iter 463, loss: 31.109811, acc: 0.551020\n",
      "epoch 4, iter 464, loss: 27.431368, acc: 0.795918\n",
      "epoch 4, iter 465, loss: 30.964053, acc: 0.612245\n",
      "epoch 4, iter 466, loss: 36.117665, acc: 0.612245\n",
      "epoch 4, iter 467, loss: 32.703099, acc: 0.591837\n",
      "epoch 4, iter 468, loss: 29.513219, acc: 0.693878\n",
      "epoch 4, iter 469, loss: 31.862243, acc: 0.530612\n",
      "epoch 4, iter 470, loss: 40.383098, acc: 0.448980\n",
      "epoch 4, iter 471, loss: 29.070504, acc: 0.816327\n",
      "epoch 4, iter 472, loss: 27.277075, acc: 0.653061\n",
      "epoch 4, iter 473, loss: 28.512693, acc: 0.673469\n",
      "epoch 4, iter 474, loss: 31.272575, acc: 0.693878\n",
      "epoch 4, iter 475, loss: 32.825576, acc: 0.469388\n",
      "epoch 4, iter 476, loss: 25.051919, acc: 0.673469\n",
      "epoch 4, iter 477, loss: 37.453611, acc: 0.591837\n",
      "epoch 4, iter 478, loss: 28.452651, acc: 0.693878\n",
      "epoch 4, iter 479, loss: 30.316077, acc: 0.612245\n",
      "epoch 4, iter 480, loss: 27.419537, acc: 0.714286\n",
      "epoch 4, iter 481, loss: 25.362920, acc: 0.653061\n",
      "epoch 4, iter 482, loss: 25.660634, acc: 0.836735\n",
      "epoch 4, iter 483, loss: 29.768349, acc: 0.714286\n",
      "epoch 4, iter 484, loss: 27.930194, acc: 0.693878\n",
      "epoch 4, iter 485, loss: 26.975116, acc: 0.653061\n",
      "epoch 4, iter 486, loss: 33.393463, acc: 0.571429\n",
      "epoch 4, iter 487, loss: 27.169765, acc: 0.734694\n",
      "epoch 4, iter 488, loss: 22.838787, acc: 0.755102\n",
      "epoch 4, iter 489, loss: 31.648694, acc: 0.755102\n",
      "epoch 4, iter 490, loss: 31.545464, acc: 0.632653\n",
      "epoch 4, iter 491, loss: 30.273205, acc: 0.755102\n",
      "epoch 4, iter 492, loss: 31.136291, acc: 0.714286\n",
      "epoch 4, iter 493, loss: 24.429686, acc: 0.653061\n",
      "epoch 4, iter 494, loss: 32.499133, acc: 0.510204\n",
      "epoch 4, iter 495, loss: 31.627340, acc: 0.448980\n",
      "epoch 4, iter 496, loss: 26.600278, acc: 0.653061\n",
      "epoch 4, iter 497, loss: 33.971671, acc: 0.551020\n",
      "epoch 4, iter 498, loss: 35.452663, acc: 0.510204\n",
      "epoch 4, iter 499, loss: 34.517485, acc: 0.571429\n",
      "epoch 4, acc: 0.654367\n",
      "epoch 5, iter 0, loss: 33.973751, acc: 0.612245\n",
      "epoch 5, iter 1, loss: 37.613608, acc: 0.632653\n",
      "epoch 5, iter 2, loss: 33.864800, acc: 0.693878\n",
      "epoch 5, iter 3, loss: 28.311067, acc: 0.530612\n",
      "epoch 5, iter 4, loss: 25.535264, acc: 0.673469\n",
      "epoch 5, iter 5, loss: 27.741783, acc: 0.816327\n",
      "epoch 5, iter 6, loss: 28.202026, acc: 0.755102\n",
      "epoch 5, iter 7, loss: 32.091565, acc: 0.693878\n",
      "epoch 5, iter 8, loss: 32.682546, acc: 0.571429\n",
      "epoch 5, iter 9, loss: 23.645979, acc: 0.734694\n",
      "epoch 5, iter 10, loss: 33.158736, acc: 0.612245\n",
      "epoch 5, iter 11, loss: 39.479658, acc: 0.530612\n",
      "epoch 5, iter 12, loss: 27.318362, acc: 0.795918\n",
      "epoch 5, iter 13, loss: 33.203822, acc: 0.653061\n",
      "epoch 5, iter 14, loss: 28.560606, acc: 0.469388\n",
      "epoch 5, iter 15, loss: 20.995890, acc: 0.775510\n",
      "epoch 5, iter 16, loss: 34.457450, acc: 0.510204\n",
      "epoch 5, iter 17, loss: 26.014715, acc: 0.714286\n",
      "epoch 5, iter 18, loss: 36.172826, acc: 0.571429\n",
      "epoch 5, iter 19, loss: 20.832455, acc: 0.795918\n",
      "epoch 5, iter 20, loss: 22.723170, acc: 0.734694\n",
      "epoch 5, iter 21, loss: 28.543681, acc: 0.714286\n",
      "epoch 5, iter 22, loss: 23.909929, acc: 0.755102\n",
      "epoch 5, iter 23, loss: 38.347841, acc: 0.612245\n",
      "epoch 5, iter 24, loss: 33.107306, acc: 0.612245\n",
      "epoch 5, iter 25, loss: 32.557307, acc: 0.530612\n",
      "epoch 5, iter 26, loss: 35.708123, acc: 0.469388\n",
      "epoch 5, iter 27, loss: 33.648478, acc: 0.673469\n",
      "epoch 5, iter 28, loss: 30.756546, acc: 0.612245\n",
      "epoch 5, iter 29, loss: 21.453697, acc: 0.795918\n",
      "epoch 5, iter 30, loss: 29.194697, acc: 0.551020\n",
      "epoch 5, iter 31, loss: 34.443422, acc: 0.489796\n",
      "epoch 5, iter 32, loss: 30.222091, acc: 0.653061\n",
      "epoch 5, iter 33, loss: 21.834626, acc: 0.714286\n",
      "epoch 5, iter 34, loss: 28.725435, acc: 0.653061\n",
      "epoch 5, iter 35, loss: 36.430920, acc: 0.591837\n",
      "epoch 5, iter 36, loss: 32.758563, acc: 0.673469\n",
      "epoch 5, iter 37, loss: 25.439842, acc: 0.734694\n",
      "epoch 5, iter 38, loss: 36.651921, acc: 0.510204\n",
      "epoch 5, iter 39, loss: 30.945388, acc: 0.693878\n",
      "epoch 5, iter 40, loss: 32.703149, acc: 0.591837\n",
      "epoch 5, iter 41, loss: 29.109804, acc: 0.734694\n",
      "epoch 5, iter 42, loss: 34.272587, acc: 0.530612\n",
      "epoch 5, iter 43, loss: 26.814250, acc: 0.734694\n",
      "epoch 5, iter 44, loss: 27.209872, acc: 0.795918\n",
      "epoch 5, iter 45, loss: 31.846719, acc: 0.632653\n",
      "epoch 5, iter 46, loss: 30.729923, acc: 0.571429\n",
      "epoch 5, iter 47, loss: 30.853215, acc: 0.612245\n",
      "epoch 5, iter 48, loss: 27.832732, acc: 0.775510\n",
      "epoch 5, iter 49, loss: 23.686472, acc: 0.653061\n",
      "epoch 5, iter 50, loss: 28.025545, acc: 0.693878\n",
      "epoch 5, iter 51, loss: 33.996496, acc: 0.591837\n",
      "epoch 5, iter 52, loss: 31.587675, acc: 0.632653\n",
      "epoch 5, iter 53, loss: 33.515228, acc: 0.714286\n",
      "epoch 5, iter 54, loss: 29.750052, acc: 0.673469\n",
      "epoch 5, iter 55, loss: 26.650515, acc: 0.693878\n",
      "epoch 5, iter 56, loss: 20.784185, acc: 0.836735\n",
      "epoch 5, iter 57, loss: 27.061334, acc: 0.693878\n",
      "epoch 5, iter 58, loss: 30.234462, acc: 0.591837\n",
      "epoch 5, iter 59, loss: 27.647312, acc: 0.734694\n",
      "epoch 5, iter 60, loss: 31.823630, acc: 0.632653\n",
      "epoch 5, iter 61, loss: 24.019425, acc: 0.755102\n",
      "epoch 5, iter 62, loss: 34.415469, acc: 0.612245\n",
      "epoch 5, iter 63, loss: 25.380679, acc: 0.836735\n",
      "epoch 5, iter 64, loss: 31.533666, acc: 0.591837\n",
      "epoch 5, iter 65, loss: 29.320790, acc: 0.632653\n",
      "epoch 5, iter 66, loss: 25.050852, acc: 0.897959\n",
      "epoch 5, iter 67, loss: 34.084644, acc: 0.632653\n",
      "epoch 5, iter 68, loss: 25.606195, acc: 0.693878\n",
      "epoch 5, iter 69, loss: 22.563566, acc: 0.734694\n",
      "epoch 5, iter 70, loss: 25.160096, acc: 0.734694\n",
      "epoch 5, iter 71, loss: 29.475369, acc: 0.693878\n",
      "epoch 5, iter 72, loss: 25.985664, acc: 0.734694\n",
      "epoch 5, iter 73, loss: 24.137760, acc: 0.693878\n",
      "epoch 5, iter 74, loss: 28.435978, acc: 0.632653\n",
      "epoch 5, iter 75, loss: 29.336785, acc: 0.775510\n",
      "epoch 5, iter 76, loss: 30.885646, acc: 0.755102\n",
      "epoch 5, iter 77, loss: 31.912649, acc: 0.530612\n",
      "epoch 5, iter 78, loss: 33.468316, acc: 0.632653\n",
      "epoch 5, iter 79, loss: 28.360015, acc: 0.673469\n",
      "epoch 5, iter 80, loss: 20.832712, acc: 0.918367\n",
      "epoch 5, iter 81, loss: 27.443442, acc: 0.653061\n",
      "epoch 5, iter 82, loss: 31.357999, acc: 0.632653\n",
      "epoch 5, iter 83, loss: 30.042047, acc: 0.673469\n",
      "epoch 5, iter 84, loss: 21.418872, acc: 0.836735\n",
      "epoch 5, iter 85, loss: 20.986889, acc: 0.795918\n",
      "epoch 5, iter 86, loss: 27.297759, acc: 0.612245\n",
      "epoch 5, iter 87, loss: 43.373760, acc: 0.387755\n",
      "epoch 5, iter 88, loss: 24.871471, acc: 0.795918\n",
      "epoch 5, iter 89, loss: 30.334371, acc: 0.591837\n",
      "epoch 5, iter 90, loss: 31.317023, acc: 0.591837\n",
      "epoch 5, iter 91, loss: 28.480221, acc: 0.734694\n",
      "epoch 5, iter 92, loss: 37.898607, acc: 0.571429\n",
      "epoch 5, iter 93, loss: 39.547709, acc: 0.551020\n",
      "epoch 5, iter 94, loss: 34.263885, acc: 0.714286\n",
      "epoch 5, iter 95, loss: 19.154266, acc: 0.918367\n",
      "epoch 5, iter 96, loss: 26.392261, acc: 0.653061\n",
      "epoch 5, iter 97, loss: 30.983208, acc: 0.653061\n",
      "epoch 5, iter 98, loss: 31.166975, acc: 0.653061\n",
      "epoch 5, iter 99, loss: 25.090999, acc: 0.755102\n",
      "epoch 5, iter 100, loss: 39.591099, acc: 0.632653\n",
      "epoch 5, iter 101, loss: 27.305602, acc: 0.714286\n",
      "epoch 5, iter 102, loss: 27.087693, acc: 0.816327\n",
      "epoch 5, iter 103, loss: 23.806894, acc: 0.755102\n",
      "epoch 5, iter 104, loss: 36.261480, acc: 0.571429\n",
      "epoch 5, iter 105, loss: 30.933942, acc: 0.653061\n",
      "epoch 5, iter 106, loss: 23.496545, acc: 0.755102\n",
      "epoch 5, iter 107, loss: 20.089502, acc: 0.816327\n",
      "epoch 5, iter 108, loss: 29.436523, acc: 0.591837\n",
      "epoch 5, iter 109, loss: 27.651154, acc: 0.653061\n",
      "epoch 5, iter 110, loss: 29.814204, acc: 0.632653\n",
      "epoch 5, iter 111, loss: 39.359006, acc: 0.510204\n",
      "epoch 5, iter 112, loss: 31.043811, acc: 0.591837\n",
      "epoch 5, iter 113, loss: 40.742267, acc: 0.408163\n",
      "epoch 5, iter 114, loss: 31.635686, acc: 0.530612\n",
      "epoch 5, iter 115, loss: 30.113864, acc: 0.551020\n",
      "epoch 5, iter 116, loss: 37.937351, acc: 0.591837\n",
      "epoch 5, iter 117, loss: 26.041145, acc: 0.795918\n",
      "epoch 5, iter 118, loss: 33.293302, acc: 0.571429\n",
      "epoch 5, iter 119, loss: 31.540006, acc: 0.795918\n",
      "epoch 5, iter 120, loss: 29.196525, acc: 0.530612\n",
      "epoch 5, iter 121, loss: 30.573090, acc: 0.693878\n",
      "epoch 5, iter 122, loss: 28.566835, acc: 0.612245\n",
      "epoch 5, iter 123, loss: 31.457072, acc: 0.693878\n",
      "epoch 5, iter 124, loss: 35.299839, acc: 0.571429\n",
      "epoch 5, iter 125, loss: 33.772751, acc: 0.571429\n",
      "epoch 5, iter 126, loss: 26.015829, acc: 0.857143\n",
      "epoch 5, iter 127, loss: 38.027635, acc: 0.571429\n",
      "epoch 5, iter 128, loss: 31.254584, acc: 0.612245\n",
      "epoch 5, iter 129, loss: 25.345197, acc: 0.693878\n",
      "epoch 5, iter 130, loss: 24.160206, acc: 0.897959\n",
      "epoch 5, iter 131, loss: 26.875525, acc: 0.775510\n",
      "epoch 5, iter 132, loss: 31.586835, acc: 0.612245\n",
      "epoch 5, iter 133, loss: 23.166945, acc: 0.795918\n",
      "epoch 5, iter 134, loss: 36.385579, acc: 0.469388\n",
      "epoch 5, iter 135, loss: 33.549940, acc: 0.653061\n",
      "epoch 5, iter 136, loss: 31.363503, acc: 0.489796\n",
      "epoch 5, iter 137, loss: 31.685871, acc: 0.693878\n",
      "epoch 5, iter 138, loss: 25.526840, acc: 0.714286\n",
      "epoch 5, iter 139, loss: 24.481154, acc: 0.693878\n",
      "epoch 5, iter 140, loss: 30.167238, acc: 0.632653\n",
      "epoch 5, iter 141, loss: 20.756008, acc: 0.857143\n",
      "epoch 5, iter 142, loss: 32.697579, acc: 0.530612\n",
      "epoch 5, iter 143, loss: 27.156915, acc: 0.693878\n",
      "epoch 5, iter 144, loss: 32.554219, acc: 0.673469\n",
      "epoch 5, iter 145, loss: 18.146183, acc: 0.734694\n",
      "epoch 5, iter 146, loss: 27.707837, acc: 0.632653\n",
      "epoch 5, iter 147, loss: 26.683692, acc: 0.673469\n",
      "epoch 5, iter 148, loss: 29.556028, acc: 0.653061\n",
      "epoch 5, iter 149, loss: 22.439838, acc: 0.836735\n",
      "epoch 5, iter 150, loss: 29.587565, acc: 0.693878\n",
      "epoch 5, iter 151, loss: 31.967125, acc: 0.673469\n",
      "epoch 5, iter 152, loss: 31.863405, acc: 0.632653\n",
      "epoch 5, iter 153, loss: 34.852671, acc: 0.530612\n",
      "epoch 5, iter 154, loss: 32.317029, acc: 0.612245\n",
      "epoch 5, iter 155, loss: 31.074716, acc: 0.632653\n",
      "epoch 5, iter 156, loss: 27.103758, acc: 0.571429\n",
      "epoch 5, iter 157, loss: 32.079445, acc: 0.632653\n",
      "epoch 5, iter 158, loss: 20.692542, acc: 0.836735\n",
      "epoch 5, iter 159, loss: 36.408255, acc: 0.530612\n",
      "epoch 5, iter 160, loss: 30.015118, acc: 0.551020\n",
      "epoch 5, iter 161, loss: 26.370646, acc: 0.693878\n",
      "epoch 5, iter 162, loss: 30.343812, acc: 0.755102\n",
      "epoch 5, iter 163, loss: 33.908516, acc: 0.632653\n",
      "epoch 5, iter 164, loss: 31.213932, acc: 0.551020\n",
      "epoch 5, iter 165, loss: 24.087927, acc: 0.816327\n",
      "epoch 5, iter 166, loss: 27.185583, acc: 0.673469\n",
      "epoch 5, iter 167, loss: 29.107199, acc: 0.673469\n",
      "epoch 5, iter 168, loss: 28.162044, acc: 0.734694\n",
      "epoch 5, iter 169, loss: 36.972658, acc: 0.612245\n",
      "epoch 5, iter 170, loss: 34.774109, acc: 0.734694\n",
      "epoch 5, iter 171, loss: 28.862076, acc: 0.591837\n",
      "epoch 5, iter 172, loss: 28.713433, acc: 0.734694\n",
      "epoch 5, iter 173, loss: 34.544398, acc: 0.612245\n",
      "epoch 5, iter 174, loss: 29.569403, acc: 0.510204\n",
      "epoch 5, iter 175, loss: 22.942029, acc: 0.632653\n",
      "epoch 5, iter 176, loss: 29.081975, acc: 0.693878\n",
      "epoch 5, iter 177, loss: 27.546630, acc: 0.653061\n",
      "epoch 5, iter 178, loss: 40.846635, acc: 0.571429\n",
      "epoch 5, iter 179, loss: 25.887767, acc: 0.673469\n",
      "epoch 5, iter 180, loss: 24.076379, acc: 0.795918\n",
      "epoch 5, iter 181, loss: 35.099380, acc: 0.673469\n",
      "epoch 5, iter 182, loss: 30.887723, acc: 0.571429\n",
      "epoch 5, iter 183, loss: 33.383264, acc: 0.632653\n",
      "epoch 5, iter 184, loss: 31.912907, acc: 0.653061\n",
      "epoch 5, iter 185, loss: 34.156735, acc: 0.551020\n",
      "epoch 5, iter 186, loss: 21.868465, acc: 0.836735\n",
      "epoch 5, iter 187, loss: 33.205494, acc: 0.632653\n",
      "epoch 5, iter 188, loss: 39.214720, acc: 0.408163\n",
      "epoch 5, iter 189, loss: 36.995165, acc: 0.510204\n",
      "epoch 5, iter 190, loss: 28.139075, acc: 0.714286\n",
      "epoch 5, iter 191, loss: 27.784888, acc: 0.693878\n",
      "epoch 5, iter 192, loss: 30.608205, acc: 0.632653\n",
      "epoch 5, iter 193, loss: 30.661937, acc: 0.571429\n",
      "epoch 5, iter 194, loss: 24.928223, acc: 0.734694\n",
      "epoch 5, iter 195, loss: 34.716711, acc: 0.530612\n",
      "epoch 5, iter 196, loss: 26.575463, acc: 0.673469\n",
      "epoch 5, iter 197, loss: 32.173035, acc: 0.673469\n",
      "epoch 5, iter 198, loss: 28.631421, acc: 0.693878\n",
      "epoch 5, iter 199, loss: 40.443050, acc: 0.551020\n",
      "epoch 5, iter 200, loss: 31.129810, acc: 0.489796\n",
      "epoch 5, iter 201, loss: 23.883613, acc: 0.836735\n",
      "epoch 5, iter 202, loss: 25.442836, acc: 0.571429\n",
      "epoch 5, iter 203, loss: 34.468850, acc: 0.571429\n",
      "epoch 5, iter 204, loss: 33.689780, acc: 0.551020\n",
      "epoch 5, iter 205, loss: 36.995246, acc: 0.448980\n",
      "epoch 5, iter 206, loss: 28.862593, acc: 0.673469\n",
      "epoch 5, iter 207, loss: 37.421563, acc: 0.571429\n",
      "epoch 5, iter 208, loss: 29.531535, acc: 0.755102\n",
      "epoch 5, iter 209, loss: 30.742891, acc: 0.734694\n",
      "epoch 5, iter 210, loss: 32.713999, acc: 0.632653\n",
      "epoch 5, iter 211, loss: 22.531576, acc: 0.795918\n",
      "epoch 5, iter 212, loss: 25.179223, acc: 0.612245\n",
      "epoch 5, iter 213, loss: 23.232848, acc: 0.816327\n",
      "epoch 5, iter 214, loss: 21.676725, acc: 0.795918\n",
      "epoch 5, iter 215, loss: 38.406204, acc: 0.612245\n",
      "epoch 5, iter 216, loss: 30.889231, acc: 0.693878\n",
      "epoch 5, iter 217, loss: 32.499056, acc: 0.510204\n",
      "epoch 5, iter 218, loss: 28.335726, acc: 0.734694\n",
      "epoch 5, iter 219, loss: 26.129326, acc: 0.734694\n",
      "epoch 5, iter 220, loss: 30.626632, acc: 0.632653\n",
      "epoch 5, iter 221, loss: 22.808496, acc: 0.755102\n",
      "epoch 5, iter 222, loss: 34.399230, acc: 0.653061\n",
      "epoch 5, iter 223, loss: 24.649114, acc: 0.673469\n",
      "epoch 5, iter 224, loss: 22.993150, acc: 0.653061\n",
      "epoch 5, iter 225, loss: 30.331324, acc: 0.714286\n",
      "epoch 5, iter 226, loss: 27.495883, acc: 0.571429\n",
      "epoch 5, iter 227, loss: 26.683718, acc: 0.632653\n",
      "epoch 5, iter 228, loss: 26.839880, acc: 0.612245\n",
      "epoch 5, iter 229, loss: 16.946908, acc: 0.836735\n",
      "epoch 5, iter 230, loss: 30.002572, acc: 0.755102\n",
      "epoch 5, iter 231, loss: 24.969120, acc: 0.795918\n",
      "epoch 5, iter 232, loss: 34.588123, acc: 0.510204\n",
      "epoch 5, iter 233, loss: 33.410160, acc: 0.653061\n",
      "epoch 5, iter 234, loss: 22.178128, acc: 0.816327\n",
      "epoch 5, iter 235, loss: 27.955414, acc: 0.734694\n",
      "epoch 5, iter 236, loss: 23.505205, acc: 0.734694\n",
      "epoch 5, iter 237, loss: 32.166702, acc: 0.612245\n",
      "epoch 5, iter 238, loss: 36.270256, acc: 0.530612\n",
      "epoch 5, iter 239, loss: 34.947846, acc: 0.530612\n",
      "epoch 5, iter 240, loss: 28.048603, acc: 0.734694\n",
      "epoch 5, iter 241, loss: 30.442206, acc: 0.734694\n",
      "epoch 5, iter 242, loss: 36.211714, acc: 0.530612\n",
      "epoch 5, iter 243, loss: 30.176378, acc: 0.489796\n",
      "epoch 5, iter 244, loss: 35.454659, acc: 0.591837\n",
      "epoch 5, iter 245, loss: 34.569849, acc: 0.612245\n",
      "epoch 5, iter 246, loss: 35.009537, acc: 0.571429\n",
      "epoch 5, iter 247, loss: 36.503729, acc: 0.653061\n",
      "epoch 5, iter 248, loss: 27.482346, acc: 0.775510\n",
      "epoch 5, iter 249, loss: 38.280898, acc: 0.632653\n",
      "epoch 5, iter 250, loss: 29.779266, acc: 0.755102\n",
      "epoch 5, iter 251, loss: 30.478180, acc: 0.693878\n",
      "epoch 5, iter 252, loss: 29.491456, acc: 0.632653\n",
      "epoch 5, iter 253, loss: 29.394661, acc: 0.714286\n",
      "epoch 5, iter 254, loss: 20.896743, acc: 0.836735\n",
      "epoch 5, iter 255, loss: 31.236924, acc: 0.571429\n",
      "epoch 5, iter 256, loss: 30.623212, acc: 0.632653\n",
      "epoch 5, iter 257, loss: 30.937609, acc: 0.693878\n",
      "epoch 5, iter 258, loss: 35.367354, acc: 0.530612\n",
      "epoch 5, iter 259, loss: 22.523947, acc: 0.734694\n",
      "epoch 5, iter 260, loss: 38.111747, acc: 0.448980\n",
      "epoch 5, iter 261, loss: 25.083009, acc: 0.816327\n",
      "epoch 5, iter 262, loss: 28.522584, acc: 0.653061\n",
      "epoch 5, iter 263, loss: 33.515677, acc: 0.653061\n",
      "epoch 5, iter 264, loss: 26.891370, acc: 0.795918\n",
      "epoch 5, iter 265, loss: 22.971861, acc: 0.816327\n",
      "epoch 5, iter 266, loss: 37.605203, acc: 0.591837\n",
      "epoch 5, iter 267, loss: 33.962751, acc: 0.551020\n",
      "epoch 5, iter 268, loss: 29.613596, acc: 0.591837\n",
      "epoch 5, iter 269, loss: 23.174246, acc: 0.714286\n",
      "epoch 5, iter 270, loss: 31.143172, acc: 0.693878\n",
      "epoch 5, iter 271, loss: 21.896263, acc: 0.775510\n",
      "epoch 5, iter 272, loss: 19.532699, acc: 0.857143\n",
      "epoch 5, iter 273, loss: 35.801364, acc: 0.530612\n",
      "epoch 5, iter 274, loss: 33.004167, acc: 0.653061\n",
      "epoch 5, iter 275, loss: 32.731760, acc: 0.591837\n",
      "epoch 5, iter 276, loss: 19.820813, acc: 0.836735\n",
      "epoch 5, iter 277, loss: 31.170718, acc: 0.816327\n",
      "epoch 5, iter 278, loss: 23.552219, acc: 0.693878\n",
      "epoch 5, iter 279, loss: 29.206534, acc: 0.591837\n",
      "epoch 5, iter 280, loss: 36.362009, acc: 0.591837\n",
      "epoch 5, iter 281, loss: 32.973323, acc: 0.673469\n",
      "epoch 5, iter 282, loss: 35.356082, acc: 0.693878\n",
      "epoch 5, iter 283, loss: 33.421104, acc: 0.673469\n",
      "epoch 5, iter 284, loss: 25.779192, acc: 0.734694\n",
      "epoch 5, iter 285, loss: 24.572105, acc: 0.755102\n",
      "epoch 5, iter 286, loss: 25.899761, acc: 0.693878\n",
      "epoch 5, iter 287, loss: 29.343893, acc: 0.673469\n",
      "epoch 5, iter 288, loss: 25.900177, acc: 0.673469\n",
      "epoch 5, iter 289, loss: 26.200203, acc: 0.714286\n",
      "epoch 5, iter 290, loss: 28.807055, acc: 0.693878\n",
      "epoch 5, iter 291, loss: 28.456353, acc: 0.673469\n",
      "epoch 5, iter 292, loss: 25.535813, acc: 0.734694\n",
      "epoch 5, iter 293, loss: 26.059092, acc: 0.673469\n",
      "epoch 5, iter 294, loss: 23.454777, acc: 0.795918\n",
      "epoch 5, iter 295, loss: 31.797764, acc: 0.632653\n",
      "epoch 5, iter 296, loss: 31.594122, acc: 0.714286\n",
      "epoch 5, iter 297, loss: 29.174157, acc: 0.734694\n",
      "epoch 5, iter 298, loss: 30.273252, acc: 0.489796\n",
      "epoch 5, iter 299, loss: 32.294796, acc: 0.632653\n",
      "epoch 5, iter 300, loss: 21.004598, acc: 0.775510\n",
      "epoch 5, iter 301, loss: 25.595270, acc: 0.714286\n",
      "epoch 5, iter 302, loss: 32.338377, acc: 0.612245\n",
      "epoch 5, iter 303, loss: 32.195742, acc: 0.591837\n",
      "epoch 5, iter 304, loss: 30.509277, acc: 0.673469\n",
      "epoch 5, iter 305, loss: 35.527757, acc: 0.551020\n",
      "epoch 5, iter 306, loss: 34.384721, acc: 0.612245\n",
      "epoch 5, iter 307, loss: 29.147931, acc: 0.653061\n",
      "epoch 5, iter 308, loss: 38.204146, acc: 0.469388\n",
      "epoch 5, iter 309, loss: 29.268171, acc: 0.612245\n",
      "epoch 5, iter 310, loss: 25.308948, acc: 0.734694\n",
      "epoch 5, iter 311, loss: 23.650374, acc: 0.795918\n",
      "epoch 5, iter 312, loss: 20.773370, acc: 0.816327\n",
      "epoch 5, iter 313, loss: 25.027978, acc: 0.755102\n",
      "epoch 5, iter 314, loss: 27.162038, acc: 0.755102\n",
      "epoch 5, iter 315, loss: 28.679902, acc: 0.612245\n",
      "epoch 5, iter 316, loss: 24.569446, acc: 0.693878\n",
      "epoch 5, iter 317, loss: 21.210066, acc: 0.755102\n",
      "epoch 5, iter 318, loss: 36.785649, acc: 0.612245\n",
      "epoch 5, iter 319, loss: 34.863481, acc: 0.489796\n",
      "epoch 5, iter 320, loss: 25.941532, acc: 0.612245\n",
      "epoch 5, iter 321, loss: 26.399254, acc: 0.693878\n",
      "epoch 5, iter 322, loss: 37.306856, acc: 0.510204\n",
      "epoch 5, iter 323, loss: 28.061068, acc: 0.489796\n",
      "epoch 5, iter 324, loss: 27.483591, acc: 0.612245\n",
      "epoch 5, iter 325, loss: 20.094077, acc: 0.857143\n",
      "epoch 5, iter 326, loss: 31.443254, acc: 0.510204\n",
      "epoch 5, iter 327, loss: 23.491136, acc: 0.775510\n",
      "epoch 5, iter 328, loss: 27.009961, acc: 0.734694\n",
      "epoch 5, iter 329, loss: 31.193501, acc: 0.632653\n",
      "epoch 5, iter 330, loss: 31.607553, acc: 0.653061\n",
      "epoch 5, iter 331, loss: 34.676041, acc: 0.551020\n",
      "epoch 5, iter 332, loss: 36.322121, acc: 0.469388\n",
      "epoch 5, iter 333, loss: 29.804370, acc: 0.653061\n",
      "epoch 5, iter 334, loss: 29.692568, acc: 0.591837\n",
      "epoch 5, iter 335, loss: 22.486528, acc: 0.775510\n",
      "epoch 5, iter 336, loss: 24.478650, acc: 0.795918\n",
      "epoch 5, iter 337, loss: 31.677186, acc: 0.653061\n",
      "epoch 5, iter 338, loss: 26.569516, acc: 0.775510\n",
      "epoch 5, iter 339, loss: 26.385296, acc: 0.693878\n",
      "epoch 5, iter 340, loss: 36.443146, acc: 0.673469\n",
      "epoch 5, iter 341, loss: 25.643115, acc: 0.877551\n",
      "epoch 5, iter 342, loss: 35.452723, acc: 0.469388\n",
      "epoch 5, iter 343, loss: 32.976026, acc: 0.632653\n",
      "epoch 5, iter 344, loss: 29.696840, acc: 0.632653\n",
      "epoch 5, iter 345, loss: 29.887345, acc: 0.591837\n",
      "epoch 5, iter 346, loss: 26.354170, acc: 0.775510\n",
      "epoch 5, iter 347, loss: 22.528085, acc: 0.591837\n",
      "epoch 5, iter 348, loss: 30.406890, acc: 0.612245\n",
      "epoch 5, iter 349, loss: 34.516295, acc: 0.591837\n",
      "epoch 5, iter 350, loss: 30.441985, acc: 0.551020\n",
      "epoch 5, iter 351, loss: 32.431951, acc: 0.571429\n",
      "epoch 5, iter 352, loss: 31.800479, acc: 0.693878\n",
      "epoch 5, iter 353, loss: 37.417674, acc: 0.571429\n",
      "epoch 5, iter 354, loss: 30.779585, acc: 0.693878\n",
      "epoch 5, iter 355, loss: 29.443728, acc: 0.632653\n",
      "epoch 5, iter 356, loss: 27.607634, acc: 0.755102\n",
      "epoch 5, iter 357, loss: 33.073714, acc: 0.612245\n",
      "epoch 5, iter 358, loss: 34.000204, acc: 0.591837\n",
      "epoch 5, iter 359, loss: 25.994333, acc: 0.673469\n",
      "epoch 5, iter 360, loss: 26.930025, acc: 0.632653\n",
      "epoch 5, iter 361, loss: 30.457506, acc: 0.489796\n",
      "epoch 5, iter 362, loss: 34.666192, acc: 0.571429\n",
      "epoch 5, iter 363, loss: 28.186703, acc: 0.653061\n",
      "epoch 5, iter 364, loss: 41.020611, acc: 0.530612\n",
      "epoch 5, iter 365, loss: 27.202467, acc: 0.693878\n",
      "epoch 5, iter 366, loss: 35.442640, acc: 0.489796\n",
      "epoch 5, iter 367, loss: 42.516443, acc: 0.510204\n",
      "epoch 5, iter 368, loss: 30.120550, acc: 0.551020\n",
      "epoch 5, iter 369, loss: 31.215841, acc: 0.510204\n",
      "epoch 5, iter 370, loss: 35.896976, acc: 0.489796\n",
      "epoch 5, iter 371, loss: 29.329821, acc: 0.734694\n",
      "epoch 5, iter 372, loss: 37.437805, acc: 0.551020\n",
      "epoch 5, iter 373, loss: 27.612342, acc: 0.755102\n",
      "epoch 5, iter 374, loss: 34.839866, acc: 0.448980\n",
      "epoch 5, iter 375, loss: 28.440575, acc: 0.714286\n",
      "epoch 5, iter 376, loss: 30.289253, acc: 0.571429\n",
      "epoch 5, iter 377, loss: 25.239173, acc: 0.734694\n",
      "epoch 5, iter 378, loss: 28.458826, acc: 0.775510\n",
      "epoch 5, iter 379, loss: 35.779191, acc: 0.653061\n",
      "epoch 5, iter 380, loss: 38.332682, acc: 0.653061\n",
      "epoch 5, iter 381, loss: 33.829814, acc: 0.612245\n",
      "epoch 5, iter 382, loss: 24.486016, acc: 0.816327\n",
      "epoch 5, iter 383, loss: 23.682435, acc: 0.714286\n",
      "epoch 5, iter 384, loss: 30.121677, acc: 0.653061\n",
      "epoch 5, iter 385, loss: 19.505361, acc: 0.918367\n",
      "epoch 5, iter 386, loss: 39.696571, acc: 0.591837\n",
      "epoch 5, iter 387, loss: 31.662484, acc: 0.632653\n",
      "epoch 5, iter 388, loss: 28.288146, acc: 0.714286\n",
      "epoch 5, iter 389, loss: 30.982187, acc: 0.673469\n",
      "epoch 5, iter 390, loss: 31.884345, acc: 0.632653\n",
      "epoch 5, iter 391, loss: 27.534463, acc: 0.714286\n",
      "epoch 5, iter 392, loss: 26.679883, acc: 0.836735\n",
      "epoch 5, iter 393, loss: 31.751462, acc: 0.591837\n",
      "epoch 5, iter 394, loss: 24.347735, acc: 0.714286\n",
      "epoch 5, iter 395, loss: 30.171295, acc: 0.551020\n",
      "epoch 5, iter 396, loss: 26.732739, acc: 0.591837\n",
      "epoch 5, iter 397, loss: 20.688544, acc: 0.714286\n",
      "epoch 5, iter 398, loss: 34.525285, acc: 0.551020\n",
      "epoch 5, iter 399, loss: 25.643454, acc: 0.836735\n",
      "epoch 5, iter 400, loss: 38.253588, acc: 0.551020\n",
      "epoch 5, iter 401, loss: 32.089839, acc: 0.693878\n",
      "epoch 5, iter 402, loss: 33.788556, acc: 0.755102\n",
      "epoch 5, iter 403, loss: 34.797425, acc: 0.612245\n",
      "epoch 5, iter 404, loss: 33.869718, acc: 0.591837\n",
      "epoch 5, iter 405, loss: 30.586676, acc: 0.571429\n",
      "epoch 5, iter 406, loss: 26.539906, acc: 0.653061\n",
      "epoch 5, iter 407, loss: 32.767007, acc: 0.551020\n",
      "epoch 5, iter 408, loss: 29.360323, acc: 0.612245\n",
      "epoch 5, iter 409, loss: 22.869103, acc: 0.693878\n",
      "epoch 5, iter 410, loss: 33.927847, acc: 0.571429\n",
      "epoch 5, iter 411, loss: 30.926166, acc: 0.653061\n",
      "epoch 5, iter 412, loss: 28.414033, acc: 0.836735\n",
      "epoch 5, iter 413, loss: 25.627196, acc: 0.673469\n",
      "epoch 5, iter 414, loss: 34.192347, acc: 0.530612\n",
      "epoch 5, iter 415, loss: 31.759057, acc: 0.612245\n",
      "epoch 5, iter 416, loss: 28.100259, acc: 0.714286\n",
      "epoch 5, iter 417, loss: 32.214111, acc: 0.612245\n",
      "epoch 5, iter 418, loss: 29.785624, acc: 0.632653\n",
      "epoch 5, iter 419, loss: 27.686995, acc: 0.673469\n",
      "epoch 5, iter 420, loss: 36.949328, acc: 0.551020\n",
      "epoch 5, iter 421, loss: 23.399392, acc: 0.755102\n",
      "epoch 5, iter 422, loss: 26.596486, acc: 0.734694\n",
      "epoch 5, iter 423, loss: 36.395736, acc: 0.612245\n",
      "epoch 5, iter 424, loss: 29.569040, acc: 0.775510\n",
      "epoch 5, iter 425, loss: 26.467145, acc: 0.714286\n",
      "epoch 5, iter 426, loss: 30.258995, acc: 0.673469\n",
      "epoch 5, iter 427, loss: 34.687886, acc: 0.571429\n",
      "epoch 5, iter 428, loss: 27.498592, acc: 0.653061\n",
      "epoch 5, iter 429, loss: 29.252072, acc: 0.673469\n",
      "epoch 5, iter 430, loss: 26.632853, acc: 0.612245\n",
      "epoch 5, iter 431, loss: 33.784817, acc: 0.693878\n",
      "epoch 5, iter 432, loss: 25.857233, acc: 0.734694\n",
      "epoch 5, iter 433, loss: 28.004126, acc: 0.612245\n",
      "epoch 5, iter 434, loss: 25.246793, acc: 0.693878\n",
      "epoch 5, iter 435, loss: 28.991750, acc: 0.734694\n",
      "epoch 5, iter 436, loss: 27.592437, acc: 0.673469\n",
      "epoch 5, iter 437, loss: 45.107702, acc: 0.551020\n",
      "epoch 5, iter 438, loss: 35.308711, acc: 0.530612\n",
      "epoch 5, iter 439, loss: 30.867084, acc: 0.530612\n",
      "epoch 5, iter 440, loss: 32.306512, acc: 0.632653\n",
      "epoch 5, iter 441, loss: 26.941088, acc: 0.673469\n",
      "epoch 5, iter 442, loss: 31.708739, acc: 0.591837\n",
      "epoch 5, iter 443, loss: 25.167751, acc: 0.857143\n",
      "epoch 5, iter 444, loss: 29.053750, acc: 0.714286\n",
      "epoch 5, iter 445, loss: 45.421928, acc: 0.591837\n",
      "epoch 5, iter 446, loss: 31.302236, acc: 0.673469\n",
      "epoch 5, iter 447, loss: 29.563725, acc: 0.714286\n",
      "epoch 5, iter 448, loss: 34.615785, acc: 0.530612\n",
      "epoch 5, iter 449, loss: 16.349852, acc: 0.836735\n",
      "epoch 5, iter 450, loss: 32.968390, acc: 0.612245\n",
      "epoch 5, iter 451, loss: 25.712564, acc: 0.755102\n",
      "epoch 5, iter 452, loss: 28.385309, acc: 0.755102\n",
      "epoch 5, iter 453, loss: 32.988526, acc: 0.469388\n",
      "epoch 5, iter 454, loss: 26.549817, acc: 0.612245\n",
      "epoch 5, iter 455, loss: 30.368722, acc: 0.653061\n",
      "epoch 5, iter 456, loss: 30.715015, acc: 0.653061\n",
      "epoch 5, iter 457, loss: 30.991516, acc: 0.714286\n",
      "epoch 5, iter 458, loss: 21.104247, acc: 0.775510\n",
      "epoch 5, iter 459, loss: 32.196874, acc: 0.612245\n",
      "epoch 5, iter 460, loss: 32.805237, acc: 0.551020\n",
      "epoch 5, iter 461, loss: 29.538221, acc: 0.653061\n",
      "epoch 5, iter 462, loss: 33.365882, acc: 0.571429\n",
      "epoch 5, iter 463, loss: 31.076731, acc: 0.551020\n",
      "epoch 5, iter 464, loss: 26.514969, acc: 0.816327\n",
      "epoch 5, iter 465, loss: 32.258637, acc: 0.612245\n",
      "epoch 5, iter 466, loss: 35.847086, acc: 0.673469\n",
      "epoch 5, iter 467, loss: 31.458547, acc: 0.571429\n",
      "epoch 5, iter 468, loss: 30.821790, acc: 0.795918\n",
      "epoch 5, iter 469, loss: 31.540422, acc: 0.591837\n",
      "epoch 5, iter 470, loss: 38.158579, acc: 0.428571\n",
      "epoch 5, iter 471, loss: 27.641301, acc: 0.795918\n",
      "epoch 5, iter 472, loss: 26.752176, acc: 0.673469\n",
      "epoch 5, iter 473, loss: 26.790224, acc: 0.734694\n",
      "epoch 5, iter 474, loss: 29.842524, acc: 0.653061\n",
      "epoch 5, iter 475, loss: 32.102744, acc: 0.530612\n",
      "epoch 5, iter 476, loss: 23.328004, acc: 0.673469\n",
      "epoch 5, iter 477, loss: 34.735065, acc: 0.530612\n",
      "epoch 5, iter 478, loss: 28.854084, acc: 0.693878\n",
      "epoch 5, iter 479, loss: 30.323400, acc: 0.653061\n",
      "epoch 5, iter 480, loss: 27.995628, acc: 0.673469\n",
      "epoch 5, iter 481, loss: 24.727799, acc: 0.653061\n",
      "epoch 5, iter 482, loss: 24.959339, acc: 0.795918\n",
      "epoch 5, iter 483, loss: 28.528816, acc: 0.755102\n",
      "epoch 5, iter 484, loss: 27.513085, acc: 0.673469\n",
      "epoch 5, iter 485, loss: 26.202090, acc: 0.632653\n",
      "epoch 5, iter 486, loss: 33.307681, acc: 0.612245\n",
      "epoch 5, iter 487, loss: 26.558273, acc: 0.755102\n",
      "epoch 5, iter 488, loss: 24.560558, acc: 0.755102\n",
      "epoch 5, iter 489, loss: 30.927770, acc: 0.816327\n",
      "epoch 5, iter 490, loss: 31.301018, acc: 0.673469\n",
      "epoch 5, iter 491, loss: 29.979176, acc: 0.755102\n",
      "epoch 5, iter 492, loss: 30.918625, acc: 0.653061\n",
      "epoch 5, iter 493, loss: 24.249338, acc: 0.693878\n",
      "epoch 5, iter 494, loss: 32.645734, acc: 0.510204\n",
      "epoch 5, iter 495, loss: 31.499228, acc: 0.428571\n",
      "epoch 5, iter 496, loss: 26.764206, acc: 0.693878\n",
      "epoch 5, iter 497, loss: 33.355001, acc: 0.551020\n",
      "epoch 5, iter 498, loss: 35.865510, acc: 0.551020\n",
      "epoch 5, iter 499, loss: 34.251544, acc: 0.612245\n",
      "epoch 5, acc: 0.658857\n",
      "epoch 6, iter 0, loss: 32.451021, acc: 0.571429\n",
      "epoch 6, iter 1, loss: 36.733720, acc: 0.693878\n",
      "epoch 6, iter 2, loss: 31.214525, acc: 0.714286\n",
      "epoch 6, iter 3, loss: 27.410052, acc: 0.571429\n",
      "epoch 6, iter 4, loss: 25.061354, acc: 0.653061\n",
      "epoch 6, iter 5, loss: 27.639545, acc: 0.775510\n",
      "epoch 6, iter 6, loss: 26.946080, acc: 0.816327\n",
      "epoch 6, iter 7, loss: 31.566390, acc: 0.714286\n",
      "epoch 6, iter 8, loss: 32.532469, acc: 0.612245\n",
      "epoch 6, iter 9, loss: 23.650108, acc: 0.693878\n",
      "epoch 6, iter 10, loss: 32.445041, acc: 0.571429\n",
      "epoch 6, iter 11, loss: 39.478100, acc: 0.530612\n",
      "epoch 6, iter 12, loss: 26.628293, acc: 0.775510\n",
      "epoch 6, iter 13, loss: 32.168124, acc: 0.653061\n",
      "epoch 6, iter 14, loss: 27.946189, acc: 0.530612\n",
      "epoch 6, iter 15, loss: 20.715829, acc: 0.775510\n",
      "epoch 6, iter 16, loss: 33.858942, acc: 0.571429\n",
      "epoch 6, iter 17, loss: 25.257088, acc: 0.734694\n",
      "epoch 6, iter 18, loss: 35.824319, acc: 0.571429\n",
      "epoch 6, iter 19, loss: 20.344447, acc: 0.816327\n",
      "epoch 6, iter 20, loss: 22.146172, acc: 0.775510\n",
      "epoch 6, iter 21, loss: 28.696699, acc: 0.673469\n",
      "epoch 6, iter 22, loss: 24.252143, acc: 0.755102\n",
      "epoch 6, iter 23, loss: 37.156745, acc: 0.612245\n",
      "epoch 6, iter 24, loss: 33.289022, acc: 0.632653\n",
      "epoch 6, iter 25, loss: 31.447855, acc: 0.510204\n",
      "epoch 6, iter 26, loss: 35.341905, acc: 0.510204\n",
      "epoch 6, iter 27, loss: 32.856327, acc: 0.673469\n",
      "epoch 6, iter 28, loss: 29.682873, acc: 0.653061\n",
      "epoch 6, iter 29, loss: 21.175279, acc: 0.795918\n",
      "epoch 6, iter 30, loss: 29.135099, acc: 0.530612\n",
      "epoch 6, iter 31, loss: 34.554312, acc: 0.530612\n",
      "epoch 6, iter 32, loss: 28.496208, acc: 0.653061\n",
      "epoch 6, iter 33, loss: 22.683232, acc: 0.734694\n",
      "epoch 6, iter 34, loss: 28.548677, acc: 0.612245\n",
      "epoch 6, iter 35, loss: 35.035033, acc: 0.632653\n",
      "epoch 6, iter 36, loss: 33.455373, acc: 0.673469\n",
      "epoch 6, iter 37, loss: 24.901034, acc: 0.693878\n",
      "epoch 6, iter 38, loss: 37.454616, acc: 0.530612\n",
      "epoch 6, iter 39, loss: 30.874494, acc: 0.755102\n",
      "epoch 6, iter 40, loss: 32.394185, acc: 0.571429\n",
      "epoch 6, iter 41, loss: 28.170691, acc: 0.734694\n",
      "epoch 6, iter 42, loss: 31.401749, acc: 0.510204\n",
      "epoch 6, iter 43, loss: 25.737089, acc: 0.734694\n",
      "epoch 6, iter 44, loss: 26.361420, acc: 0.816327\n",
      "epoch 6, iter 45, loss: 30.688558, acc: 0.632653\n",
      "epoch 6, iter 46, loss: 30.932127, acc: 0.571429\n",
      "epoch 6, iter 47, loss: 29.941887, acc: 0.653061\n",
      "epoch 6, iter 48, loss: 27.882620, acc: 0.755102\n",
      "epoch 6, iter 49, loss: 22.606860, acc: 0.653061\n",
      "epoch 6, iter 50, loss: 26.831956, acc: 0.673469\n",
      "epoch 6, iter 51, loss: 35.630046, acc: 0.591837\n",
      "epoch 6, iter 52, loss: 31.186016, acc: 0.653061\n",
      "epoch 6, iter 53, loss: 32.518539, acc: 0.714286\n",
      "epoch 6, iter 54, loss: 29.402421, acc: 0.714286\n",
      "epoch 6, iter 55, loss: 26.464712, acc: 0.693878\n",
      "epoch 6, iter 56, loss: 20.652596, acc: 0.877551\n",
      "epoch 6, iter 57, loss: 27.374077, acc: 0.714286\n",
      "epoch 6, iter 58, loss: 30.742489, acc: 0.612245\n",
      "epoch 6, iter 59, loss: 27.551245, acc: 0.755102\n",
      "epoch 6, iter 60, loss: 32.175388, acc: 0.693878\n",
      "epoch 6, iter 61, loss: 23.715781, acc: 0.775510\n",
      "epoch 6, iter 62, loss: 34.126032, acc: 0.612245\n",
      "epoch 6, iter 63, loss: 25.472004, acc: 0.775510\n",
      "epoch 6, iter 64, loss: 31.475294, acc: 0.632653\n",
      "epoch 6, iter 65, loss: 28.129418, acc: 0.673469\n",
      "epoch 6, iter 66, loss: 23.430670, acc: 0.857143\n",
      "epoch 6, iter 67, loss: 32.283804, acc: 0.591837\n",
      "epoch 6, iter 68, loss: 24.634984, acc: 0.673469\n",
      "epoch 6, iter 69, loss: 23.526434, acc: 0.734694\n",
      "epoch 6, iter 70, loss: 24.519885, acc: 0.714286\n",
      "epoch 6, iter 71, loss: 28.265150, acc: 0.755102\n",
      "epoch 6, iter 72, loss: 24.701669, acc: 0.734694\n",
      "epoch 6, iter 73, loss: 22.690561, acc: 0.734694\n",
      "epoch 6, iter 74, loss: 27.064597, acc: 0.653061\n",
      "epoch 6, iter 75, loss: 30.224514, acc: 0.795918\n",
      "epoch 6, iter 76, loss: 31.026623, acc: 0.734694\n",
      "epoch 6, iter 77, loss: 31.509201, acc: 0.551020\n",
      "epoch 6, iter 78, loss: 32.768508, acc: 0.673469\n",
      "epoch 6, iter 79, loss: 27.950572, acc: 0.653061\n",
      "epoch 6, iter 80, loss: 20.886935, acc: 0.918367\n",
      "epoch 6, iter 81, loss: 27.800766, acc: 0.673469\n",
      "epoch 6, iter 82, loss: 30.872728, acc: 0.632653\n",
      "epoch 6, iter 83, loss: 29.360264, acc: 0.632653\n",
      "epoch 6, iter 84, loss: 21.434939, acc: 0.816327\n",
      "epoch 6, iter 85, loss: 20.286295, acc: 0.816327\n",
      "epoch 6, iter 86, loss: 27.409730, acc: 0.632653\n",
      "epoch 6, iter 87, loss: 42.377919, acc: 0.367347\n",
      "epoch 6, iter 88, loss: 25.680603, acc: 0.795918\n",
      "epoch 6, iter 89, loss: 29.565239, acc: 0.612245\n",
      "epoch 6, iter 90, loss: 31.385774, acc: 0.612245\n",
      "epoch 6, iter 91, loss: 27.618391, acc: 0.734694\n",
      "epoch 6, iter 92, loss: 36.536827, acc: 0.510204\n",
      "epoch 6, iter 93, loss: 39.543548, acc: 0.591837\n",
      "epoch 6, iter 94, loss: 33.029062, acc: 0.734694\n",
      "epoch 6, iter 95, loss: 19.637491, acc: 0.877551\n",
      "epoch 6, iter 96, loss: 25.942345, acc: 0.673469\n",
      "epoch 6, iter 97, loss: 30.990211, acc: 0.632653\n",
      "epoch 6, iter 98, loss: 32.582005, acc: 0.632653\n",
      "epoch 6, iter 99, loss: 25.397515, acc: 0.673469\n",
      "epoch 6, iter 100, loss: 40.006838, acc: 0.591837\n",
      "epoch 6, iter 101, loss: 27.564346, acc: 0.775510\n",
      "epoch 6, iter 102, loss: 25.952646, acc: 0.816327\n",
      "epoch 6, iter 103, loss: 22.884195, acc: 0.734694\n",
      "epoch 6, iter 104, loss: 35.192987, acc: 0.591837\n",
      "epoch 6, iter 105, loss: 30.765140, acc: 0.591837\n",
      "epoch 6, iter 106, loss: 23.712659, acc: 0.775510\n",
      "epoch 6, iter 107, loss: 19.631936, acc: 0.857143\n",
      "epoch 6, iter 108, loss: 29.366380, acc: 0.612245\n",
      "epoch 6, iter 109, loss: 26.039247, acc: 0.612245\n",
      "epoch 6, iter 110, loss: 29.365022, acc: 0.653061\n",
      "epoch 6, iter 111, loss: 39.109023, acc: 0.571429\n",
      "epoch 6, iter 112, loss: 29.944793, acc: 0.632653\n",
      "epoch 6, iter 113, loss: 38.968427, acc: 0.428571\n",
      "epoch 6, iter 114, loss: 31.032434, acc: 0.489796\n",
      "epoch 6, iter 115, loss: 27.837674, acc: 0.530612\n",
      "epoch 6, iter 116, loss: 37.352595, acc: 0.571429\n",
      "epoch 6, iter 117, loss: 25.868942, acc: 0.775510\n",
      "epoch 6, iter 118, loss: 33.049589, acc: 0.632653\n",
      "epoch 6, iter 119, loss: 29.902081, acc: 0.775510\n",
      "epoch 6, iter 120, loss: 28.543697, acc: 0.530612\n",
      "epoch 6, iter 121, loss: 29.934529, acc: 0.653061\n",
      "epoch 6, iter 122, loss: 28.089757, acc: 0.653061\n",
      "epoch 6, iter 123, loss: 29.984544, acc: 0.653061\n",
      "epoch 6, iter 124, loss: 34.826895, acc: 0.591837\n",
      "epoch 6, iter 125, loss: 33.510886, acc: 0.530612\n",
      "epoch 6, iter 126, loss: 25.140316, acc: 0.816327\n",
      "epoch 6, iter 127, loss: 36.442489, acc: 0.591837\n",
      "epoch 6, iter 128, loss: 31.092155, acc: 0.653061\n",
      "epoch 6, iter 129, loss: 25.956609, acc: 0.693878\n",
      "epoch 6, iter 130, loss: 24.088708, acc: 0.877551\n",
      "epoch 6, iter 131, loss: 26.770687, acc: 0.714286\n",
      "epoch 6, iter 132, loss: 31.505876, acc: 0.632653\n",
      "epoch 6, iter 133, loss: 23.745693, acc: 0.775510\n",
      "epoch 6, iter 134, loss: 36.653171, acc: 0.469388\n",
      "epoch 6, iter 135, loss: 33.043402, acc: 0.653061\n",
      "epoch 6, iter 136, loss: 31.368817, acc: 0.510204\n",
      "epoch 6, iter 137, loss: 29.500672, acc: 0.714286\n",
      "epoch 6, iter 138, loss: 25.067780, acc: 0.693878\n",
      "epoch 6, iter 139, loss: 24.129303, acc: 0.673469\n",
      "epoch 6, iter 140, loss: 29.024037, acc: 0.653061\n",
      "epoch 6, iter 141, loss: 20.521594, acc: 0.836735\n",
      "epoch 6, iter 142, loss: 32.073232, acc: 0.551020\n",
      "epoch 6, iter 143, loss: 26.745785, acc: 0.653061\n",
      "epoch 6, iter 144, loss: 31.450887, acc: 0.653061\n",
      "epoch 6, iter 145, loss: 18.238421, acc: 0.755102\n",
      "epoch 6, iter 146, loss: 27.652012, acc: 0.612245\n",
      "epoch 6, iter 147, loss: 26.041472, acc: 0.673469\n",
      "epoch 6, iter 148, loss: 29.563382, acc: 0.693878\n",
      "epoch 6, iter 149, loss: 22.254730, acc: 0.857143\n",
      "epoch 6, iter 150, loss: 29.539552, acc: 0.673469\n",
      "epoch 6, iter 151, loss: 32.975885, acc: 0.571429\n",
      "epoch 6, iter 152, loss: 32.107929, acc: 0.612245\n",
      "epoch 6, iter 153, loss: 34.822960, acc: 0.612245\n",
      "epoch 6, iter 154, loss: 32.263774, acc: 0.612245\n",
      "epoch 6, iter 155, loss: 31.159529, acc: 0.571429\n",
      "epoch 6, iter 156, loss: 26.452308, acc: 0.632653\n",
      "epoch 6, iter 157, loss: 32.533223, acc: 0.591837\n",
      "epoch 6, iter 158, loss: 21.466885, acc: 0.857143\n",
      "epoch 6, iter 159, loss: 36.251330, acc: 0.551020\n",
      "epoch 6, iter 160, loss: 29.174395, acc: 0.530612\n",
      "epoch 6, iter 161, loss: 26.003080, acc: 0.673469\n",
      "epoch 6, iter 162, loss: 29.164293, acc: 0.734694\n",
      "epoch 6, iter 163, loss: 33.999631, acc: 0.612245\n",
      "epoch 6, iter 164, loss: 31.553572, acc: 0.551020\n",
      "epoch 6, iter 165, loss: 22.832421, acc: 0.836735\n",
      "epoch 6, iter 166, loss: 27.594767, acc: 0.693878\n",
      "epoch 6, iter 167, loss: 29.796502, acc: 0.591837\n",
      "epoch 6, iter 168, loss: 27.553174, acc: 0.734694\n",
      "epoch 6, iter 169, loss: 37.331278, acc: 0.632653\n",
      "epoch 6, iter 170, loss: 34.512246, acc: 0.734694\n",
      "epoch 6, iter 171, loss: 28.224438, acc: 0.551020\n",
      "epoch 6, iter 172, loss: 29.746355, acc: 0.693878\n",
      "epoch 6, iter 173, loss: 33.910277, acc: 0.571429\n",
      "epoch 6, iter 174, loss: 30.418444, acc: 0.530612\n",
      "epoch 6, iter 175, loss: 24.291452, acc: 0.653061\n",
      "epoch 6, iter 176, loss: 29.688376, acc: 0.755102\n",
      "epoch 6, iter 177, loss: 26.072191, acc: 0.591837\n",
      "epoch 6, iter 178, loss: 40.825137, acc: 0.632653\n",
      "epoch 6, iter 179, loss: 25.979753, acc: 0.673469\n",
      "epoch 6, iter 180, loss: 23.096849, acc: 0.836735\n",
      "epoch 6, iter 181, loss: 34.971558, acc: 0.653061\n",
      "epoch 6, iter 182, loss: 31.617943, acc: 0.612245\n",
      "epoch 6, iter 183, loss: 32.590486, acc: 0.714286\n",
      "epoch 6, iter 184, loss: 31.145271, acc: 0.653061\n",
      "epoch 6, iter 185, loss: 32.657698, acc: 0.551020\n",
      "epoch 6, iter 186, loss: 21.745530, acc: 0.816327\n",
      "epoch 6, iter 187, loss: 32.932543, acc: 0.612245\n",
      "epoch 6, iter 188, loss: 37.970898, acc: 0.489796\n",
      "epoch 6, iter 189, loss: 37.243075, acc: 0.530612\n",
      "epoch 6, iter 190, loss: 26.917520, acc: 0.714286\n",
      "epoch 6, iter 191, loss: 28.579421, acc: 0.673469\n",
      "epoch 6, iter 192, loss: 29.667347, acc: 0.632653\n",
      "epoch 6, iter 193, loss: 30.182559, acc: 0.530612\n",
      "epoch 6, iter 194, loss: 24.644212, acc: 0.693878\n",
      "epoch 6, iter 195, loss: 32.620366, acc: 0.551020\n",
      "epoch 6, iter 196, loss: 25.573369, acc: 0.734694\n",
      "epoch 6, iter 197, loss: 30.974156, acc: 0.693878\n",
      "epoch 6, iter 198, loss: 27.977103, acc: 0.734694\n",
      "epoch 6, iter 199, loss: 40.354719, acc: 0.551020\n",
      "epoch 6, iter 200, loss: 30.285353, acc: 0.448980\n",
      "epoch 6, iter 201, loss: 24.951324, acc: 0.857143\n",
      "epoch 6, iter 202, loss: 24.779825, acc: 0.591837\n",
      "epoch 6, iter 203, loss: 34.506833, acc: 0.591837\n",
      "epoch 6, iter 204, loss: 33.736044, acc: 0.632653\n",
      "epoch 6, iter 205, loss: 37.790779, acc: 0.346939\n",
      "epoch 6, iter 206, loss: 26.831551, acc: 0.693878\n",
      "epoch 6, iter 207, loss: 35.999025, acc: 0.632653\n",
      "epoch 6, iter 208, loss: 27.529722, acc: 0.755102\n",
      "epoch 6, iter 209, loss: 30.324109, acc: 0.775510\n",
      "epoch 6, iter 210, loss: 34.113966, acc: 0.714286\n",
      "epoch 6, iter 211, loss: 21.621856, acc: 0.795918\n",
      "epoch 6, iter 212, loss: 25.050272, acc: 0.612245\n",
      "epoch 6, iter 213, loss: 22.554187, acc: 0.795918\n",
      "epoch 6, iter 214, loss: 20.887002, acc: 0.795918\n",
      "epoch 6, iter 215, loss: 37.566964, acc: 0.571429\n",
      "epoch 6, iter 216, loss: 31.110191, acc: 0.755102\n",
      "epoch 6, iter 217, loss: 32.920957, acc: 0.530612\n",
      "epoch 6, iter 218, loss: 28.899535, acc: 0.693878\n",
      "epoch 6, iter 219, loss: 27.395333, acc: 0.734694\n",
      "epoch 6, iter 220, loss: 30.569865, acc: 0.591837\n",
      "epoch 6, iter 221, loss: 22.812595, acc: 0.734694\n",
      "epoch 6, iter 222, loss: 33.698854, acc: 0.653061\n",
      "epoch 6, iter 223, loss: 25.316927, acc: 0.693878\n",
      "epoch 6, iter 224, loss: 23.948515, acc: 0.632653\n",
      "epoch 6, iter 225, loss: 29.804838, acc: 0.673469\n",
      "epoch 6, iter 226, loss: 27.448695, acc: 0.591837\n",
      "epoch 6, iter 227, loss: 26.648266, acc: 0.612245\n",
      "epoch 6, iter 228, loss: 27.625044, acc: 0.653061\n",
      "epoch 6, iter 229, loss: 17.490573, acc: 0.938776\n",
      "epoch 6, iter 230, loss: 29.100519, acc: 0.734694\n",
      "epoch 6, iter 231, loss: 25.766034, acc: 0.755102\n",
      "epoch 6, iter 232, loss: 33.631406, acc: 0.510204\n",
      "epoch 6, iter 233, loss: 33.636111, acc: 0.632653\n",
      "epoch 6, iter 234, loss: 21.653014, acc: 0.775510\n",
      "epoch 6, iter 235, loss: 28.317560, acc: 0.693878\n",
      "epoch 6, iter 236, loss: 22.929734, acc: 0.734694\n",
      "epoch 6, iter 237, loss: 31.432425, acc: 0.632653\n",
      "epoch 6, iter 238, loss: 35.706805, acc: 0.551020\n",
      "epoch 6, iter 239, loss: 33.370672, acc: 0.510204\n",
      "epoch 6, iter 240, loss: 27.981401, acc: 0.734694\n",
      "epoch 6, iter 241, loss: 30.832297, acc: 0.734694\n",
      "epoch 6, iter 242, loss: 36.759918, acc: 0.551020\n",
      "epoch 6, iter 243, loss: 29.651231, acc: 0.510204\n",
      "epoch 6, iter 244, loss: 34.938825, acc: 0.591837\n",
      "epoch 6, iter 245, loss: 36.494920, acc: 0.653061\n",
      "epoch 6, iter 246, loss: 35.281579, acc: 0.530612\n",
      "epoch 6, iter 247, loss: 36.702361, acc: 0.714286\n",
      "epoch 6, iter 248, loss: 27.529947, acc: 0.836735\n",
      "epoch 6, iter 249, loss: 36.096121, acc: 0.612245\n",
      "epoch 6, iter 250, loss: 29.590815, acc: 0.714286\n",
      "epoch 6, iter 251, loss: 28.867204, acc: 0.653061\n",
      "epoch 6, iter 252, loss: 29.856182, acc: 0.551020\n",
      "epoch 6, iter 253, loss: 28.301770, acc: 0.693878\n",
      "epoch 6, iter 254, loss: 19.960632, acc: 0.836735\n",
      "epoch 6, iter 255, loss: 30.397983, acc: 0.612245\n",
      "epoch 6, iter 256, loss: 30.799788, acc: 0.591837\n",
      "epoch 6, iter 257, loss: 30.560627, acc: 0.612245\n",
      "epoch 6, iter 258, loss: 34.588265, acc: 0.551020\n",
      "epoch 6, iter 259, loss: 22.228584, acc: 0.673469\n",
      "epoch 6, iter 260, loss: 36.155925, acc: 0.408163\n",
      "epoch 6, iter 261, loss: 21.982309, acc: 0.816327\n",
      "epoch 6, iter 262, loss: 28.233368, acc: 0.612245\n",
      "epoch 6, iter 263, loss: 32.877716, acc: 0.693878\n",
      "epoch 6, iter 264, loss: 27.456594, acc: 0.816327\n",
      "epoch 6, iter 265, loss: 23.147752, acc: 0.816327\n",
      "epoch 6, iter 266, loss: 37.477636, acc: 0.571429\n",
      "epoch 6, iter 267, loss: 33.218586, acc: 0.632653\n",
      "epoch 6, iter 268, loss: 28.016537, acc: 0.612245\n",
      "epoch 6, iter 269, loss: 23.372904, acc: 0.714286\n",
      "epoch 6, iter 270, loss: 28.092797, acc: 0.653061\n",
      "epoch 6, iter 271, loss: 21.526614, acc: 0.775510\n",
      "epoch 6, iter 272, loss: 19.903579, acc: 0.877551\n",
      "epoch 6, iter 273, loss: 35.573742, acc: 0.571429\n",
      "epoch 6, iter 274, loss: 31.362214, acc: 0.612245\n",
      "epoch 6, iter 275, loss: 32.525898, acc: 0.591837\n",
      "epoch 6, iter 276, loss: 19.306419, acc: 0.857143\n",
      "epoch 6, iter 277, loss: 31.991876, acc: 0.795918\n",
      "epoch 6, iter 278, loss: 24.172884, acc: 0.734694\n",
      "epoch 6, iter 279, loss: 28.302987, acc: 0.653061\n",
      "epoch 6, iter 280, loss: 36.311883, acc: 0.591837\n",
      "epoch 6, iter 281, loss: 33.002113, acc: 0.632653\n",
      "epoch 6, iter 282, loss: 34.216012, acc: 0.714286\n",
      "epoch 6, iter 283, loss: 33.330620, acc: 0.632653\n",
      "epoch 6, iter 284, loss: 25.831260, acc: 0.632653\n",
      "epoch 6, iter 285, loss: 23.133372, acc: 0.734694\n",
      "epoch 6, iter 286, loss: 25.685311, acc: 0.714286\n",
      "epoch 6, iter 287, loss: 28.381508, acc: 0.693878\n",
      "epoch 6, iter 288, loss: 25.760203, acc: 0.693878\n",
      "epoch 6, iter 289, loss: 26.641443, acc: 0.734694\n",
      "epoch 6, iter 290, loss: 29.257776, acc: 0.673469\n",
      "epoch 6, iter 291, loss: 28.530904, acc: 0.714286\n",
      "epoch 6, iter 292, loss: 26.368005, acc: 0.755102\n",
      "epoch 6, iter 293, loss: 25.365043, acc: 0.693878\n",
      "epoch 6, iter 294, loss: 23.183073, acc: 0.816327\n",
      "epoch 6, iter 295, loss: 31.014853, acc: 0.673469\n",
      "epoch 6, iter 296, loss: 30.791785, acc: 0.653061\n",
      "epoch 6, iter 297, loss: 28.369596, acc: 0.734694\n",
      "epoch 6, iter 298, loss: 30.667001, acc: 0.510204\n",
      "epoch 6, iter 299, loss: 32.367561, acc: 0.632653\n",
      "epoch 6, iter 300, loss: 19.103695, acc: 0.816327\n",
      "epoch 6, iter 301, loss: 25.197737, acc: 0.693878\n",
      "epoch 6, iter 302, loss: 31.390017, acc: 0.632653\n",
      "epoch 6, iter 303, loss: 32.948997, acc: 0.551020\n",
      "epoch 6, iter 304, loss: 31.136970, acc: 0.612245\n",
      "epoch 6, iter 305, loss: 35.140652, acc: 0.530612\n",
      "epoch 6, iter 306, loss: 33.222064, acc: 0.591837\n",
      "epoch 6, iter 307, loss: 28.169623, acc: 0.591837\n",
      "epoch 6, iter 308, loss: 37.033458, acc: 0.571429\n",
      "epoch 6, iter 309, loss: 28.455073, acc: 0.591837\n",
      "epoch 6, iter 310, loss: 24.625897, acc: 0.734694\n",
      "epoch 6, iter 311, loss: 22.205737, acc: 0.775510\n",
      "epoch 6, iter 312, loss: 20.714321, acc: 0.877551\n",
      "epoch 6, iter 313, loss: 24.429984, acc: 0.755102\n",
      "epoch 6, iter 314, loss: 27.905438, acc: 0.714286\n",
      "epoch 6, iter 315, loss: 29.753993, acc: 0.632653\n",
      "epoch 6, iter 316, loss: 24.505305, acc: 0.693878\n",
      "epoch 6, iter 317, loss: 21.609287, acc: 0.755102\n",
      "epoch 6, iter 318, loss: 37.770910, acc: 0.632653\n",
      "epoch 6, iter 319, loss: 33.297506, acc: 0.510204\n",
      "epoch 6, iter 320, loss: 24.481472, acc: 0.632653\n",
      "epoch 6, iter 321, loss: 25.760008, acc: 0.673469\n",
      "epoch 6, iter 322, loss: 36.847339, acc: 0.448980\n",
      "epoch 6, iter 323, loss: 27.625585, acc: 0.530612\n",
      "epoch 6, iter 324, loss: 27.482282, acc: 0.653061\n",
      "epoch 6, iter 325, loss: 18.816605, acc: 0.857143\n",
      "epoch 6, iter 326, loss: 33.091007, acc: 0.530612\n",
      "epoch 6, iter 327, loss: 22.090862, acc: 0.755102\n",
      "epoch 6, iter 328, loss: 27.251020, acc: 0.673469\n",
      "epoch 6, iter 329, loss: 30.676285, acc: 0.571429\n",
      "epoch 6, iter 330, loss: 30.864360, acc: 0.653061\n",
      "epoch 6, iter 331, loss: 33.296877, acc: 0.551020\n",
      "epoch 6, iter 332, loss: 35.468965, acc: 0.489796\n",
      "epoch 6, iter 333, loss: 29.999818, acc: 0.632653\n",
      "epoch 6, iter 334, loss: 30.938444, acc: 0.612245\n",
      "epoch 6, iter 335, loss: 22.896414, acc: 0.816327\n",
      "epoch 6, iter 336, loss: 24.906321, acc: 0.795918\n",
      "epoch 6, iter 337, loss: 31.536350, acc: 0.653061\n",
      "epoch 6, iter 338, loss: 25.521714, acc: 0.775510\n",
      "epoch 6, iter 339, loss: 25.729954, acc: 0.714286\n",
      "epoch 6, iter 340, loss: 35.299259, acc: 0.653061\n",
      "epoch 6, iter 341, loss: 25.237183, acc: 0.877551\n",
      "epoch 6, iter 342, loss: 35.189371, acc: 0.510204\n",
      "epoch 6, iter 343, loss: 32.245500, acc: 0.612245\n",
      "epoch 6, iter 344, loss: 26.908622, acc: 0.612245\n",
      "epoch 6, iter 345, loss: 29.602825, acc: 0.653061\n",
      "epoch 6, iter 346, loss: 26.177364, acc: 0.795918\n",
      "epoch 6, iter 347, loss: 22.067285, acc: 0.632653\n",
      "epoch 6, iter 348, loss: 30.498384, acc: 0.591837\n",
      "epoch 6, iter 349, loss: 33.746389, acc: 0.591837\n",
      "epoch 6, iter 350, loss: 30.402085, acc: 0.489796\n",
      "epoch 6, iter 351, loss: 32.747400, acc: 0.530612\n",
      "epoch 6, iter 352, loss: 30.788697, acc: 0.693878\n",
      "epoch 6, iter 353, loss: 37.736470, acc: 0.612245\n",
      "epoch 6, iter 354, loss: 28.684439, acc: 0.673469\n",
      "epoch 6, iter 355, loss: 29.400002, acc: 0.734694\n",
      "epoch 6, iter 356, loss: 26.348660, acc: 0.714286\n",
      "epoch 6, iter 357, loss: 32.384598, acc: 0.632653\n",
      "epoch 6, iter 358, loss: 34.541607, acc: 0.612245\n",
      "epoch 6, iter 359, loss: 25.194617, acc: 0.734694\n",
      "epoch 6, iter 360, loss: 26.407454, acc: 0.510204\n",
      "epoch 6, iter 361, loss: 29.468972, acc: 0.612245\n",
      "epoch 6, iter 362, loss: 34.624800, acc: 0.510204\n",
      "epoch 6, iter 363, loss: 27.441586, acc: 0.653061\n",
      "epoch 6, iter 364, loss: 41.018541, acc: 0.551020\n",
      "epoch 6, iter 365, loss: 26.739657, acc: 0.714286\n",
      "epoch 6, iter 366, loss: 32.492426, acc: 0.489796\n",
      "epoch 6, iter 367, loss: 42.774425, acc: 0.530612\n",
      "epoch 6, iter 368, loss: 28.604706, acc: 0.551020\n",
      "epoch 6, iter 369, loss: 31.191004, acc: 0.489796\n",
      "epoch 6, iter 370, loss: 34.257859, acc: 0.510204\n",
      "epoch 6, iter 371, loss: 28.346369, acc: 0.693878\n",
      "epoch 6, iter 372, loss: 34.971733, acc: 0.551020\n",
      "epoch 6, iter 373, loss: 26.739025, acc: 0.734694\n",
      "epoch 6, iter 374, loss: 34.076064, acc: 0.510204\n",
      "epoch 6, iter 375, loss: 28.087781, acc: 0.714286\n",
      "epoch 6, iter 376, loss: 30.342300, acc: 0.551020\n",
      "epoch 6, iter 377, loss: 25.252054, acc: 0.755102\n",
      "epoch 6, iter 378, loss: 28.074627, acc: 0.714286\n",
      "epoch 6, iter 379, loss: 34.896274, acc: 0.653061\n",
      "epoch 6, iter 380, loss: 38.201691, acc: 0.673469\n",
      "epoch 6, iter 381, loss: 33.318587, acc: 0.632653\n",
      "epoch 6, iter 382, loss: 23.574779, acc: 0.816327\n",
      "epoch 6, iter 383, loss: 23.498813, acc: 0.693878\n",
      "epoch 6, iter 384, loss: 30.205981, acc: 0.673469\n",
      "epoch 6, iter 385, loss: 19.016063, acc: 0.857143\n",
      "epoch 6, iter 386, loss: 39.268076, acc: 0.612245\n",
      "epoch 6, iter 387, loss: 30.456813, acc: 0.653061\n",
      "epoch 6, iter 388, loss: 26.741579, acc: 0.734694\n",
      "epoch 6, iter 389, loss: 30.805871, acc: 0.673469\n",
      "epoch 6, iter 390, loss: 31.649084, acc: 0.632653\n",
      "epoch 6, iter 391, loss: 27.640716, acc: 0.734694\n",
      "epoch 6, iter 392, loss: 27.291570, acc: 0.836735\n",
      "epoch 6, iter 393, loss: 31.208373, acc: 0.612245\n",
      "epoch 6, iter 394, loss: 23.892571, acc: 0.714286\n",
      "epoch 6, iter 395, loss: 28.876331, acc: 0.612245\n",
      "epoch 6, iter 396, loss: 26.512859, acc: 0.673469\n",
      "epoch 6, iter 397, loss: 20.194365, acc: 0.714286\n",
      "epoch 6, iter 398, loss: 33.479657, acc: 0.551020\n",
      "epoch 6, iter 399, loss: 23.691483, acc: 0.816327\n",
      "epoch 6, iter 400, loss: 38.057918, acc: 0.530612\n",
      "epoch 6, iter 401, loss: 31.921676, acc: 0.673469\n",
      "epoch 6, iter 402, loss: 32.838610, acc: 0.734694\n",
      "epoch 6, iter 403, loss: 35.431782, acc: 0.612245\n",
      "epoch 6, iter 404, loss: 35.383743, acc: 0.612245\n",
      "epoch 6, iter 405, loss: 31.368360, acc: 0.591837\n",
      "epoch 6, iter 406, loss: 25.558471, acc: 0.632653\n",
      "epoch 6, iter 407, loss: 32.577322, acc: 0.551020\n",
      "epoch 6, iter 408, loss: 29.967380, acc: 0.632653\n",
      "epoch 6, iter 409, loss: 22.060916, acc: 0.673469\n",
      "epoch 6, iter 410, loss: 32.743217, acc: 0.571429\n",
      "epoch 6, iter 411, loss: 29.980628, acc: 0.653061\n",
      "epoch 6, iter 412, loss: 28.386182, acc: 0.836735\n",
      "epoch 6, iter 413, loss: 25.548246, acc: 0.693878\n",
      "epoch 6, iter 414, loss: 32.870352, acc: 0.591837\n",
      "epoch 6, iter 415, loss: 30.604787, acc: 0.612245\n",
      "epoch 6, iter 416, loss: 27.152185, acc: 0.714286\n",
      "epoch 6, iter 417, loss: 32.488939, acc: 0.612245\n",
      "epoch 6, iter 418, loss: 27.832274, acc: 0.673469\n",
      "epoch 6, iter 419, loss: 27.379284, acc: 0.653061\n",
      "epoch 6, iter 420, loss: 35.087684, acc: 0.571429\n",
      "epoch 6, iter 421, loss: 23.249555, acc: 0.775510\n",
      "epoch 6, iter 422, loss: 26.071061, acc: 0.714286\n",
      "epoch 6, iter 423, loss: 35.278269, acc: 0.571429\n",
      "epoch 6, iter 424, loss: 29.866979, acc: 0.795918\n",
      "epoch 6, iter 425, loss: 27.094150, acc: 0.673469\n",
      "epoch 6, iter 426, loss: 29.141985, acc: 0.714286\n",
      "epoch 6, iter 427, loss: 33.027970, acc: 0.551020\n",
      "epoch 6, iter 428, loss: 27.330768, acc: 0.653061\n",
      "epoch 6, iter 429, loss: 27.751542, acc: 0.571429\n",
      "epoch 6, iter 430, loss: 27.066828, acc: 0.612245\n",
      "epoch 6, iter 431, loss: 33.243034, acc: 0.693878\n",
      "epoch 6, iter 432, loss: 25.992879, acc: 0.734694\n",
      "epoch 6, iter 433, loss: 25.970616, acc: 0.632653\n",
      "epoch 6, iter 434, loss: 24.198840, acc: 0.714286\n",
      "epoch 6, iter 435, loss: 29.433402, acc: 0.734694\n",
      "epoch 6, iter 436, loss: 27.601860, acc: 0.673469\n",
      "epoch 6, iter 437, loss: 44.645969, acc: 0.530612\n",
      "epoch 6, iter 438, loss: 34.066495, acc: 0.510204\n",
      "epoch 6, iter 439, loss: 31.792803, acc: 0.571429\n",
      "epoch 6, iter 440, loss: 31.640961, acc: 0.653061\n",
      "epoch 6, iter 441, loss: 27.228643, acc: 0.632653\n",
      "epoch 6, iter 442, loss: 31.544547, acc: 0.591837\n",
      "epoch 6, iter 443, loss: 24.509379, acc: 0.816327\n",
      "epoch 6, iter 444, loss: 27.292176, acc: 0.673469\n",
      "epoch 6, iter 445, loss: 45.083345, acc: 0.571429\n",
      "epoch 6, iter 446, loss: 31.728026, acc: 0.693878\n",
      "epoch 6, iter 447, loss: 27.822079, acc: 0.693878\n",
      "epoch 6, iter 448, loss: 34.306742, acc: 0.530612\n",
      "epoch 6, iter 449, loss: 17.293467, acc: 0.795918\n",
      "epoch 6, iter 450, loss: 31.824272, acc: 0.632653\n",
      "epoch 6, iter 451, loss: 24.869361, acc: 0.755102\n",
      "epoch 6, iter 452, loss: 26.712324, acc: 0.755102\n",
      "epoch 6, iter 453, loss: 33.016141, acc: 0.469388\n",
      "epoch 6, iter 454, loss: 27.268307, acc: 0.673469\n",
      "epoch 6, iter 455, loss: 30.461580, acc: 0.612245\n",
      "epoch 6, iter 456, loss: 29.586889, acc: 0.632653\n",
      "epoch 6, iter 457, loss: 31.297233, acc: 0.755102\n",
      "epoch 6, iter 458, loss: 21.167425, acc: 0.795918\n",
      "epoch 6, iter 459, loss: 32.325849, acc: 0.612245\n",
      "epoch 6, iter 460, loss: 31.883484, acc: 0.551020\n",
      "epoch 6, iter 461, loss: 29.110173, acc: 0.653061\n",
      "epoch 6, iter 462, loss: 33.048038, acc: 0.551020\n",
      "epoch 6, iter 463, loss: 30.127930, acc: 0.551020\n",
      "epoch 6, iter 464, loss: 25.486393, acc: 0.816327\n",
      "epoch 6, iter 465, loss: 31.838892, acc: 0.632653\n",
      "epoch 6, iter 466, loss: 36.148449, acc: 0.612245\n",
      "epoch 6, iter 467, loss: 30.594991, acc: 0.571429\n",
      "epoch 6, iter 468, loss: 30.780755, acc: 0.714286\n",
      "epoch 6, iter 469, loss: 32.694708, acc: 0.673469\n",
      "epoch 6, iter 470, loss: 37.275459, acc: 0.428571\n",
      "epoch 6, iter 471, loss: 27.412378, acc: 0.795918\n",
      "epoch 6, iter 472, loss: 26.182523, acc: 0.693878\n",
      "epoch 6, iter 473, loss: 26.771393, acc: 0.632653\n",
      "epoch 6, iter 474, loss: 28.684296, acc: 0.693878\n",
      "epoch 6, iter 475, loss: 30.824047, acc: 0.489796\n",
      "epoch 6, iter 476, loss: 24.650437, acc: 0.653061\n",
      "epoch 6, iter 477, loss: 34.654326, acc: 0.571429\n",
      "epoch 6, iter 478, loss: 27.851342, acc: 0.693878\n",
      "epoch 6, iter 479, loss: 30.123646, acc: 0.653061\n",
      "epoch 6, iter 480, loss: 28.336868, acc: 0.693878\n",
      "epoch 6, iter 481, loss: 24.065192, acc: 0.673469\n",
      "epoch 6, iter 482, loss: 25.799603, acc: 0.775510\n",
      "epoch 6, iter 483, loss: 28.154973, acc: 0.714286\n",
      "epoch 6, iter 484, loss: 26.900753, acc: 0.693878\n",
      "epoch 6, iter 485, loss: 26.355007, acc: 0.632653\n",
      "epoch 6, iter 486, loss: 32.556891, acc: 0.632653\n",
      "epoch 6, iter 487, loss: 26.144062, acc: 0.755102\n",
      "epoch 6, iter 488, loss: 23.882353, acc: 0.755102\n",
      "epoch 6, iter 489, loss: 31.253870, acc: 0.836735\n",
      "epoch 6, iter 490, loss: 31.215838, acc: 0.653061\n",
      "epoch 6, iter 491, loss: 30.559173, acc: 0.755102\n",
      "epoch 6, iter 492, loss: 30.429918, acc: 0.653061\n",
      "epoch 6, iter 493, loss: 23.312888, acc: 0.693878\n",
      "epoch 6, iter 494, loss: 30.126247, acc: 0.612245\n",
      "epoch 6, iter 495, loss: 31.089206, acc: 0.469388\n",
      "epoch 6, iter 496, loss: 26.738711, acc: 0.673469\n",
      "epoch 6, iter 497, loss: 32.761770, acc: 0.551020\n",
      "epoch 6, iter 498, loss: 34.486491, acc: 0.551020\n",
      "epoch 6, iter 499, loss: 33.216046, acc: 0.653061\n",
      "epoch 6, acc: 0.660531\n",
      "epoch 7, iter 0, loss: 32.365522, acc: 0.571429\n",
      "epoch 7, iter 1, loss: 36.351302, acc: 0.673469\n",
      "epoch 7, iter 2, loss: 29.962787, acc: 0.714286\n",
      "epoch 7, iter 3, loss: 27.626059, acc: 0.632653\n",
      "epoch 7, iter 4, loss: 24.663919, acc: 0.693878\n",
      "epoch 7, iter 5, loss: 27.082206, acc: 0.775510\n",
      "epoch 7, iter 6, loss: 26.261888, acc: 0.857143\n",
      "epoch 7, iter 7, loss: 32.699901, acc: 0.673469\n",
      "epoch 7, iter 8, loss: 30.489271, acc: 0.653061\n",
      "epoch 7, iter 9, loss: 22.882400, acc: 0.734694\n",
      "epoch 7, iter 10, loss: 32.543446, acc: 0.612245\n",
      "epoch 7, iter 11, loss: 40.400026, acc: 0.469388\n",
      "epoch 7, iter 12, loss: 26.174731, acc: 0.734694\n",
      "epoch 7, iter 13, loss: 31.007206, acc: 0.714286\n",
      "epoch 7, iter 14, loss: 28.299107, acc: 0.551020\n",
      "epoch 7, iter 15, loss: 20.520050, acc: 0.775510\n",
      "epoch 7, iter 16, loss: 34.544377, acc: 0.551020\n",
      "epoch 7, iter 17, loss: 24.321175, acc: 0.714286\n",
      "epoch 7, iter 18, loss: 35.952079, acc: 0.551020\n",
      "epoch 7, iter 19, loss: 20.102611, acc: 0.857143\n",
      "epoch 7, iter 20, loss: 21.686238, acc: 0.734694\n",
      "epoch 7, iter 21, loss: 28.101587, acc: 0.673469\n",
      "epoch 7, iter 22, loss: 25.179070, acc: 0.714286\n",
      "epoch 7, iter 23, loss: 35.704904, acc: 0.591837\n",
      "epoch 7, iter 24, loss: 33.251717, acc: 0.591837\n",
      "epoch 7, iter 25, loss: 30.821795, acc: 0.612245\n",
      "epoch 7, iter 26, loss: 35.386685, acc: 0.428571\n",
      "epoch 7, iter 27, loss: 32.662099, acc: 0.591837\n",
      "epoch 7, iter 28, loss: 29.208704, acc: 0.673469\n",
      "epoch 7, iter 29, loss: 20.396214, acc: 0.775510\n",
      "epoch 7, iter 30, loss: 29.057042, acc: 0.551020\n",
      "epoch 7, iter 31, loss: 33.191183, acc: 0.510204\n",
      "epoch 7, iter 32, loss: 28.972163, acc: 0.632653\n",
      "epoch 7, iter 33, loss: 22.813415, acc: 0.734694\n",
      "epoch 7, iter 34, loss: 29.058746, acc: 0.653061\n",
      "epoch 7, iter 35, loss: 35.120829, acc: 0.632653\n",
      "epoch 7, iter 36, loss: 33.956712, acc: 0.653061\n",
      "epoch 7, iter 37, loss: 24.538020, acc: 0.673469\n",
      "epoch 7, iter 38, loss: 36.669021, acc: 0.530612\n",
      "epoch 7, iter 39, loss: 30.649771, acc: 0.734694\n",
      "epoch 7, iter 40, loss: 32.674325, acc: 0.591837\n",
      "epoch 7, iter 41, loss: 28.729870, acc: 0.734694\n",
      "epoch 7, iter 42, loss: 31.451424, acc: 0.530612\n",
      "epoch 7, iter 43, loss: 25.051148, acc: 0.836735\n",
      "epoch 7, iter 44, loss: 25.755656, acc: 0.816327\n",
      "epoch 7, iter 45, loss: 31.289622, acc: 0.653061\n",
      "epoch 7, iter 46, loss: 32.130353, acc: 0.571429\n",
      "epoch 7, iter 47, loss: 29.764819, acc: 0.653061\n",
      "epoch 7, iter 48, loss: 27.724281, acc: 0.714286\n",
      "epoch 7, iter 49, loss: 21.427989, acc: 0.632653\n",
      "epoch 7, iter 50, loss: 27.677383, acc: 0.673469\n",
      "epoch 7, iter 51, loss: 35.327987, acc: 0.591837\n",
      "epoch 7, iter 52, loss: 32.340963, acc: 0.653061\n",
      "epoch 7, iter 53, loss: 31.637336, acc: 0.714286\n",
      "epoch 7, iter 54, loss: 29.000199, acc: 0.653061\n",
      "epoch 7, iter 55, loss: 26.749399, acc: 0.673469\n",
      "epoch 7, iter 56, loss: 20.489991, acc: 0.857143\n",
      "epoch 7, iter 57, loss: 26.066101, acc: 0.693878\n",
      "epoch 7, iter 58, loss: 29.587510, acc: 0.591837\n",
      "epoch 7, iter 59, loss: 27.494356, acc: 0.734694\n",
      "epoch 7, iter 60, loss: 31.718180, acc: 0.673469\n",
      "epoch 7, iter 61, loss: 23.039702, acc: 0.755102\n",
      "epoch 7, iter 62, loss: 33.549599, acc: 0.632653\n",
      "epoch 7, iter 63, loss: 25.729652, acc: 0.775510\n",
      "epoch 7, iter 64, loss: 30.056354, acc: 0.612245\n",
      "epoch 7, iter 65, loss: 27.528935, acc: 0.673469\n",
      "epoch 7, iter 66, loss: 22.195637, acc: 0.857143\n",
      "epoch 7, iter 67, loss: 31.965912, acc: 0.632653\n",
      "epoch 7, iter 68, loss: 24.528000, acc: 0.693878\n",
      "epoch 7, iter 69, loss: 23.172637, acc: 0.775510\n",
      "epoch 7, iter 70, loss: 24.103492, acc: 0.714286\n",
      "epoch 7, iter 71, loss: 28.457868, acc: 0.734694\n",
      "epoch 7, iter 72, loss: 24.889474, acc: 0.755102\n",
      "epoch 7, iter 73, loss: 21.988757, acc: 0.714286\n",
      "epoch 7, iter 74, loss: 26.760054, acc: 0.673469\n",
      "epoch 7, iter 75, loss: 29.864854, acc: 0.795918\n",
      "epoch 7, iter 76, loss: 31.206717, acc: 0.734694\n",
      "epoch 7, iter 77, loss: 32.057455, acc: 0.510204\n",
      "epoch 7, iter 78, loss: 32.338176, acc: 0.653061\n",
      "epoch 7, iter 79, loss: 27.637488, acc: 0.653061\n",
      "epoch 7, iter 80, loss: 20.594426, acc: 0.897959\n",
      "epoch 7, iter 81, loss: 27.115593, acc: 0.653061\n",
      "epoch 7, iter 82, loss: 30.062171, acc: 0.673469\n",
      "epoch 7, iter 83, loss: 28.961209, acc: 0.693878\n",
      "epoch 7, iter 84, loss: 21.628020, acc: 0.775510\n",
      "epoch 7, iter 85, loss: 19.817800, acc: 0.816327\n",
      "epoch 7, iter 86, loss: 28.099824, acc: 0.653061\n",
      "epoch 7, iter 87, loss: 40.624680, acc: 0.346939\n",
      "epoch 7, iter 88, loss: 26.564299, acc: 0.755102\n",
      "epoch 7, iter 89, loss: 29.281590, acc: 0.632653\n",
      "epoch 7, iter 90, loss: 30.234615, acc: 0.591837\n",
      "epoch 7, iter 91, loss: 27.960426, acc: 0.775510\n",
      "epoch 7, iter 92, loss: 36.462912, acc: 0.469388\n",
      "epoch 7, iter 93, loss: 37.953350, acc: 0.612245\n",
      "epoch 7, iter 94, loss: 32.829333, acc: 0.734694\n",
      "epoch 7, iter 95, loss: 19.860222, acc: 0.857143\n",
      "epoch 7, iter 96, loss: 25.008711, acc: 0.693878\n",
      "epoch 7, iter 97, loss: 30.120052, acc: 0.632653\n",
      "epoch 7, iter 98, loss: 31.979452, acc: 0.612245\n",
      "epoch 7, iter 99, loss: 25.446737, acc: 0.714286\n",
      "epoch 7, iter 100, loss: 39.204559, acc: 0.612245\n",
      "epoch 7, iter 101, loss: 26.208616, acc: 0.775510\n",
      "epoch 7, iter 102, loss: 26.312440, acc: 0.816327\n",
      "epoch 7, iter 103, loss: 22.240539, acc: 0.755102\n",
      "epoch 7, iter 104, loss: 33.097102, acc: 0.591837\n",
      "epoch 7, iter 105, loss: 30.630179, acc: 0.673469\n",
      "epoch 7, iter 106, loss: 23.658095, acc: 0.755102\n",
      "epoch 7, iter 107, loss: 19.317187, acc: 0.816327\n",
      "epoch 7, iter 108, loss: 29.540006, acc: 0.612245\n",
      "epoch 7, iter 109, loss: 25.550019, acc: 0.632653\n",
      "epoch 7, iter 110, loss: 30.175811, acc: 0.673469\n",
      "epoch 7, iter 111, loss: 37.905078, acc: 0.551020\n",
      "epoch 7, iter 112, loss: 29.579961, acc: 0.571429\n",
      "epoch 7, iter 113, loss: 38.085644, acc: 0.428571\n",
      "epoch 7, iter 114, loss: 30.909866, acc: 0.530612\n",
      "epoch 7, iter 115, loss: 26.962877, acc: 0.591837\n",
      "epoch 7, iter 116, loss: 37.104444, acc: 0.591837\n",
      "epoch 7, iter 117, loss: 25.629157, acc: 0.755102\n",
      "epoch 7, iter 118, loss: 33.285309, acc: 0.632653\n",
      "epoch 7, iter 119, loss: 29.071444, acc: 0.795918\n",
      "epoch 7, iter 120, loss: 27.156279, acc: 0.530612\n",
      "epoch 7, iter 121, loss: 30.481386, acc: 0.653061\n",
      "epoch 7, iter 122, loss: 28.890131, acc: 0.673469\n",
      "epoch 7, iter 123, loss: 29.261558, acc: 0.673469\n",
      "epoch 7, iter 124, loss: 33.886332, acc: 0.591837\n",
      "epoch 7, iter 125, loss: 34.539149, acc: 0.530612\n",
      "epoch 7, iter 126, loss: 25.113555, acc: 0.816327\n",
      "epoch 7, iter 127, loss: 35.788782, acc: 0.530612\n",
      "epoch 7, iter 128, loss: 32.114157, acc: 0.673469\n",
      "epoch 7, iter 129, loss: 25.565331, acc: 0.693878\n",
      "epoch 7, iter 130, loss: 24.318961, acc: 0.897959\n",
      "epoch 7, iter 131, loss: 25.965740, acc: 0.775510\n",
      "epoch 7, iter 132, loss: 31.260404, acc: 0.612245\n",
      "epoch 7, iter 133, loss: 24.251228, acc: 0.836735\n",
      "epoch 7, iter 134, loss: 36.238168, acc: 0.428571\n",
      "epoch 7, iter 135, loss: 31.954132, acc: 0.673469\n",
      "epoch 7, iter 136, loss: 29.812288, acc: 0.551020\n",
      "epoch 7, iter 137, loss: 27.740698, acc: 0.673469\n",
      "epoch 7, iter 138, loss: 25.402404, acc: 0.693878\n",
      "epoch 7, iter 139, loss: 24.099521, acc: 0.653061\n",
      "epoch 7, iter 140, loss: 28.290470, acc: 0.673469\n",
      "epoch 7, iter 141, loss: 20.173589, acc: 0.836735\n",
      "epoch 7, iter 142, loss: 31.968351, acc: 0.551020\n",
      "epoch 7, iter 143, loss: 27.438426, acc: 0.673469\n",
      "epoch 7, iter 144, loss: 31.802575, acc: 0.653061\n",
      "epoch 7, iter 145, loss: 17.525067, acc: 0.775510\n",
      "epoch 7, iter 146, loss: 26.568001, acc: 0.591837\n",
      "epoch 7, iter 147, loss: 24.547827, acc: 0.673469\n",
      "epoch 7, iter 148, loss: 29.250858, acc: 0.693878\n",
      "epoch 7, iter 149, loss: 21.852647, acc: 0.857143\n",
      "epoch 7, iter 150, loss: 29.268095, acc: 0.673469\n",
      "epoch 7, iter 151, loss: 33.645951, acc: 0.632653\n",
      "epoch 7, iter 152, loss: 32.227731, acc: 0.653061\n",
      "epoch 7, iter 153, loss: 34.303252, acc: 0.612245\n",
      "epoch 7, iter 154, loss: 32.132740, acc: 0.612245\n",
      "epoch 7, iter 155, loss: 31.917111, acc: 0.632653\n",
      "epoch 7, iter 156, loss: 25.746586, acc: 0.591837\n",
      "epoch 7, iter 157, loss: 31.561210, acc: 0.653061\n",
      "epoch 7, iter 158, loss: 21.201101, acc: 0.857143\n",
      "epoch 7, iter 159, loss: 34.966249, acc: 0.551020\n",
      "epoch 7, iter 160, loss: 28.294009, acc: 0.530612\n",
      "epoch 7, iter 161, loss: 24.920726, acc: 0.693878\n",
      "epoch 7, iter 162, loss: 27.970986, acc: 0.693878\n",
      "epoch 7, iter 163, loss: 33.587533, acc: 0.591837\n",
      "epoch 7, iter 164, loss: 31.525318, acc: 0.551020\n",
      "epoch 7, iter 165, loss: 22.937605, acc: 0.857143\n",
      "epoch 7, iter 166, loss: 27.616871, acc: 0.693878\n",
      "epoch 7, iter 167, loss: 30.251721, acc: 0.571429\n",
      "epoch 7, iter 168, loss: 27.450873, acc: 0.714286\n",
      "epoch 7, iter 169, loss: 36.016026, acc: 0.612245\n",
      "epoch 7, iter 170, loss: 34.535724, acc: 0.714286\n",
      "epoch 7, iter 171, loss: 28.459628, acc: 0.591837\n",
      "epoch 7, iter 172, loss: 27.789435, acc: 0.673469\n",
      "epoch 7, iter 173, loss: 33.334084, acc: 0.591837\n",
      "epoch 7, iter 174, loss: 29.625482, acc: 0.591837\n",
      "epoch 7, iter 175, loss: 23.015596, acc: 0.612245\n",
      "epoch 7, iter 176, loss: 28.229238, acc: 0.734694\n",
      "epoch 7, iter 177, loss: 25.613512, acc: 0.653061\n",
      "epoch 7, iter 178, loss: 38.835916, acc: 0.591837\n",
      "epoch 7, iter 179, loss: 26.119602, acc: 0.734694\n",
      "epoch 7, iter 180, loss: 22.605028, acc: 0.836735\n",
      "epoch 7, iter 181, loss: 35.165100, acc: 0.591837\n",
      "epoch 7, iter 182, loss: 31.486207, acc: 0.591837\n",
      "epoch 7, iter 183, loss: 32.126008, acc: 0.612245\n",
      "epoch 7, iter 184, loss: 31.489841, acc: 0.673469\n",
      "epoch 7, iter 185, loss: 32.633071, acc: 0.530612\n",
      "epoch 7, iter 186, loss: 21.437009, acc: 0.857143\n",
      "epoch 7, iter 187, loss: 32.615265, acc: 0.591837\n",
      "epoch 7, iter 188, loss: 36.843211, acc: 0.346939\n",
      "epoch 7, iter 189, loss: 38.510605, acc: 0.530612\n",
      "epoch 7, iter 190, loss: 26.416426, acc: 0.714286\n",
      "epoch 7, iter 191, loss: 28.335680, acc: 0.734694\n",
      "epoch 7, iter 192, loss: 31.090882, acc: 0.591837\n",
      "epoch 7, iter 193, loss: 31.270645, acc: 0.571429\n",
      "epoch 7, iter 194, loss: 24.108777, acc: 0.755102\n",
      "epoch 7, iter 195, loss: 33.379837, acc: 0.571429\n",
      "epoch 7, iter 196, loss: 25.942881, acc: 0.755102\n",
      "epoch 7, iter 197, loss: 30.567065, acc: 0.653061\n",
      "epoch 7, iter 198, loss: 27.689947, acc: 0.693878\n",
      "epoch 7, iter 199, loss: 40.907507, acc: 0.632653\n",
      "epoch 7, iter 200, loss: 29.011217, acc: 0.510204\n",
      "epoch 7, iter 201, loss: 24.233089, acc: 0.816327\n",
      "epoch 7, iter 202, loss: 26.587402, acc: 0.653061\n",
      "epoch 7, iter 203, loss: 33.611219, acc: 0.571429\n",
      "epoch 7, iter 204, loss: 33.837622, acc: 0.632653\n",
      "epoch 7, iter 205, loss: 37.036880, acc: 0.469388\n",
      "epoch 7, iter 206, loss: 27.245623, acc: 0.653061\n",
      "epoch 7, iter 207, loss: 34.128761, acc: 0.693878\n",
      "epoch 7, iter 208, loss: 27.748982, acc: 0.775510\n",
      "epoch 7, iter 209, loss: 29.661923, acc: 0.775510\n",
      "epoch 7, iter 210, loss: 31.913355, acc: 0.612245\n",
      "epoch 7, iter 211, loss: 20.177788, acc: 0.755102\n",
      "epoch 7, iter 212, loss: 26.054247, acc: 0.591837\n",
      "epoch 7, iter 213, loss: 22.468879, acc: 0.795918\n",
      "epoch 7, iter 214, loss: 20.327153, acc: 0.816327\n",
      "epoch 7, iter 215, loss: 37.182495, acc: 0.591837\n",
      "epoch 7, iter 216, loss: 29.667834, acc: 0.755102\n",
      "epoch 7, iter 217, loss: 32.420537, acc: 0.489796\n",
      "epoch 7, iter 218, loss: 28.444492, acc: 0.693878\n",
      "epoch 7, iter 219, loss: 26.017381, acc: 0.693878\n",
      "epoch 7, iter 220, loss: 29.202230, acc: 0.632653\n",
      "epoch 7, iter 221, loss: 22.132463, acc: 0.734694\n",
      "epoch 7, iter 222, loss: 33.402491, acc: 0.673469\n",
      "epoch 7, iter 223, loss: 25.103565, acc: 0.714286\n",
      "epoch 7, iter 224, loss: 22.462527, acc: 0.693878\n",
      "epoch 7, iter 225, loss: 28.786470, acc: 0.714286\n",
      "epoch 7, iter 226, loss: 26.079135, acc: 0.591837\n",
      "epoch 7, iter 227, loss: 25.686449, acc: 0.591837\n",
      "epoch 7, iter 228, loss: 26.314410, acc: 0.653061\n",
      "epoch 7, iter 229, loss: 15.766863, acc: 0.897959\n",
      "epoch 7, iter 230, loss: 28.947797, acc: 0.632653\n",
      "epoch 7, iter 231, loss: 26.779543, acc: 0.795918\n",
      "epoch 7, iter 232, loss: 33.708404, acc: 0.489796\n",
      "epoch 7, iter 233, loss: 32.165646, acc: 0.653061\n",
      "epoch 7, iter 234, loss: 22.603513, acc: 0.714286\n",
      "epoch 7, iter 235, loss: 27.528453, acc: 0.653061\n",
      "epoch 7, iter 236, loss: 23.525191, acc: 0.755102\n",
      "epoch 7, iter 237, loss: 31.321382, acc: 0.612245\n",
      "epoch 7, iter 238, loss: 35.830540, acc: 0.571429\n",
      "epoch 7, iter 239, loss: 33.223819, acc: 0.530612\n",
      "epoch 7, iter 240, loss: 28.513237, acc: 0.734694\n",
      "epoch 7, iter 241, loss: 30.558556, acc: 0.714286\n",
      "epoch 7, iter 242, loss: 36.406235, acc: 0.591837\n",
      "epoch 7, iter 243, loss: 29.655625, acc: 0.551020\n",
      "epoch 7, iter 244, loss: 35.172732, acc: 0.571429\n",
      "epoch 7, iter 245, loss: 34.053238, acc: 0.612245\n",
      "epoch 7, iter 246, loss: 34.851496, acc: 0.530612\n",
      "epoch 7, iter 247, loss: 36.614316, acc: 0.673469\n",
      "epoch 7, iter 248, loss: 26.813097, acc: 0.775510\n",
      "epoch 7, iter 249, loss: 35.182747, acc: 0.653061\n",
      "epoch 7, iter 250, loss: 30.144965, acc: 0.755102\n",
      "epoch 7, iter 251, loss: 27.716077, acc: 0.653061\n",
      "epoch 7, iter 252, loss: 28.185111, acc: 0.653061\n",
      "epoch 7, iter 253, loss: 26.533797, acc: 0.755102\n",
      "epoch 7, iter 254, loss: 19.329866, acc: 0.836735\n",
      "epoch 7, iter 255, loss: 31.107024, acc: 0.591837\n",
      "epoch 7, iter 256, loss: 30.660059, acc: 0.632653\n",
      "epoch 7, iter 257, loss: 29.870006, acc: 0.591837\n",
      "epoch 7, iter 258, loss: 35.549662, acc: 0.530612\n",
      "epoch 7, iter 259, loss: 22.192035, acc: 0.714286\n",
      "epoch 7, iter 260, loss: 36.331783, acc: 0.367347\n",
      "epoch 7, iter 261, loss: 21.586164, acc: 0.795918\n",
      "epoch 7, iter 262, loss: 27.890758, acc: 0.693878\n",
      "epoch 7, iter 263, loss: 32.236529, acc: 0.714286\n",
      "epoch 7, iter 264, loss: 27.095067, acc: 0.816327\n",
      "epoch 7, iter 265, loss: 23.590255, acc: 0.795918\n",
      "epoch 7, iter 266, loss: 36.116715, acc: 0.571429\n",
      "epoch 7, iter 267, loss: 32.881661, acc: 0.653061\n",
      "epoch 7, iter 268, loss: 28.394972, acc: 0.632653\n",
      "epoch 7, iter 269, loss: 23.659464, acc: 0.734694\n",
      "epoch 7, iter 270, loss: 30.035568, acc: 0.673469\n",
      "epoch 7, iter 271, loss: 20.781816, acc: 0.775510\n",
      "epoch 7, iter 272, loss: 19.599248, acc: 0.857143\n",
      "epoch 7, iter 273, loss: 34.254203, acc: 0.632653\n",
      "epoch 7, iter 274, loss: 30.032021, acc: 0.612245\n",
      "epoch 7, iter 275, loss: 31.931650, acc: 0.632653\n",
      "epoch 7, iter 276, loss: 18.691303, acc: 0.836735\n",
      "epoch 7, iter 277, loss: 31.378220, acc: 0.836735\n",
      "epoch 7, iter 278, loss: 23.834947, acc: 0.693878\n",
      "epoch 7, iter 279, loss: 28.925677, acc: 0.612245\n",
      "epoch 7, iter 280, loss: 36.546468, acc: 0.612245\n",
      "epoch 7, iter 281, loss: 32.322190, acc: 0.510204\n",
      "epoch 7, iter 282, loss: 34.886771, acc: 0.714286\n",
      "epoch 7, iter 283, loss: 32.945033, acc: 0.612245\n",
      "epoch 7, iter 284, loss: 24.953609, acc: 0.653061\n",
      "epoch 7, iter 285, loss: 21.345809, acc: 0.775510\n",
      "epoch 7, iter 286, loss: 24.998742, acc: 0.714286\n",
      "epoch 7, iter 287, loss: 28.718781, acc: 0.673469\n",
      "epoch 7, iter 288, loss: 25.529811, acc: 0.734694\n",
      "epoch 7, iter 289, loss: 26.554874, acc: 0.714286\n",
      "epoch 7, iter 290, loss: 29.744766, acc: 0.693878\n",
      "epoch 7, iter 291, loss: 27.790201, acc: 0.632653\n",
      "epoch 7, iter 292, loss: 25.575400, acc: 0.734694\n",
      "epoch 7, iter 293, loss: 25.608572, acc: 0.653061\n",
      "epoch 7, iter 294, loss: 23.283291, acc: 0.836735\n",
      "epoch 7, iter 295, loss: 31.105380, acc: 0.693878\n",
      "epoch 7, iter 296, loss: 30.049894, acc: 0.693878\n",
      "epoch 7, iter 297, loss: 28.107485, acc: 0.755102\n",
      "epoch 7, iter 298, loss: 29.931690, acc: 0.530612\n",
      "epoch 7, iter 299, loss: 31.895120, acc: 0.673469\n",
      "epoch 7, iter 300, loss: 19.181552, acc: 0.816327\n",
      "epoch 7, iter 301, loss: 24.507974, acc: 0.734694\n",
      "epoch 7, iter 302, loss: 29.274486, acc: 0.632653\n",
      "epoch 7, iter 303, loss: 31.531340, acc: 0.551020\n",
      "epoch 7, iter 304, loss: 30.062589, acc: 0.612245\n",
      "epoch 7, iter 305, loss: 34.918381, acc: 0.510204\n",
      "epoch 7, iter 306, loss: 32.281671, acc: 0.591837\n",
      "epoch 7, iter 307, loss: 27.672925, acc: 0.612245\n",
      "epoch 7, iter 308, loss: 35.715295, acc: 0.632653\n",
      "epoch 7, iter 309, loss: 26.373580, acc: 0.632653\n",
      "epoch 7, iter 310, loss: 24.642147, acc: 0.734694\n",
      "epoch 7, iter 311, loss: 21.630491, acc: 0.775510\n",
      "epoch 7, iter 312, loss: 20.366409, acc: 0.836735\n",
      "epoch 7, iter 313, loss: 24.329457, acc: 0.795918\n",
      "epoch 7, iter 314, loss: 26.954938, acc: 0.734694\n",
      "epoch 7, iter 315, loss: 30.276161, acc: 0.591837\n",
      "epoch 7, iter 316, loss: 23.789076, acc: 0.714286\n",
      "epoch 7, iter 317, loss: 19.846365, acc: 0.755102\n",
      "epoch 7, iter 318, loss: 36.356246, acc: 0.673469\n",
      "epoch 7, iter 319, loss: 33.882419, acc: 0.571429\n",
      "epoch 7, iter 320, loss: 24.690399, acc: 0.673469\n",
      "epoch 7, iter 321, loss: 25.251423, acc: 0.714286\n",
      "epoch 7, iter 322, loss: 36.527315, acc: 0.387755\n",
      "epoch 7, iter 323, loss: 27.279487, acc: 0.510204\n",
      "epoch 7, iter 324, loss: 26.368602, acc: 0.673469\n",
      "epoch 7, iter 325, loss: 19.963784, acc: 0.877551\n",
      "epoch 7, iter 326, loss: 33.419219, acc: 0.551020\n",
      "epoch 7, iter 327, loss: 22.218067, acc: 0.816327\n",
      "epoch 7, iter 328, loss: 26.654272, acc: 0.755102\n",
      "epoch 7, iter 329, loss: 30.196071, acc: 0.612245\n",
      "epoch 7, iter 330, loss: 30.654643, acc: 0.673469\n",
      "epoch 7, iter 331, loss: 31.713355, acc: 0.571429\n",
      "epoch 7, iter 332, loss: 36.482783, acc: 0.489796\n",
      "epoch 7, iter 333, loss: 30.789601, acc: 0.591837\n",
      "epoch 7, iter 334, loss: 32.465411, acc: 0.653061\n",
      "epoch 7, iter 335, loss: 20.315707, acc: 0.795918\n",
      "epoch 7, iter 336, loss: 23.171614, acc: 0.857143\n",
      "epoch 7, iter 337, loss: 31.176154, acc: 0.612245\n",
      "epoch 7, iter 338, loss: 25.920212, acc: 0.795918\n",
      "epoch 7, iter 339, loss: 25.798959, acc: 0.755102\n",
      "epoch 7, iter 340, loss: 34.148278, acc: 0.632653\n",
      "epoch 7, iter 341, loss: 26.442401, acc: 0.836735\n",
      "epoch 7, iter 342, loss: 34.940335, acc: 0.408163\n",
      "epoch 7, iter 343, loss: 31.572014, acc: 0.653061\n",
      "epoch 7, iter 344, loss: 28.017388, acc: 0.653061\n",
      "epoch 7, iter 345, loss: 29.005776, acc: 0.591837\n",
      "epoch 7, iter 346, loss: 24.764556, acc: 0.816327\n",
      "epoch 7, iter 347, loss: 21.197242, acc: 0.591837\n",
      "epoch 7, iter 348, loss: 31.951931, acc: 0.551020\n",
      "epoch 7, iter 349, loss: 36.097166, acc: 0.612245\n",
      "epoch 7, iter 350, loss: 30.678363, acc: 0.469388\n",
      "epoch 7, iter 351, loss: 33.802306, acc: 0.591837\n",
      "epoch 7, iter 352, loss: 31.600522, acc: 0.673469\n",
      "epoch 7, iter 353, loss: 38.434789, acc: 0.571429\n",
      "epoch 7, iter 354, loss: 28.759644, acc: 0.693878\n",
      "epoch 7, iter 355, loss: 29.254564, acc: 0.714286\n",
      "epoch 7, iter 356, loss: 25.815155, acc: 0.693878\n",
      "epoch 7, iter 357, loss: 32.668869, acc: 0.632653\n",
      "epoch 7, iter 358, loss: 33.920928, acc: 0.510204\n",
      "epoch 7, iter 359, loss: 23.847283, acc: 0.734694\n",
      "epoch 7, iter 360, loss: 26.219348, acc: 0.571429\n",
      "epoch 7, iter 361, loss: 29.575140, acc: 0.591837\n",
      "epoch 7, iter 362, loss: 33.360342, acc: 0.612245\n",
      "epoch 7, iter 363, loss: 26.378471, acc: 0.612245\n",
      "epoch 7, iter 364, loss: 39.990388, acc: 0.551020\n",
      "epoch 7, iter 365, loss: 27.782713, acc: 0.612245\n",
      "epoch 7, iter 366, loss: 31.171509, acc: 0.489796\n",
      "epoch 7, iter 367, loss: 43.016768, acc: 0.551020\n",
      "epoch 7, iter 368, loss: 29.233045, acc: 0.551020\n",
      "epoch 7, iter 369, loss: 31.602383, acc: 0.551020\n",
      "epoch 7, iter 370, loss: 35.313518, acc: 0.530612\n",
      "epoch 7, iter 371, loss: 27.518931, acc: 0.693878\n",
      "epoch 7, iter 372, loss: 37.709853, acc: 0.489796\n",
      "epoch 7, iter 373, loss: 27.061142, acc: 0.714286\n",
      "epoch 7, iter 374, loss: 32.180686, acc: 0.530612\n",
      "epoch 7, iter 375, loss: 27.218164, acc: 0.714286\n",
      "epoch 7, iter 376, loss: 29.628289, acc: 0.591837\n",
      "epoch 7, iter 377, loss: 24.467072, acc: 0.693878\n",
      "epoch 7, iter 378, loss: 28.070015, acc: 0.693878\n",
      "epoch 7, iter 379, loss: 33.328660, acc: 0.632653\n",
      "epoch 7, iter 380, loss: 38.289506, acc: 0.591837\n",
      "epoch 7, iter 381, loss: 33.374728, acc: 0.612245\n",
      "epoch 7, iter 382, loss: 23.151233, acc: 0.734694\n",
      "epoch 7, iter 383, loss: 23.752800, acc: 0.693878\n",
      "epoch 7, iter 384, loss: 29.330478, acc: 0.673469\n",
      "epoch 7, iter 385, loss: 18.066238, acc: 0.857143\n",
      "epoch 7, iter 386, loss: 38.906322, acc: 0.612245\n",
      "epoch 7, iter 387, loss: 28.986006, acc: 0.551020\n",
      "epoch 7, iter 388, loss: 25.504638, acc: 0.673469\n",
      "epoch 7, iter 389, loss: 31.154744, acc: 0.653061\n",
      "epoch 7, iter 390, loss: 31.190834, acc: 0.591837\n",
      "epoch 7, iter 391, loss: 26.850844, acc: 0.775510\n",
      "epoch 7, iter 392, loss: 26.846496, acc: 0.857143\n",
      "epoch 7, iter 393, loss: 30.730843, acc: 0.591837\n",
      "epoch 7, iter 394, loss: 23.944872, acc: 0.734694\n",
      "epoch 7, iter 395, loss: 28.046620, acc: 0.632653\n",
      "epoch 7, iter 396, loss: 25.889217, acc: 0.612245\n",
      "epoch 7, iter 397, loss: 20.514668, acc: 0.734694\n",
      "epoch 7, iter 398, loss: 32.217639, acc: 0.632653\n",
      "epoch 7, iter 399, loss: 22.841206, acc: 0.836735\n",
      "epoch 7, iter 400, loss: 38.058707, acc: 0.551020\n",
      "epoch 7, iter 401, loss: 32.243427, acc: 0.673469\n",
      "epoch 7, iter 402, loss: 32.944389, acc: 0.755102\n",
      "epoch 7, iter 403, loss: 34.796687, acc: 0.673469\n",
      "epoch 7, iter 404, loss: 33.717195, acc: 0.632653\n",
      "epoch 7, iter 405, loss: 31.418222, acc: 0.632653\n",
      "epoch 7, iter 406, loss: 25.261142, acc: 0.632653\n",
      "epoch 7, iter 407, loss: 31.632032, acc: 0.551020\n",
      "epoch 7, iter 408, loss: 29.738022, acc: 0.653061\n",
      "epoch 7, iter 409, loss: 22.519924, acc: 0.714286\n",
      "epoch 7, iter 410, loss: 32.343574, acc: 0.591837\n",
      "epoch 7, iter 411, loss: 28.905188, acc: 0.714286\n",
      "epoch 7, iter 412, loss: 26.392122, acc: 0.816327\n",
      "epoch 7, iter 413, loss: 25.685336, acc: 0.693878\n",
      "epoch 7, iter 414, loss: 32.406414, acc: 0.653061\n",
      "epoch 7, iter 415, loss: 31.257594, acc: 0.612245\n",
      "epoch 7, iter 416, loss: 27.279580, acc: 0.693878\n",
      "epoch 7, iter 417, loss: 31.084928, acc: 0.612245\n",
      "epoch 7, iter 418, loss: 27.832163, acc: 0.693878\n",
      "epoch 7, iter 419, loss: 27.108726, acc: 0.673469\n",
      "epoch 7, iter 420, loss: 36.302453, acc: 0.571429\n",
      "epoch 7, iter 421, loss: 24.721044, acc: 0.795918\n",
      "epoch 7, iter 422, loss: 25.929288, acc: 0.714286\n",
      "epoch 7, iter 423, loss: 34.596731, acc: 0.591837\n",
      "epoch 7, iter 424, loss: 31.432422, acc: 0.775510\n",
      "epoch 7, iter 425, loss: 25.741633, acc: 0.653061\n",
      "epoch 7, iter 426, loss: 29.684369, acc: 0.734694\n",
      "epoch 7, iter 427, loss: 32.546449, acc: 0.571429\n",
      "epoch 7, iter 428, loss: 26.848977, acc: 0.693878\n",
      "epoch 7, iter 429, loss: 28.956910, acc: 0.612245\n",
      "epoch 7, iter 430, loss: 25.954321, acc: 0.632653\n",
      "epoch 7, iter 431, loss: 32.027810, acc: 0.693878\n",
      "epoch 7, iter 432, loss: 26.872939, acc: 0.795918\n",
      "epoch 7, iter 433, loss: 25.899539, acc: 0.591837\n",
      "epoch 7, iter 434, loss: 25.947178, acc: 0.775510\n",
      "epoch 7, iter 435, loss: 27.838701, acc: 0.734694\n",
      "epoch 7, iter 436, loss: 27.721048, acc: 0.693878\n",
      "epoch 7, iter 437, loss: 44.296943, acc: 0.632653\n",
      "epoch 7, iter 438, loss: 35.484542, acc: 0.551020\n",
      "epoch 7, iter 439, loss: 30.783554, acc: 0.591837\n",
      "epoch 7, iter 440, loss: 30.118593, acc: 0.673469\n",
      "epoch 7, iter 441, loss: 26.326782, acc: 0.653061\n",
      "epoch 7, iter 442, loss: 32.222708, acc: 0.591837\n",
      "epoch 7, iter 443, loss: 25.605267, acc: 0.816327\n",
      "epoch 7, iter 444, loss: 27.900966, acc: 0.693878\n",
      "epoch 7, iter 445, loss: 44.051288, acc: 0.551020\n",
      "epoch 7, iter 446, loss: 31.596240, acc: 0.632653\n",
      "epoch 7, iter 447, loss: 27.400865, acc: 0.734694\n",
      "epoch 7, iter 448, loss: 32.983034, acc: 0.510204\n",
      "epoch 7, iter 449, loss: 16.688816, acc: 0.816327\n",
      "epoch 7, iter 450, loss: 31.387042, acc: 0.632653\n",
      "epoch 7, iter 451, loss: 25.934589, acc: 0.755102\n",
      "epoch 7, iter 452, loss: 26.360153, acc: 0.755102\n",
      "epoch 7, iter 453, loss: 32.589343, acc: 0.510204\n",
      "epoch 7, iter 454, loss: 27.106272, acc: 0.632653\n",
      "epoch 7, iter 455, loss: 28.897167, acc: 0.612245\n",
      "epoch 7, iter 456, loss: 29.420865, acc: 0.653061\n",
      "epoch 7, iter 457, loss: 31.665145, acc: 0.693878\n",
      "epoch 7, iter 458, loss: 19.866458, acc: 0.795918\n",
      "epoch 7, iter 459, loss: 33.136063, acc: 0.632653\n",
      "epoch 7, iter 460, loss: 31.090776, acc: 0.551020\n",
      "epoch 7, iter 461, loss: 29.045025, acc: 0.632653\n",
      "epoch 7, iter 462, loss: 31.367225, acc: 0.571429\n",
      "epoch 7, iter 463, loss: 31.136495, acc: 0.551020\n",
      "epoch 7, iter 464, loss: 25.120711, acc: 0.836735\n",
      "epoch 7, iter 465, loss: 31.743603, acc: 0.653061\n",
      "epoch 7, iter 466, loss: 37.765276, acc: 0.612245\n",
      "epoch 7, iter 467, loss: 30.350608, acc: 0.591837\n",
      "epoch 7, iter 468, loss: 31.263932, acc: 0.714286\n",
      "epoch 7, iter 469, loss: 33.917658, acc: 0.612245\n",
      "epoch 7, iter 470, loss: 37.016508, acc: 0.428571\n",
      "epoch 7, iter 471, loss: 28.506877, acc: 0.795918\n",
      "epoch 7, iter 472, loss: 27.719454, acc: 0.693878\n",
      "epoch 7, iter 473, loss: 27.302255, acc: 0.714286\n",
      "epoch 7, iter 474, loss: 30.135461, acc: 0.693878\n",
      "epoch 7, iter 475, loss: 31.188198, acc: 0.469388\n",
      "epoch 7, iter 476, loss: 23.272731, acc: 0.693878\n",
      "epoch 7, iter 477, loss: 34.365352, acc: 0.530612\n",
      "epoch 7, iter 478, loss: 28.560528, acc: 0.673469\n",
      "epoch 7, iter 479, loss: 29.890071, acc: 0.612245\n",
      "epoch 7, iter 480, loss: 27.673610, acc: 0.632653\n",
      "epoch 7, iter 481, loss: 26.551779, acc: 0.673469\n",
      "epoch 7, iter 482, loss: 24.301642, acc: 0.836735\n",
      "epoch 7, iter 483, loss: 27.748436, acc: 0.734694\n",
      "epoch 7, iter 484, loss: 26.303829, acc: 0.632653\n",
      "epoch 7, iter 485, loss: 25.757544, acc: 0.591837\n",
      "epoch 7, iter 486, loss: 33.851929, acc: 0.653061\n",
      "epoch 7, iter 487, loss: 26.517295, acc: 0.775510\n",
      "epoch 7, iter 488, loss: 23.769558, acc: 0.755102\n",
      "epoch 7, iter 489, loss: 29.608791, acc: 0.775510\n",
      "epoch 7, iter 490, loss: 31.014242, acc: 0.612245\n",
      "epoch 7, iter 491, loss: 30.178961, acc: 0.734694\n",
      "epoch 7, iter 492, loss: 30.241998, acc: 0.653061\n",
      "epoch 7, iter 493, loss: 23.535003, acc: 0.673469\n",
      "epoch 7, iter 494, loss: 30.909624, acc: 0.571429\n",
      "epoch 7, iter 495, loss: 29.926296, acc: 0.448980\n",
      "epoch 7, iter 496, loss: 26.561682, acc: 0.673469\n",
      "epoch 7, iter 497, loss: 32.352606, acc: 0.571429\n",
      "epoch 7, iter 498, loss: 34.723416, acc: 0.591837\n",
      "epoch 7, iter 499, loss: 33.327921, acc: 0.673469\n",
      "epoch 7, acc: 0.662694\n",
      "epoch 8, iter 0, loss: 31.439451, acc: 0.612245\n",
      "epoch 8, iter 1, loss: 38.143841, acc: 0.632653\n",
      "epoch 8, iter 2, loss: 29.701186, acc: 0.734694\n",
      "epoch 8, iter 3, loss: 26.183323, acc: 0.571429\n",
      "epoch 8, iter 4, loss: 24.305287, acc: 0.693878\n",
      "epoch 8, iter 5, loss: 26.782604, acc: 0.775510\n",
      "epoch 8, iter 6, loss: 26.779433, acc: 0.816327\n",
      "epoch 8, iter 7, loss: 31.909859, acc: 0.673469\n",
      "epoch 8, iter 8, loss: 29.857851, acc: 0.673469\n",
      "epoch 8, iter 9, loss: 21.698079, acc: 0.714286\n",
      "epoch 8, iter 10, loss: 32.333191, acc: 0.591837\n",
      "epoch 8, iter 11, loss: 39.619105, acc: 0.469388\n",
      "epoch 8, iter 12, loss: 26.602499, acc: 0.734694\n",
      "epoch 8, iter 13, loss: 32.540579, acc: 0.673469\n",
      "epoch 8, iter 14, loss: 27.154665, acc: 0.510204\n",
      "epoch 8, iter 15, loss: 21.533986, acc: 0.755102\n",
      "epoch 8, iter 16, loss: 35.046368, acc: 0.489796\n",
      "epoch 8, iter 17, loss: 25.490762, acc: 0.693878\n",
      "epoch 8, iter 18, loss: 35.282553, acc: 0.612245\n",
      "epoch 8, iter 19, loss: 21.159985, acc: 0.836735\n",
      "epoch 8, iter 20, loss: 20.906860, acc: 0.755102\n",
      "epoch 8, iter 21, loss: 27.951443, acc: 0.714286\n",
      "epoch 8, iter 22, loss: 24.749680, acc: 0.755102\n",
      "epoch 8, iter 23, loss: 36.364598, acc: 0.591837\n",
      "epoch 8, iter 24, loss: 32.743984, acc: 0.551020\n",
      "epoch 8, iter 25, loss: 30.443190, acc: 0.591837\n",
      "epoch 8, iter 26, loss: 34.177989, acc: 0.510204\n",
      "epoch 8, iter 27, loss: 33.103385, acc: 0.693878\n",
      "epoch 8, iter 28, loss: 29.919906, acc: 0.653061\n",
      "epoch 8, iter 29, loss: 20.684949, acc: 0.775510\n",
      "epoch 8, iter 30, loss: 29.925775, acc: 0.469388\n",
      "epoch 8, iter 31, loss: 33.718535, acc: 0.591837\n",
      "epoch 8, iter 32, loss: 28.311706, acc: 0.693878\n",
      "epoch 8, iter 33, loss: 21.677152, acc: 0.734694\n",
      "epoch 8, iter 34, loss: 27.930578, acc: 0.653061\n",
      "epoch 8, iter 35, loss: 34.861874, acc: 0.612245\n",
      "epoch 8, iter 36, loss: 33.322309, acc: 0.591837\n",
      "epoch 8, iter 37, loss: 23.722926, acc: 0.673469\n",
      "epoch 8, iter 38, loss: 34.741509, acc: 0.551020\n",
      "epoch 8, iter 39, loss: 29.638078, acc: 0.693878\n",
      "epoch 8, iter 40, loss: 33.079805, acc: 0.591837\n",
      "epoch 8, iter 41, loss: 28.787982, acc: 0.714286\n",
      "epoch 8, iter 42, loss: 32.264498, acc: 0.551020\n",
      "epoch 8, iter 43, loss: 22.836322, acc: 0.816327\n",
      "epoch 8, iter 44, loss: 25.714944, acc: 0.836735\n",
      "epoch 8, iter 45, loss: 31.152563, acc: 0.591837\n",
      "epoch 8, iter 46, loss: 32.295395, acc: 0.591837\n",
      "epoch 8, iter 47, loss: 29.190208, acc: 0.653061\n",
      "epoch 8, iter 48, loss: 27.275562, acc: 0.734694\n",
      "epoch 8, iter 49, loss: 22.745384, acc: 0.673469\n",
      "epoch 8, iter 50, loss: 25.704124, acc: 0.673469\n",
      "epoch 8, iter 51, loss: 32.898997, acc: 0.591837\n",
      "epoch 8, iter 52, loss: 30.447452, acc: 0.653061\n",
      "epoch 8, iter 53, loss: 29.874781, acc: 0.755102\n",
      "epoch 8, iter 54, loss: 29.223142, acc: 0.673469\n",
      "epoch 8, iter 55, loss: 26.914175, acc: 0.612245\n",
      "epoch 8, iter 56, loss: 20.642173, acc: 0.816327\n",
      "epoch 8, iter 57, loss: 26.260813, acc: 0.673469\n",
      "epoch 8, iter 58, loss: 29.414264, acc: 0.612245\n",
      "epoch 8, iter 59, loss: 27.638138, acc: 0.734694\n",
      "epoch 8, iter 60, loss: 31.798957, acc: 0.612245\n",
      "epoch 8, iter 61, loss: 23.930876, acc: 0.734694\n",
      "epoch 8, iter 62, loss: 33.469972, acc: 0.612245\n",
      "epoch 8, iter 63, loss: 24.348221, acc: 0.775510\n",
      "epoch 8, iter 64, loss: 29.689109, acc: 0.632653\n",
      "epoch 8, iter 65, loss: 27.327852, acc: 0.714286\n",
      "epoch 8, iter 66, loss: 21.312992, acc: 0.897959\n",
      "epoch 8, iter 67, loss: 32.191593, acc: 0.653061\n",
      "epoch 8, iter 68, loss: 23.789280, acc: 0.734694\n",
      "epoch 8, iter 69, loss: 22.127315, acc: 0.755102\n",
      "epoch 8, iter 70, loss: 23.428511, acc: 0.714286\n",
      "epoch 8, iter 71, loss: 27.638944, acc: 0.714286\n",
      "epoch 8, iter 72, loss: 25.301870, acc: 0.755102\n",
      "epoch 8, iter 73, loss: 22.558526, acc: 0.734694\n",
      "epoch 8, iter 74, loss: 25.195266, acc: 0.714286\n",
      "epoch 8, iter 75, loss: 29.589008, acc: 0.755102\n",
      "epoch 8, iter 76, loss: 30.277292, acc: 0.755102\n",
      "epoch 8, iter 77, loss: 32.500579, acc: 0.530612\n",
      "epoch 8, iter 78, loss: 32.248300, acc: 0.653061\n",
      "epoch 8, iter 79, loss: 26.996147, acc: 0.673469\n",
      "epoch 8, iter 80, loss: 19.243150, acc: 0.897959\n",
      "epoch 8, iter 81, loss: 25.968873, acc: 0.632653\n",
      "epoch 8, iter 82, loss: 30.193315, acc: 0.653061\n",
      "epoch 8, iter 83, loss: 28.163430, acc: 0.673469\n",
      "epoch 8, iter 84, loss: 22.310117, acc: 0.775510\n",
      "epoch 8, iter 85, loss: 19.415383, acc: 0.795918\n",
      "epoch 8, iter 86, loss: 27.795318, acc: 0.673469\n",
      "epoch 8, iter 87, loss: 40.464120, acc: 0.387755\n",
      "epoch 8, iter 88, loss: 26.769340, acc: 0.775510\n",
      "epoch 8, iter 89, loss: 29.528244, acc: 0.612245\n",
      "epoch 8, iter 90, loss: 30.160163, acc: 0.612245\n",
      "epoch 8, iter 91, loss: 27.663964, acc: 0.734694\n",
      "epoch 8, iter 92, loss: 36.331601, acc: 0.510204\n",
      "epoch 8, iter 93, loss: 38.374052, acc: 0.612245\n",
      "epoch 8, iter 94, loss: 32.243238, acc: 0.734694\n",
      "epoch 8, iter 95, loss: 18.472716, acc: 0.877551\n",
      "epoch 8, iter 96, loss: 26.019441, acc: 0.714286\n",
      "epoch 8, iter 97, loss: 29.526939, acc: 0.693878\n",
      "epoch 8, iter 98, loss: 31.057089, acc: 0.612245\n",
      "epoch 8, iter 99, loss: 23.928462, acc: 0.734694\n",
      "epoch 8, iter 100, loss: 38.591453, acc: 0.612245\n",
      "epoch 8, iter 101, loss: 27.473213, acc: 0.775510\n",
      "epoch 8, iter 102, loss: 25.596844, acc: 0.816327\n",
      "epoch 8, iter 103, loss: 22.057509, acc: 0.734694\n",
      "epoch 8, iter 104, loss: 32.784394, acc: 0.591837\n",
      "epoch 8, iter 105, loss: 29.808498, acc: 0.612245\n",
      "epoch 8, iter 106, loss: 23.856802, acc: 0.734694\n",
      "epoch 8, iter 107, loss: 19.200468, acc: 0.857143\n",
      "epoch 8, iter 108, loss: 28.238154, acc: 0.673469\n",
      "epoch 8, iter 109, loss: 25.416763, acc: 0.653061\n",
      "epoch 8, iter 110, loss: 29.849646, acc: 0.612245\n",
      "epoch 8, iter 111, loss: 38.549717, acc: 0.510204\n",
      "epoch 8, iter 112, loss: 27.576018, acc: 0.612245\n",
      "epoch 8, iter 113, loss: 38.483243, acc: 0.408163\n",
      "epoch 8, iter 114, loss: 31.050829, acc: 0.530612"
     ]
    }
   ],
   "source": [
    "mWxh, mWhh, mWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
    "mbh, mby = np.zeros_like(bh), np.zeros_like(by) # memory variables for Adagrad\n",
    "smooth_loss = -np.log(1.0/num_problems)*num_timesteps # loss at iteration 0\n",
    "\n",
    "losses = []\n",
    "for e in xrange(epochs):\n",
    "    hprev = np.zeros((hidden_size,1)) # reset RNN memory\n",
    "    total_acc = 0.0\n",
    "    for i in xrange(num_train):\n",
    "        inputs = X_train[i,:,:].reshape((num_timesteps, num_problems * 2))\n",
    "        targets = y_train[i,:].reshape((num_timesteps,))\n",
    "        correctness_for_student = correctness[i,:].reshape((num_problems))\n",
    "\n",
    "        # sample from the model now and then\n",
    "        # if n % 100 == 0:\n",
    "        #   sample_ix = sample(hprev, inputs[0], 200)\n",
    "        #   txt = ''.join(ix_to_char[ix] for ix in sample_ix)\n",
    "        #   print '----\\n %s \\n----' % (txt, )\n",
    "\n",
    "        # forward num_timesteps characters through the net and fetch gradient\n",
    "        loss, dWxh, dWhh, dWhy, dbh, dby, hprev = lossFun(inputs, targets, correctness_for_student, hprev)\n",
    "        #       smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "        losses.append(loss)\n",
    "\n",
    "\n",
    "\n",
    "        # perform parameter update with Adagrad\n",
    "        for param, dparam, mem in zip([Wxh, Whh, Why, bh, by], \n",
    "                                      [dWxh, dWhh, dWhy, dbh, dby], \n",
    "                                      [mWxh, mWhh, mWhy, mbh, mby]):\n",
    "            mem += dparam * dparam\n",
    "            param += -learning_rate * dparam / np.sqrt(mem + 1e-8) # adagrad update\n",
    "        ps = forward_pass(inputs)\n",
    "        acc = accuracy(ps, targets, correctness_for_student)      \n",
    "        print ('epoch %d, iter %d, loss: %f, acc: %f' % (e, i, loss, acc)) # print progress\n",
    "        total_acc += acc\n",
    "    total_acc /= num_train\n",
    "    print ('epoch %d, acc: %f' % (e, total_acc)) # print progress\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(xrange(len(losses)), losses)\n",
    "\n",
    "# plot the trend line with error bars that correspond to standard deviation\n",
    "plt.title('Loss History')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
