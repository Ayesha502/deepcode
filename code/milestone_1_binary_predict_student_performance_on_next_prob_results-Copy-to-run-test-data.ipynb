{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Python libraries\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as Tensor\n",
    "import lasagne\n",
    "import random\n",
    "import sys\n",
    "import csv\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "# allows plots to show inline in ipython notebook\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import our own modules\n",
    "import utils\n",
    "import model\n",
    "import visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_SETS_MAP = {\n",
    "    'synth':\"../syntheticDetailed/naive_c5_q50_s4000_v0.csv\",\n",
    "    'code_org' : \"../data/hoc_1-9_binary_input.csv\"\n",
    "}\n",
    "\n",
    "DATA_SET = 'code_org'\n",
    "# DATA_SZ = 500000\n",
    "# DATA_SET = 'synth'\n",
    "\n",
    "# if DATA_SZ = -1, use entire data set\n",
    "DATA_SZ = 50000\n",
    "# DATA_SZ = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in the data set\n",
    "# This function can be moved to utils.py\n",
    "data_array = np.array(list(csv.reader(open(DATA_SETS_MAP[DATA_SET],\"rb\"),delimiter=','))).astype('int')\n",
    "if DATA_SZ != -1:\n",
    "    data_array = data_array[:DATA_SZ]\n",
    "    \n",
    "np.random.shuffle(data_array)\n",
    "num_samples = data_array.shape[0]\n",
    "num_problems = data_array.shape[1]\n",
    "\n",
    "# time steps is number of problems - 1 because we cannot predict on the last problem.\n",
    "num_timesteps = num_problems - 1 \n",
    "\n",
    "# Split data into train and test (half and half)\n",
    "\n",
    "train_data = data_array[0:7*num_samples/8,:]\n",
    "val_data =  data_array[7*num_samples/8: 15*num_samples/16 ,:]\n",
    "test_data = data_array[15*num_samples/16:num_samples,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Total : percent correct 0.848597777778\n",
      "Train : percent correct 0.848515555556\n",
      "Val : percent correct 0.848071111111\n",
      "Test : percent correct 0.850275555556\n"
     ]
    }
   ],
   "source": [
    "# code to see how many percent is correct\n",
    "print (num_problems)\n",
    "# for prob in xrange(num_problems):\n",
    "#     print ('Train Prob {} : percent correct {}'.format(prob, np.mean(train_data[:,prob]) ))\n",
    "#     print ('Val Prob {} : percent correct {}'.format(prob, np.mean(val_data[:,prob]) ))\n",
    "#     print ('Test Prob {} : percent correct {}'.format(prob, np.mean(test_data[:,prob]) ))\n",
    "print ('Total : percent correct {}'.format( np.mean(np.concatenate((np.concatenate((train_data, val_data), axis=0),test_data), axis=0 ))))\n",
    "print ('Train : percent correct {}'.format( np.mean(train_data) ))\n",
    "print ('Val : percent correct {}'.format( np.mean(val_data) ))\n",
    "print ('Test : percent correct {}'.format( np.mean(test_data) ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "Vectorization done!\n",
      "(43750, 8, 18)\n",
      "(3125, 8, 18)\n",
      "(3125, 8, 18)\n"
     ]
    }
   ],
   "source": [
    "num_train = train_data.shape[0]\n",
    "num_test = test_data.shape[0]\n",
    "\n",
    "print('Vectorization...')\n",
    "X_train, next_problem_train, truth_train = utils.vectorize_data(train_data)\n",
    "X_val, next_problem_val, truth_val = utils.vectorize_data(val_data)\n",
    "X_test, next_problem_test, truth_test = utils.vectorize_data(test_data)\n",
    "\n",
    "train_data = utils.vectorize_data(train_data)\n",
    "val_data = utils.vectorize_data(val_data)\n",
    "test_data = utils.vectorize_data(test_data)\n",
    "\n",
    "print (\"Vectorization done!\")\n",
    "print X_train.shape\n",
    "print X_val.shape\n",
    "print X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "hidden_size = 200 # size of hidden layer of neurons\n",
    "learning_rate = 1e-2\n",
    "lr_decay = 1.0\n",
    "reg_strength = 0.0\n",
    "grad_clip = 10\n",
    "batchsize = 32\n",
    "num_epochs = 20\n",
    "dropout_p = 0.2\n",
    "num_lstm_layers = 1\n",
    "theano.config.optimizer='fast_compile'\n",
    "theano.config.exception_verbosity='high'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing updates ...\n",
      "Compiling functions ...\n",
      "Compiling done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/angelasy/.local/lib/python2.7/site-packages/theano/scan_module/scan.py:1019: Warning: In the strict mode, all neccessary shared variables must be passed as a part of non_sequences\n",
      "  'must be passed as a part of non_sequences', Warning)\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "train_acc_fn, compute_cost_acc = model.create_model(num_timesteps, num_problems, hidden_size, learning_rate, grad_clip, dropout_p, num_lstm_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "  Epoch 0 \tbatch 1 \tloss 0.693057948408 \ttrain acc 48.05 \tval acc 85.23 \n",
      "  Epoch 0 \tbatch 2 \tloss 0.659701252469 \ttrain acc 91.80 \tval acc 84.47 \n",
      "  Epoch 0 \tbatch 3 \tloss 0.599327606375 \ttrain acc 87.89 \tval acc 83.11 \n",
      "  Epoch 0 \tbatch 4 \tloss 0.586372828012 \ttrain acc 74.61 \tval acc 83.94 \n",
      "  Epoch 0 \tbatch 5 \tloss 0.513062263777 \ttrain acc 81.64 \tval acc 81.20 \n",
      "  Epoch 0 \tbatch 6 \tloss 0.423424546851 \ttrain acc 80.86 \tval acc 83.37 \n",
      "  Epoch 0 \tbatch 7 \tloss 0.472739867124 \ttrain acc 81.25 \tval acc 83.50 \n",
      "  Epoch 0 \tbatch 8 \tloss 0.380546985824 \ttrain acc 82.42 \tval acc 85.57 \n",
      "  Epoch 0 \tbatch 9 \tloss 0.390641874915 \ttrain acc 86.33 \tval acc 84.75 \n",
      "  Epoch 0 \tbatch 10 \tloss 0.36816992182 \ttrain acc 84.38 \tval acc 85.51 \n",
      "  Epoch 0 \tbatch 11 \tloss 0.378334993304 \ttrain acc 85.16 \tval acc 85.51 \n",
      "  Epoch 0 \tbatch 12 \tloss 0.265770617614 \ttrain acc 90.23 \tval acc 85.78 \n",
      "  Epoch 0 \tbatch 13 \tloss 0.421738068554 \ttrain acc 82.03 \tval acc 86.18 \n",
      "  Epoch 0 \tbatch 14 \tloss 0.360847268176 \ttrain acc 85.16 \tval acc 87.12 \n",
      "  Epoch 0 \tbatch 15 \tloss 0.297461198691 \ttrain acc 89.84 \tval acc 85.20 \n",
      "  Epoch 0 \tbatch 16 \tloss 0.280705538466 \ttrain acc 89.45 \tval acc 84.05 \n",
      "  Epoch 0 \tbatch 17 \tloss 0.433049215859 \ttrain acc 81.64 \tval acc 85.64 \n",
      "  Epoch 0 \tbatch 18 \tloss 0.248532959931 \ttrain acc 89.45 \tval acc 87.54 \n",
      "  Epoch 0 \tbatch 19 \tloss 0.328226547258 \ttrain acc 86.72 \tval acc 88.35 \n",
      "  Epoch 0 \tbatch 20 \tloss 0.288527956043 \ttrain acc 89.06 \tval acc 88.71 \n",
      "  Epoch 0 \tbatch 21 \tloss 0.405249234558 \ttrain acc 84.77 \tval acc 89.04 \n",
      "  Epoch 0 \tbatch 22 \tloss 0.304047629679 \ttrain acc 87.89 \tval acc 87.53 \n",
      "  Epoch 0 \tbatch 23 \tloss 0.317189700744 \ttrain acc 87.11 \tval acc 87.08 \n",
      "  Epoch 0 \tbatch 24 \tloss 0.318684100823 \ttrain acc 85.16 \tval acc 88.04 \n",
      "  Epoch 0 \tbatch 25 \tloss 0.391926960949 \ttrain acc 83.59 \tval acc 88.35 \n",
      "  Epoch 0 \tbatch 26 \tloss 0.290891634587 \ttrain acc 89.45 \tval acc 88.72 \n",
      "  Epoch 0 \tbatch 27 \tloss 0.302428252245 \ttrain acc 85.55 \tval acc 88.79 \n",
      "  Epoch 0 \tbatch 28 \tloss 0.281810905004 \ttrain acc 87.89 \tval acc 88.95 \n",
      "  Epoch 0 \tbatch 29 \tloss 0.34882003472 \ttrain acc 87.50 \tval acc 88.88 \n",
      "  Epoch 0 \tbatch 30 \tloss 0.33970608963 \ttrain acc 85.55 \tval acc 88.97 \n",
      "  Epoch 0 \tbatch 31 \tloss 0.241641320219 \ttrain acc 91.02 \tval acc 89.02 \n",
      "  Epoch 0 \tbatch 32 \tloss 0.282591723714 \ttrain acc 91.41 \tval acc 89.10 \n",
      "  Epoch 0 \tbatch 33 \tloss 0.283878012397 \ttrain acc 90.23 \tval acc 89.13 \n",
      "  Epoch 0 \tbatch 34 \tloss 0.227393103786 \ttrain acc 92.58 \tval acc 88.96 \n",
      "  Epoch 0 \tbatch 35 \tloss 0.272595896635 \ttrain acc 89.06 \tval acc 88.92 \n",
      "  Epoch 0 \tbatch 36 \tloss 0.264695949681 \ttrain acc 87.50 \tval acc 89.10 \n",
      "  Epoch 0 \tbatch 37 \tloss 0.273528401197 \ttrain acc 87.89 \tval acc 87.96 \n",
      "  Epoch 0 \tbatch 38 \tloss 0.346512233929 \ttrain acc 86.72 \tval acc 87.88 \n",
      "  Epoch 0 \tbatch 39 \tloss 0.229977351755 \ttrain acc 92.19 \tval acc 87.60 \n",
      "  Epoch 0 \tbatch 40 \tloss 0.33396136699 \ttrain acc 85.55 \tval acc 88.04 \n",
      "  Epoch 0 \tbatch 41 \tloss 0.306424975757 \ttrain acc 87.89 \tval acc 88.65 \n",
      "  Epoch 0 \tbatch 42 \tloss 0.250111771133 \ttrain acc 89.45 \tval acc 89.18 \n",
      "  Epoch 0 \tbatch 43 \tloss 0.349355581991 \ttrain acc 87.50 \tval acc 89.38 \n",
      "  Epoch 0 \tbatch 44 \tloss 0.250930167454 \ttrain acc 90.62 \tval acc 89.32 \n",
      "  Epoch 0 \tbatch 45 \tloss 0.294561102691 \ttrain acc 88.28 \tval acc 89.34 \n",
      "  Epoch 0 \tbatch 46 \tloss 0.304795776488 \ttrain acc 87.50 \tval acc 89.31 \n",
      "  Epoch 0 \tbatch 47 \tloss 0.233039808231 \ttrain acc 91.80 \tval acc 89.40 \n",
      "  Epoch 0 \tbatch 48 \tloss 0.248653063447 \ttrain acc 90.62 \tval acc 89.34 \n",
      "  Epoch 0 \tbatch 49 \tloss 0.342472110592 \ttrain acc 86.72 \tval acc 89.31 \n",
      "  Epoch 0 \tbatch 50 \tloss 0.240305461583 \ttrain acc 89.45 \tval acc 89.29 \n",
      "  Epoch 0 \tbatch 51 \tloss 0.274511754302 \ttrain acc 89.06 \tval acc 89.26 \n",
      "  Epoch 0 \tbatch 52 \tloss 0.238009053925 \ttrain acc 91.41 \tval acc 89.23 \n",
      "  Epoch 0 \tbatch 53 \tloss 0.276187588359 \ttrain acc 91.02 \tval acc 89.26 \n",
      "  Epoch 0 \tbatch 54 \tloss 0.275418760484 \ttrain acc 89.06 \tval acc 89.26 \n",
      "  Epoch 0 \tbatch 55 \tloss 0.297822288472 \ttrain acc 88.67 \tval acc 89.30 \n",
      "  Epoch 0 \tbatch 56 \tloss 0.303395054919 \ttrain acc 88.67 \tval acc 89.58 \n",
      "  Epoch 0 \tbatch 57 \tloss 0.270146646167 \ttrain acc 87.89 \tval acc 89.61 \n",
      "  Epoch 0 \tbatch 58 \tloss 0.24397852974 \ttrain acc 91.41 \tval acc 89.60 \n",
      "  Epoch 0 \tbatch 59 \tloss 0.228562132363 \ttrain acc 91.02 \tval acc 89.63 \n",
      "  Epoch 0 \tbatch 60 \tloss 0.351821975352 \ttrain acc 87.11 \tval acc 89.65 \n",
      "  Epoch 0 \tbatch 61 \tloss 0.226525463541 \ttrain acc 92.19 \tval acc 89.70 \n",
      "  Epoch 0 \tbatch 62 \tloss 0.249474744136 \ttrain acc 89.84 \tval acc 89.63 "
     ]
    }
   ],
   "source": [
    "# Training!!!\n",
    "train_losses, train_accuracies, val_accuracies = model.train(train_data, val_data, train_acc_fn, compute_cost_acc,  num_epochs=num_epochs, batchsize=batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.check_accuracy(train_data, compute_cost_acc, dataset_name='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize the loss and the accuracies for both training and validation sets for each epoch\n",
    "visualize.plot_loss_acc(DATA_SET + '_train', train_losses, val_accuracies, train_accuracies, learning_rate, reg_strength, num_epochs, num_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.check_accuracy(test_data, compute_cost_acc, dataset_name='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
