{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Deep Knowledge Tracing\n",
    "Authors: Lisa Wang, Angela Sy\n",
    "\n",
    "### Task: Predict what the student is going to code next.\n",
    "\n",
    "Input: For each of the N students, we have a time series of Abstract Syntax Trees (ASTs), which represent the student's code at that time step.\n",
    "- input shape (num_students, num_timesteps, num_asts)\n",
    "    - num_timesteps is the max sequence length of asts that we are taking into account.\n",
    "    - num_asts is the total number of asts for that problem.\n",
    "\n",
    "Output: At each timestep, we are predicting the next AST.\n",
    "- Output shape (num_students, num_timesteps, num_asts). (one-hot encoding)\n",
    "\n",
    "The truth matrix contains the desired output for a given input, and is used to compute the loss as well as train/val/test accuracies.\n",
    "- Truth shape (num_students, num_timesteps) Values are in range (0, num_asts)\n",
    "\n",
    "Accuracy:\n",
    "- Raw Accuracy: For all predictions at all timesteps, we get the percentage of predictions we got correct.\n",
    "- Corrected Accuracy: Since many trajectories contain fewer asts than max_traj_len, we fill the empty asts with our dummy ast token at row 0. However, predicting on end tokens is to simple of a task and might bias our results. The corrected accuracy ignores all predictions on the end token.\n",
    "\n",
    "### Current Issues:\n",
    "AST IDs are not consistent across different HOCs. Hence, we can only train and run this model on each HOC individually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Python libraries\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as Tensor\n",
    "import lasagne\n",
    "import random\n",
    "import sys\n",
    "import csv\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "# allows plots to show inline in ipython notebook\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import our own modules\n",
    "import utils\n",
    "import model_predict_ast as model\n",
    "import visualize\n",
    "\n",
    "HOC_NUM = 5\n",
    "DATA_SZ = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4195, 7, 432)\n",
      "(4195, 7, 432)\n",
      "Preparing network inputs and targets...\n",
      "(3670, 6, 432)\n",
      "(3670, 6)\n",
      "(262, 6, 432)\n",
      "(263, 6, 432)\n",
      "6\n",
      "Inputs and targets done!\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data, test_data, ast_id_to_row_map, row_to_ast_id_map, num_timesteps, num_asts =\\\n",
    "utils.load_dataset_predict_ast(hoc_num=HOC_NUM, data_sz=DATA_SZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "hidden_size = 256 # size of hidden layer of neurons\n",
    "learning_rate = 2e-2\n",
    "lr_decay = 0.995\n",
    "reg_strength = 2e-2\n",
    "grad_clip = 10\n",
    "batchsize = 32\n",
    "num_epochs = 10\n",
    "dropout_p = 0.5\n",
    "num_lstm_layers = 2\n",
    "theano.config.optimizer='fast_compile'\n",
    "theano.config.exception_verbosity='high'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building network ...\n",
      "Computing updates ...\n",
      "Compiling functions ...\n",
      "Compiling done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lisa1010/anaconda/lib/python2.7/site-packages/theano/scan_module/scan.py:1019: Warning: In the strict mode, all neccessary shared variables must be passed as a part of non_sequences\n",
      "  'must be passed as a part of non_sequences', Warning)\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "train_loss_acc, compute_loss_acc, probs = model.create_model(num_timesteps, num_asts, hidden_size, learning_rate, grad_clip, dropout_p, num_lstm_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Total training iterations: 1140\n",
      "Ep 0 \titer 1  \tloss 6.06765, train acc 0.00, train corr acc 0.00, val acc 62.28, val corr acc 24.62\n",
      "Ep 0 \titer 2  \tloss 5.66984, train acc 59.90, train corr acc 23.00, val acc 66.79, val corr acc 33.42\n",
      "Ep 0 \titer 3  \tloss 1.86565, train acc 70.31, train corr acc 35.96, val acc 66.79, val corr acc 33.42\n",
      "Ep 0 \titer 4  \tloss 2.64516, train acc 60.42, train corr acc 29.63, val acc 66.73, val corr acc 33.29\n",
      "Ep 0 \titer 5  \tloss 2.10575, train acc 67.71, train corr acc 34.04, val acc 63.30, val corr acc 33.16\n",
      "Ep 0 \titer 6  \tloss 2.20798, train acc 63.54, train corr acc 35.71, val acc 66.98, val corr acc 33.80\n",
      "Ep 0 \titer 7  \tloss 1.60937, train acc 71.35, train corr acc 36.78, val acc 66.60, val corr acc 33.04\n",
      "Ep 0 \titer 8  \tloss 1.88699, train acc 64.58, train corr acc 32.67, val acc 63.87, val corr acc 28.95\n",
      "Ep 0 \titer 9  \tloss 1.91909, train acc 60.42, train corr acc 27.62, val acc 63.10, val corr acc 27.93\n",
      "Ep 0 \titer 10  \tloss 1.99862, train acc 61.46, train corr acc 27.72, val acc 66.54, val corr acc 32.91\n",
      "Ep 0 \titer 11  \tloss 1.62151, train acc 68.23, train corr acc 34.41, val acc 66.60, val corr acc 33.04\n",
      "Ep 0 \titer 12  \tloss 1.88321, train acc 59.38, train corr acc 29.73, val acc 66.03, val corr acc 32.27\n",
      "Ep 0 \titer 13  \tloss 2.09396, train acc 59.90, train corr acc 28.97, val acc 67.11, val corr acc 34.06\n",
      "Ep 0 \titer 14  \tloss 1.87337, train acc 67.71, train corr acc 35.42, val acc 67.11, val corr acc 34.06\n",
      "Ep 0 \titer 15  \tloss 1.68195, train acc 64.06, train corr acc 32.35, val acc 67.24, val corr acc 34.31\n",
      "Ep 0 \titer 16  \tloss 2.12931, train acc 63.54, train corr acc 33.33, val acc 67.30, val corr acc 35.46\n",
      "Ep 0 \titer 17  \tloss 1.73957, train acc 64.58, train corr acc 37.04, val acc 66.28, val corr acc 34.06\n",
      "Ep 0 \titer 18  \tloss 1.54967, train acc 67.71, train corr acc 37.50, val acc 66.48, val corr acc 34.95\n",
      "Ep 0 \titer 19  \tloss 1.62600, train acc 63.02, train corr acc 33.64, val acc 66.48, val corr acc 34.69\n",
      "Ep 0 \titer 20  \tloss 1.45610, train acc 68.23, train corr acc 37.23, val acc 67.11, val corr acc 35.20\n",
      "Ep 0 \titer 21  \tloss 1.56558, train acc 67.19, train corr acc 28.41, val acc 67.24, val corr acc 34.69\n",
      "Ep 0 \titer 22  \tloss 1.54293, train acc 67.19, train corr acc 36.46, val acc 67.30, val corr acc 34.57\n",
      "Ep 0 \titer 23  \tloss 1.50871, train acc 66.67, train corr acc 34.02, val acc 67.81, val corr acc 35.46\n",
      "Ep 0 \titer 24  \tloss 1.47227, train acc 66.15, train corr acc 35.64, val acc 67.11, val corr acc 34.06\n",
      "Ep 0 \titer 25  \tloss 1.72731, train acc 60.42, train corr acc 31.53, val acc 67.49, val corr acc 35.59\n",
      "Ep 0 \titer 26  \tloss 1.56470, train acc 69.27, train corr acc 38.54, val acc 67.30, val corr acc 34.82\n",
      "Ep 0 \titer 27  \tloss 1.76137, train acc 66.15, train corr acc 35.64, val acc 67.24, val corr acc 34.31\n",
      "Ep 0 \titer 28  \tloss 1.35571, train acc 67.71, train corr acc 36.08, val acc 67.11, val corr acc 34.18\n",
      "Ep 0 \titer 29  \tloss 1.63843, train acc 64.06, train corr acc 32.35, val acc 67.37, val corr acc 34.57\n",
      "Ep 0 \titer 30  \tloss 1.61013, train acc 66.15, train corr acc 33.67, val acc 67.24, val corr acc 34.31\n",
      "Ep 0 \titer 31  \tloss 2.01666, train acc 60.94, train corr acc 31.82, val acc 67.94, val corr acc 35.84\n",
      "Ep 0 \titer 32  \tloss 1.48924, train acc 69.27, train corr acc 37.63, val acc 67.11, val corr acc 34.82\n",
      "Ep 0 \titer 33  \tloss 1.57860, train acc 68.75, train corr acc 37.50, val acc 67.05, val corr acc 34.18\n",
      "Ep 0 \titer 34  \tloss 1.31195, train acc 71.35, train corr acc 36.05, val acc 67.49, val corr acc 34.95\n",
      "Ep 0 \titer 35  \tloss 1.46355, train acc 67.71, train corr acc 35.42, val acc 67.49, val corr acc 34.82\n",
      "Ep 0 \titer 36  \tloss 1.65147, train acc 61.46, train corr acc 29.52, val acc 67.75, val corr acc 35.33\n",
      "Ep 0 \titer 37  \tloss 1.59621, train acc 64.06, train corr acc 33.65, val acc 68.07, val corr acc 35.97\n",
      "Ep 0 \titer 38  \tloss 1.28000, train acc 72.40, train corr acc 39.77, val acc 68.00, val corr acc 35.84\n",
      "Ep 0 \titer 39  \tloss 1.42118, train acc 70.83, train corr acc 37.78, val acc 68.13, val corr acc 36.22\n",
      "Ep 0 \titer 40  \tloss 1.67278, train acc 59.90, train corr acc 31.86, val acc 68.19, val corr acc 36.99\n",
      "Ep 0 \titer 41  \tloss 1.54654, train acc 68.23, train corr acc 39.60, val acc 67.49, val corr acc 36.22\n",
      "Ep 0 \titer 42  \tloss 1.51398, train acc 68.75, train corr acc 42.31, val acc 67.18, val corr acc 34.95\n",
      "Ep 0 \titer 43  \tloss 1.55335, train acc 63.54, train corr acc 30.69, val acc 69.08, val corr acc 38.39\n",
      "Ep 0 \titer 44  \tloss 1.28877, train acc 68.23, train corr acc 37.50, val acc 68.26, val corr acc 36.48\n",
      "Ep 0 \titer 45  \tloss 1.27923, train acc 69.27, train corr acc 34.44, val acc 68.26, val corr acc 36.35\n",
      "Ep 0 \titer 46  \tloss 1.50794, train acc 62.50, train corr acc 31.43, val acc 68.13, val corr acc 36.10\n",
      "Ep 0 \titer 47  \tloss 1.47233, train acc 66.67, train corr acc 34.69, val acc 69.15, val corr acc 38.27\n",
      "Ep 0 \titer 48  \tloss 1.41129, train acc 66.15, train corr acc 38.10, val acc 69.53, val corr acc 39.03\n",
      "Ep 0 \titer 49  \tloss 1.31058, train acc 71.35, train corr acc 38.89, val acc 68.89, val corr acc 38.65\n",
      "Ep 0 \titer 50  \tloss 1.31823, train acc 67.19, train corr acc 36.36, val acc 68.58, val corr acc 38.14\n",
      "Ep 0 \titer 51  \tloss 1.47467, train acc 65.10, train corr acc 32.29, val acc 70.29, val corr acc 41.33\n",
      "Ep 0 \titer 52  \tloss 1.27298, train acc 71.88, train corr acc 42.39, val acc 69.66, val corr acc 39.92\n",
      "Ep 0 \titer 53  \tloss 1.30439, train acc 71.35, train corr acc 38.89, val acc 69.72, val corr acc 39.41\n",
      "Ep 0 \titer 54  \tloss 1.25245, train acc 76.04, train corr acc 48.31, val acc 69.53, val corr acc 38.90\n",
      "Ep 0 \titer 55  \tloss 1.47262, train acc 69.27, train corr acc 42.16, val acc 69.34, val corr acc 38.52\n",
      "Ep 0 \titer 56  \tloss 1.34772, train acc 68.75, train corr acc 41.18, val acc 69.85, val corr acc 39.54\n",
      "Ep 0 \titer 57  \tloss 1.29682, train acc 69.27, train corr acc 37.89, val acc 70.29, val corr acc 40.43\n",
      "Ep 0 \titer 58  \tloss 1.33094, train acc 71.35, train corr acc 42.11, val acc 71.31, val corr acc 42.47\n",
      "Ep 0 \titer 59  \tloss 1.49444, train acc 68.23, train corr acc 35.79, val acc 71.37, val corr acc 42.73\n",
      "Ep 0 \titer 60  \tloss 1.15188, train acc 72.92, train corr acc 40.23, val acc 71.50, val corr acc 43.49\n",
      "Ep 0 \titer 61  \tloss 1.36000, train acc 74.48, train corr acc 44.32, val acc 72.58, val corr acc 45.28\n",
      "Ep 0 \titer 62  \tloss 1.63521, train acc 68.75, train corr acc 43.40, val acc 72.20, val corr acc 44.26\n",
      "Ep 0 \titer 63  \tloss 1.34094, train acc 73.96, train corr acc 49.49, val acc 72.26, val corr acc 44.39\n",
      "Ep 0 \titer 64  \tloss 1.33659, train acc 68.23, train corr acc 42.99, val acc 71.63, val corr acc 43.11\n",
      "Ep 0 \titer 65  \tloss 1.32079, train acc 70.31, train corr acc 41.24, val acc 71.18, val corr acc 42.22\n",
      "Ep 0 \titer 66  \tloss 1.21675, train acc 69.79, train corr acc 37.63, val acc 71.56, val corr acc 42.98\n",
      "Ep 0 \titer 67  \tloss 1.21051, train acc 70.83, train corr acc 41.05, val acc 72.14, val corr acc 44.13\n",
      "Ep 0 \titer 68  \tloss 1.37694, train acc 65.62, train corr acc 33.33, val acc 72.20, val corr acc 44.26\n",
      "Ep 0 \titer 69  \tloss 1.20292, train acc 73.96, train corr acc 49.49, val acc 72.65, val corr acc 45.15\n",
      "Ep 0 \titer 70  \tloss 1.30100, train acc 72.40, train corr acc 43.62, val acc 73.09, val corr acc 46.05\n",
      "Ep 0 \titer 71  \tloss 1.17572, train acc 73.44, train corr acc 48.48, val acc 73.73, val corr acc 47.32\n",
      "Ep 0 \titer 72  \tloss 1.11285, train acc 75.00, train corr acc 46.67, val acc 73.47, val corr acc 46.81\n",
      "Ep 0 \titer 73  \tloss 1.62657, train acc 68.75, train corr acc 43.40, val acc 73.66, val corr acc 47.19\n",
      "Ep 0 \titer 74  \tloss 1.33372, train acc 74.48, train corr acc 51.00, val acc 73.22, val corr acc 46.30\n",
      "Ep 0 \titer 75  \tloss 1.43739, train acc 70.83, train corr acc 39.13, val acc 73.73, val corr acc 47.32\n",
      "Ep 0 \titer 76  \tloss 1.48828, train acc 68.23, train corr acc 45.05, val acc 73.79, val corr acc 47.45\n",
      "Ep 0 \titer 77  \tloss 0.97454, train acc 79.17, train corr acc 51.81, val acc 73.98, val corr acc 47.83\n",
      "Ep 0 \titer 78  \tloss 1.27212, train acc 73.96, train corr acc 45.65, val acc 73.79, val corr acc 47.45\n",
      "Ep 0 \titer 79  \tloss 1.37658, train acc 69.27, train corr acc 45.87, val acc 73.66, val corr acc 47.19\n",
      "Ep 0 \titer 80  \tloss 1.26112, train acc 71.35, train corr acc 45.00, val acc 74.05, val corr acc 47.96\n",
      "Ep 0 \titer 81  \tloss 1.18216, train acc 73.96, train corr acc 49.49, val acc 73.79, val corr acc 47.45\n",
      "Ep 0 \titer 82  \tloss 1.18193, train acc 70.31, train corr acc 45.19, val acc 73.28, val corr acc 46.43\n",
      "Ep 0 \titer 83  \tloss 1.31158, train acc 68.75, train corr acc 33.33, val acc 72.84, val corr acc 45.54\n",
      "Ep 0 \titer 84  \tloss 1.21691, train acc 72.92, train corr acc 46.94, val acc 73.28, val corr acc 46.43\n",
      "Ep 0 \titer 85  \tloss 1.43885, train acc 68.75, train corr acc 43.40, val acc 73.41, val corr acc 46.68\n",
      "Ep 0 \titer 86  \tloss 1.47634, train acc 68.75, train corr acc 41.18, val acc 73.35, val corr acc 46.56\n",
      "Ep 0 \titer 87  \tloss 1.25081, train acc 72.92, train corr acc 44.09, val acc 73.73, val corr acc 47.32\n",
      "Ep 0 \titer 88  \tloss 1.36801, train acc 70.31, train corr acc 38.04, val acc 73.28, val corr acc 46.43\n",
      "Ep 0 \titer 89  \tloss 1.23926, train acc 73.96, train corr acc 42.53, val acc 74.05, val corr acc 47.96\n",
      "Ep 0 \titer 90  \tloss 1.21979, train acc 73.96, train corr acc 48.98, val acc 73.79, val corr acc 47.45\n",
      "Ep 0 \titer 91  \tloss 1.26653, train acc 71.35, train corr acc 44.44, val acc 73.54, val corr acc 46.94\n",
      "Ep 0 \titer 92  \tloss 1.23418, train acc 72.40, train corr acc 45.92, val acc 74.24, val corr acc 48.34\n",
      "Ep 0 \titer 93  \tloss 1.43807, train acc 70.83, train corr acc 44.55, val acc 74.17, val corr acc 48.21\n",
      "Ep 0 \titer 94  \tloss 1.26703, train acc 71.35, train corr acc 41.49, val acc 73.92, val corr acc 47.70\n",
      "Ep 0 \titer 95  \tloss 1.33537, train acc 70.83, train corr acc 44.55, val acc 74.24, val corr acc 48.34\n",
      "Ep 0 \titer 96  \tloss 1.34108, train acc 66.15, train corr acc 40.37, val acc 73.66, val corr acc 47.19\n",
      "Ep 0 \titer 97  \tloss 1.21070, train acc 70.83, train corr acc 41.05, val acc 73.47, val corr acc 46.81\n",
      "Ep 0 \titer 98  \tloss 1.28812, train acc 71.88, train corr acc 48.08, val acc 73.79, val corr acc 47.45\n",
      "Ep 0 \titer 99  \tloss 1.32380, train acc 70.83, train corr acc 45.10, val acc 73.66, val corr acc 47.19\n",
      "Ep 0 \titer 100  \tloss 1.43163, train acc 67.19, train corr acc 42.73, val acc 74.43, val corr acc 48.72\n",
      "Ep 0 \titer 101  \tloss 1.27132, train acc 70.83, train corr acc 44.55, val acc 73.60, val corr acc 47.07\n",
      "Ep 0 \titer 102  \tloss 1.13463, train acc 76.04, train corr acc 50.00, val acc 73.41, val corr acc 46.68\n",
      "Ep 0 \titer 103  \tloss 1.06885, train acc 73.96, train corr acc 50.50, val acc 73.79, val corr acc 47.45\n",
      "Ep 0 \titer 104  \tloss 1.20053, train acc 71.35, train corr acc 45.00, val acc 73.73, val corr acc 47.32\n",
      "Ep 0 \titer 105  \tloss 1.44013, train acc 69.27, train corr acc 47.79, val acc 73.98, val corr acc 47.83\n",
      "Ep 0 \titer 106  \tloss 1.32034, train acc 72.40, train corr acc 49.52, val acc 73.92, val corr acc 47.70\n",
      "Ep 0 \titer 107  \tloss 1.24255, train acc 75.00, train corr acc 50.52, val acc 73.66, val corr acc 47.19\n",
      "Ep 0 \titer 108  \tloss 1.09082, train acc 78.12, train corr acc 55.79, val acc 73.41, val corr acc 46.68\n",
      "Ep 0 \titer 109  \tloss 1.52498, train acc 71.88, train corr acc 47.57, val acc 73.60, val corr acc 47.07\n",
      "Ep 0 \titer 110  \tloss 1.50916, train acc 70.83, train corr acc 42.86, val acc 73.54, val corr acc 46.94\n",
      "Ep 0 \titer 111  \tloss 1.30415, train acc 73.96, train corr acc 45.65, val acc 74.49, val corr acc 48.85\n",
      "Ep 0 \titer 112  \tloss 1.33218, train acc 71.88, train corr acc 47.06, val acc 73.98, val corr acc 47.83\n",
      "Ep 0 \titer 113  \tloss 1.27322, train acc 75.52, train corr acc 47.19, val acc 73.85, val corr acc 47.58\n",
      "Ep 0 \titer 114  \tloss 1.34645, train acc 71.88, train corr acc 47.06, val acc 74.30, val corr acc 48.47\n",
      "\n",
      "Epoch 1 of 10 took 74.494s\n",
      "  training loss:\t\t1.214376\n",
      "  training raw accuracy:\t\t72.95 %\n",
      "  training corrected acc:\t\t47.32 %\n",
      "  validation loss:\t\t1.179453\n",
      "  validation raw accuracy:\t\t74.30 %\n",
      "  validation corrected acc:\t\t48.47 % \n",
      "\n",
      "Ep 1 \titer 115  \tloss 1.11744, train acc 73.44, train corr acc 47.42, val acc 73.73, val corr acc 47.32\n",
      "Ep 1 \titer 116  \tloss 1.26356, train acc 75.00, train corr acc 52.00, val acc 74.05, val corr acc 47.96\n",
      "Ep 1 \titer 117  \tloss 1.04004, train acc 72.92, train corr acc 41.57, val acc 74.36, val corr acc 48.60\n",
      "Ep 1 \titer 118  \tloss 1.38152, train acc 69.27, train corr acc 45.37, val acc 73.98, val corr acc 47.83\n",
      "Ep 1 \titer 119  \tloss 1.18252, train acc 74.48, train corr acc 47.87, val acc 73.85, val corr acc 47.58\n",
      "Ep 1 \titer 120  \tloss 1.25370, train acc 73.96, train corr acc 48.98, val acc 74.05, val corr acc 47.96\n",
      "Ep 1 \titer 121  \tloss 1.19130, train acc 72.92, train corr acc 40.23, val acc 74.05, val corr acc 47.96\n",
      "Ep 1 \titer 122  \tloss 1.30838, train acc 69.79, train corr acc 42.57, val acc 73.66, val corr acc 47.19\n",
      "Ep 1 \titer 123  \tloss 1.08666, train acc 73.96, train corr acc 52.38, val acc 74.11, val corr acc 48.09\n",
      "Ep 1 \titer 124  \tloss 1.42265, train acc 71.35, train corr acc 45.54, val acc 73.60, val corr acc 47.07\n",
      "Ep 1 \titer 125  \tloss 1.05302, train acc 78.65, train corr acc 55.91, val acc 73.66, val corr acc 47.19\n",
      "Ep 1 \titer 126  \tloss 1.22758, train acc 69.79, train corr acc 47.75, val acc 74.49, val corr acc 48.85\n",
      "Ep 1 \titer 127  \tloss 1.38276, train acc 73.96, train corr acc 53.27, val acc 73.85, val corr acc 47.58\n",
      "Ep 1 \titer 128  \tloss 1.30458, train acc 73.96, train corr acc 47.92, val acc 73.60, val corr acc 47.07\n",
      "Ep 1 \titer 129  \tloss 1.24749, train acc 72.92, train corr acc 49.02, val acc 73.98, val corr acc 47.83\n",
      "Ep 1 \titer 130  \tloss 1.47043, train acc 69.79, train corr acc 44.76, val acc 73.98, val corr acc 47.83\n",
      "Ep 1 \titer 131  \tloss 1.25627, train acc 69.79, train corr acc 46.30, val acc 73.54, val corr acc 46.94\n",
      "Ep 1 \titer 132  \tloss 1.14805, train acc 73.96, train corr acc 47.92, val acc 73.66, val corr acc 47.19\n",
      "Ep 1 \titer 133  \tloss 1.12964, train acc 71.35, train corr acc 48.60, val acc 74.17, val corr acc 48.21\n",
      "Ep 1 \titer 134  \tloss 1.17585, train acc 74.48, train corr acc 47.87, val acc 74.87, val corr acc 49.62\n",
      "Ep 1 \titer 135  \tloss 1.19389, train acc 76.04, train corr acc 47.73, val acc 74.17, val corr acc 48.21\n",
      "Ep 1 \titer 136  \tloss 1.06333, train acc 75.00, train corr acc 50.00, val acc 74.11, val corr acc 48.09\n",
      "Ep 1 \titer 137  \tloss 1.04156, train acc 75.00, train corr acc 50.52, val acc 74.24, val corr acc 48.34\n",
      "Ep 1 \titer 138  \tloss 1.05386, train acc 77.08, train corr acc 56.44, val acc 74.11, val corr acc 48.09\n",
      "Ep 1 \titer 139  \tloss 1.31812, train acc 69.79, train corr acc 47.75, val acc 74.62, val corr acc 49.11\n",
      "Ep 1 \titer 140  \tloss 1.15262, train acc 74.48, train corr acc 48.96, val acc 74.68, val corr acc 49.23\n",
      "Ep 1 \titer 141  \tloss 1.30168, train acc 71.35, train corr acc 45.54, val acc 75.00, val corr acc 49.87\n",
      "Ep 1 \titer 142  \tloss 1.03987, train acc 77.08, train corr acc 54.64, val acc 74.36, val corr acc 48.60\n",
      "Ep 1 \titer 143  \tloss 1.30508, train acc 75.00, train corr acc 52.94, val acc 74.81, val corr acc 49.49\n",
      "Ep 1 \titer 144  \tloss 1.12824, train acc 72.40, train corr acc 45.92, val acc 74.94, val corr acc 49.74\n",
      "Ep 1 \titer 145  \tloss 1.51417, train acc 67.71, train corr acc 43.64, val acc 74.68, val corr acc 49.23\n",
      "Ep 1 \titer 146  \tloss 1.13711, train acc 75.52, train corr acc 49.46, val acc 74.30, val corr acc 48.47\n",
      "Ep 1 \titer 147  \tloss 1.20867, train acc 73.44, train corr acc 46.88, val acc 74.43, val corr acc 48.72\n",
      "Ep 1 \titer 148  \tloss 1.02938, train acc 75.52, train corr acc 45.35, val acc 74.24, val corr acc 48.34\n",
      "Ep 1 \titer 149  \tloss 1.10774, train acc 76.56, train corr acc 53.12, val acc 74.30, val corr acc 48.47\n",
      "Ep 1 \titer 150  \tloss 1.27734, train acc 71.35, train corr acc 47.62, val acc 74.11, val corr acc 48.09\n",
      "Ep 1 \titer 151  \tloss 1.31795, train acc 72.92, train corr acc 50.00, val acc 74.49, val corr acc 48.85\n",
      "Ep 1 \titer 152  \tloss 0.97395, train acc 75.00, train corr acc 45.45, val acc 74.75, val corr acc 49.36\n",
      "Ep 1 \titer 153  \tloss 1.20986, train acc 75.00, train corr acc 46.67, val acc 74.17, val corr acc 48.21\n",
      "Ep 1 \titer 154  \tloss 1.34316, train acc 69.27, train corr acc 47.79, val acc 74.68, val corr acc 49.23\n",
      "Ep 1 \titer 155  \tloss 1.17067, train acc 76.04, train corr acc 54.46, val acc 75.25, val corr acc 50.38\n",
      "Ep 1 \titer 156  \tloss 1.12376, train acc 72.40, train corr acc 49.04, val acc 74.43, val corr acc 48.72\n",
      "Ep 1 \titer 157  \tloss 1.23658, train acc 69.79, train corr acc 42.57, val acc 74.43, val corr acc 48.72\n",
      "Ep 1 \titer 158  \tloss 1.07989, train acc 72.92, train corr acc 45.83, val acc 74.24, val corr acc 48.34\n",
      "Ep 1 \titer 159  \tloss 1.11600, train acc 77.08, train corr acc 51.11, val acc 74.81, val corr acc 49.49\n",
      "Ep 1 \titer 160  \tloss 1.19530, train acc 72.40, train corr acc 49.52, val acc 74.55, val corr acc 48.98\n",
      "Ep 1 \titer 161  \tloss 1.14539, train acc 75.52, train corr acc 52.04, val acc 74.55, val corr acc 48.98\n",
      "Ep 1 \titer 162  \tloss 1.23492, train acc 72.40, train corr acc 49.52, val acc 75.38, val corr acc 50.64\n",
      "Ep 1 \titer 163  \tloss 1.00321, train acc 75.52, train corr acc 47.78, val acc 75.13, val corr acc 50.13\n",
      "Ep 1 \titer 164  \tloss 1.12056, train acc 75.00, train corr acc 51.52, val acc 74.81, val corr acc 49.49\n",
      "Ep 1 \titer 165  \tloss 1.28362, train acc 72.92, train corr acc 45.83, val acc 74.36, val corr acc 48.60\n",
      "Ep 1 \titer 166  \tloss 1.02263, train acc 76.04, train corr acc 50.00, val acc 74.05, val corr acc 47.96\n",
      "Ep 1 \titer 167  \tloss 1.10710, train acc 75.00, train corr acc 46.67, val acc 75.13, val corr acc 50.13\n",
      "Ep 1 \titer 168  \tloss 1.11984, train acc 77.60, train corr acc 51.69, val acc 74.24, val corr acc 48.34\n",
      "Ep 1 \titer 169  \tloss 1.23706, train acc 72.92, train corr acc 49.02, val acc 74.81, val corr acc 49.49\n",
      "Ep 1 \titer 170  \tloss 1.13445, train acc 73.44, train corr acc 50.00, val acc 74.43, val corr acc 48.72\n",
      "Ep 1 \titer 171  \tloss 1.09153, train acc 74.48, train corr acc 48.42, val acc 74.43, val corr acc 48.72\n",
      "Ep 1 \titer 172  \tloss 1.01173, train acc 75.00, train corr acc 49.47, val acc 74.62, val corr acc 49.11\n",
      "Ep 1 \titer 173  \tloss 1.30776, train acc 71.88, train corr acc 43.16, val acc 74.36, val corr acc 48.60\n",
      "Ep 1 \titer 174  \tloss 0.94619, train acc 75.00, train corr acc 44.83, val acc 74.11, val corr acc 48.09\n",
      "Ep 1 \titer 175  \tloss 1.16862, train acc 76.04, train corr acc 47.73, val acc 74.81, val corr acc 49.49\n",
      "Ep 1 \titer 176  \tloss 1.25149, train acc 72.40, train corr acc 50.00, val acc 74.94, val corr acc 49.74\n",
      "Ep 1 \titer 177  \tloss 1.16368, train acc 76.04, train corr acc 53.54, val acc 74.68, val corr acc 49.23\n",
      "Ep 1 \titer 178  \tloss 2.31252, train acc 67.19, train corr acc 48.60, val acc 74.87, val corr acc 49.62\n",
      "Ep 1 \titer 179  \tloss 1.21498, train acc 71.88, train corr acc 44.33, val acc 73.60, val corr acc 47.07\n",
      "Ep 1 \titer 180  \tloss 1.04245, train acc 75.52, train corr acc 49.46, val acc 73.47, val corr acc 46.81\n",
      "Ep 1 \titer 181  \tloss 1.07683, train acc 75.52, train corr acc 50.53, val acc 73.85, val corr acc 47.58\n",
      "Ep 1 \titer 182  \tloss 1.31810, train acc 66.67, train corr acc 35.35, val acc 73.79, val corr acc 47.45\n",
      "Ep 1 \titer 183  \tloss 1.11707, train acc 73.44, train corr acc 48.48, val acc 73.98, val corr acc 47.83\n",
      "Ep 1 \titer 184  \tloss 1.19458, train acc 74.48, train corr acc 47.87, val acc 73.79, val corr acc 47.45\n",
      "Ep 1 \titer 185  \tloss 1.11105, train acc 75.52, train corr acc 52.53, val acc 73.54, val corr acc 46.94\n",
      "Ep 1 \titer 186  \tloss 1.05307, train acc 74.48, train corr acc 45.56, val acc 74.68, val corr acc 49.23\n",
      "Ep 1 \titer 187  \tloss 1.58103, train acc 70.83, train corr acc 47.17, val acc 73.66, val corr acc 47.19\n",
      "Ep 1 \titer 188  \tloss 1.23409, train acc 70.83, train corr acc 44.00, val acc 73.73, val corr acc 47.32\n",
      "Ep 1 \titer 189  \tloss 1.42187, train acc 71.88, train corr acc 41.30, val acc 73.47, val corr acc 46.81\n",
      "Ep 1 \titer 190  \tloss 1.35532, train acc 70.83, train corr acc 49.55, val acc 72.58, val corr acc 45.03\n",
      "Ep 1 \titer 191  \tloss 1.01560, train acc 77.60, train corr acc 48.19, val acc 73.09, val corr acc 46.05\n",
      "Ep 1 \titer 192  \tloss 1.20151, train acc 72.40, train corr acc 42.39, val acc 72.84, val corr acc 45.66\n",
      "Ep 1 \titer 193  \tloss 1.41252, train acc 67.71, train corr acc 43.12, val acc 71.76, val corr acc 43.37\n",
      "Ep 1 \titer 194  \tloss 1.33834, train acc 69.79, train corr acc 42.00, val acc 73.16, val corr acc 46.17\n",
      "Ep 1 \titer 195  \tloss 1.22253, train acc 74.48, train corr acc 50.51, val acc 71.31, val corr acc 42.47\n",
      "Ep 1 \titer 196  \tloss 1.30083, train acc 70.83, train corr acc 46.15, val acc 72.20, val corr acc 44.26\n",
      "Ep 1 \titer 197  \tloss 1.33132, train acc 68.23, train corr acc 32.22, val acc 72.20, val corr acc 44.26\n",
      "Ep 1 \titer 198  \tloss 1.34830, train acc 71.88, train corr acc 44.90, val acc 72.01, val corr acc 43.88\n",
      "Ep 1 \titer 199  \tloss 1.46006, train acc 67.71, train corr acc 41.51, val acc 71.88, val corr acc 43.62\n",
      "Ep 1 \titer 200  \tloss 1.41191, train acc 68.23, train corr acc 40.20, val acc 72.71, val corr acc 45.28\n",
      "Ep 1 \titer 201  \tloss 1.26325, train acc 72.92, train corr acc 44.09, val acc 72.01, val corr acc 43.88\n",
      "Ep 1 \titer 202  \tloss 1.37508, train acc 71.88, train corr acc 42.39, val acc 72.26, val corr acc 44.39\n",
      "Ep 1 \titer 203  \tloss 1.16378, train acc 74.48, train corr acc 43.68, val acc 70.67, val corr acc 41.20\n",
      "Ep 1 \titer 204  \tloss 1.27291, train acc 71.88, train corr acc 44.90, val acc 71.69, val corr acc 43.24\n",
      "Ep 1 \titer 205  \tloss 1.34848, train acc 71.88, train corr acc 45.45, val acc 71.69, val corr acc 43.24\n",
      "Ep 1 \titer 206  \tloss 1.26517, train acc 69.79, train corr acc 40.82, val acc 71.82, val corr acc 43.49\n",
      "Ep 1 \titer 207  \tloss 1.41323, train acc 71.88, train corr acc 46.53, val acc 71.63, val corr acc 43.11\n",
      "Ep 1 \titer 208  \tloss 1.33374, train acc 69.79, train corr acc 38.30, val acc 72.14, val corr acc 44.13\n",
      "Ep 1 \titer 209  \tloss 1.34632, train acc 69.79, train corr acc 42.57, val acc 72.58, val corr acc 45.03\n",
      "Ep 1 \titer 210  \tloss 1.36502, train acc 65.62, train corr acc 39.45, val acc 70.61, val corr acc 41.07\n",
      "Ep 1 \titer 211  \tloss 1.29383, train acc 71.88, train corr acc 43.16, val acc 71.31, val corr acc 42.47\n",
      "Ep 1 \titer 212  \tloss 1.33560, train acc 69.79, train corr acc 44.23, val acc 73.03, val corr acc 45.92\n",
      "Ep 1 \titer 213  \tloss 1.30680, train acc 73.44, train corr acc 50.00, val acc 73.28, val corr acc 46.43\n",
      "Ep 1 \titer 214  \tloss 1.37339, train acc 69.27, train corr acc 46.36, val acc 72.39, val corr acc 44.64\n",
      "Ep 1 \titer 215  \tloss 1.27232, train acc 70.31, train corr acc 43.56, val acc 72.14, val corr acc 44.26\n",
      "Ep 1 \titer 216  \tloss 1.19517, train acc 72.92, train corr acc 43.48, val acc 71.88, val corr acc 43.62\n",
      "Ep 1 \titer 217  \tloss 1.12804, train acc 72.92, train corr acc 48.51, val acc 72.39, val corr acc 44.64\n",
      "Ep 1 \titer 218  \tloss 1.44634, train acc 68.75, train corr acc 40.00, val acc 72.71, val corr acc 45.28\n",
      "Ep 1 \titer 219  \tloss 1.57225, train acc 66.67, train corr acc 43.36, val acc 72.58, val corr acc 45.03\n",
      "Ep 1 \titer 220  \tloss 1.38904, train acc 71.88, train corr acc 48.57, val acc 72.20, val corr acc 44.26\n",
      "Ep 1 \titer 221  \tloss 1.29144, train acc 71.88, train corr acc 44.33, val acc 72.46, val corr acc 44.77\n",
      "Ep 1 \titer 222  \tloss 1.27456, train acc 72.40, train corr acc 44.21, val acc 72.07, val corr acc 44.01\n",
      "Ep 1 \titer 223  \tloss 1.51801, train acc 71.35, train corr acc 46.60, val acc 71.88, val corr acc 43.62\n",
      "Ep 1 \titer 224  \tloss 1.47145, train acc 71.35, train corr acc 43.88, val acc 71.82, val corr acc 43.49\n",
      "Ep 1 \titer 225  \tloss 1.33582, train acc 72.92, train corr acc 43.48, val acc 72.33, val corr acc 44.52\n",
      "Ep 1 \titer 226  \tloss 1.37112, train acc 68.75, train corr acc 41.18, val acc 72.14, val corr acc 44.13\n",
      "Ep 1 \titer 227  \tloss 1.34424, train acc 72.92, train corr acc 41.57, val acc 72.39, val corr acc 44.64\n",
      "Ep 1 \titer 228  \tloss 1.31677, train acc 71.88, train corr acc 47.06, val acc 72.71, val corr acc 45.28\n",
      "\n",
      "Epoch 2 of 10 took 61.866s\n",
      "  training loss:\t\t1.258078\n",
      "  training raw accuracy:\t\t72.10 %\n",
      "  training corrected acc:\t\t45.66 %\n",
      "  validation loss:\t\t1.223261\n",
      "  validation raw accuracy:\t\t72.71 %\n",
      "  validation corrected acc:\t\t45.28 % \n",
      "\n",
      "Ep 2 \titer 229  \tloss 1.12796, train acc 73.44, train corr acc 47.42, val acc 72.20, val corr acc 44.26\n",
      "Ep 2 \titer 230  \tloss 1.27841, train acc 73.44, train corr acc 49.00, val acc 72.58, val corr acc 45.03\n",
      "Ep 2 \titer 231  \tloss 1.14952, train acc 71.35, train corr acc 38.20, val acc 72.52, val corr acc 44.90\n",
      "Ep 2 \titer 232  \tloss 1.41188, train acc 70.31, train corr acc 47.22, val acc 72.39, val corr acc 44.64\n",
      "Ep 2 \titer 233  \tloss 1.16854, train acc 72.92, train corr acc 44.68, val acc 72.90, val corr acc 45.66\n",
      "Ep 2 \titer 234  \tloss 1.28196, train acc 70.83, train corr acc 42.86, val acc 72.52, val corr acc 44.90\n",
      "Ep 2 \titer 235  \tloss 1.27656, train acc 71.35, train corr acc 36.78, val acc 72.84, val corr acc 45.54\n",
      "Ep 2 \titer 236  \tloss 1.32197, train acc 70.31, train corr acc 43.56, val acc 72.52, val corr acc 44.90\n",
      "Ep 2 \titer 237  \tloss 1.14569, train acc 72.92, train corr acc 50.48, val acc 73.79, val corr acc 47.45\n",
      "Ep 2 \titer 238  \tloss 1.43534, train acc 68.75, train corr acc 40.59, val acc 73.22, val corr acc 46.30\n",
      "Ep 2 \titer 239  \tloss 1.10989, train acc 73.96, train corr acc 46.24, val acc 72.84, val corr acc 45.54\n",
      "Ep 2 \titer 240  \tloss 1.26175, train acc 71.35, train corr acc 50.45, val acc 72.90, val corr acc 45.66\n",
      "Ep 2 \titer 241  \tloss 1.44358, train acc 70.31, train corr acc 46.73, val acc 72.52, val corr acc 44.90\n",
      "Ep 2 \titer 242  \tloss 1.37390, train acc 70.31, train corr acc 40.62, val acc 73.28, val corr acc 46.43\n",
      "Ep 2 \titer 243  \tloss 1.30528, train acc 71.35, train corr acc 46.08, val acc 73.79, val corr acc 47.45\n",
      "Ep 2 \titer 244  \tloss 1.43971, train acc 69.79, train corr acc 44.76, val acc 72.58, val corr acc 45.03\n",
      "Ep 2 \titer 245  \tloss 1.32699, train acc 69.79, train corr acc 46.30, val acc 73.09, val corr acc 46.05\n",
      "Ep 2 \titer 246  \tloss 1.26322, train acc 72.92, train corr acc 45.83, val acc 72.58, val corr acc 45.03\n",
      "Ep 2 \titer 247  \tloss 1.18801, train acc 71.88, train corr acc 49.53, val acc 72.84, val corr acc 45.54\n",
      "Ep 2 \titer 248  \tloss 1.23776, train acc 71.35, train corr acc 41.49, val acc 72.58, val corr acc 45.03\n",
      "Ep 2 \titer 249  \tloss 1.19330, train acc 75.52, train corr acc 46.59, val acc 73.22, val corr acc 46.30\n",
      "Ep 2 \titer 250  \tloss 1.17076, train acc 73.44, train corr acc 46.88, val acc 72.33, val corr acc 44.52\n",
      "Ep 2 \titer 251  \tloss 1.14144, train acc 73.96, train corr acc 48.45, val acc 73.41, val corr acc 46.68\n",
      "Ep 2 \titer 252  \tloss 1.14910, train acc 75.52, train corr acc 53.47, val acc 72.33, val corr acc 44.52\n",
      "Ep 2 \titer 253  \tloss 1.34312, train acc 67.71, train corr acc 44.14, val acc 72.71, val corr acc 45.28\n",
      "Ep 2 \titer 254  \tloss 1.23394, train acc 71.88, train corr acc 43.75, val acc 72.26, val corr acc 44.39\n",
      "Ep 2 \titer 255  \tloss 1.30381, train acc 71.35, train corr acc 45.54, val acc 72.71, val corr acc 45.28\n",
      "Ep 2 \titer 256  \tloss 1.11411, train acc 75.52, train corr acc 51.55, val acc 72.58, val corr acc 45.03\n",
      "Ep 2 \titer 257  \tloss 1.32984, train acc 73.44, train corr acc 50.00, val acc 72.96, val corr acc 45.79\n",
      "Ep 2 \titer 258  \tloss 1.22364, train acc 72.92, train corr acc 46.94, val acc 73.03, val corr acc 45.92\n",
      "Ep 2 \titer 259  \tloss 1.49571, train acc 65.10, train corr acc 39.09, val acc 72.96, val corr acc 45.79\n",
      "Ep 2 \titer 260  \tloss 1.25340, train acc 71.88, train corr acc 41.94, val acc 73.35, val corr acc 46.56\n",
      "Ep 2 \titer 261  \tloss 1.17200, train acc 74.48, train corr acc 48.96, val acc 72.77, val corr acc 45.41\n",
      "Ep 2 \titer 262  \tloss 1.09760, train acc 76.56, train corr acc 47.67, val acc 73.66, val corr acc 47.19\n",
      "Ep 2 \titer 263  \tloss 1.11068, train acc 75.00, train corr acc 50.00, val acc 72.39, val corr acc 44.64\n",
      "Ep 2 \titer 264  \tloss 1.38069, train acc 68.23, train corr acc 41.90, val acc 73.03, val corr acc 45.92\n",
      "Ep 2 \titer 265  \tloss 1.24036, train acc 75.00, train corr acc 53.85, val acc 73.47, val corr acc 46.81\n",
      "Ep 2 \titer 266  \tloss 1.09055, train acc 76.56, train corr acc 48.86, val acc 72.90, val corr acc 45.66\n",
      "Ep 2 \titer 267  \tloss 1.15995, train acc 73.96, train corr acc 44.44, val acc 73.22, val corr acc 46.30\n",
      "Ep 2 \titer 268  \tloss 1.37404, train acc 69.79, train corr acc 48.67, val acc 73.03, val corr acc 45.92\n",
      "Ep 2 \titer 269  \tloss 1.20415, train acc 75.52, train corr acc 53.47, val acc 72.58, val corr acc 45.03\n",
      "Ep 2 \titer 270  \tloss 1.17808, train acc 75.00, train corr acc 53.85, val acc 72.71, val corr acc 45.28\n",
      "Ep 2 \titer 271  \tloss 1.29850, train acc 68.23, train corr acc 39.60, val acc 72.90, val corr acc 45.66\n",
      "Ep 2 \titer 272  \tloss 1.06885, train acc 72.40, train corr acc 44.79, val acc 72.77, val corr acc 45.41\n",
      "Ep 2 \titer 273  \tloss 1.13989, train acc 76.04, train corr acc 48.89, val acc 73.03, val corr acc 45.92\n",
      "Ep 2 \titer 274  \tloss 1.23218, train acc 72.40, train corr acc 49.52, val acc 73.16, val corr acc 46.17\n",
      "Ep 2 \titer 275  \tloss 1.18502, train acc 72.92, train corr acc 46.94, val acc 73.60, val corr acc 47.07\n",
      "Ep 2 \titer 276  \tloss 1.26836, train acc 70.31, train corr acc 45.71, val acc 73.03, val corr acc 45.92\n",
      "Ep 2 \titer 277  \tloss 1.06543, train acc 73.44, train corr acc 43.33, val acc 72.90, val corr acc 45.66\n",
      "Ep 2 \titer 278  \tloss 1.18864, train acc 71.88, train corr acc 45.45, val acc 72.84, val corr acc 45.54\n",
      "Ep 2 \titer 279  \tloss 1.29806, train acc 69.79, train corr acc 39.58, val acc 72.46, val corr acc 44.77\n",
      "Ep 2 \titer 280  \tloss 1.04284, train acc 75.52, train corr acc 48.91, val acc 72.84, val corr acc 45.54\n",
      "Ep 2 \titer 281  \tloss 1.12055, train acc 74.48, train corr acc 45.56, val acc 73.03, val corr acc 45.92\n",
      "Ep 2 \titer 282  \tloss 1.16426, train acc 78.12, train corr acc 52.81, val acc 72.71, val corr acc 45.28\n",
      "Ep 2 \titer 283  \tloss 1.27310, train acc 72.92, train corr acc 49.02, val acc 73.16, val corr acc 46.17\n",
      "Ep 2 \titer 284  \tloss 1.14722, train acc 71.88, train corr acc 47.06, val acc 73.35, val corr acc 46.56\n",
      "Ep 2 \titer 285  \tloss 1.14880, train acc 72.92, train corr acc 45.26, val acc 72.96, val corr acc 45.79\n",
      "Ep 2 \titer 286  \tloss 1.07275, train acc 71.88, train corr acc 43.16, val acc 72.71, val corr acc 45.28\n",
      "Ep 2 \titer 287  \tloss 1.37915, train acc 70.83, train corr acc 41.05, val acc 72.71, val corr acc 45.28\n",
      "Ep 2 \titer 288  \tloss 1.04159, train acc 73.44, train corr acc 41.38, val acc 72.96, val corr acc 45.79\n",
      "Ep 2 \titer 289  \tloss 1.27499, train acc 75.00, train corr acc 45.45, val acc 72.26, val corr acc 44.39\n",
      "Ep 2 \titer 290  \tloss 1.28778, train acc 69.79, train corr acc 45.28, val acc 72.65, val corr acc 45.15\n",
      "Ep 2 \titer 291  \tloss 1.30277, train acc 70.83, train corr acc 43.43, val acc 72.46, val corr acc 44.77\n",
      "Ep 2 \titer 292  \tloss 1.18946, train acc 71.88, train corr acc 49.53, val acc 73.22, val corr acc 46.30\n",
      "Ep 2 \titer 293  \tloss 1.24460, train acc 71.88, train corr acc 44.33, val acc 73.35, val corr acc 46.56\n",
      "Ep 2 \titer 294  \tloss 1.14248, train acc 73.44, train corr acc 45.16, val acc 73.22, val corr acc 46.30\n",
      "Ep 2 \titer 295  \tloss 1.14266, train acc 73.44, train corr acc 46.32, val acc 73.41, val corr acc 46.68\n",
      "Ep 2 \titer 296  \tloss 1.32580, train acc 67.71, train corr acc 37.37, val acc 73.35, val corr acc 46.56\n",
      "Ep 2 \titer 297  \tloss 1.21393, train acc 72.92, train corr acc 47.47, val acc 73.28, val corr acc 46.43\n",
      "Ep 2 \titer 298  \tloss 1.21158, train acc 73.96, train corr acc 46.81, val acc 73.09, val corr acc 46.05\n",
      "Ep 2 \titer 299  \tloss 1.13375, train acc 75.00, train corr acc 51.52, val acc 73.35, val corr acc 46.56\n",
      "Ep 2 \titer 300  \tloss 1.05749, train acc 75.00, train corr acc 46.67, val acc 73.09, val corr acc 46.05\n",
      "Ep 2 \titer 301  \tloss 1.42053, train acc 70.83, train corr acc 47.17, val acc 72.52, val corr acc 44.90\n",
      "Ep 2 \titer 302  \tloss 1.29692, train acc 72.92, train corr acc 48.00, val acc 72.77, val corr acc 45.41\n",
      "Ep 2 \titer 303  \tloss 1.31630, train acc 72.40, train corr acc 42.39, val acc 72.84, val corr acc 45.54\n",
      "Ep 2 \titer 304  \tloss 1.35199, train acc 71.35, train corr acc 50.45, val acc 72.90, val corr acc 45.66\n",
      "Ep 2 \titer 305  \tloss 1.02185, train acc 74.48, train corr acc 40.96, val acc 72.58, val corr acc 45.03\n",
      "Ep 2 \titer 306  \tloss 1.21379, train acc 72.92, train corr acc 43.48, val acc 73.54, val corr acc 46.94\n",
      "Ep 2 \titer 307  \tloss 1.30816, train acc 69.27, train corr acc 45.87, val acc 73.79, val corr acc 47.45\n",
      "Ep 2 \titer 308  \tloss 1.19724, train acc 72.92, train corr acc 48.00, val acc 73.03, val corr acc 45.92\n",
      "Ep 2 \titer 309  \tloss 1.15271, train acc 71.35, train corr acc 44.44, val acc 73.41, val corr acc 46.68\n",
      "Ep 2 \titer 310  \tloss 1.14686, train acc 71.35, train corr acc 47.12, val acc 73.22, val corr acc 46.30\n",
      "Ep 2 \titer 311  \tloss 1.27445, train acc 69.27, train corr acc 34.44, val acc 72.77, val corr acc 45.41\n",
      "Ep 2 \titer 312  \tloss 1.12927, train acc 73.96, train corr acc 48.98, val acc 72.90, val corr acc 45.79\n",
      "Ep 2 \titer 313  \tloss 1.33932, train acc 67.71, train corr acc 41.51, val acc 72.71, val corr acc 45.28\n",
      "Ep 2 \titer 314  \tloss 1.39064, train acc 69.27, train corr acc 42.16, val acc 73.60, val corr acc 47.07\n",
      "Ep 2 \titer 315  \tloss 1.13158, train acc 73.44, train corr acc 45.16, val acc 73.47, val corr acc 46.94\n",
      "Ep 2 \titer 316  \tloss 1.26973, train acc 73.44, train corr acc 44.57, val acc 72.96, val corr acc 45.79\n",
      "Ep 2 \titer 317  \tloss 1.10041, train acc 75.52, train corr acc 45.98, val acc 73.22, val corr acc 46.30\n",
      "Ep 2 \titer 318  \tloss 1.13925, train acc 75.00, train corr acc 51.02, val acc 73.03, val corr acc 45.92\n",
      "Ep 2 \titer 319  \tloss 1.28956, train acc 70.83, train corr acc 43.43, val acc 73.22, val corr acc 46.30\n",
      "Ep 2 \titer 320  \tloss 1.23521, train acc 72.92, train corr acc 46.94, val acc 73.22, val corr acc 46.30\n",
      "Ep 2 \titer 321  \tloss 1.30308, train acc 74.48, train corr acc 51.49, val acc 73.16, val corr acc 46.17\n",
      "Ep 2 \titer 322  \tloss 1.23981, train acc 71.35, train corr acc 41.49, val acc 72.65, val corr acc 45.15\n",
      "Ep 2 \titer 323  \tloss 1.19531, train acc 72.40, train corr acc 47.52, val acc 72.90, val corr acc 45.66\n",
      "Ep 2 \titer 324  \tloss 1.20103, train acc 69.79, train corr acc 46.79, val acc 72.77, val corr acc 45.41\n",
      "Ep 2 \titer 325  \tloss 1.20981, train acc 72.40, train corr acc 44.21, val acc 72.39, val corr acc 44.64\n",
      "Ep 2 \titer 326  \tloss 1.27761, train acc 70.83, train corr acc 46.15, val acc 72.33, val corr acc 44.52\n",
      "Ep 2 \titer 327  \tloss 1.29584, train acc 73.44, train corr acc 50.00, val acc 72.33, val corr acc 44.52\n",
      "Ep 2 \titer 328  \tloss 1.36020, train acc 70.31, train corr acc 48.18, val acc 72.52, val corr acc 44.90\n",
      "Ep 2 \titer 329  \tloss 1.19965, train acc 72.92, train corr acc 48.51, val acc 72.58, val corr acc 45.03\n",
      "Ep 2 \titer 330  \tloss 1.10311, train acc 73.96, train corr acc 45.65, val acc 73.03, val corr acc 45.92\n",
      "Ep 2 \titer 331  \tloss 1.06145, train acc 74.48, train corr acc 51.49, val acc 72.65, val corr acc 45.15\n",
      "Ep 2 \titer 332  \tloss 1.17706, train acc 71.88, train corr acc 46.00, val acc 73.28, val corr acc 46.43\n",
      "Ep 2 \titer 333  \tloss 1.37154, train acc 68.23, train corr acc 46.02, val acc 73.66, val corr acc 47.19\n",
      "Ep 2 \titer 334  \tloss 1.34574, train acc 70.31, train corr acc 45.71, val acc 73.16, val corr acc 46.17\n",
      "Ep 2 \titer 335  \tloss 1.20911, train acc 71.88, train corr acc 44.33, val acc 73.54, val corr acc 46.94\n",
      "Ep 2 \titer 336  \tloss 1.13336, train acc 73.96, train corr acc 47.37, val acc 73.22, val corr acc 46.30\n",
      "Ep 2 \titer 337  \tloss 1.44320, train acc 73.44, train corr acc 50.49, val acc 72.90, val corr acc 45.66\n",
      "Ep 2 \titer 338  \tloss 1.40017, train acc 72.40, train corr acc 45.92, val acc 73.41, val corr acc 46.68\n",
      "Ep 2 \titer 339  \tloss 1.26920, train acc 72.92, train corr acc 43.48, val acc 72.65, val corr acc 45.15\n",
      "Ep 2 \titer 340  \tloss 1.36580, train acc 69.79, train corr acc 43.14, val acc 73.03, val corr acc 45.92\n",
      "Ep 2 \titer 341  \tloss 1.23903, train acc 76.56, train corr acc 49.44, val acc 72.84, val corr acc 45.54\n",
      "Ep 2 \titer 342  \tloss 1.22797, train acc 72.40, train corr acc 48.04, val acc 73.16, val corr acc 46.17\n",
      "\n",
      "Epoch 3 of 10 took 58.251s\n",
      "  training loss:\t\t1.201598\n",
      "  training raw accuracy:\t\t72.56 %\n",
      "  training corrected acc:\t\t46.56 %\n",
      "  validation loss:\t\t1.181918\n",
      "  validation raw accuracy:\t\t73.16 %\n",
      "  validation corrected acc:\t\t46.17 % \n",
      "\n",
      "Ep 3 \titer 343  \tloss 1.02980, train acc 73.96, train corr acc 48.45, val acc 72.90, val corr acc 45.66\n",
      "Ep 3 \titer 344  \tloss 1.18277, train acc 74.48, train corr acc 51.00, val acc 73.28, val corr acc 46.43\n",
      "Ep 3 \titer 345  \tloss 1.07758, train acc 75.00, train corr acc 46.07, val acc 72.65, val corr acc 45.15\n",
      "Ep 3 \titer 346  \tloss 1.35712, train acc 69.79, train corr acc 46.30, val acc 73.09, val corr acc 46.05\n",
      "Ep 3 \titer 347  \tloss 1.15895, train acc 75.00, train corr acc 48.94, val acc 72.58, val corr acc 45.03\n",
      "Ep 3 \titer 348  \tloss 1.27115, train acc 71.35, train corr acc 43.88, val acc 72.90, val corr acc 45.66\n",
      "Ep 3 \titer 349  \tloss 1.20946, train acc 70.83, train corr acc 35.63, val acc 72.46, val corr acc 44.77\n",
      "Ep 3 \titer 350  \tloss 1.25272, train acc 69.27, train corr acc 41.58, val acc 72.39, val corr acc 44.64\n",
      "Ep 3 \titer 351  \tloss 1.09796, train acc 75.00, train corr acc 54.29, val acc 72.46, val corr acc 44.77\n",
      "Ep 3 \titer 352  \tloss 1.40567, train acc 68.75, train corr acc 40.59, val acc 72.84, val corr acc 45.54\n",
      "Ep 3 \titer 353  \tloss 1.13175, train acc 75.00, train corr acc 48.39, val acc 72.26, val corr acc 44.39\n",
      "Ep 3 \titer 354  \tloss 1.21206, train acc 69.27, train corr acc 46.85, val acc 72.90, val corr acc 45.66\n",
      "Ep 3 \titer 355  \tloss 1.29302, train acc 71.88, train corr acc 49.53, val acc 72.26, val corr acc 44.39\n",
      "Ep 3 \titer 356  \tloss 1.24435, train acc 73.44, train corr acc 46.88, val acc 72.58, val corr acc 45.03\n",
      "Ep 3 \titer 357  \tloss 1.23064, train acc 69.27, train corr acc 42.16, val acc 72.39, val corr acc 44.64\n",
      "Ep 3 \titer 358  \tloss 1.37245, train acc 70.31, train corr acc 45.71, val acc 72.77, val corr acc 45.41\n",
      "Ep 3 \titer 359  \tloss 1.22690, train acc 69.79, train corr acc 46.30, val acc 72.58, val corr acc 45.03\n",
      "Ep 3 \titer 360  \tloss 1.18837, train acc 72.92, train corr acc 45.83, val acc 72.26, val corr acc 44.39\n",
      "Ep 3 \titer 361  \tloss 1.22218, train acc 68.75, train corr acc 43.93, val acc 73.03, val corr acc 45.92\n",
      "Ep 3 \titer 362  \tloss 1.16491, train acc 71.88, train corr acc 42.55, val acc 73.22, val corr acc 46.30\n",
      "Ep 3 \titer 363  \tloss 1.10479, train acc 75.52, train corr acc 46.59, val acc 73.92, val corr acc 47.70\n",
      "Ep 3 \titer 364  \tloss 1.11427, train acc 73.44, train corr acc 46.88, val acc 73.47, val corr acc 46.81\n",
      "Ep 3 \titer 365  \tloss 1.09372, train acc 75.00, train corr acc 50.52, val acc 73.60, val corr acc 47.07\n",
      "Ep 3 \titer 366  \tloss 1.12694, train acc 75.00, train corr acc 52.48, val acc 73.22, val corr acc 46.30\n",
      "Ep 3 \titer 367  \tloss 1.24664, train acc 71.35, train corr acc 50.45, val acc 73.60, val corr acc 47.07\n",
      "Ep 3 \titer 368  \tloss 1.15529, train acc 73.44, train corr acc 46.88, val acc 72.96, val corr acc 45.79\n",
      "Ep 3 \titer 369  \tloss 1.23304, train acc 70.83, train corr acc 44.55, val acc 73.03, val corr acc 45.92\n",
      "Ep 3 \titer 370  \tloss 1.03158, train acc 75.00, train corr acc 50.52, val acc 73.09, val corr acc 46.05\n",
      "Ep 3 \titer 371  \tloss 1.28644, train acc 72.92, train corr acc 49.02, val acc 72.90, val corr acc 45.66\n",
      "Ep 3 \titer 372  \tloss 1.22104, train acc 72.40, train corr acc 45.92, val acc 73.35, val corr acc 46.56\n",
      "Ep 3 \titer 373  \tloss 1.50120, train acc 65.62, train corr acc 40.00, val acc 72.96, val corr acc 45.79\n",
      "Ep 3 \titer 374  \tloss 1.16850, train acc 72.40, train corr acc 43.01, val acc 72.58, val corr acc 45.03\n",
      "Ep 3 \titer 375  \tloss 1.19055, train acc 73.96, train corr acc 47.92, val acc 73.03, val corr acc 45.92\n",
      "Ep 3 \titer 376  \tloss 1.03037, train acc 75.52, train corr acc 45.35, val acc 73.03, val corr acc 45.92\n",
      "Ep 3 \titer 377  \tloss 1.04807, train acc 78.12, train corr acc 56.25, val acc 72.58, val corr acc 45.03\n",
      "Ep 3 \titer 378  \tloss 1.26477, train acc 70.83, train corr acc 46.67, val acc 72.96, val corr acc 45.79\n",
      "Ep 3 \titer 379  \tloss 1.19023, train acc 75.00, train corr acc 53.85, val acc 73.28, val corr acc 46.43\n",
      "Ep 3 \titer 380  \tloss 0.99329, train acc 77.08, train corr acc 50.00, val acc 72.96, val corr acc 45.79\n",
      "Ep 3 \titer 381  \tloss 1.08889, train acc 75.00, train corr acc 46.67, val acc 73.03, val corr acc 45.92\n",
      "Ep 3 \titer 382  \tloss 1.33035, train acc 70.31, train corr acc 49.56, val acc 73.41, val corr acc 46.68\n",
      "Ep 3 \titer 383  \tloss 1.16378, train acc 75.52, train corr acc 53.47, val acc 73.35, val corr acc 46.56\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-79b630acd31e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Training!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_corrected_accs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_corrected_accs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord_per_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/lisa1010/dev/deepcode/code/model_predict_ast.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_data, val_data, train_loss_acc, compute_loss_acc, num_epochs, batchsize, record_per_iter)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_minibatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruth_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mX_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruth_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loss_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruth_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0mtrain_corrected_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_corrected_acc_on_ast_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruth_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;31m# train_loss_ep += train_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lisa1010/anaconda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lisa1010/anaconda/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    961\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[1;32m    962\u001b[0m                  allow_gc=allow_gc):\n\u001b[0;32m--> 963\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lisa1010/anaconda/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(node, args, outs)\u001b[0m\n\u001b[1;32m    950\u001b[0m                         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m                         \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m                         self, node)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (/Users/lisa1010/.theano/compiledir_Darwin-15.2.0-x86_64-i386-64bit-i386-2.7.11-64/scan_perform/mod.cpp:4193)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/lisa1010/anaconda/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    877\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lisa1010/anaconda/lib/python2.7/site-packages/theano/tensor/blas.pyc\u001b[0m in \u001b[0;36mperform\u001b[0;34m(self, node, inp, out)\u001b[0m\n\u001b[1;32m   1732\u001b[0m         \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1733\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1734\u001b[0;31m             \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1735\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m             \u001b[0;31m# The error raised by numpy has no shape information, we mean to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training!\n",
    "train_losses, train_accs, train_corrected_accs, val_losses, val_accs, val_corrected_accs = model.train(train_data, val_data, train_loss_acc, compute_loss_acc, num_epochs=num_epochs, batchsize=batchsize, record_per_iter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "Final results:\n",
      "  test loss:\t\t\t1.107700\n",
      "  test raw accuracy:\t\t74.59 %\n",
      "  test corrected accuracy:\t51.04 %\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_raw_acc, test_corrected_acc, pred_test = model.check_accuracy(test_data, compute_loss_acc, row_to_ast_id_map, dataset_name='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X AST IDs\n",
      "[[   1.   75.   29.   -1.   -1.   -1.]\n",
      " [  13.   74.    0.   -1.   -1.   -1.]\n",
      " [ 214.   14.   -1.   -1.   -1.   -1.]\n",
      " [   1.    8.    3.    0.   -1.   -1.]\n",
      " [   1.    3.    7.    9.   -1.   -1.]\n",
      " [   5.    1.    5.    0.   -1.   -1.]\n",
      " [  38.    1.   -1.   -1.   -1.   -1.]\n",
      " [   2.   27.    0.   -1.   -1.   -1.]\n",
      " [   1.    4.   11.    2.    0.   -1.]\n",
      " [ 498.    0.   -1.   -1.   -1.   -1.]]\n",
      "Truth AST IDs\n",
      "[[ 75.  29.  -1.  -1.  -1.  -1.]\n",
      " [ 74.   0.  -1.  -1.  -1.  -1.]\n",
      " [ 14.  -1.  -1.  -1.  -1.  -1.]\n",
      " [  8.   3.   0.  -1.  -1.  -1.]\n",
      " [  3.   7.   9.  -1.  -1.  -1.]\n",
      " [  1.   5.   0.  -1.  -1.  -1.]\n",
      " [  1.  -1.  -1.  -1.  -1.  -1.]\n",
      " [ 27.   0.  -1.  -1.  -1.  -1.]\n",
      " [  4.  11.   2.   0.  -1.  -1.]\n",
      " [  0.  -1.  -1.  -1.  -1.  -1.]]\n",
      "Predicted AST IDs\n",
      "[[   4.   66.    0.   -1.   -1.   -1.]\n",
      " [  74.   27.   -1.   -1.   -1.   -1.]\n",
      " [   0.   -1.   -1.   -1.   -1.   -1.]\n",
      " [   4.    3.    0.   -1.   -1.   -1.]\n",
      " [   4.   11.    0.   -1.   -1.   -1.]\n",
      " [   3.    0.    0.   -1.   -1.   -1.]\n",
      " [  20.    0.   -1.   -1.   -1.   -1.]\n",
      " [ 108.    0.   -1.   -1.   -1.   -1.]\n",
      " [   4.    3.    3.    0.   -1.   -1.]\n",
      " [  -1.   -1.   -1.   -1.   -1.   -1.]]\n"
     ]
    }
   ],
   "source": [
    "# Convert to AST IDs so we can look at the AST json files\n",
    "X_test_ast_ids, y_test_ast_ids = utils.convert_data_to_ast_ids(test_data, row_to_ast_id_map)\n",
    "pred_test_ast_ids = utils.convert_pred_to_ast_ids(pred_test, row_to_ast_id_map)\n",
    "print(\"X AST IDs\")\n",
    "print X_test_ast_ids[:10,:]\n",
    "print (\"Truth AST IDs\")\n",
    "print y_test_ast_ids[:10, :]\n",
    "print(\"Predicted AST IDs\")\n",
    "print pred_test_ast_ids[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAE+CAYAAABSoh3fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n71jhY7FYLJZ6xwofi8VisdQ7/x9xvHy8Zcm+7AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1277ac510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the loss and the accuracies for both training and validation sets for each epoch\n",
    "visualize.plot_loss_acc(DATA_SET + '_train', train_losses, train_corrected_accs, val_corrected_accs, learning_rate, reg_strength, num_epochs, num_train, xlabel='iterations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are more trial runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "hidden_size = 256 # size of hidden layer of neurons\n",
    "learning_rate = 1e-2\n",
    "lr_decay = 0.95\n",
    "reg_strength = 2e-2\n",
    "grad_clip = 10\n",
    "batchsize = 32\n",
    "num_epochs = 4\n",
    "dropout_p = 0.2\n",
    "num_lstm_layers = 2\n",
    "theano.config.optimizer='fast_compile'\n",
    "theano.config.exception_verbosity='high'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building network ...\n",
      "Computing updates ...\n",
      "Compiling functions ...\n",
      "Compiling done!\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "train_loss_acc, compute_loss_acc, probs = model.create_model(num_timesteps, num_asts, hidden_size, learning_rate, grad_clip, dropout_p, num_lstm_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
