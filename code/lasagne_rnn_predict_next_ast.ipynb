{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Deep Knowledge Tracing\n",
    "Authors: Lisa Wang, Angela Sy\n",
    "\n",
    "### Task: Predict what the student is going to code next.\n",
    "\n",
    "Input: For each of the N students, we have a time series of Abstract Syntax Trees (ASTs), which represent the student's code at that time step.\n",
    "- input shape (num_students, num_timesteps, num_asts)\n",
    "    - num_timesteps is the max sequence length of asts that we are taking into account.\n",
    "    - num_asts is the total number of asts for that problem.\n",
    "\n",
    "Output: At each timestep, we are predicting the next AST.\n",
    "- Output shape (num_students, num_timesteps, num_asts). (one-hot encoding)\n",
    "\n",
    "The truth matrix contains the desired output for a given input, and is used to compute the loss as well as train/val/test accuracies.\n",
    "- Truth shape (num_students, num_timesteps) Values are in range (0, num_asts)\n",
    "\n",
    "Accuracy:\n",
    "- Raw Accuracy: For all predictions at all timesteps, we get the percentage of predictions we got correct.\n",
    "- Corrected Accuracy: Since many trajectories contain fewer asts than max_traj_len, we fill the empty asts with our dummy ast token at row 0. However, predicting on end tokens is to simple of a task and might bias our results. The corrected accuracy ignores all predictions on the end token.\n",
    "\n",
    "### Current Issues:\n",
    "    1. AST IDs are not consistent across different HOCs. Hence, we can only train and run this model on each HOC individually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Python libraries\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as Tensor\n",
    "import lasagne\n",
    "import random\n",
    "import sys\n",
    "import csv\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "# allows plots to show inline in ipython notebook\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import our own modules\n",
    "import utils\n",
    "import model_predict_ast as model\n",
    "import visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Each trajectory matrix corresponds to one hoc exercise and is\n",
    "# its own data set. Mixing data sets currently does not make much\n",
    "# sense since the AST IDs don't persist betweeen different hoc's.\n",
    "TRAJ_MAP = {\n",
    "    'hoc1': '../processed_data/traj_matrix_1.npy',\n",
    "    'hoc2': '../processed_data/traj_matrix_2.npy',\n",
    "    'hoc3': '../processed_data/traj_matrix_3.npy',\n",
    "    'hoc4': '../processed_data/traj_matrix_4.npy',\n",
    "    'hoc5': '../processed_data/traj_matrix_5.npy',\n",
    "    'hoc6': '../processed_data/traj_matrix_6.npy',\n",
    "    'hoc7': '../processed_data/traj_matrix_7.npy',\n",
    "    'hoc8': '../processed_data/traj_matrix_8.npy',\n",
    "    'hoc9': '../processed_data/traj_matrix_9.npy' \n",
    "}\n",
    "\n",
    "TRAJ_MAP_PREFIX = '../processed_data/traj_matrix_'\n",
    "TRAJ_MAP_SUFFIX = '.npy'\n",
    "\n",
    "HOC_NUM = str(7)\n",
    "DATA_SET = 'hoc' + HOC_NUM\n",
    "# if DATA_SZ = -1, use entire data set\n",
    "# For DATA_SZ, powers of 2 work best for performance.\n",
    "DATA_SZ = -1\n",
    "AST_MAP_FILE = '../processed_data/map_ast_row_' + HOC_NUM + '.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load AST ID to Row Map\n",
    "ast_id_to_row_map = pickle.load(open( AST_MAP_FILE, \"rb\" ))\n",
    "# Create Row to AST ID Map by inverting the previous one\n",
    "row_to_ast_id_map = {v: k for k, v in ast_id_to_row_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4195, 7, 432)\n"
     ]
    }
   ],
   "source": [
    "# trajectories matrix for a single hoc exercise\n",
    "# shape (num_traj, max_traj_len, num_asts)\n",
    "# Note that ast_index = 0 corresponds to the <END> token,\n",
    "# marking that the student has already finished.\n",
    "# The <END> token does not correspond to an AST.\n",
    "traj_mat = np.load(TRAJ_MAP[DATA_SET])\n",
    "print traj_mat.shape\n",
    "# print traj_mat[:10, :, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4195, 7, 432)\n"
     ]
    }
   ],
   "source": [
    "# if DATA_SZ specified, reduce matrix. \n",
    "# Useful to create smaller data sets for testing purposes.\n",
    "if DATA_SZ != -1:\n",
    "    traj_mat = traj_mat[:DATA_SZ]\n",
    "print traj_mat.shape\n",
    "# print traj_mat_sm[:, :, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# shuffle the first dimension of the matrix\n",
    "np.random.shuffle(traj_mat)\n",
    "# print traj_mat_sm[:, :, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_traj, max_traj_len, num_asts = traj_mat.shape\n",
    "# Split data into train, val, test\n",
    "# TODO: Replace with kfold validation in the future\n",
    "# perhaps we can use sklearn kfold?\n",
    "\n",
    "train_mat = traj_mat[0:7*num_traj/8,:]\n",
    "val_mat =  traj_mat[7*num_traj/8: 15*num_traj/16 ,:]\n",
    "test_mat = traj_mat[15*num_traj/16:num_traj,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing network inputs and targets...\n",
      "(3670, 6, 432)\n",
      "(3670, 6)\n",
      "(262, 6, 432)\n",
      "(263, 6, 432)\n",
      "[[   2.   43.    0.    0.    0.    0.]\n",
      " [  51.    3.    0.    0.    0.    0.]\n",
      " [  36.    2.   27.   28.    0.    0.]\n",
      " [  59.    1.    3.    0.    0.    0.]\n",
      " [   2.  322.    0.    0.    0.    0.]\n",
      " [   2.   27.    3.    0.    0.    0.]\n",
      " [  37.  108.    3.    0.    0.    0.]\n",
      " [   1.    3.    0.    0.    0.    0.]\n",
      " [ 219.   43.    0.    0.    0.    0.]\n",
      " [  30.   34.    3.    0.    0.    0.]]\n",
      "[[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]]\n",
      "[[  8.   3.  25.  -1.  -1.  -1.]\n",
      " [  4.  12.   0.  -1.  -1.  -1.]\n",
      " [  4.  11.   3.   7.   9.  -1.]\n",
      " [  1.   8.   1.   0.  -1.  -1.]\n",
      " [  1.   3.  77.  -1.  -1.  -1.]\n",
      " [  8.   3.   7.   0.  -1.  -1.]\n",
      " [  1.   2.  59.   0.  -1.  -1.]\n",
      " [ 12.   1.   0.  -1.  -1.  -1.]\n",
      " [ 61.  86.  25.  -1.  -1.  -1.]\n",
      " [  1.   5.  19.   0.  -1.  -1.]]\n",
      "[[  3.  25.  -1.  -1.  -1.  -1.]\n",
      " [ 12.   0.  -1.  -1.  -1.  -1.]\n",
      " [ 11.   3.   7.   9.  -1.  -1.]\n",
      " [  8.   1.   0.  -1.  -1.  -1.]\n",
      " [  3.  77.  -1.  -1.  -1.  -1.]\n",
      " [  3.   7.   0.  -1.  -1.  -1.]\n",
      " [  2.  59.   0.  -1.  -1.  -1.]\n",
      " [  1.   0.  -1.  -1.  -1.  -1.]\n",
      " [ 86.  25.  -1.  -1.  -1.  -1.]\n",
      " [  5.  19.   0.  -1.  -1.  -1.]]\n",
      "6\n",
      "Inputs and targets done!\n"
     ]
    }
   ],
   "source": [
    "print('Preparing network inputs and targets...')\n",
    "# X_train, y_train = utils.prepare_traj_data_for_rnn(train_data)\n",
    "# X_val, y_val = utils.prepare_traj_data_for_rnn(val_data)\n",
    "# X_test, y_test = utils.prepare_traj_data_for_rnn(test_data)\n",
    "\n",
    "train_data = utils.prepare_traj_data_for_rnn(train_mat)\n",
    "val_data = utils.prepare_traj_data_for_rnn(val_mat)\n",
    "test_data = utils.prepare_traj_data_for_rnn(test_mat)\n",
    "\n",
    "\n",
    "X_train, y_train = train_data\n",
    "X_val, y_val = val_data\n",
    "X_test, y_test = test_data\n",
    "print X_train.shape\n",
    "print y_train.shape\n",
    "print X_val.shape\n",
    "print X_test.shape\n",
    "num_train, num_timesteps, num_asts = X_train.shape\n",
    "\n",
    "print y_train[:10]\n",
    "print X_train[:10,:, :10]\n",
    "\n",
    "X_train_ast_ids, y_train_ast_ids = utils.convert_data_to_ast_ids(train_data, row_to_ast_id_map)\n",
    "print X_train_ast_ids[:10]\n",
    "print y_train_ast_ids[:10]\n",
    "\n",
    "print num_timesteps\n",
    "print (\"Inputs and targets done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "hidden_size = 256 # size of hidden layer of neurons\n",
    "learning_rate = 2e-2\n",
    "lr_decay = 0.995\n",
    "reg_strength = 1e-2\n",
    "grad_clip = 10\n",
    "batchsize = 32\n",
    "num_epochs = 10\n",
    "dropout_p = 0.2\n",
    "num_lstm_layers = 2\n",
    "theano.config.optimizer='fast_compile'\n",
    "theano.config.exception_verbosity='high'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building network ...\n",
      "Computing updates ...\n",
      "Compiling functions ...\n",
      "Compiling done!\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "train_loss_acc, compute_loss_acc, probs = model.create_model(num_timesteps, num_asts, hidden_size, learning_rate, grad_clip, dropout_p, num_lstm_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Total training iterations: 1140\n",
      "Ep 0 \titer 1  \tloss 5.71710, train acc 64.06, train corr acc 36.11, val acc 66.16, val corr acc 33.00\n",
      "Ep 0 \titer 2  \tloss 2.10251, train acc 68.75, train corr acc 34.78, val acc 66.16, val corr acc 33.00\n",
      "Ep 0 \titer 3  \tloss 1.99258, train acc 65.62, train corr acc 32.65, val acc 66.09, val corr acc 32.87\n",
      "Ep 0 \titer 4  \tloss 2.22885, train acc 65.62, train corr acc 32.65, val acc 66.16, val corr acc 33.00\n",
      "Ep 0 \titer 5  \tloss 2.32056, train acc 64.58, train corr acc 32.00, val acc 66.28, val corr acc 33.25\n",
      "Ep 0 \titer 6  \tloss 2.17487, train acc 59.90, train corr acc 29.36, val acc 66.67, val corr acc 34.01\n",
      "Ep 0 \titer 7  \tloss 2.22112, train acc 67.19, train corr acc 36.36, val acc 61.32, val corr acc 25.57\n",
      "Ep 0 \titer 8  \tloss 1.81876, train acc 64.06, train corr acc 29.90, val acc 65.84, val corr acc 32.37\n",
      "Ep 0 \titer 9  \tloss 1.53966, train acc 63.02, train corr acc 30.39, val acc 66.98, val corr acc 34.63\n",
      "Ep 0 \titer 10  \tloss 1.84297, train acc 64.06, train corr acc 36.11, val acc 66.98, val corr acc 34.63\n",
      "Ep 0 \titer 11  \tloss 1.68237, train acc 64.58, train corr acc 33.98, val acc 67.05, val corr acc 35.01\n",
      "Ep 0 \titer 12  \tloss 1.51641, train acc 68.75, train corr acc 37.23, val acc 65.71, val corr acc 34.13\n",
      "Ep 0 \titer 13  \tloss 1.49005, train acc 66.67, train corr acc 30.00, val acc 66.09, val corr acc 34.63\n",
      "Ep 0 \titer 14  \tloss 1.54207, train acc 68.23, train corr acc 38.54, val acc 68.07, val corr acc 36.90\n",
      "Ep 0 \titer 15  \tloss 1.95962, train acc 65.10, train corr acc 39.09, val acc 67.88, val corr acc 36.52\n",
      "Ep 0 \titer 16  \tloss 1.40798, train acc 69.27, train corr acc 37.23, val acc 67.94, val corr acc 36.65\n",
      "Ep 0 \titer 17  \tloss 1.46333, train acc 64.06, train corr acc 33.01, val acc 67.49, val corr acc 35.77\n",
      "Ep 0 \titer 18  \tloss 1.60890, train acc 64.06, train corr acc 33.65, val acc 67.05, val corr acc 35.14\n",
      "Ep 0 \titer 19  \tloss 1.51129, train acc 65.62, train corr acc 32.29, val acc 66.98, val corr acc 34.63\n",
      "Ep 0 \titer 20  \tloss 1.68883, train acc 67.19, train corr acc 34.38, val acc 67.18, val corr acc 35.01\n",
      "Ep 0 \titer 21  \tloss 1.46056, train acc 72.40, train corr acc 38.37, val acc 67.37, val corr acc 35.39\n",
      "Ep 0 \titer 22  \tloss 1.85491, train acc 64.58, train corr acc 34.62, val acc 66.67, val corr acc 34.01\n",
      "Ep 0 \titer 23  \tloss 1.33307, train acc 69.79, train corr acc 31.76, val acc 65.84, val corr acc 33.00\n",
      "Ep 0 \titer 24  \tloss 1.44986, train acc 66.67, train corr acc 36.63, val acc 66.48, val corr acc 34.13\n",
      "Ep 0 \titer 25  \tloss 1.63830, train acc 66.15, train corr acc 34.02, val acc 66.35, val corr acc 33.38\n",
      "Ep 0 \titer 26  \tloss 1.42909, train acc 67.19, train corr acc 35.71, val acc 66.41, val corr acc 33.50\n",
      "Ep 0 \titer 27  \tloss 1.72074, train acc 63.02, train corr acc 31.07, val acc 66.60, val corr acc 33.88\n",
      "Ep 0 \titer 28  \tloss 1.47576, train acc 68.23, train corr acc 38.38, val acc 66.92, val corr acc 34.63\n",
      "Ep 0 \titer 29  \tloss 1.55528, train acc 66.67, train corr acc 35.35, val acc 67.18, val corr acc 35.01\n",
      "Ep 0 \titer 30  \tloss 1.68219, train acc 66.67, train corr acc 37.25, val acc 67.37, val corr acc 35.77\n",
      "Ep 0 \titer 31  \tloss 1.49045, train acc 63.02, train corr acc 26.04, val acc 67.49, val corr acc 35.89\n",
      "Ep 0 \titer 32  \tloss 1.51654, train acc 70.31, train corr acc 38.71, val acc 67.37, val corr acc 35.39\n",
      "Ep 0 \titer 33  \tloss 1.21158, train acc 69.79, train corr acc 36.96, val acc 67.30, val corr acc 35.26\n",
      "Ep 0 \titer 34  \tloss 1.51233, train acc 65.62, train corr acc 32.65, val acc 67.88, val corr acc 36.40\n",
      "Ep 0 \titer 35  \tloss 1.72461, train acc 61.46, train corr acc 30.84, val acc 68.26, val corr acc 37.28\n",
      "Ep 0 \titer 36  \tloss 1.50663, train acc 64.58, train corr acc 33.98, val acc 68.26, val corr acc 37.78\n",
      "Ep 0 \titer 37  \tloss 1.63599, train acc 66.67, train corr acc 38.83, val acc 68.89, val corr acc 38.54\n",
      "Ep 0 \titer 38  \tloss 1.64662, train acc 68.23, train corr acc 40.20, val acc 69.53, val corr acc 39.80\n",
      "Ep 0 \titer 39  \tloss 1.25628, train acc 71.88, train corr acc 39.33, val acc 68.58, val corr acc 37.78\n",
      "Ep 0 \titer 40  \tloss 1.54467, train acc 66.15, train corr acc 35.00, val acc 67.43, val corr acc 35.52\n",
      "Ep 0 \titer 41  \tloss 1.62610, train acc 63.02, train corr acc 30.39, val acc 68.45, val corr acc 37.66\n",
      "Ep 0 \titer 42  \tloss 1.61127, train acc 65.10, train corr acc 36.79, val acc 69.34, val corr acc 39.55\n",
      "Ep 0 \titer 43  \tloss 1.40020, train acc 65.10, train corr acc 30.93, val acc 69.40, val corr acc 39.67\n",
      "Ep 0 \titer 44  \tloss 1.45773, train acc 69.27, train corr acc 43.56, val acc 67.75, val corr acc 37.15\n",
      "Ep 0 \titer 45  \tloss 1.46557, train acc 66.15, train corr acc 37.86, val acc 69.02, val corr acc 38.92\n",
      "Ep 0 \titer 46  \tloss 1.49650, train acc 64.06, train corr acc 33.98, val acc 69.02, val corr acc 38.79\n",
      "Ep 0 \titer 47  \tloss 1.28222, train acc 70.83, train corr acc 41.67, val acc 69.02, val corr acc 38.79\n",
      "Ep 0 \titer 48  \tloss 1.41531, train acc 64.58, train corr acc 34.62, val acc 69.91, val corr acc 40.43\n",
      "Ep 0 \titer 49  \tloss 1.37821, train acc 68.23, train corr acc 37.11, val acc 71.44, val corr acc 43.45\n",
      "Ep 0 \titer 50  \tloss 1.26039, train acc 68.75, train corr acc 39.39, val acc 71.56, val corr acc 43.70\n",
      "Ep 0 \titer 51  \tloss 1.48167, train acc 69.27, train corr acc 43.27, val acc 71.56, val corr acc 43.83\n",
      "Ep 0 \titer 52  \tloss 1.34194, train acc 69.79, train corr acc 47.27, val acc 72.14, val corr acc 45.09\n",
      "Ep 0 \titer 53  \tloss 1.50245, train acc 69.27, train corr acc 40.21, val acc 71.88, val corr acc 44.46\n",
      "Ep 0 \titer 54  \tloss 1.29130, train acc 72.92, train corr acc 43.48, val acc 72.20, val corr acc 44.96\n",
      "Ep 0 \titer 55  \tloss 1.34686, train acc 72.40, train corr acc 46.46, val acc 72.07, val corr acc 44.71\n",
      "Ep 0 \titer 56  \tloss 1.24665, train acc 72.40, train corr acc 43.62, val acc 72.07, val corr acc 44.84\n",
      "Ep 0 \titer 57  \tloss 1.38602, train acc 70.83, train corr acc 41.05, val acc 72.46, val corr acc 45.47\n",
      "Ep 0 \titer 58  \tloss 1.22579, train acc 69.79, train corr acc 41.41, val acc 72.39, val corr acc 45.34\n",
      "Ep 0 \titer 59  \tloss 1.19821, train acc 72.40, train corr acc 41.76, val acc 72.20, val corr acc 44.96\n",
      "Ep 0 \titer 60  \tloss 1.15518, train acc 74.48, train corr acc 43.68, val acc 72.33, val corr acc 45.21\n",
      "Ep 0 \titer 61  \tloss 1.13985, train acc 72.40, train corr acc 40.45, val acc 72.46, val corr acc 45.47\n",
      "Ep 0 \titer 62  \tloss 1.38632, train acc 71.88, train corr acc 46.53, val acc 73.35, val corr acc 47.23\n",
      "Ep 0 \titer 63  \tloss 1.29661, train acc 69.79, train corr acc 44.23, val acc 72.84, val corr acc 46.22\n",
      "Ep 0 \titer 64  \tloss 1.29360, train acc 71.35, train corr acc 46.08, val acc 72.58, val corr acc 45.72\n",
      "Ep 0 \titer 65  \tloss 1.33166, train acc 69.79, train corr acc 41.41, val acc 72.33, val corr acc 45.21\n",
      "Ep 0 \titer 66  \tloss 1.25252, train acc 71.88, train corr acc 42.55, val acc 73.16, val corr acc 46.85\n",
      "Ep 0 \titer 67  \tloss 1.23463, train acc 73.44, train corr acc 46.88, val acc 73.16, val corr acc 46.85\n",
      "Ep 0 \titer 68  \tloss 1.48964, train acc 69.79, train corr acc 40.21, val acc 73.66, val corr acc 47.86\n",
      "Ep 0 \titer 69  \tloss 1.27441, train acc 72.92, train corr acc 44.68, val acc 73.41, val corr acc 47.36\n",
      "Ep 0 \titer 70  \tloss 1.42173, train acc 68.75, train corr acc 43.93, val acc 73.22, val corr acc 46.98\n",
      "Ep 0 \titer 71  \tloss 1.20738, train acc 72.40, train corr acc 43.62, val acc 73.41, val corr acc 47.36\n",
      "Ep 0 \titer 72  \tloss 1.44573, train acc 69.27, train corr acc 42.72, val acc 73.79, val corr acc 48.11\n",
      "Ep 0 \titer 73  \tloss 1.30053, train acc 70.31, train corr acc 41.84, val acc 74.11, val corr acc 48.74\n",
      "Ep 0 \titer 74  \tloss 1.16379, train acc 72.92, train corr acc 43.48, val acc 74.17, val corr acc 48.87\n",
      "Ep 0 \titer 75  \tloss 1.36013, train acc 69.79, train corr acc 43.69, val acc 73.85, val corr acc 48.24\n",
      "Ep 0 \titer 76  \tloss 1.37382, train acc 72.40, train corr acc 48.04, val acc 73.79, val corr acc 48.11\n",
      "Ep 0 \titer 77  \tloss 1.27145, train acc 72.40, train corr acc 50.47, val acc 73.60, val corr acc 47.73\n",
      "Ep 0 \titer 78  \tloss 1.34103, train acc 71.88, train corr acc 45.45, val acc 73.41, val corr acc 47.36\n",
      "Ep 0 \titer 79  \tloss 1.19507, train acc 75.00, train corr acc 49.47, val acc 73.35, val corr acc 47.23\n",
      "Ep 0 \titer 80  \tloss 1.12867, train acc 75.52, train corr acc 50.00, val acc 73.60, val corr acc 47.73\n",
      "Ep 0 \titer 81  \tloss 1.39910, train acc 68.23, train corr acc 46.96, val acc 73.85, val corr acc 48.24\n",
      "Ep 0 \titer 82  \tloss 1.31795, train acc 70.83, train corr acc 43.43, val acc 74.11, val corr acc 48.74\n",
      "Ep 0 \titer 83  \tloss 1.29200, train acc 71.35, train corr acc 46.60, val acc 73.79, val corr acc 48.11\n",
      "Ep 0 \titer 84  \tloss 1.34308, train acc 68.23, train corr acc 37.76, val acc 73.73, val corr acc 47.98\n",
      "Ep 0 \titer 85  \tloss 1.18349, train acc 71.88, train corr acc 44.33, val acc 73.73, val corr acc 47.98\n",
      "Ep 0 \titer 86  \tloss 1.29198, train acc 70.83, train corr acc 44.00, val acc 73.60, val corr acc 47.73\n",
      "Ep 0 \titer 87  \tloss 1.38776, train acc 70.83, train corr acc 45.63, val acc 73.92, val corr acc 48.36\n",
      "Ep 0 \titer 88  \tloss 1.21837, train acc 75.00, train corr acc 48.94, val acc 74.24, val corr acc 48.99\n",
      "Ep 0 \titer 89  \tloss 1.28715, train acc 72.92, train corr acc 48.51, val acc 74.30, val corr acc 49.12\n",
      "Ep 0 \titer 90  \tloss 1.22932, train acc 69.79, train corr acc 45.28, val acc 74.05, val corr acc 48.61\n",
      "Ep 0 \titer 91  \tloss 1.17630, train acc 71.88, train corr acc 44.33, val acc 73.54, val corr acc 47.61\n",
      "Ep 0 \titer 92  \tloss 1.39332, train acc 66.15, train corr acc 34.34, val acc 73.54, val corr acc 47.61\n",
      "Ep 0 \titer 93  \tloss 1.28053, train acc 71.35, train corr acc 48.60, val acc 73.85, val corr acc 48.24\n",
      "Ep 0 \titer 94  \tloss 1.06262, train acc 76.56, train corr acc 53.61, val acc 73.85, val corr acc 48.24\n",
      "Ep 0 \titer 95  \tloss 1.20960, train acc 75.52, train corr acc 50.00, val acc 74.05, val corr acc 48.61\n",
      "Ep 0 \titer 96  \tloss 1.39729, train acc 71.35, train corr acc 46.60, val acc 73.98, val corr acc 48.49\n",
      "Ep 0 \titer 97  \tloss 1.13355, train acc 77.08, train corr acc 51.11, val acc 73.92, val corr acc 48.36\n",
      "Ep 0 \titer 98  \tloss 1.09098, train acc 72.40, train corr acc 44.79, val acc 73.60, val corr acc 47.73\n",
      "Ep 0 \titer 99  \tloss 1.31632, train acc 70.83, train corr acc 44.00, val acc 73.85, val corr acc 48.24\n",
      "Ep 0 \titer 100  \tloss 1.30562, train acc 72.92, train corr acc 46.39, val acc 74.17, val corr acc 48.87\n",
      "Ep 0 \titer 101  \tloss 1.23310, train acc 71.35, train corr acc 43.88, val acc 74.11, val corr acc 48.74\n",
      "Ep 0 \titer 102  \tloss 1.31976, train acc 69.27, train corr acc 45.87, val acc 74.24, val corr acc 48.99\n",
      "Ep 0 \titer 103  \tloss 1.03902, train acc 76.04, train corr acc 47.13, val acc 74.24, val corr acc 48.99\n",
      "Ep 0 \titer 104  \tloss 1.19667, train acc 75.52, train corr acc 47.19, val acc 73.98, val corr acc 48.49\n",
      "Ep 0 \titer 105  \tloss 1.18353, train acc 73.96, train corr acc 48.98, val acc 73.79, val corr acc 48.11\n",
      "Ep 0 \titer 106  \tloss 1.15941, train acc 74.48, train corr acc 51.49, val acc 73.85, val corr acc 48.24\n",
      "Ep 0 \titer 107  \tloss 1.07329, train acc 77.08, train corr acc 48.84, val acc 74.17, val corr acc 48.87\n",
      "Ep 0 \titer 108  \tloss 1.16734, train acc 75.00, train corr acc 50.52, val acc 74.68, val corr acc 49.87\n",
      "Ep 0 \titer 109  \tloss 0.90802, train acc 77.08, train corr acc 53.68, val acc 74.75, val corr acc 50.00\n",
      "Ep 0 \titer 110  \tloss 1.24284, train acc 76.04, train corr acc 48.89, val acc 74.43, val corr acc 49.37\n",
      "Ep 0 \titer 111  \tloss 1.01184, train acc 75.00, train corr acc 50.00, val acc 74.62, val corr acc 49.75\n",
      "Ep 0 \titer 112  \tloss 1.16887, train acc 75.00, train corr acc 51.02, val acc 74.62, val corr acc 49.75\n",
      "Ep 0 \titer 113  \tloss 1.24945, train acc 68.75, train corr acc 43.93, val acc 74.30, val corr acc 49.12\n",
      "Ep 0 \titer 114  \tloss 1.13801, train acc 75.52, train corr acc 50.00, val acc 74.43, val corr acc 49.37\n",
      "\n",
      "Epoch 1 of 10 took 60.709s\n",
      "  training loss:\t\t1.450534\n",
      "  training raw accuracy:\t\t69.63 %\n",
      "  training corrected acc:\t\t41.02 %\n",
      "  validation loss:\t\t1.153610\n",
      "  validation raw accuracy:\t\t74.62 %\n",
      "  validation corrected acc:\t\t49.75 % \n",
      "\n",
      "Ep 1 \titer 115  \tloss 1.21821, train acc 70.31, train corr acc 47.22, val acc 74.55, val corr acc 49.62\n",
      "Ep 1 \titer 116  \tloss 1.07130, train acc 78.12, train corr acc 54.35, val acc 74.30, val corr acc 49.12\n",
      "Ep 1 \titer 117  \tloss 1.14522, train acc 74.48, train corr acc 50.00, val acc 73.85, val corr acc 48.24\n",
      "Ep 1 \titer 118  \tloss 1.24076, train acc 73.44, train corr acc 47.96, val acc 74.49, val corr acc 49.50\n",
      "Ep 1 \titer 119  \tloss 1.22774, train acc 71.35, train corr acc 45.00, val acc 73.73, val corr acc 47.98\n",
      "Ep 1 \titer 120  \tloss 1.26471, train acc 71.88, train corr acc 50.46, val acc 73.92, val corr acc 48.36\n",
      "Ep 1 \titer 121  \tloss 1.31911, train acc 71.35, train corr acc 44.44, val acc 74.24, val corr acc 48.99\n",
      "Ep 1 \titer 122  \tloss 1.17978, train acc 72.40, train corr acc 45.36, val acc 74.49, val corr acc 49.50\n",
      "Ep 1 \titer 123  \tloss 1.11042, train acc 74.48, train corr acc 51.96, val acc 74.43, val corr acc 49.37\n",
      "Ep 1 \titer 124  \tloss 1.30651, train acc 69.27, train corr acc 45.37, val acc 74.11, val corr acc 48.74\n",
      "Ep 1 \titer 125  \tloss 1.14684, train acc 71.88, train corr acc 47.57, val acc 74.62, val corr acc 49.75\n",
      "Ep 1 \titer 126  \tloss 1.08985, train acc 73.96, train corr acc 46.81, val acc 74.49, val corr acc 49.50\n",
      "Ep 1 \titer 127  \tloss 1.19452, train acc 74.48, train corr acc 45.56, val acc 74.81, val corr acc 50.13\n",
      "Ep 1 \titer 128  \tloss 1.20800, train acc 74.48, train corr acc 48.96, val acc 74.81, val corr acc 50.13\n",
      "Ep 1 \titer 129  \tloss 1.36970, train acc 68.75, train corr acc 45.45, val acc 74.24, val corr acc 48.99\n",
      "Ep 1 \titer 130  \tloss 1.02273, train acc 77.60, train corr acc 54.26, val acc 74.11, val corr acc 48.74\n",
      "Ep 1 \titer 131  \tloss 1.15961, train acc 72.92, train corr acc 49.51, val acc 73.98, val corr acc 48.49\n",
      "Ep 1 \titer 132  \tloss 1.29755, train acc 69.79, train corr acc 44.23, val acc 73.54, val corr acc 47.61\n",
      "Ep 1 \titer 133  \tloss 1.21548, train acc 69.79, train corr acc 39.58, val acc 73.28, val corr acc 47.10\n",
      "Ep 1 \titer 134  \tloss 0.97605, train acc 76.56, train corr acc 53.12, val acc 74.05, val corr acc 48.61\n",
      "Ep 1 \titer 135  \tloss 0.94084, train acc 78.12, train corr acc 51.16, val acc 73.54, val corr acc 47.61\n",
      "Ep 1 \titer 136  \tloss 1.31884, train acc 72.92, train corr acc 50.00, val acc 74.05, val corr acc 48.61\n",
      "Ep 1 \titer 137  \tloss 0.99270, train acc 76.56, train corr acc 47.06, val acc 74.43, val corr acc 49.37\n",
      "Ep 1 \titer 138  \tloss 1.07621, train acc 76.04, train corr acc 54.46, val acc 73.73, val corr acc 47.98\n",
      "Ep 1 \titer 139  \tloss 1.16740, train acc 75.52, train corr acc 51.55, val acc 73.79, val corr acc 48.11\n",
      "Ep 1 \titer 140  \tloss 1.10371, train acc 76.04, train corr acc 53.06, val acc 73.92, val corr acc 48.36\n",
      "Ep 1 \titer 141  \tloss 1.25681, train acc 70.31, train corr acc 44.66, val acc 73.92, val corr acc 48.36\n",
      "Ep 1 \titer 142  \tloss 1.21888, train acc 70.83, train corr acc 43.43, val acc 74.36, val corr acc 49.24\n",
      "Ep 1 \titer 143  \tloss 1.17084, train acc 74.48, train corr acc 50.51, val acc 73.54, val corr acc 47.61\n",
      "Ep 1 \titer 144  \tloss 1.32855, train acc 74.48, train corr acc 51.96, val acc 73.66, val corr acc 47.86\n",
      "Ep 1 \titer 145  \tloss 1.17416, train acc 71.35, train corr acc 42.71, val acc 73.54, val corr acc 47.61\n",
      "Ep 1 \titer 146  \tloss 1.11903, train acc 75.52, train corr acc 49.46, val acc 73.79, val corr acc 48.11\n",
      "Ep 1 \titer 147  \tloss 0.95007, train acc 76.04, train corr acc 50.00, val acc 73.60, val corr acc 47.73\n",
      "Ep 1 \titer 148  \tloss 1.13200, train acc 71.88, train corr acc 44.90, val acc 74.43, val corr acc 49.37\n",
      "Ep 1 \titer 149  \tloss 1.20518, train acc 71.88, train corr acc 49.53, val acc 74.11, val corr acc 48.74\n",
      "Ep 1 \titer 150  \tloss 1.28367, train acc 71.35, train corr acc 46.60, val acc 74.62, val corr acc 49.75\n",
      "Ep 1 \titer 151  \tloss 1.25314, train acc 73.96, train corr acc 51.46, val acc 74.87, val corr acc 50.25\n",
      "Ep 1 \titer 152  \tloss 1.29108, train acc 71.88, train corr acc 47.06, val acc 74.55, val corr acc 49.62\n",
      "Ep 1 \titer 153  \tloss 1.02241, train acc 77.08, train corr acc 50.56, val acc 73.92, val corr acc 48.36\n",
      "Ep 1 \titer 154  \tloss 1.23573, train acc 71.88, train corr acc 46.00, val acc 74.36, val corr acc 49.24\n",
      "Ep 1 \titer 155  \tloss 1.21324, train acc 72.92, train corr acc 49.02, val acc 74.43, val corr acc 49.37\n",
      "Ep 1 \titer 156  \tloss 1.31463, train acc 70.83, train corr acc 47.17, val acc 74.55, val corr acc 49.62\n",
      "Ep 1 \titer 157  \tloss 1.09969, train acc 73.44, train corr acc 47.42, val acc 74.81, val corr acc 50.13\n",
      "Ep 1 \titer 158  \tloss 1.16325, train acc 73.96, train corr acc 50.50, val acc 75.13, val corr acc 50.76\n",
      "Ep 1 \titer 159  \tloss 1.16477, train acc 73.44, train corr acc 50.49, val acc 75.13, val corr acc 50.76\n",
      "Ep 1 \titer 160  \tloss 1.14790, train acc 72.40, train corr acc 48.54, val acc 75.06, val corr acc 50.63\n",
      "Ep 1 \titer 161  \tloss 1.02739, train acc 77.08, train corr acc 54.17, val acc 74.68, val corr acc 49.87\n",
      "Ep 1 \titer 162  \tloss 1.17567, train acc 72.40, train corr acc 49.04, val acc 74.43, val corr acc 49.37\n",
      "Ep 1 \titer 163  \tloss 1.20579, train acc 73.96, train corr acc 48.45, val acc 73.92, val corr acc 48.36\n",
      "Ep 1 \titer 164  \tloss 1.01789, train acc 76.04, train corr acc 53.54, val acc 74.55, val corr acc 49.62\n",
      "Ep 1 \titer 165  \tloss 1.27700, train acc 73.44, train corr acc 50.96, val acc 75.00, val corr acc 50.50\n",
      "Ep 1 \titer 166  \tloss 1.13655, train acc 69.79, train corr acc 47.27, val acc 74.36, val corr acc 49.24\n",
      "Ep 1 \titer 167  \tloss 1.32721, train acc 70.31, train corr acc 41.24, val acc 74.55, val corr acc 49.62\n",
      "Ep 1 \titer 168  \tloss 0.99592, train acc 78.65, train corr acc 55.43, val acc 75.13, val corr acc 50.76\n",
      "Ep 1 \titer 169  \tloss 1.08021, train acc 76.04, train corr acc 53.54, val acc 74.68, val corr acc 49.87\n",
      "Ep 1 \titer 170  \tloss 1.01746, train acc 77.08, train corr acc 53.19, val acc 75.00, val corr acc 50.50\n",
      "Ep 1 \titer 171  \tloss 1.22537, train acc 72.40, train corr acc 44.21, val acc 75.13, val corr acc 50.76\n",
      "Ep 1 \titer 172  \tloss 1.04267, train acc 74.48, train corr acc 50.51, val acc 74.87, val corr acc 50.25\n",
      "Ep 1 \titer 173  \tloss 0.98479, train acc 78.12, train corr acc 53.85, val acc 75.25, val corr acc 51.01\n",
      "Ep 1 \titer 174  \tloss 1.04116, train acc 77.60, train corr acc 50.57, val acc 75.13, val corr acc 50.76\n",
      "Ep 1 \titer 175  \tloss 0.97085, train acc 78.65, train corr acc 53.93, val acc 75.00, val corr acc 50.50\n",
      "Ep 1 \titer 176  \tloss 1.07607, train acc 77.08, train corr acc 56.44, val acc 75.19, val corr acc 50.88\n",
      "Ep 1 \titer 177  \tloss 1.09112, train acc 74.48, train corr acc 52.88, val acc 75.25, val corr acc 51.01\n",
      "Ep 1 \titer 178  \tloss 1.02954, train acc 78.65, train corr acc 59.80, val acc 75.25, val corr acc 51.01\n",
      "Ep 1 \titer 179  \tloss 1.06137, train acc 73.44, train corr acc 48.48, val acc 75.70, val corr acc 51.89\n",
      "Ep 1 \titer 180  \tloss 0.99033, train acc 77.60, train corr acc 54.26, val acc 75.51, val corr acc 51.51\n",
      "Ep 1 \titer 181  \tloss 1.02652, train acc 76.04, train corr acc 52.08, val acc 75.70, val corr acc 51.89\n",
      "Ep 1 \titer 182  \tloss 1.19331, train acc 72.92, train corr acc 46.39, val acc 75.25, val corr acc 51.01\n",
      "Ep 1 \titer 183  \tloss 1.16621, train acc 74.48, train corr acc 47.87, val acc 75.32, val corr acc 51.13\n",
      "Ep 1 \titer 184  \tloss 1.13082, train acc 72.92, train corr acc 51.40, val acc 75.51, val corr acc 51.51\n",
      "Ep 1 \titer 185  \tloss 1.01736, train acc 76.56, train corr acc 52.13, val acc 75.45, val corr acc 51.39\n",
      "Ep 1 \titer 186  \tloss 1.17912, train acc 72.92, train corr acc 49.51, val acc 74.81, val corr acc 50.13\n",
      "Ep 1 \titer 187  \tloss 1.10181, train acc 73.96, train corr acc 48.98, val acc 75.32, val corr acc 51.13\n",
      "Ep 1 \titer 188  \tloss 1.02623, train acc 74.48, train corr acc 46.74, val acc 76.15, val corr acc 52.77\n",
      "Ep 1 \titer 189  \tloss 1.19690, train acc 72.92, train corr acc 49.51, val acc 76.15, val corr acc 52.77\n",
      "Ep 1 \titer 190  \tloss 1.20052, train acc 74.48, train corr acc 51.96, val acc 75.64, val corr acc 51.76\n",
      "Ep 1 \titer 191  \tloss 1.10674, train acc 74.48, train corr acc 54.21, val acc 75.95, val corr acc 52.39\n",
      "Ep 1 \titer 192  \tloss 1.13590, train acc 73.96, train corr acc 49.49, val acc 76.02, val corr acc 52.52\n",
      "Ep 1 \titer 193  \tloss 1.13444, train acc 76.04, train corr acc 51.58, val acc 75.64, val corr acc 51.76\n",
      "Ep 1 \titer 194  \tloss 0.97526, train acc 77.60, train corr acc 54.26, val acc 75.51, val corr acc 51.51\n",
      "Ep 1 \titer 195  \tloss 1.13940, train acc 73.44, train corr acc 55.65, val acc 76.21, val corr acc 52.90\n",
      "Ep 1 \titer 196  \tloss 1.12052, train acc 73.44, train corr acc 48.48, val acc 75.06, val corr acc 50.63\n",
      "Ep 1 \titer 197  \tloss 1.08281, train acc 75.00, train corr acc 53.40, val acc 75.83, val corr acc 52.14\n",
      "Ep 1 \titer 198  \tloss 1.21242, train acc 69.79, train corr acc 40.82, val acc 75.25, val corr acc 51.01\n",
      "Ep 1 \titer 199  \tloss 1.08214, train acc 74.48, train corr acc 49.48, val acc 75.57, val corr acc 51.64\n",
      "Ep 1 \titer 200  \tloss 1.09684, train acc 72.92, train corr acc 48.00, val acc 76.08, val corr acc 52.64\n",
      "Ep 1 \titer 201  \tloss 1.16420, train acc 72.92, train corr acc 49.51, val acc 76.40, val corr acc 53.27\n",
      "Ep 1 \titer 202  \tloss 1.05528, train acc 75.52, train corr acc 50.00, val acc 76.02, val corr acc 52.52\n",
      "Ep 1 \titer 203  \tloss 1.08451, train acc 73.96, train corr acc 50.50, val acc 76.02, val corr acc 52.52\n",
      "Ep 1 \titer 204  \tloss 1.08989, train acc 72.92, train corr acc 50.94, val acc 75.89, val corr acc 52.27\n",
      "Ep 1 \titer 205  \tloss 1.01631, train acc 76.04, train corr acc 52.58, val acc 76.08, val corr acc 52.64\n",
      "Ep 1 \titer 206  \tloss 1.19930, train acc 70.31, train corr acc 42.42, val acc 75.95, val corr acc 52.39\n",
      "Ep 1 \titer 207  \tloss 1.13002, train acc 72.40, train corr acc 50.47, val acc 75.45, val corr acc 51.39\n",
      "Ep 1 \titer 208  \tloss 1.02771, train acc 74.48, train corr acc 49.48, val acc 76.34, val corr acc 53.15\n",
      "Ep 1 \titer 209  \tloss 1.06237, train acc 77.60, train corr acc 54.26, val acc 76.40, val corr acc 53.27\n",
      "Ep 1 \titer 210  \tloss 1.22432, train acc 70.31, train corr acc 44.66, val acc 75.95, val corr acc 52.39\n",
      "Ep 1 \titer 211  \tloss 0.97896, train acc 77.60, train corr acc 52.22, val acc 76.72, val corr acc 53.90\n",
      "Ep 1 \titer 212  \tloss 0.96777, train acc 73.96, train corr acc 47.92, val acc 76.27, val corr acc 53.02\n",
      "Ep 1 \titer 213  \tloss 1.14247, train acc 72.92, train corr acc 48.00, val acc 75.83, val corr acc 52.14\n",
      "Ep 1 \titer 214  \tloss 1.16075, train acc 73.96, train corr acc 48.45, val acc 75.51, val corr acc 51.51\n",
      "Ep 1 \titer 215  \tloss 1.02857, train acc 75.52, train corr acc 52.04, val acc 75.06, val corr acc 50.63\n",
      "Ep 1 \titer 216  \tloss 1.19377, train acc 68.75, train corr acc 44.95, val acc 75.25, val corr acc 51.01\n",
      "Ep 1 \titer 217  \tloss 0.91010, train acc 77.08, train corr acc 49.43, val acc 75.06, val corr acc 50.63\n",
      "Ep 1 \titer 218  \tloss 1.03154, train acc 77.60, train corr acc 51.69, val acc 75.00, val corr acc 50.50\n",
      "Ep 1 \titer 219  \tloss 1.07188, train acc 76.04, train corr acc 53.06, val acc 74.87, val corr acc 50.25\n",
      "Ep 1 \titer 220  \tloss 1.05119, train acc 76.04, train corr acc 54.46, val acc 75.32, val corr acc 51.13\n",
      "Ep 1 \titer 221  \tloss 0.92839, train acc 79.69, train corr acc 54.65, val acc 75.45, val corr acc 51.39\n",
      "Ep 1 \titer 222  \tloss 1.01216, train acc 75.00, train corr acc 50.52, val acc 75.64, val corr acc 51.76\n",
      "Ep 1 \titer 223  \tloss 0.82281, train acc 82.81, train corr acc 65.26, val acc 75.64, val corr acc 51.76\n",
      "Ep 1 \titer 224  \tloss 1.08109, train acc 73.44, train corr acc 43.33, val acc 75.64, val corr acc 51.76\n",
      "Ep 1 \titer 225  \tloss 0.92474, train acc 76.04, train corr acc 52.08, val acc 76.08, val corr acc 52.64\n",
      "Ep 1 \titer 226  \tloss 1.01393, train acc 75.52, train corr acc 52.04, val acc 75.64, val corr acc 51.76\n",
      "Ep 1 \titer 227  \tloss 1.15829, train acc 67.19, train corr acc 41.12, val acc 75.95, val corr acc 52.39\n",
      "Ep 1 \titer 228  \tloss 0.99124, train acc 75.52, train corr acc 50.00, val acc 75.57, val corr acc 51.64\n",
      "\n",
      "Epoch 2 of 10 took 61.816s\n",
      "  training loss:\t\t1.120456\n",
      "  training raw accuracy:\t\t74.15 %\n",
      "  training corrected acc:\t\t49.70 %\n",
      "  validation loss:\t\t1.058919\n",
      "  validation raw accuracy:\t\t76.08 %\n",
      "  validation corrected acc:\t\t52.64 % \n",
      "\n",
      "Ep 2 \titer 229  \tloss 1.14781, train acc 72.40, train corr acc 50.93, val acc 75.57, val corr acc 51.64\n",
      "Ep 2 \titer 230  \tloss 0.93290, train acc 79.17, train corr acc 56.52, val acc 76.15, val corr acc 52.77\n",
      "Ep 2 \titer 231  \tloss 1.02948, train acc 76.04, train corr acc 53.06, val acc 76.08, val corr acc 52.64\n",
      "Ep 2 \titer 232  \tloss 1.16367, train acc 73.96, train corr acc 48.98, val acc 75.95, val corr acc 52.39\n",
      "Ep 2 \titer 233  \tloss 1.12254, train acc 73.44, train corr acc 49.00, val acc 75.38, val corr acc 51.26\n",
      "Ep 2 \titer 234  \tloss 1.12042, train acc 73.96, train corr acc 54.13, val acc 75.25, val corr acc 51.01\n",
      "Ep 2 \titer 235  \tloss 1.18686, train acc 72.40, train corr acc 46.46, val acc 75.70, val corr acc 51.89\n",
      "Ep 2 \titer 236  \tloss 1.07618, train acc 73.96, train corr acc 48.45, val acc 75.45, val corr acc 51.39\n",
      "Ep 2 \titer 237  \tloss 0.99296, train acc 75.52, train corr acc 53.92, val acc 75.51, val corr acc 51.51\n",
      "Ep 2 \titer 238  \tloss 1.20172, train acc 70.83, train corr acc 48.15, val acc 75.64, val corr acc 51.76\n",
      "Ep 2 \titer 239  \tloss 1.04235, train acc 73.44, train corr acc 50.49, val acc 76.02, val corr acc 52.52\n",
      "Ep 2 \titer 240  \tloss 0.99465, train acc 76.04, train corr acc 51.06, val acc 76.15, val corr acc 52.77\n",
      "Ep 2 \titer 241  \tloss 1.05511, train acc 77.08, train corr acc 51.11, val acc 76.53, val corr acc 53.53\n",
      "Ep 2 \titer 242  \tloss 1.09774, train acc 74.48, train corr acc 48.96, val acc 76.02, val corr acc 52.52\n",
      "Ep 2 \titer 243  \tloss 1.22698, train acc 71.88, train corr acc 50.91, val acc 75.76, val corr acc 52.02\n",
      "Ep 2 \titer 244  \tloss 0.96093, train acc 76.04, train corr acc 51.06, val acc 76.15, val corr acc 52.77\n",
      "Ep 2 \titer 245  \tloss 1.02385, train acc 73.96, train corr acc 51.46, val acc 75.70, val corr acc 51.89\n",
      "Ep 2 \titer 246  \tloss 1.02770, train acc 76.56, train corr acc 56.73, val acc 75.57, val corr acc 51.64\n",
      "Ep 2 \titer 247  \tloss 1.04652, train acc 72.92, train corr acc 45.83, val acc 75.57, val corr acc 51.64\n",
      "Ep 2 \titer 248  \tloss 0.92216, train acc 78.12, train corr acc 56.25, val acc 75.70, val corr acc 51.89\n",
      "Ep 2 \titer 249  \tloss 0.81908, train acc 79.17, train corr acc 53.49, val acc 75.83, val corr acc 52.14\n",
      "Ep 2 \titer 250  \tloss 1.16121, train acc 73.44, train corr acc 50.96, val acc 75.32, val corr acc 51.13\n",
      "Ep 2 \titer 251  \tloss 0.89115, train acc 78.65, train corr acc 51.76, val acc 75.51, val corr acc 51.51\n",
      "Ep 2 \titer 252  \tloss 1.00338, train acc 76.04, train corr acc 54.46, val acc 75.25, val corr acc 51.01\n",
      "Ep 2 \titer 253  \tloss 1.03568, train acc 78.12, train corr acc 56.70, val acc 75.13, val corr acc 50.76\n",
      "Ep 2 \titer 254  \tloss 1.01701, train acc 76.04, train corr acc 53.06, val acc 75.19, val corr acc 50.88\n",
      "Ep 2 \titer 255  \tloss 1.13328, train acc 71.88, train corr acc 47.57, val acc 75.32, val corr acc 51.13\n",
      "Ep 2 \titer 256  \tloss 1.06824, train acc 73.96, train corr acc 49.49, val acc 75.32, val corr acc 51.13\n",
      "Ep 2 \titer 257  \tloss 1.11114, train acc 73.44, train corr acc 48.48, val acc 75.70, val corr acc 51.89\n",
      "Ep 2 \titer 258  \tloss 1.15942, train acc 73.44, train corr acc 50.00, val acc 75.83, val corr acc 52.14\n",
      "Ep 2 \titer 259  \tloss 1.09499, train acc 73.44, train corr acc 46.88, val acc 75.76, val corr acc 52.02\n",
      "Ep 2 \titer 260  \tloss 0.96479, train acc 77.60, train corr acc 53.76, val acc 75.89, val corr acc 52.27\n",
      "Ep 2 \titer 261  \tloss 0.83814, train acc 81.77, train corr acc 61.96, val acc 75.32, val corr acc 51.13\n",
      "Ep 2 \titer 262  \tloss 0.98771, train acc 78.12, train corr acc 57.14, val acc 76.02, val corr acc 52.52\n",
      "Ep 2 \titer 263  \tloss 1.12388, train acc 77.08, train corr acc 58.88, val acc 76.02, val corr acc 52.52\n",
      "Ep 2 \titer 264  \tloss 1.14138, train acc 72.92, train corr acc 49.51, val acc 75.89, val corr acc 52.27\n",
      "Ep 2 \titer 265  \tloss 1.10178, train acc 78.12, train corr acc 59.22, val acc 76.15, val corr acc 52.77\n",
      "Ep 2 \titer 266  \tloss 1.18515, train acc 73.96, train corr acc 50.98, val acc 75.76, val corr acc 52.02\n",
      "Ep 2 \titer 267  \tloss 0.89376, train acc 79.69, train corr acc 56.18, val acc 75.89, val corr acc 52.27\n",
      "Ep 2 \titer 268  \tloss 1.07392, train acc 73.96, train corr acc 50.00, val acc 75.64, val corr acc 51.76\n",
      "Ep 2 \titer 269  \tloss 1.03614, train acc 76.04, train corr acc 54.90, val acc 75.45, val corr acc 51.39\n",
      "Ep 2 \titer 270  \tloss 1.21023, train acc 72.92, train corr acc 50.94, val acc 75.38, val corr acc 51.26\n",
      "Ep 2 \titer 271  \tloss 0.94912, train acc 76.04, train corr acc 52.58, val acc 75.89, val corr acc 52.27\n",
      "Ep 2 \titer 272  \tloss 1.05667, train acc 76.04, train corr acc 54.46, val acc 75.51, val corr acc 51.51\n",
      "Ep 2 \titer 273  \tloss 1.06534, train acc 74.48, train corr acc 52.43, val acc 75.64, val corr acc 51.76\n",
      "Ep 2 \titer 274  \tloss 1.00866, train acc 75.00, train corr acc 53.40, val acc 75.25, val corr acc 51.01\n",
      "Ep 2 \titer 275  \tloss 0.91126, train acc 77.08, train corr acc 54.17, val acc 75.32, val corr acc 51.13\n",
      "Ep 2 \titer 276  \tloss 1.07518, train acc 72.92, train corr acc 50.00, val acc 75.76, val corr acc 52.02\n",
      "Ep 2 \titer 277  \tloss 1.08107, train acc 74.48, train corr acc 49.48, val acc 75.32, val corr acc 51.13\n",
      "Ep 2 \titer 278  \tloss 0.95951, train acc 78.12, train corr acc 57.58, val acc 75.32, val corr acc 51.13\n",
      "Ep 2 \titer 279  \tloss 1.17791, train acc 73.44, train corr acc 50.96, val acc 76.02, val corr acc 52.52\n",
      "Ep 2 \titer 280  \tloss 1.03104, train acc 73.96, train corr acc 54.55, val acc 75.76, val corr acc 52.02\n",
      "Ep 2 \titer 281  \tloss 1.17087, train acc 71.88, train corr acc 44.33, val acc 75.76, val corr acc 52.02\n",
      "Ep 2 \titer 282  \tloss 0.86877, train acc 78.65, train corr acc 55.43, val acc 75.89, val corr acc 52.27\n",
      "Ep 2 \titer 283  \tloss 0.95701, train acc 77.60, train corr acc 56.57, val acc 76.27, val corr acc 53.02\n",
      "Ep 2 \titer 284  \tloss 0.91210, train acc 77.08, train corr acc 53.19, val acc 76.02, val corr acc 52.52\n",
      "Ep 2 \titer 285  \tloss 1.12700, train acc 73.44, train corr acc 46.32, val acc 75.89, val corr acc 52.27\n",
      "Ep 2 \titer 286  \tloss 0.98028, train acc 73.96, train corr acc 49.49, val acc 75.57, val corr acc 51.64\n",
      "Ep 2 \titer 287  \tloss 0.82715, train acc 80.21, train corr acc 58.24, val acc 75.38, val corr acc 51.26\n",
      "Ep 2 \titer 288  \tloss 0.92730, train acc 78.12, train corr acc 51.72, val acc 75.00, val corr acc 50.50\n",
      "Ep 2 \titer 289  \tloss 0.87003, train acc 78.65, train corr acc 53.93, val acc 75.32, val corr acc 51.13\n",
      "Ep 2 \titer 290  \tloss 0.95608, train acc 76.04, train corr acc 54.46, val acc 75.00, val corr acc 50.50\n",
      "Ep 2 \titer 291  \tloss 0.96691, train acc 73.96, train corr acc 51.92, val acc 74.68, val corr acc 49.87\n",
      "Ep 2 \titer 292  \tloss 0.91612, train acc 79.17, train corr acc 60.78, val acc 74.49, val corr acc 49.50\n",
      "Ep 2 \titer 293  \tloss 0.93794, train acc 77.08, train corr acc 55.56, val acc 75.06, val corr acc 50.63\n",
      "Ep 2 \titer 294  \tloss 0.91916, train acc 77.08, train corr acc 53.19, val acc 74.36, val corr acc 49.24\n",
      "Ep 2 \titer 295  \tloss 0.96798, train acc 76.04, train corr acc 52.08, val acc 75.89, val corr acc 52.27\n",
      "Ep 2 \titer 296  \tloss 1.06311, train acc 75.52, train corr acc 51.55, val acc 75.70, val corr acc 51.89\n",
      "Ep 2 \titer 297  \tloss 1.06385, train acc 75.00, train corr acc 48.94, val acc 75.70, val corr acc 51.89\n",
      "Ep 2 \titer 298  \tloss 1.00776, train acc 72.92, train corr acc 51.40, val acc 75.64, val corr acc 51.76\n",
      "Ep 2 \titer 299  \tloss 0.95378, train acc 78.65, train corr acc 56.38, val acc 75.32, val corr acc 51.13\n",
      "Ep 2 \titer 300  \tloss 1.05184, train acc 75.52, train corr acc 54.37, val acc 75.83, val corr acc 52.14\n",
      "Ep 2 \titer 301  \tloss 0.99069, train acc 77.60, train corr acc 56.12, val acc 75.06, val corr acc 50.63\n",
      "Ep 2 \titer 302  \tloss 0.96057, train acc 76.56, train corr acc 51.09, val acc 75.76, val corr acc 52.02\n",
      "Ep 2 \titer 303  \tloss 1.07053, train acc 73.96, train corr acc 51.46, val acc 75.45, val corr acc 51.39\n",
      "Ep 2 \titer 304  \tloss 1.13281, train acc 72.92, train corr acc 49.02, val acc 74.81, val corr acc 50.13\n",
      "Ep 2 \titer 305  \tloss 1.00651, train acc 76.04, train corr acc 57.01, val acc 75.00, val corr acc 50.50\n",
      "Ep 2 \titer 306  \tloss 1.84207, train acc 70.83, train corr acc 47.47, val acc 75.89, val corr acc 52.27\n",
      "Ep 2 \titer 307  \tloss 1.09927, train acc 74.48, train corr acc 48.42, val acc 75.00, val corr acc 50.50\n",
      "Ep 2 \titer 308  \tloss 0.97514, train acc 78.12, train corr acc 55.32, val acc 74.87, val corr acc 50.25\n",
      "Ep 2 \titer 309  \tloss 1.16239, train acc 70.31, train corr acc 50.43, val acc 74.94, val corr acc 50.38\n",
      "Ep 2 \titer 310  \tloss 1.10091, train acc 71.35, train corr acc 44.44, val acc 74.17, val corr acc 48.87\n",
      "Ep 2 \titer 311  \tloss 1.07775, train acc 75.52, train corr acc 54.37, val acc 74.49, val corr acc 49.50\n",
      "Ep 2 \titer 312  \tloss 1.13636, train acc 72.40, train corr acc 45.92, val acc 75.19, val corr acc 50.88\n",
      "Ep 2 \titer 313  \tloss 1.02109, train acc 75.00, train corr acc 50.52, val acc 74.75, val corr acc 50.00\n",
      "Ep 2 \titer 314  \tloss 1.11122, train acc 70.31, train corr acc 43.00, val acc 75.38, val corr acc 51.26\n",
      "Ep 2 \titer 315  \tloss 1.15580, train acc 73.96, train corr acc 51.46, val acc 74.87, val corr acc 50.25\n",
      "Ep 2 \titer 316  \tloss 1.03466, train acc 75.52, train corr acc 50.00, val acc 74.62, val corr acc 49.75\n",
      "Ep 2 \titer 317  \tloss 1.12819, train acc 73.44, train corr acc 49.50, val acc 75.57, val corr acc 51.64\n",
      "Ep 2 \titer 318  \tloss 1.08163, train acc 71.35, train corr acc 48.11, val acc 75.32, val corr acc 51.13\n",
      "Ep 2 \titer 319  \tloss 1.08043, train acc 75.00, train corr acc 50.52, val acc 74.87, val corr acc 50.25\n",
      "Ep 2 \titer 320  \tloss 1.19170, train acc 70.83, train corr acc 43.43, val acc 73.79, val corr acc 48.11\n",
      "Ep 2 \titer 321  \tloss 1.16896, train acc 73.96, train corr acc 53.27, val acc 74.81, val corr acc 50.13\n",
      "Ep 2 \titer 322  \tloss 1.06316, train acc 76.04, train corr acc 52.58, val acc 75.25, val corr acc 51.01\n",
      "Ep 2 \titer 323  \tloss 1.15618, train acc 73.96, train corr acc 46.81, val acc 74.75, val corr acc 50.00\n",
      "Ep 2 \titer 324  \tloss 1.24838, train acc 69.79, train corr acc 43.69, val acc 75.06, val corr acc 50.63\n",
      "Ep 2 \titer 325  \tloss 1.03665, train acc 78.12, train corr acc 53.33, val acc 74.87, val corr acc 50.25\n",
      "Ep 2 \titer 326  \tloss 1.02413, train acc 73.96, train corr acc 47.92, val acc 74.17, val corr acc 48.87\n",
      "Ep 2 \titer 327  \tloss 1.15628, train acc 73.44, train corr acc 49.00, val acc 74.55, val corr acc 49.62\n",
      "Ep 2 \titer 328  \tloss 1.16751, train acc 73.96, train corr acc 48.45, val acc 71.88, val corr acc 44.33\n",
      "Ep 2 \titer 329  \tloss 1.22960, train acc 72.92, train corr acc 46.94, val acc 72.14, val corr acc 45.47\n",
      "Ep 2 \titer 330  \tloss 1.39318, train acc 66.67, train corr acc 41.28, val acc 71.82, val corr acc 44.21\n",
      "Ep 2 \titer 331  \tloss 1.08809, train acc 74.48, train corr acc 43.68, val acc 72.71, val corr acc 45.97\n",
      "Ep 2 \titer 332  \tloss 1.17465, train acc 72.92, train corr acc 41.57, val acc 73.09, val corr acc 46.85\n",
      "Ep 2 \titer 333  \tloss 1.16191, train acc 73.96, train corr acc 48.98, val acc 73.85, val corr acc 48.24\n",
      "Ep 2 \titer 334  \tloss 1.14569, train acc 73.96, train corr acc 50.50, val acc 73.79, val corr acc 48.24\n",
      "Ep 2 \titer 335  \tloss 1.07215, train acc 78.12, train corr acc 51.16, val acc 73.54, val corr acc 47.86\n",
      "Ep 2 \titer 336  \tloss 1.18714, train acc 73.44, train corr acc 47.42, val acc 74.24, val corr acc 49.12\n",
      "Ep 2 \titer 337  \tloss 0.96826, train acc 78.12, train corr acc 55.79, val acc 73.66, val corr acc 47.86\n",
      "Ep 2 \titer 338  \tloss 1.22187, train acc 75.00, train corr acc 46.67, val acc 74.30, val corr acc 49.12\n",
      "Ep 2 \titer 339  \tloss 1.02031, train acc 77.08, train corr acc 54.17, val acc 73.79, val corr acc 48.11\n",
      "Ep 2 \titer 340  \tloss 1.16219, train acc 72.40, train corr acc 45.92, val acc 73.09, val corr acc 46.73\n",
      "Ep 2 \titer 341  \tloss 1.24057, train acc 67.19, train corr acc 41.12, val acc 73.92, val corr acc 48.36\n",
      "Ep 2 \titer 342  \tloss 1.17100, train acc 73.44, train corr acc 45.74, val acc 71.69, val corr acc 43.95\n",
      "\n",
      "Epoch 3 of 10 took 68.055s\n",
      "  training loss:\t\t1.068442\n",
      "  training raw accuracy:\t\t74.90 %\n",
      "  training corrected acc:\t\t51.17 %\n",
      "  validation loss:\t\t1.198060\n",
      "  validation raw accuracy:\t\t71.69 %\n",
      "  validation corrected acc:\t\t43.95 % \n",
      "\n",
      "Ep 3 \titer 343  \tloss 1.32064, train acc 68.75, train corr acc 44.44, val acc 74.49, val corr acc 49.50\n",
      "Ep 3 \titer 344  \tloss 1.04656, train acc 75.52, train corr acc 48.91, val acc 73.35, val corr acc 47.23\n",
      "Ep 3 \titer 345  \tloss 1.15918, train acc 70.83, train corr acc 42.86, val acc 74.68, val corr acc 49.87\n",
      "Ep 3 \titer 346  \tloss 1.24581, train acc 70.31, train corr acc 41.84, val acc 73.73, val corr acc 47.98\n",
      "Ep 3 \titer 347  \tloss 1.22381, train acc 71.88, train corr acc 46.00, val acc 72.26, val corr acc 45.09\n",
      "Ep 3 \titer 348  \tloss 1.26019, train acc 68.23, train corr acc 44.04, val acc 74.17, val corr acc 48.87\n",
      "Ep 3 \titer 349  \tloss 1.30966, train acc 71.88, train corr acc 45.45, val acc 74.30, val corr acc 49.12\n",
      "Ep 3 \titer 350  \tloss 1.17404, train acc 71.88, train corr acc 44.33, val acc 73.66, val corr acc 47.86\n",
      "Ep 3 \titer 351  \tloss 1.15997, train acc 75.52, train corr acc 53.92, val acc 73.92, val corr acc 48.36\n",
      "Ep 3 \titer 352  \tloss 1.38052, train acc 69.79, train corr acc 46.30, val acc 73.66, val corr acc 47.86\n",
      "Ep 3 \titer 353  \tloss 1.20874, train acc 72.92, train corr acc 49.51, val acc 73.35, val corr acc 47.23\n",
      "Ep 3 \titer 354  \tloss 1.20632, train acc 73.44, train corr acc 45.74, val acc 73.92, val corr acc 48.36\n",
      "Ep 3 \titer 355  \tloss 1.19242, train acc 72.40, train corr acc 41.11, val acc 73.66, val corr acc 47.86\n",
      "Ep 3 \titer 356  \tloss 1.24584, train acc 72.92, train corr acc 45.83, val acc 73.54, val corr acc 47.61\n",
      "Ep 3 \titer 357  \tloss 1.37036, train acc 69.79, train corr acc 47.27, val acc 73.47, val corr acc 47.48\n",
      "Ep 3 \titer 358  \tloss 1.12132, train acc 74.48, train corr acc 47.87, val acc 73.35, val corr acc 47.23\n",
      "Ep 3 \titer 359  \tloss 1.21902, train acc 70.31, train corr acc 44.66, val acc 73.35, val corr acc 47.23\n",
      "Ep 3 \titer 360  \tloss 1.26819, train acc 70.31, train corr acc 45.19, val acc 74.05, val corr acc 48.61\n",
      "Ep 3 \titer 361  \tloss 1.16309, train acc 72.40, train corr acc 44.79, val acc 74.55, val corr acc 49.62\n",
      "Ep 3 \titer 362  \tloss 1.07993, train acc 76.04, train corr acc 52.08, val acc 73.66, val corr acc 47.86\n",
      "Ep 3 \titer 363  \tloss 0.99841, train acc 75.52, train corr acc 45.35, val acc 73.66, val corr acc 47.86\n",
      "Ep 3 \titer 364  \tloss 1.33128, train acc 70.83, train corr acc 46.15, val acc 74.49, val corr acc 49.50\n",
      "Ep 3 \titer 365  \tloss 0.99579, train acc 75.52, train corr acc 44.71, val acc 73.47, val corr acc 47.48\n",
      "Ep 3 \titer 366  \tloss 1.16521, train acc 72.92, train corr acc 48.51, val acc 73.60, val corr acc 47.73\n",
      "Ep 3 \titer 367  \tloss 1.16906, train acc 75.52, train corr acc 51.55, val acc 73.28, val corr acc 47.10\n",
      "Ep 3 \titer 368  \tloss 1.12626, train acc 75.52, train corr acc 52.04, val acc 74.24, val corr acc 48.99\n",
      "Ep 3 \titer 369  \tloss 1.22311, train acc 72.40, train corr acc 48.54, val acc 72.96, val corr acc 46.47\n",
      "Ep 3 \titer 370  \tloss 1.16119, train acc 69.79, train corr acc 41.41, val acc 73.98, val corr acc 48.49\n",
      "Ep 3 \titer 371  \tloss 1.19543, train acc 71.88, train corr acc 45.45, val acc 73.79, val corr acc 48.11\n",
      "Ep 3 \titer 372  \tloss 1.33170, train acc 71.35, train corr acc 46.08, val acc 73.92, val corr acc 48.36\n",
      "Ep 3 \titer 373  \tloss 1.17524, train acc 72.40, train corr acc 44.79, val acc 74.36, val corr acc 49.24\n",
      "Ep 3 \titer 374  \tloss 1.11435, train acc 75.52, train corr acc 49.46, val acc 73.73, val corr acc 47.98\n",
      "Ep 3 \titer 375  \tloss 0.99772, train acc 77.08, train corr acc 52.17, val acc 74.24, val corr acc 48.99\n",
      "Ep 3 \titer 376  \tloss 1.06842, train acc 72.40, train corr acc 45.92, val acc 74.62, val corr acc 49.75\n",
      "Ep 3 \titer 377  \tloss 1.22219, train acc 72.92, train corr acc 51.40, val acc 74.05, val corr acc 48.61\n",
      "Ep 3 \titer 378  \tloss 1.21623, train acc 70.31, train corr acc 44.66, val acc 74.30, val corr acc 49.12\n",
      "Ep 3 \titer 379  \tloss 1.18634, train acc 73.44, train corr acc 50.49, val acc 73.85, val corr acc 48.24\n",
      "Ep 3 \titer 380  \tloss 1.36939, train acc 69.79, train corr acc 43.14, val acc 74.11, val corr acc 48.74\n",
      "Ep 3 \titer 381  \tloss 1.02867, train acc 77.60, train corr acc 51.69, val acc 73.73, val corr acc 47.98\n",
      "Ep 3 \titer 382  \tloss 1.16843, train acc 72.92, train corr acc 48.00, val acc 73.35, val corr acc 47.23\n",
      "Ep 3 \titer 383  \tloss 1.27832, train acc 68.75, train corr acc 41.18, val acc 73.09, val corr acc 46.73\n",
      "Ep 3 \titer 384  \tloss 1.30981, train acc 69.79, train corr acc 45.28, val acc 73.41, val corr acc 47.36\n",
      "Ep 3 \titer 385  \tloss 1.09162, train acc 70.83, train corr acc 42.27, val acc 73.85, val corr acc 48.24\n",
      "Ep 3 \titer 386  \tloss 1.20311, train acc 73.44, train corr acc 49.50, val acc 74.17, val corr acc 48.87\n",
      "Ep 3 \titer 387  \tloss 1.15604, train acc 71.88, train corr acc 47.57, val acc 73.35, val corr acc 47.23\n",
      "Ep 3 \titer 388  \tloss 1.22716, train acc 70.31, train corr acc 44.66, val acc 73.35, val corr acc 47.23\n",
      "Ep 3 \titer 389  \tloss 1.05638, train acc 74.48, train corr acc 48.96, val acc 73.79, val corr acc 48.11\n",
      "Ep 3 \titer 390  \tloss 1.15518, train acc 73.96, train corr acc 51.92, val acc 73.41, val corr acc 47.36\n",
      "Ep 3 \titer 391  \tloss 1.17975, train acc 71.88, train corr acc 44.33, val acc 74.30, val corr acc 49.12\n",
      "Ep 3 \titer 392  \tloss 1.06306, train acc 73.44, train corr acc 48.48, val acc 74.11, val corr acc 48.74\n",
      "Ep 3 \titer 393  \tloss 1.28654, train acc 73.96, train corr acc 51.92, val acc 73.98, val corr acc 48.49\n",
      "Ep 3 \titer 394  \tloss 1.10821, train acc 73.96, train corr acc 54.55, val acc 73.54, val corr acc 47.61\n",
      "Ep 3 \titer 395  \tloss 1.33540, train acc 68.75, train corr acc 38.14, val acc 73.98, val corr acc 48.49\n",
      "Ep 3 \titer 396  \tloss 1.09427, train acc 73.44, train corr acc 44.57, val acc 75.00, val corr acc 50.50\n",
      "Ep 3 \titer 397  \tloss 1.15617, train acc 72.92, train corr acc 47.47, val acc 74.05, val corr acc 48.61\n",
      "Ep 3 \titer 398  \tloss 1.02891, train acc 75.52, train corr acc 50.00, val acc 74.11, val corr acc 48.74\n",
      "Ep 3 \titer 399  \tloss 1.27626, train acc 72.92, train corr acc 45.26, val acc 74.49, val corr acc 49.50\n",
      "Ep 3 \titer 400  \tloss 1.05839, train acc 72.40, train corr acc 46.46, val acc 74.17, val corr acc 48.87\n",
      "Ep 3 \titer 401  \tloss 1.03480, train acc 76.04, train corr acc 49.45, val acc 74.17, val corr acc 48.87\n",
      "Ep 3 \titer 402  \tloss 1.08804, train acc 74.48, train corr acc 43.68, val acc 73.92, val corr acc 48.36\n",
      "Ep 3 \titer 403  \tloss 0.98414, train acc 78.65, train corr acc 53.93, val acc 73.85, val corr acc 48.24\n",
      "Ep 3 \titer 404  \tloss 1.12403, train acc 75.00, train corr acc 52.48, val acc 73.54, val corr acc 47.61\n",
      "Ep 3 \titer 405  \tloss 1.14509, train acc 72.92, train corr acc 50.00, val acc 73.98, val corr acc 48.49\n",
      "Ep 3 \titer 406  \tloss 1.11943, train acc 73.96, train corr acc 50.98, val acc 74.24, val corr acc 48.99\n",
      "Ep 3 \titer 407  \tloss 1.12026, train acc 71.88, train corr acc 45.45, val acc 73.73, val corr acc 47.98\n",
      "Ep 3 \titer 408  \tloss 1.07723, train acc 77.08, train corr acc 53.19, val acc 74.55, val corr acc 49.62\n",
      "Ep 3 \titer 409  \tloss 1.05437, train acc 75.00, train corr acc 50.00, val acc 75.06, val corr acc 50.63\n",
      "Ep 3 \titer 410  \tloss 1.20693, train acc 72.92, train corr acc 46.39, val acc 74.94, val corr acc 50.38\n",
      "Ep 3 \titer 411  \tloss 1.13368, train acc 73.96, train corr acc 46.81, val acc 74.30, val corr acc 49.12\n",
      "Ep 3 \titer 412  \tloss 1.14383, train acc 72.92, train corr acc 51.40, val acc 74.17, val corr acc 48.87\n",
      "Ep 3 \titer 413  \tloss 1.03131, train acc 75.52, train corr acc 50.00, val acc 73.66, val corr acc 47.86\n",
      "Ep 3 \titer 414  \tloss 1.23542, train acc 69.27, train corr acc 42.72, val acc 73.92, val corr acc 48.36\n",
      "Ep 3 \titer 415  \tloss 1.15955, train acc 72.40, train corr acc 45.92, val acc 74.62, val corr acc 49.75\n",
      "Ep 3 \titer 416  \tloss 1.08811, train acc 73.44, train corr acc 44.57, val acc 74.68, val corr acc 49.87\n",
      "Ep 3 \titer 417  \tloss 1.25172, train acc 70.83, train corr acc 45.63, val acc 74.55, val corr acc 49.62\n",
      "Ep 3 \titer 418  \tloss 1.17554, train acc 72.92, train corr acc 49.02, val acc 73.41, val corr acc 47.36\n",
      "Ep 3 \titer 419  \tloss 1.08476, train acc 73.96, train corr acc 53.27, val acc 73.98, val corr acc 48.49\n",
      "Ep 3 \titer 420  \tloss 1.16112, train acc 75.52, train corr acc 52.53, val acc 74.36, val corr acc 49.24\n",
      "Ep 3 \titer 421  \tloss 1.14132, train acc 72.92, train corr acc 45.26, val acc 74.94, val corr acc 50.38\n",
      "Ep 3 \titer 422  \tloss 1.05614, train acc 78.12, train corr acc 55.32, val acc 74.75, val corr acc 50.00\n",
      "Ep 3 \titer 423  \tloss 1.20862, train acc 70.31, train corr acc 50.43, val acc 74.49, val corr acc 49.50\n",
      "Ep 3 \titer 424  \tloss 1.15755, train acc 70.83, train corr acc 43.43, val acc 74.68, val corr acc 49.87\n",
      "Ep 3 \titer 425  \tloss 1.10522, train acc 72.92, train corr acc 49.51, val acc 74.17, val corr acc 48.87\n",
      "Ep 3 \titer 426  \tloss 1.18883, train acc 70.31, train corr acc 41.84, val acc 74.55, val corr acc 49.62\n",
      "Ep 3 \titer 427  \tloss 1.07736, train acc 76.04, train corr acc 52.58, val acc 74.94, val corr acc 50.38\n",
      "Ep 3 \titer 428  \tloss 1.18098, train acc 71.88, train corr acc 46.00, val acc 75.45, val corr acc 51.39\n",
      "Ep 3 \titer 429  \tloss 1.24133, train acc 74.48, train corr acc 52.43, val acc 74.62, val corr acc 49.75\n",
      "Ep 3 \titer 430  \tloss 1.10988, train acc 73.44, train corr acc 45.74, val acc 73.73, val corr acc 47.98\n",
      "Ep 3 \titer 431  \tloss 1.19944, train acc 72.40, train corr acc 47.52, val acc 73.60, val corr acc 47.73\n",
      "Ep 3 \titer 432  \tloss 1.08996, train acc 71.35, train corr acc 48.11, val acc 73.98, val corr acc 48.49\n",
      "Ep 3 \titer 433  \tloss 1.08031, train acc 73.44, train corr acc 47.42, val acc 74.05, val corr acc 48.61\n",
      "Ep 3 \titer 434  \tloss 1.19867, train acc 73.44, train corr acc 48.48, val acc 74.36, val corr acc 49.24\n",
      "Ep 3 \titer 435  \tloss 1.21262, train acc 72.92, train corr acc 51.40, val acc 74.81, val corr acc 50.13\n",
      "Ep 3 \titer 436  \tloss 1.02601, train acc 73.96, train corr acc 48.45, val acc 75.51, val corr acc 51.51\n",
      "Ep 3 \titer 437  \tloss 1.08708, train acc 76.04, train corr acc 51.06, val acc 75.13, val corr acc 50.76\n",
      "Ep 3 \titer 438  \tloss 1.19998, train acc 69.79, train corr acc 43.69, val acc 74.55, val corr acc 49.62\n",
      "Ep 3 \titer 439  \tloss 1.05037, train acc 77.08, train corr acc 51.11, val acc 74.30, val corr acc 49.12\n",
      "Ep 3 \titer 440  \tloss 1.05070, train acc 73.44, train corr acc 46.88, val acc 74.36, val corr acc 49.24\n",
      "Ep 3 \titer 441  \tloss 1.14593, train acc 73.96, train corr acc 50.00, val acc 74.55, val corr acc 49.62\n",
      "Ep 3 \titer 442  \tloss 1.12790, train acc 74.48, train corr acc 49.48, val acc 74.68, val corr acc 49.87\n",
      "Ep 3 \titer 443  \tloss 1.04542, train acc 73.44, train corr acc 47.96, val acc 74.55, val corr acc 49.62\n",
      "Ep 3 \titer 444  \tloss 1.28954, train acc 68.23, train corr acc 44.04, val acc 74.17, val corr acc 48.87\n",
      "Ep 3 \titer 445  \tloss 0.96472, train acc 77.60, train corr acc 50.57, val acc 75.06, val corr acc 50.63\n",
      "Ep 3 \titer 446  \tloss 1.09084, train acc 76.56, train corr acc 49.44, val acc 74.62, val corr acc 49.75\n",
      "Ep 3 \titer 447  \tloss 1.07352, train acc 76.56, train corr acc 54.08, val acc 74.62, val corr acc 49.75\n",
      "Ep 3 \titer 448  \tloss 1.13322, train acc 73.96, train corr acc 50.50, val acc 75.13, val corr acc 50.76\n",
      "Ep 3 \titer 449  \tloss 1.02635, train acc 78.65, train corr acc 52.33, val acc 74.75, val corr acc 50.00\n",
      "Ep 3 \titer 450  \tloss 1.07684, train acc 75.52, train corr acc 51.55, val acc 74.87, val corr acc 50.25\n",
      "Ep 3 \titer 451  \tloss 0.88049, train acc 79.69, train corr acc 58.95, val acc 74.62, val corr acc 49.75\n",
      "Ep 3 \titer 452  \tloss 1.16224, train acc 75.00, train corr acc 46.67, val acc 74.68, val corr acc 50.00\n",
      "Ep 3 \titer 453  \tloss 1.01226, train acc 74.48, train corr acc 48.96, val acc 75.06, val corr acc 50.63\n",
      "Ep 3 \titer 454  \tloss 1.11322, train acc 72.92, train corr acc 46.94, val acc 74.87, val corr acc 50.25\n",
      "Ep 3 \titer 455  \tloss 1.19733, train acc 67.71, train corr acc 42.06, val acc 74.75, val corr acc 50.00\n",
      "Ep 3 \titer 456  \tloss 1.09396, train acc 75.52, train corr acc 50.00, val acc 74.68, val corr acc 49.87\n",
      "\n",
      "Epoch 4 of 10 took 96.779s\n",
      "  training loss:\t\t1.150703\n",
      "  training raw accuracy:\t\t73.21 %\n",
      "  training corrected acc:\t\t47.84 %\n",
      "  validation loss:\t\t1.122374\n",
      "  validation raw accuracy:\t\t74.68 %\n",
      "  validation corrected acc:\t\t49.87 % \n",
      "\n",
      "Ep 4 \titer 457  \tloss 1.20324, train acc 70.83, train corr acc 48.15, val acc 75.19, val corr acc 50.88\n",
      "Ep 4 \titer 458  \tloss 1.02561, train acc 76.04, train corr acc 50.00, val acc 74.36, val corr acc 49.24\n",
      "Ep 4 \titer 459  \tloss 1.07038, train acc 73.96, train corr acc 48.98, val acc 74.68, val corr acc 49.87\n",
      "Ep 4 \titer 460  \tloss 1.13107, train acc 72.40, train corr acc 45.92, val acc 74.49, val corr acc 49.50\n",
      "Ep 4 \titer 461  \tloss 1.14139, train acc 73.44, train corr acc 49.00, val acc 74.87, val corr acc 50.25\n",
      "Ep 4 \titer 462  \tloss 1.17965, train acc 72.40, train corr acc 51.38, val acc 75.06, val corr acc 50.63\n",
      "Ep 4 \titer 463  \tloss 1.23503, train acc 71.88, train corr acc 45.45, val acc 74.30, val corr acc 49.12\n",
      "Ep 4 \titer 464  \tloss 1.12452, train acc 75.52, train corr acc 51.55, val acc 74.24, val corr acc 48.99\n",
      "Ep 4 \titer 465  \tloss 1.01878, train acc 74.48, train corr acc 51.96, val acc 74.43, val corr acc 49.37\n",
      "Ep 4 \titer 466  \tloss 1.25774, train acc 70.31, train corr acc 47.22, val acc 73.92, val corr acc 48.36\n",
      "Ep 4 \titer 467  \tloss 1.09325, train acc 70.31, train corr acc 44.66, val acc 73.85, val corr acc 48.24\n",
      "Ep 4 \titer 468  \tloss 1.09350, train acc 75.00, train corr acc 48.94, val acc 74.87, val corr acc 50.25\n",
      "Ep 4 \titer 469  \tloss 1.11805, train acc 72.92, train corr acc 42.22, val acc 74.87, val corr acc 50.25\n",
      "Ep 4 \titer 470  \tloss 1.08089, train acc 73.44, train corr acc 46.88, val acc 73.73, val corr acc 47.98\n",
      "Ep 4 \titer 471  \tloss 1.17200, train acc 72.40, train corr acc 51.82, val acc 73.60, val corr acc 47.73\n",
      "Ep 4 \titer 472  \tloss 1.03575, train acc 75.00, train corr acc 48.94, val acc 73.73, val corr acc 47.98\n",
      "Ep 4 \titer 473  \tloss 1.13489, train acc 69.27, train corr acc 42.72, val acc 74.36, val corr acc 49.24\n",
      "Ep 4 \titer 474  \tloss 1.20865, train acc 70.83, train corr acc 46.15, val acc 74.62, val corr acc 49.75\n",
      "Ep 4 \titer 475  \tloss 1.06783, train acc 72.92, train corr acc 45.83, val acc 74.55, val corr acc 49.62\n",
      "Ep 4 \titer 476  \tloss 1.00664, train acc 77.08, train corr acc 54.17, val acc 74.62, val corr acc 49.75\n",
      "Ep 4 \titer 477  \tloss 0.94329, train acc 78.12, train corr acc 51.16, val acc 75.00, val corr acc 50.50\n",
      "Ep 4 \titer 478  \tloss 1.21940, train acc 70.83, train corr acc 46.15, val acc 74.81, val corr acc 50.13\n",
      "Ep 4 \titer 479  \tloss 0.96395, train acc 75.52, train corr acc 44.71, val acc 74.49, val corr acc 49.50\n",
      "Ep 4 \titer 480  \tloss 1.07650, train acc 75.52, train corr acc 53.47, val acc 73.47, val corr acc 47.48\n",
      "Ep 4 \titer 481  \tloss 1.05967, train acc 75.00, train corr acc 50.52, val acc 73.22, val corr acc 46.98\n",
      "Ep 4 \titer 482  \tloss 1.09420, train acc 75.52, train corr acc 52.04, val acc 74.30, val corr acc 49.12\n",
      "Ep 4 \titer 483  \tloss 1.17803, train acc 72.92, train corr acc 49.51, val acc 74.11, val corr acc 48.74\n",
      "Ep 4 \titer 484  \tloss 1.08842, train acc 72.92, train corr acc 47.47, val acc 74.17, val corr acc 48.87\n",
      "Ep 4 \titer 485  \tloss 1.13911, train acc 72.40, train corr acc 46.46, val acc 73.92, val corr acc 48.36\n",
      "Ep 4 \titer 486  \tloss 1.24963, train acc 73.96, train corr acc 50.98, val acc 73.79, val corr acc 48.11\n",
      "Ep 4 \titer 487  \tloss 1.09812, train acc 73.96, train corr acc 47.92, val acc 73.85, val corr acc 48.24\n",
      "Ep 4 \titer 488  \tloss 1.04676, train acc 77.60, train corr acc 53.76, val acc 73.85, val corr acc 48.24\n",
      "Ep 4 \titer 489  \tloss 0.92601, train acc 78.12, train corr acc 54.35, val acc 74.49, val corr acc 49.50\n",
      "Ep 4 \titer 490  \tloss 1.03433, train acc 74.48, train corr acc 50.00, val acc 74.75, val corr acc 50.00\n",
      "Ep 4 \titer 491  \tloss 1.14530, train acc 73.96, train corr acc 53.27, val acc 74.49, val corr acc 49.50\n",
      "Ep 4 \titer 492  \tloss 1.15118, train acc 70.31, train corr acc 44.66, val acc 73.98, val corr acc 48.49\n",
      "Ep 4 \titer 493  \tloss 1.15601, train acc 76.04, train corr acc 55.34, val acc 74.24, val corr acc 48.99\n",
      "Ep 4 \titer 494  \tloss 1.30658, train acc 71.88, train corr acc 47.06, val acc 74.24, val corr acc 48.99\n",
      "Ep 4 \titer 495  \tloss 1.01557, train acc 79.17, train corr acc 55.06, val acc 74.05, val corr acc 48.61\n",
      "Ep 4 \titer 496  \tloss 1.13950, train acc 71.88, train corr acc 46.00, val acc 74.43, val corr acc 49.37\n",
      "Ep 4 \titer 497  \tloss 1.18862, train acc 71.88, train corr acc 47.06, val acc 74.62, val corr acc 49.75\n",
      "Ep 4 \titer 498  \tloss 1.31027, train acc 70.83, train corr acc 47.17, val acc 74.81, val corr acc 50.13\n",
      "Ep 4 \titer 499  \tloss 1.12211, train acc 75.52, train corr acc 51.55, val acc 74.87, val corr acc 50.25\n",
      "Ep 4 \titer 500  \tloss 1.14064, train acc 75.52, train corr acc 53.47, val acc 73.73, val corr acc 47.98\n",
      "Ep 4 \titer 501  \tloss 1.15383, train acc 72.40, train corr acc 48.54, val acc 74.24, val corr acc 48.99\n",
      "Ep 4 \titer 502  \tloss 1.12880, train acc 72.92, train corr acc 49.51, val acc 74.24, val corr acc 48.99\n",
      "Ep 4 \titer 503  \tloss 1.01303, train acc 74.48, train corr acc 48.96, val acc 73.73, val corr acc 47.98\n",
      "Ep 4 \titer 504  \tloss 1.20016, train acc 71.35, train corr acc 47.12, val acc 73.79, val corr acc 48.11\n",
      "Ep 4 \titer 505  \tloss 1.13424, train acc 71.35, train corr acc 43.30, val acc 74.49, val corr acc 49.50\n",
      "Ep 4 \titer 506  \tloss 1.04976, train acc 75.52, train corr acc 52.53, val acc 74.17, val corr acc 48.87\n",
      "Ep 4 \titer 507  \tloss 1.19631, train acc 70.83, train corr acc 46.15, val acc 75.00, val corr acc 50.50\n",
      "Ep 4 \titer 508  \tloss 1.09714, train acc 73.44, train corr acc 53.64, val acc 74.68, val corr acc 49.87\n",
      "Ep 4 \titer 509  \tloss 1.25053, train acc 71.35, train corr acc 43.30, val acc 74.62, val corr acc 49.75\n",
      "Ep 4 \titer 510  \tloss 0.97789, train acc 77.60, train corr acc 53.26, val acc 74.11, val corr acc 48.74\n",
      "Ep 4 \titer 511  \tloss 1.10375, train acc 74.48, train corr acc 50.51, val acc 74.81, val corr acc 50.13\n",
      "Ep 4 \titer 512  \tloss 1.02685, train acc 75.00, train corr acc 48.94, val acc 74.49, val corr acc 49.50\n",
      "Ep 4 \titer 513  \tloss 1.17132, train acc 71.35, train corr acc 42.11, val acc 74.17, val corr acc 48.87\n",
      "Ep 4 \titer 514  \tloss 1.05293, train acc 72.40, train corr acc 46.46, val acc 74.36, val corr acc 49.24\n",
      "Ep 4 \titer 515  \tloss 0.97797, train acc 77.60, train corr acc 52.75, val acc 74.94, val corr acc 50.38\n",
      "Ep 4 \titer 516  \tloss 1.01022, train acc 76.56, train corr acc 48.28, val acc 75.00, val corr acc 50.50\n",
      "Ep 4 \titer 517  \tloss 0.95684, train acc 78.65, train corr acc 53.93, val acc 74.75, val corr acc 50.00\n",
      "Ep 4 \titer 518  \tloss 1.05891, train acc 76.04, train corr acc 54.46, val acc 75.00, val corr acc 50.50\n",
      "Ep 4 \titer 519  \tloss 1.08514, train acc 71.88, train corr acc 48.08, val acc 73.66, val corr acc 47.86\n",
      "Ep 4 \titer 520  \tloss 1.01618, train acc 78.12, train corr acc 58.82, val acc 73.60, val corr acc 47.73\n",
      "Ep 4 \titer 521  \tloss 1.04077, train acc 72.40, train corr acc 46.46, val acc 73.41, val corr acc 47.36\n",
      "Ep 4 \titer 522  \tloss 1.04291, train acc 73.96, train corr acc 46.81, val acc 73.28, val corr acc 47.10\n",
      "Ep 4 \titer 523  \tloss 1.01636, train acc 78.12, train corr acc 56.25, val acc 74.75, val corr acc 50.00\n",
      "Ep 4 \titer 524  \tloss 1.11766, train acc 75.52, train corr acc 51.55, val acc 74.81, val corr acc 50.13\n",
      "Ep 4 \titer 525  \tloss 1.09065, train acc 73.44, train corr acc 45.74, val acc 75.25, val corr acc 51.01\n",
      "Ep 4 \titer 526  \tloss 1.09986, train acc 74.48, train corr acc 54.21, val acc 75.38, val corr acc 51.26\n",
      "Ep 4 \titer 527  \tloss 0.99375, train acc 76.56, train corr acc 52.13, val acc 74.94, val corr acc 50.38\n",
      "Ep 4 \titer 528  \tloss 1.11289, train acc 70.83, train corr acc 45.63, val acc 74.36, val corr acc 49.24\n",
      "Ep 4 \titer 529  \tloss 1.11406, train acc 71.88, train corr acc 44.90, val acc 74.55, val corr acc 49.62\n",
      "Ep 4 \titer 530  \tloss 1.03571, train acc 74.48, train corr acc 46.74, val acc 74.81, val corr acc 50.13\n",
      "Ep 4 \titer 531  \tloss 1.11272, train acc 72.92, train corr acc 49.51, val acc 74.81, val corr acc 50.13\n",
      "Ep 4 \titer 532  \tloss 1.12638, train acc 72.40, train corr acc 48.04, val acc 74.11, val corr acc 48.74\n",
      "Ep 4 \titer 533  \tloss 1.04023, train acc 74.48, train corr acc 54.21, val acc 74.62, val corr acc 49.75\n",
      "Ep 4 \titer 534  \tloss 1.10008, train acc 74.48, train corr acc 50.51, val acc 74.43, val corr acc 49.37\n",
      "Ep 4 \titer 535  \tloss 1.09454, train acc 75.52, train corr acc 50.53, val acc 74.11, val corr acc 48.74\n",
      "Ep 4 \titer 536  \tloss 0.97151, train acc 76.04, train corr acc 51.06, val acc 74.68, val corr acc 49.87\n",
      "Ep 4 \titer 537  \tloss 1.07121, train acc 72.40, train corr acc 53.91, val acc 74.55, val corr acc 49.62\n",
      "Ep 4 \titer 538  \tloss 1.09888, train acc 70.83, train corr acc 43.43, val acc 74.55, val corr acc 49.62\n",
      "Ep 4 \titer 539  \tloss 1.03024, train acc 74.48, train corr acc 52.43, val acc 74.81, val corr acc 50.13\n",
      "Ep 4 \titer 540  \tloss 1.17454, train acc 71.35, train corr acc 43.88, val acc 74.68, val corr acc 49.87\n",
      "Ep 4 \titer 541  \tloss 1.00144, train acc 75.00, train corr acc 50.52, val acc 74.30, val corr acc 49.12\n",
      "Ep 4 \titer 542  \tloss 1.17650, train acc 71.35, train corr acc 45.00, val acc 74.49, val corr acc 49.50\n",
      "Ep 4 \titer 543  \tloss 1.15740, train acc 73.44, train corr acc 50.49, val acc 74.75, val corr acc 50.00\n",
      "Ep 4 \titer 544  \tloss 1.04515, train acc 76.04, train corr acc 51.06, val acc 75.06, val corr acc 50.63\n",
      "Ep 4 \titer 545  \tloss 1.08874, train acc 73.44, train corr acc 49.50, val acc 75.25, val corr acc 51.01\n",
      "Ep 4 \titer 546  \tloss 1.06235, train acc 73.44, train corr acc 51.89, val acc 75.19, val corr acc 50.88\n",
      "Ep 4 \titer 547  \tloss 0.98214, train acc 75.00, train corr acc 50.52, val acc 74.81, val corr acc 50.13\n",
      "Ep 4 \titer 548  \tloss 1.05667, train acc 73.96, train corr acc 49.49, val acc 74.81, val corr acc 50.13\n",
      "Ep 4 \titer 549  \tloss 1.15094, train acc 73.96, train corr acc 53.27, val acc 74.43, val corr acc 49.37\n",
      "Ep 4 \titer 550  \tloss 0.94620, train acc 73.96, train corr acc 48.45, val acc 75.57, val corr acc 51.64\n",
      "Ep 4 \titer 551  \tloss 1.01826, train acc 76.56, train corr acc 52.13, val acc 75.32, val corr acc 51.13\n",
      "Ep 4 \titer 552  \tloss 1.22824, train acc 71.35, train corr acc 46.60, val acc 75.19, val corr acc 50.88\n",
      "Ep 4 \titer 553  \tloss 0.99353, train acc 76.04, train corr acc 48.89, val acc 74.55, val corr acc 49.62\n",
      "Ep 4 \titer 554  \tloss 0.96660, train acc 75.52, train corr acc 51.04, val acc 75.06, val corr acc 50.63\n",
      "Ep 4 \titer 555  \tloss 1.10313, train acc 71.88, train corr acc 46.00, val acc 75.13, val corr acc 50.76\n",
      "Ep 4 \titer 556  \tloss 1.07473, train acc 74.48, train corr acc 49.48, val acc 75.25, val corr acc 51.01\n",
      "Ep 4 \titer 557  \tloss 1.03884, train acc 75.00, train corr acc 51.02, val acc 74.68, val corr acc 49.87\n",
      "Ep 4 \titer 558  \tloss 1.12173, train acc 70.83, train corr acc 48.62, val acc 74.81, val corr acc 50.13\n",
      "Ep 4 \titer 559  \tloss 0.87142, train acc 76.56, train corr acc 48.28, val acc 75.00, val corr acc 50.50\n",
      "Ep 4 \titer 560  \tloss 0.99995, train acc 77.08, train corr acc 50.56, val acc 74.94, val corr acc 50.38\n",
      "Ep 4 \titer 561  \tloss 1.02472, train acc 74.48, train corr acc 50.00, val acc 75.45, val corr acc 51.39\n",
      "Ep 4 \titer 562  \tloss 1.04545, train acc 74.48, train corr acc 51.49, val acc 75.32, val corr acc 51.13\n",
      "Ep 4 \titer 563  \tloss 0.90509, train acc 79.69, train corr acc 54.65, val acc 74.81, val corr acc 50.13\n",
      "Ep 4 \titer 564  \tloss 1.02532, train acc 77.08, train corr acc 54.64, val acc 74.87, val corr acc 50.25\n",
      "Ep 4 \titer 565  \tloss 0.84359, train acc 80.73, train corr acc 61.05, val acc 74.75, val corr acc 50.00\n",
      "Ep 4 \titer 566  \tloss 1.05370, train acc 76.56, train corr acc 50.00, val acc 75.00, val corr acc 50.50\n",
      "Ep 4 \titer 567  \tloss 0.93698, train acc 75.52, train corr acc 51.04, val acc 75.25, val corr acc 51.01\n",
      "Ep 4 \titer 568  \tloss 1.01160, train acc 74.48, train corr acc 50.00, val acc 75.19, val corr acc 50.88\n",
      "Ep 4 \titer 569  \tloss 1.15247, train acc 68.23, train corr acc 42.99, val acc 75.57, val corr acc 51.64\n",
      "Ep 4 \titer 570  \tloss 1.04590, train acc 76.04, train corr acc 51.06, val acc 75.13, val corr acc 50.76\n",
      "\n",
      "Epoch 5 of 10 took 68.762s\n",
      "  training loss:\t\t1.083049\n",
      "  training raw accuracy:\t\t74.09 %\n",
      "  training corrected acc:\t\t49.56 %\n",
      "  validation loss:\t\t1.124348\n",
      "  validation raw accuracy:\t\t75.00 %\n",
      "  validation corrected acc:\t\t50.50 % \n",
      "\n",
      "Ep 5 \titer 571  \tloss 1.17266, train acc 72.92, train corr acc 51.85, val acc 75.00, val corr acc 50.50\n",
      "Ep 5 \titer 572  \tloss 0.98027, train acc 77.60, train corr acc 53.26, val acc 73.85, val corr acc 48.24\n",
      "Ep 5 \titer 573  \tloss 1.02382, train acc 74.48, train corr acc 50.00, val acc 74.87, val corr acc 50.25\n",
      "Ep 5 \titer 574  \tloss 1.10761, train acc 71.88, train corr acc 44.90, val acc 74.55, val corr acc 49.62\n",
      "Ep 5 \titer 575  \tloss 1.13295, train acc 73.44, train corr acc 49.00, val acc 74.68, val corr acc 49.87\n",
      "Ep 5 \titer 576  \tloss 1.17113, train acc 72.40, train corr acc 51.38, val acc 74.11, val corr acc 48.74\n",
      "Ep 5 \titer 577  \tloss 1.15523, train acc 71.88, train corr acc 45.45, val acc 74.05, val corr acc 48.61\n",
      "Ep 5 \titer 578  \tloss 1.11330, train acc 72.92, train corr acc 46.39, val acc 73.98, val corr acc 48.49\n",
      "Ep 5 \titer 579  \tloss 1.02772, train acc 72.92, train corr acc 49.02, val acc 74.49, val corr acc 49.50\n",
      "Ep 5 \titer 580  \tloss 1.23937, train acc 71.35, train corr acc 49.07, val acc 74.43, val corr acc 49.37\n",
      "Ep 5 \titer 581  \tloss 1.05475, train acc 74.48, train corr acc 52.43, val acc 75.00, val corr acc 50.50\n",
      "Ep 5 \titer 582  \tloss 1.03898, train acc 75.52, train corr acc 50.00, val acc 74.81, val corr acc 50.13\n",
      "Ep 5 \titer 583  \tloss 1.01885, train acc 75.00, train corr acc 46.67, val acc 75.00, val corr acc 50.50\n",
      "Ep 5 \titer 584  \tloss 1.06522, train acc 75.00, train corr acc 50.00, val acc 75.32, val corr acc 51.13\n",
      "Ep 5 \titer 585  \tloss 1.17345, train acc 71.88, train corr acc 50.91, val acc 75.38, val corr acc 51.26\n",
      "Ep 5 \titer 586  \tloss 0.94608, train acc 76.56, train corr acc 52.13, val acc 75.76, val corr acc 52.02\n",
      "Ep 5 \titer 587  \tloss 1.04883, train acc 72.92, train corr acc 49.51, val acc 75.25, val corr acc 51.01\n",
      "Ep 5 \titer 588  \tloss 1.08462, train acc 73.44, train corr acc 50.96, val acc 75.06, val corr acc 50.63\n",
      "Ep 5 \titer 589  \tloss 1.03148, train acc 73.44, train corr acc 46.88, val acc 75.19, val corr acc 50.88\n",
      "Ep 5 \titer 590  \tloss 0.94136, train acc 77.60, train corr acc 55.21, val acc 74.43, val corr acc 49.37\n",
      "Ep 5 \titer 591  \tloss 0.90089, train acc 79.17, train corr acc 53.49, val acc 74.68, val corr acc 49.87\n",
      "Ep 5 \titer 592  \tloss 1.13117, train acc 71.35, train corr acc 47.12, val acc 74.62, val corr acc 49.75\n",
      "Ep 5 \titer 593  \tloss 0.90375, train acc 79.69, train corr acc 54.12, val acc 74.81, val corr acc 50.13\n",
      "Ep 5 \titer 594  \tloss 1.02964, train acc 73.96, train corr acc 50.50, val acc 74.62, val corr acc 49.75\n",
      "Ep 5 \titer 595  \tloss 1.03408, train acc 73.44, train corr acc 47.42, val acc 74.55, val corr acc 49.62\n",
      "Ep 5 \titer 596  \tloss 1.07647, train acc 76.04, train corr acc 53.06, val acc 74.43, val corr acc 49.37\n",
      "Ep 5 \titer 597  \tloss 1.11262, train acc 72.92, train corr acc 49.51, val acc 74.17, val corr acc 48.87\n",
      "Ep 5 \titer 598  \tloss 1.06907, train acc 73.44, train corr acc 48.48, val acc 74.36, val corr acc 49.24\n",
      "Ep 5 \titer 599  \tloss 1.11594, train acc 73.96, train corr acc 49.49, val acc 74.05, val corr acc 48.61\n",
      "Ep 5 \titer 600  \tloss 1.19813, train acc 71.88, train corr acc 47.06, val acc 74.81, val corr acc 50.13\n",
      "Ep 5 \titer 601  \tloss 1.03289, train acc 72.92, train corr acc 45.83, val acc 74.87, val corr acc 50.25\n",
      "Ep 5 \titer 602  \tloss 0.95779, train acc 78.12, train corr acc 54.84, val acc 74.87, val corr acc 50.25\n",
      "Ep 5 \titer 603  \tloss 0.89220, train acc 77.60, train corr acc 53.26, val acc 75.13, val corr acc 50.76\n",
      "Ep 5 \titer 604  \tloss 0.99680, train acc 74.48, train corr acc 50.00, val acc 75.51, val corr acc 51.51\n",
      "Ep 5 \titer 605  \tloss 1.01872, train acc 74.48, train corr acc 54.21, val acc 75.13, val corr acc 50.76\n",
      "Ep 5 \titer 606  \tloss 1.07957, train acc 73.44, train corr acc 50.49, val acc 75.64, val corr acc 51.76\n",
      "Ep 5 \titer 607  \tloss 1.07898, train acc 75.52, train corr acc 54.37, val acc 75.45, val corr acc 51.39\n",
      "Ep 5 \titer 608  \tloss 1.16161, train acc 72.92, train corr acc 49.02, val acc 75.38, val corr acc 51.26\n",
      "Ep 5 \titer 609  \tloss 0.90049, train acc 78.12, train corr acc 52.81, val acc 75.51, val corr acc 51.51\n",
      "Ep 5 \titer 610  \tloss 1.07323, train acc 71.35, train corr acc 45.00, val acc 75.64, val corr acc 51.76\n",
      "Ep 5 \titer 611  \tloss 1.01192, train acc 72.92, train corr acc 49.02, val acc 75.45, val corr acc 51.39\n",
      "Ep 5 \titer 612  \tloss 1.15572, train acc 73.44, train corr acc 51.89, val acc 75.19, val corr acc 50.88\n",
      "Ep 5 \titer 613  \tloss 0.99864, train acc 73.44, train corr acc 47.42, val acc 75.89, val corr acc 52.27\n",
      "Ep 5 \titer 614  \tloss 1.06858, train acc 75.00, train corr acc 52.48, val acc 75.32, val corr acc 51.13\n",
      "Ep 5 \titer 615  \tloss 1.02772, train acc 76.56, train corr acc 56.31, val acc 75.45, val corr acc 51.39\n",
      "Ep 5 \titer 616  \tloss 1.01239, train acc 73.96, train corr acc 51.46, val acc 75.51, val corr acc 51.51\n",
      "Ep 5 \titer 617  \tloss 0.90039, train acc 78.12, train corr acc 56.25, val acc 75.00, val corr acc 50.50\n",
      "Ep 5 \titer 618  \tloss 1.03039, train acc 73.96, train corr acc 51.92, val acc 75.45, val corr acc 51.39\n",
      "Ep 5 \titer 619  \tloss 1.10459, train acc 72.92, train corr acc 46.39, val acc 75.32, val corr acc 51.13\n",
      "Ep 5 \titer 620  \tloss 0.97011, train acc 77.08, train corr acc 55.56, val acc 75.70, val corr acc 51.89\n",
      "Ep 5 \titer 621  \tloss 1.12900, train acc 72.40, train corr acc 49.04, val acc 75.19, val corr acc 50.88\n",
      "Ep 5 \titer 622  \tloss 1.01189, train acc 73.44, train corr acc 53.64, val acc 74.81, val corr acc 50.13\n",
      "Ep 5 \titer 623  \tloss 1.14016, train acc 73.44, train corr acc 47.42, val acc 75.70, val corr acc 51.89\n",
      "Ep 5 \titer 624  \tloss 0.91701, train acc 78.12, train corr acc 54.35, val acc 75.51, val corr acc 51.51\n",
      "Ep 5 \titer 625  \tloss 0.98793, train acc 76.56, train corr acc 54.55, val acc 75.38, val corr acc 51.26\n",
      "Ep 5 \titer 626  \tloss 0.92964, train acc 75.00, train corr acc 48.94, val acc 75.83, val corr acc 52.14\n",
      "Ep 5 \titer 627  \tloss 1.08180, train acc 71.88, train corr acc 43.16, val acc 75.45, val corr acc 51.39\n",
      "Ep 5 \titer 628  \tloss 0.98563, train acc 75.52, train corr acc 52.53, val acc 74.87, val corr acc 50.25\n",
      "Ep 5 \titer 629  \tloss 0.84733, train acc 78.12, train corr acc 53.85, val acc 75.19, val corr acc 50.88\n",
      "Ep 5 \titer 630  \tloss 0.91180, train acc 76.56, train corr acc 48.28, val acc 75.06, val corr acc 50.63\n",
      "Ep 5 \titer 631  \tloss 0.83394, train acc 79.69, train corr acc 56.18, val acc 74.17, val corr acc 48.87\n",
      "Ep 5 \titer 632  \tloss 0.96483, train acc 76.56, train corr acc 55.45, val acc 73.98, val corr acc 48.49\n",
      "Ep 5 \titer 633  \tloss 1.04546, train acc 76.04, train corr acc 55.77, val acc 75.13, val corr acc 50.76\n",
      "Ep 5 \titer 634  \tloss 0.90130, train acc 78.65, train corr acc 59.80, val acc 74.36, val corr acc 49.24\n",
      "Ep 5 \titer 635  \tloss 0.95527, train acc 75.52, train corr acc 52.53, val acc 75.32, val corr acc 51.13\n",
      "Ep 5 \titer 636  \tloss 0.88720, train acc 76.56, train corr acc 52.13, val acc 75.32, val corr acc 51.13\n",
      "Ep 5 \titer 637  \tloss 0.94952, train acc 78.12, train corr acc 56.25, val acc 75.57, val corr acc 51.64\n",
      "Ep 5 \titer 638  \tloss 1.05065, train acc 76.04, train corr acc 52.58, val acc 75.83, val corr acc 52.14\n",
      "Ep 5 \titer 639  \tloss 1.02726, train acc 73.96, train corr acc 46.81, val acc 75.51, val corr acc 51.51\n",
      "Ep 5 \titer 640  \tloss 0.93908, train acc 74.48, train corr acc 54.21, val acc 75.83, val corr acc 52.14\n",
      "Ep 5 \titer 641  \tloss 0.94239, train acc 76.04, train corr acc 51.06, val acc 75.76, val corr acc 52.02\n",
      "Ep 5 \titer 642  \tloss 1.05808, train acc 72.92, train corr acc 49.51, val acc 75.45, val corr acc 51.39\n",
      "Ep 5 \titer 643  \tloss 1.00566, train acc 78.12, train corr acc 57.14, val acc 76.08, val corr acc 52.64\n",
      "Ep 5 \titer 644  \tloss 0.94370, train acc 76.56, train corr acc 51.09, val acc 76.21, val corr acc 52.90\n",
      "Ep 5 \titer 645  \tloss 1.06666, train acc 72.40, train corr acc 48.54, val acc 75.51, val corr acc 51.51\n",
      "Ep 5 \titer 646  \tloss 1.05046, train acc 74.48, train corr acc 51.96, val acc 75.25, val corr acc 51.01\n",
      "Ep 5 \titer 647  \tloss 0.97721, train acc 75.52, train corr acc 56.07, val acc 75.89, val corr acc 52.27\n",
      "Ep 5 \titer 648  \tloss 1.02306, train acc 75.52, train corr acc 52.53, val acc 76.08, val corr acc 52.64\n",
      "Ep 5 \titer 649  \tloss 0.95953, train acc 76.56, train corr acc 52.63, val acc 75.25, val corr acc 51.01\n",
      "Ep 5 \titer 650  \tloss 0.89105, train acc 76.56, train corr acc 52.13, val acc 75.57, val corr acc 51.64\n",
      "Ep 5 \titer 651  \tloss 1.09796, train acc 71.35, train corr acc 52.17, val acc 75.51, val corr acc 51.51\n",
      "Ep 5 \titer 652  \tloss 1.04438, train acc 71.88, train corr acc 45.45, val acc 75.51, val corr acc 51.51\n",
      "Ep 5 \titer 653  \tloss 0.96271, train acc 76.56, train corr acc 56.31, val acc 74.81, val corr acc 50.13\n",
      "Ep 5 \titer 654  \tloss 1.09724, train acc 72.40, train corr acc 45.92, val acc 75.70, val corr acc 51.89\n",
      "Ep 5 \titer 655  \tloss 0.92272, train acc 75.52, train corr acc 51.55, val acc 75.32, val corr acc 51.13\n",
      "Ep 5 \titer 656  \tloss 1.06094, train acc 70.31, train corr acc 43.00, val acc 75.19, val corr acc 50.88\n",
      "Ep 5 \titer 657  \tloss 1.05841, train acc 75.00, train corr acc 53.40, val acc 75.51, val corr acc 51.51\n",
      "Ep 5 \titer 658  \tloss 0.95437, train acc 76.56, train corr acc 52.13, val acc 75.13, val corr acc 50.76\n",
      "Ep 5 \titer 659  \tloss 0.97082, train acc 73.44, train corr acc 49.50, val acc 75.45, val corr acc 51.39\n",
      "Ep 5 \titer 660  \tloss 0.98189, train acc 73.96, train corr acc 52.83, val acc 75.51, val corr acc 51.51\n",
      "Ep 5 \titer 661  \tloss 0.91166, train acc 76.56, train corr acc 53.61, val acc 75.76, val corr acc 52.02\n",
      "Ep 5 \titer 662  \tloss 1.05741, train acc 72.40, train corr acc 46.46, val acc 75.76, val corr acc 52.02\n",
      "Ep 5 \titer 663  \tloss 1.03455, train acc 75.00, train corr acc 55.14, val acc 75.70, val corr acc 51.89\n",
      "Ep 5 \titer 664  \tloss 0.96061, train acc 76.56, train corr acc 53.61, val acc 76.21, val corr acc 52.90\n",
      "Ep 5 \titer 665  \tloss 0.93711, train acc 77.08, train corr acc 53.19, val acc 75.64, val corr acc 51.76\n",
      "Ep 5 \titer 666  \tloss 1.09069, train acc 72.40, train corr acc 48.54, val acc 75.57, val corr acc 51.64\n",
      "Ep 5 \titer 667  \tloss 0.88569, train acc 80.21, train corr acc 57.78, val acc 76.21, val corr acc 52.90\n",
      "Ep 5 \titer 668  \tloss 0.86163, train acc 76.56, train corr acc 53.12, val acc 75.70, val corr acc 51.89\n",
      "Ep 5 \titer 669  \tloss 1.06090, train acc 73.44, train corr acc 49.00, val acc 75.13, val corr acc 50.76\n",
      "Ep 5 \titer 670  \tloss 0.97689, train acc 75.52, train corr acc 51.55, val acc 75.57, val corr acc 51.64\n",
      "Ep 5 \titer 671  \tloss 0.94744, train acc 75.52, train corr acc 52.04, val acc 74.68, val corr acc 49.87\n",
      "Ep 5 \titer 672  \tloss 1.14323, train acc 68.75, train corr acc 44.95, val acc 75.70, val corr acc 51.89\n",
      "Ep 5 \titer 673  \tloss 0.87931, train acc 77.60, train corr acc 50.57, val acc 74.94, val corr acc 50.38\n",
      "Ep 5 \titer 674  \tloss 0.94926, train acc 77.60, train corr acc 51.69, val acc 74.81, val corr acc 50.13\n",
      "Ep 5 \titer 675  \tloss 0.91983, train acc 77.08, train corr acc 55.10, val acc 74.62, val corr acc 49.75\n",
      "Ep 5 \titer 676  \tloss 0.94357, train acc 76.56, train corr acc 55.45, val acc 75.25, val corr acc 51.01\n",
      "Ep 5 \titer 677  \tloss 0.81284, train acc 79.69, train corr acc 54.65, val acc 75.51, val corr acc 51.51\n",
      "Ep 5 \titer 678  \tloss 0.94768, train acc 77.60, train corr acc 55.67, val acc 75.06, val corr acc 50.63\n",
      "Ep 5 \titer 679  \tloss 0.76746, train acc 81.77, train corr acc 63.16, val acc 75.38, val corr acc 51.26\n",
      "Ep 5 \titer 680  \tloss 0.92675, train acc 77.60, train corr acc 52.22, val acc 75.13, val corr acc 50.76\n",
      "Ep 5 \titer 681  \tloss 0.87413, train acc 75.00, train corr acc 50.00, val acc 74.62, val corr acc 49.75\n",
      "Ep 5 \titer 682  \tloss 0.91309, train acc 76.04, train corr acc 53.06, val acc 74.75, val corr acc 50.00\n",
      "Ep 5 \titer 683  \tloss 1.09491, train acc 68.75, train corr acc 43.93, val acc 74.81, val corr acc 50.13\n",
      "Ep 5 \titer 684  \tloss 0.92959, train acc 77.60, train corr acc 54.26, val acc 75.13, val corr acc 50.76\n",
      "\n",
      "Epoch 6 of 10 took 69.046s\n",
      "  training loss:\t\t1.008459\n",
      "  training raw accuracy:\t\t75.01 %\n",
      "  training corrected acc:\t\t51.36 %\n",
      "  validation loss:\t\t1.106590\n",
      "  validation raw accuracy:\t\t75.89 %\n",
      "  validation corrected acc:\t\t52.27 % \n",
      "\n",
      "Ep 6 \titer 685  \tloss 1.06722, train acc 73.44, train corr acc 52.78, val acc 75.00, val corr acc 50.50\n",
      "Ep 6 \titer 686  \tloss 0.92618, train acc 76.56, train corr acc 51.09, val acc 75.76, val corr acc 52.02\n",
      "Ep 6 \titer 687  \tloss 1.00038, train acc 74.48, train corr acc 50.00, val acc 75.51, val corr acc 51.51\n",
      "Ep 6 \titer 688  \tloss 1.11434, train acc 71.88, train corr acc 44.90, val acc 75.45, val corr acc 51.39\n",
      "Ep 6 \titer 689  \tloss 1.07474, train acc 72.92, train corr acc 48.00, val acc 74.87, val corr acc 50.25\n",
      "Ep 6 \titer 690  \tloss 1.01321, train acc 73.96, train corr acc 54.13, val acc 75.00, val corr acc 50.50\n",
      "Ep 6 \titer 691  \tloss 1.09818, train acc 75.52, train corr acc 52.53, val acc 75.38, val corr acc 51.26\n",
      "Ep 6 \titer 692  \tloss 1.03688, train acc 75.52, train corr acc 51.55, val acc 74.81, val corr acc 50.13\n",
      "Ep 6 \titer 693  \tloss 0.94786, train acc 75.00, train corr acc 52.94, val acc 74.94, val corr acc 50.38\n",
      "Ep 6 \titer 694  \tloss 1.18238, train acc 71.88, train corr acc 50.00, val acc 75.83, val corr acc 52.14\n",
      "Ep 6 \titer 695  \tloss 0.96393, train acc 75.00, train corr acc 53.40, val acc 75.13, val corr acc 50.76\n",
      "Ep 6 \titer 696  \tloss 0.94050, train acc 76.04, train corr acc 51.06, val acc 75.38, val corr acc 51.26\n",
      "Ep 6 \titer 697  \tloss 0.91111, train acc 79.17, train corr acc 55.56, val acc 75.70, val corr acc 51.89\n",
      "Ep 6 \titer 698  \tloss 1.02754, train acc 76.04, train corr acc 52.08, val acc 75.51, val corr acc 51.51\n",
      "Ep 6 \titer 699  \tloss 1.09102, train acc 74.48, train corr acc 55.45, val acc 75.19, val corr acc 50.88\n",
      "Ep 6 \titer 700  \tloss 0.88365, train acc 78.65, train corr acc 56.38, val acc 75.19, val corr acc 50.88\n",
      "Ep 6 \titer 701  \tloss 0.96822, train acc 75.52, train corr acc 54.37, val acc 75.64, val corr acc 51.76\n",
      "Ep 6 \titer 702  \tloss 0.95089, train acc 74.48, train corr acc 52.88, val acc 75.64, val corr acc 51.76\n",
      "Ep 6 \titer 703  \tloss 1.01706, train acc 73.44, train corr acc 46.88, val acc 75.76, val corr acc 52.02\n",
      "Ep 6 \titer 704  \tloss 0.83803, train acc 78.65, train corr acc 57.29, val acc 75.51, val corr acc 51.51\n",
      "Ep 6 \titer 705  \tloss 0.85182, train acc 78.65, train corr acc 52.33, val acc 75.45, val corr acc 51.39\n",
      "Ep 6 \titer 706  \tloss 1.02742, train acc 72.92, train corr acc 50.00, val acc 75.25, val corr acc 51.01\n",
      "Ep 6 \titer 707  \tloss 0.84072, train acc 78.65, train corr acc 51.76, val acc 75.57, val corr acc 51.64\n",
      "Ep 6 \titer 708  \tloss 0.93412, train acc 76.04, train corr acc 54.46, val acc 75.45, val corr acc 51.39\n",
      "Ep 6 \titer 709  \tloss 0.96026, train acc 77.60, train corr acc 55.67, val acc 75.70, val corr acc 51.89\n",
      "Ep 6 \titer 710  \tloss 0.92342, train acc 77.60, train corr acc 56.12, val acc 75.64, val corr acc 51.76\n",
      "Ep 6 \titer 711  \tloss 1.08744, train acc 71.88, train corr acc 47.57, val acc 75.51, val corr acc 51.51\n",
      "Ep 6 \titer 712  \tloss 0.95770, train acc 75.52, train corr acc 52.53, val acc 75.89, val corr acc 52.27\n",
      "Ep 6 \titer 713  \tloss 1.03687, train acc 74.48, train corr acc 50.51, val acc 76.02, val corr acc 52.52\n",
      "Ep 6 \titer 714  \tloss 1.08013, train acc 73.96, train corr acc 50.98, val acc 75.25, val corr acc 51.01\n",
      "Ep 6 \titer 715  \tloss 1.02308, train acc 74.48, train corr acc 48.96, val acc 75.64, val corr acc 51.76\n",
      "Ep 6 \titer 716  \tloss 0.88104, train acc 78.12, train corr acc 54.84, val acc 74.81, val corr acc 50.13\n",
      "Ep 6 \titer 717  \tloss 0.80510, train acc 79.17, train corr acc 56.52, val acc 75.51, val corr acc 51.51\n",
      "Ep 6 \titer 718  \tloss 0.91869, train acc 76.56, train corr acc 54.08, val acc 75.51, val corr acc 51.51\n",
      "Ep 6 \titer 719  \tloss 0.97029, train acc 76.04, train corr acc 57.01, val acc 75.45, val corr acc 51.39\n",
      "Ep 6 \titer 720  \tloss 1.03468, train acc 73.44, train corr acc 50.49, val acc 75.70, val corr acc 51.89\n",
      "Ep 6 \titer 721  \tloss 1.02329, train acc 78.65, train corr acc 60.19, val acc 75.95, val corr acc 52.39\n",
      "Ep 6 \titer 722  \tloss 1.11874, train acc 73.96, train corr acc 50.98, val acc 75.57, val corr acc 51.64\n",
      "Ep 6 \titer 723  \tloss 0.85506, train acc 79.69, train corr acc 56.18, val acc 75.70, val corr acc 51.89\n",
      "Ep 6 \titer 724  \tloss 1.06673, train acc 72.92, train corr acc 48.00, val acc 76.02, val corr acc 52.52\n",
      "Ep 6 \titer 725  \tloss 0.94590, train acc 77.08, train corr acc 56.86, val acc 75.89, val corr acc 52.27\n",
      "Ep 6 \titer 726  \tloss 1.04627, train acc 74.48, train corr acc 53.77, val acc 75.89, val corr acc 52.27\n",
      "Ep 6 \titer 727  \tloss 0.95975, train acc 76.56, train corr acc 53.61, val acc 76.02, val corr acc 52.52\n",
      "Ep 6 \titer 728  \tloss 0.95588, train acc 76.56, train corr acc 55.45, val acc 75.89, val corr acc 52.27\n",
      "Ep 6 \titer 729  \tloss 0.96198, train acc 78.12, train corr acc 59.22, val acc 76.08, val corr acc 52.64\n",
      "Ep 6 \titer 730  \tloss 0.96578, train acc 76.04, train corr acc 55.34, val acc 76.02, val corr acc 52.52\n",
      "Ep 6 \titer 731  \tloss 0.85898, train acc 78.12, train corr acc 56.25, val acc 76.59, val corr acc 53.65\n",
      "Ep 6 \titer 732  \tloss 1.03158, train acc 73.96, train corr acc 51.92, val acc 75.76, val corr acc 52.02\n",
      "Ep 6 \titer 733  \tloss 1.02820, train acc 76.04, train corr acc 52.58, val acc 76.40, val corr acc 53.27\n",
      "Ep 6 \titer 734  \tloss 0.89259, train acc 78.12, train corr acc 57.58, val acc 76.34, val corr acc 53.15\n",
      "Ep 6 \titer 735  \tloss 1.06683, train acc 76.56, train corr acc 56.73, val acc 76.15, val corr acc 52.77\n",
      "Ep 6 \titer 736  \tloss 1.00806, train acc 73.96, train corr acc 54.55, val acc 75.83, val corr acc 52.14\n",
      "Ep 6 \titer 737  \tloss 1.04837, train acc 72.92, train corr acc 46.39, val acc 75.89, val corr acc 52.27\n",
      "Ep 6 \titer 738  \tloss 0.81291, train acc 80.21, train corr acc 58.70, val acc 75.70, val corr acc 51.89\n",
      "Ep 6 \titer 739  \tloss 0.89772, train acc 79.17, train corr acc 59.60, val acc 75.95, val corr acc 52.39\n",
      "Ep 6 \titer 740  \tloss 0.90655, train acc 76.56, train corr acc 52.13, val acc 75.83, val corr acc 52.14\n",
      "Ep 6 \titer 741  \tloss 0.97961, train acc 75.52, train corr acc 50.53, val acc 75.64, val corr acc 51.76\n",
      "Ep 6 \titer 742  \tloss 0.94284, train acc 73.96, train corr acc 49.49, val acc 75.70, val corr acc 51.89\n",
      "Ep 6 \titer 743  \tloss 0.81354, train acc 79.69, train corr acc 57.14, val acc 75.45, val corr acc 51.39\n",
      "Ep 6 \titer 744  \tloss 0.85628, train acc 77.60, train corr acc 50.57, val acc 75.13, val corr acc 50.76\n",
      "Ep 6 \titer 745  \tloss 0.80761, train acc 80.73, train corr acc 58.43, val acc 75.89, val corr acc 52.27\n",
      "Ep 6 \titer 746  \tloss 0.87179, train acc 79.17, train corr acc 60.40, val acc 74.49, val corr acc 49.50\n",
      "Ep 6 \titer 747  \tloss 0.97127, train acc 75.00, train corr acc 53.85, val acc 74.87, val corr acc 50.25\n",
      "Ep 6 \titer 748  \tloss 0.80179, train acc 81.25, train corr acc 64.71, val acc 75.32, val corr acc 51.13\n",
      "Ep 6 \titer 749  \tloss 0.89574, train acc 76.04, train corr acc 53.54, val acc 75.32, val corr acc 51.13\n",
      "Ep 6 \titer 750  \tloss 0.76259, train acc 78.65, train corr acc 56.38, val acc 75.19, val corr acc 50.88\n",
      "Ep 6 \titer 751  \tloss 0.93336, train acc 78.12, train corr acc 56.25, val acc 75.76, val corr acc 52.02\n",
      "Ep 6 \titer 752  \tloss 0.95243, train acc 77.08, train corr acc 54.64, val acc 75.70, val corr acc 51.89\n",
      "Ep 6 \titer 753  \tloss 1.02075, train acc 73.96, train corr acc 46.81, val acc 75.38, val corr acc 51.26\n",
      "Ep 6 \titer 754  \tloss 0.91897, train acc 72.40, train corr acc 50.47, val acc 75.57, val corr acc 51.64\n",
      "Ep 6 \titer 755  \tloss 0.88644, train acc 78.12, train corr acc 55.32, val acc 75.38, val corr acc 51.26\n",
      "Ep 6 \titer 756  \tloss 1.02755, train acc 72.92, train corr acc 49.51, val acc 75.32, val corr acc 51.13\n",
      "Ep 6 \titer 757  \tloss 0.94769, train acc 78.65, train corr acc 58.16, val acc 75.38, val corr acc 51.26\n",
      "Ep 6 \titer 758  \tloss 0.92943, train acc 76.04, train corr acc 50.00, val acc 75.19, val corr acc 50.88\n",
      "Ep 6 \titer 759  \tloss 1.02012, train acc 73.44, train corr acc 50.49, val acc 75.51, val corr acc 51.51\n",
      "Ep 6 \titer 760  \tloss 1.00724, train acc 73.96, train corr acc 50.98, val acc 74.94, val corr acc 50.38\n",
      "Ep 6 \titer 761  \tloss 0.95258, train acc 76.56, train corr acc 57.94, val acc 75.83, val corr acc 52.14\n",
      "Ep 6 \titer 762  \tloss 0.91346, train acc 76.56, train corr acc 54.55, val acc 76.02, val corr acc 52.52\n",
      "Ep 6 \titer 763  \tloss 0.92093, train acc 76.56, train corr acc 52.63, val acc 75.57, val corr acc 51.64\n",
      "Ep 6 \titer 764  \tloss 0.88539, train acc 78.65, train corr acc 56.38, val acc 74.87, val corr acc 50.25\n",
      "Ep 6 \titer 765  \tloss 0.99727, train acc 75.00, train corr acc 58.26, val acc 74.87, val corr acc 50.25\n",
      "Ep 6 \titer 766  \tloss 0.99002, train acc 74.48, train corr acc 50.51, val acc 75.64, val corr acc 51.76\n",
      "Ep 6 \titer 767  \tloss 0.92478, train acc 77.60, train corr acc 58.25, val acc 75.64, val corr acc 51.76\n",
      "Ep 6 \titer 768  \tloss 1.02536, train acc 73.44, train corr acc 47.96, val acc 76.15, val corr acc 52.77\n",
      "Ep 6 \titer 769  \tloss 0.89975, train acc 77.08, train corr acc 54.64, val acc 75.45, val corr acc 51.39\n",
      "Ep 6 \titer 770  \tloss 1.00746, train acc 71.88, train corr acc 46.00, val acc 75.95, val corr acc 52.39\n",
      "Ep 6 \titer 771  \tloss 0.94336, train acc 73.44, train corr acc 50.49, val acc 75.45, val corr acc 51.39\n",
      "Ep 6 \titer 772  \tloss 0.92023, train acc 76.56, train corr acc 52.13, val acc 75.13, val corr acc 50.76\n",
      "Ep 6 \titer 773  \tloss 0.97566, train acc 74.48, train corr acc 51.49, val acc 75.89, val corr acc 52.27\n",
      "Ep 6 \titer 774  \tloss 0.95763, train acc 75.00, train corr acc 54.72, val acc 76.21, val corr acc 52.90\n",
      "Ep 6 \titer 775  \tloss 0.90894, train acc 76.56, train corr acc 53.61, val acc 75.95, val corr acc 52.39\n",
      "Ep 6 \titer 776  \tloss 1.01954, train acc 73.96, train corr acc 49.49, val acc 75.64, val corr acc 51.76\n",
      "Ep 6 \titer 777  \tloss 1.00976, train acc 75.00, train corr acc 55.14, val acc 75.89, val corr acc 52.27\n",
      "Ep 6 \titer 778  \tloss 0.84161, train acc 77.60, train corr acc 55.67, val acc 76.21, val corr acc 52.90\n",
      "Ep 6 \titer 779  \tloss 0.91121, train acc 75.52, train corr acc 50.00, val acc 76.21, val corr acc 52.90\n",
      "Ep 6 \titer 780  \tloss 1.06746, train acc 71.35, train corr acc 46.60, val acc 76.72, val corr acc 53.90\n",
      "Ep 6 \titer 781  \tloss 0.83812, train acc 80.73, train corr acc 58.89, val acc 75.89, val corr acc 52.27\n",
      "Ep 6 \titer 782  \tloss 0.85140, train acc 77.08, train corr acc 54.17, val acc 75.25, val corr acc 51.01\n",
      "Ep 6 \titer 783  \tloss 1.03557, train acc 72.92, train corr acc 48.00, val acc 75.19, val corr acc 50.88\n",
      "Ep 6 \titer 784  \tloss 1.02274, train acc 73.96, train corr acc 48.45, val acc 75.64, val corr acc 51.76\n",
      "Ep 6 \titer 785  \tloss 0.89422, train acc 76.56, train corr acc 54.08, val acc 75.00, val corr acc 50.50\n",
      "Ep 6 \titer 786  \tloss 1.03713, train acc 71.35, train corr acc 49.54, val acc 74.81, val corr acc 50.13\n",
      "Ep 6 \titer 787  \tloss 0.86245, train acc 77.08, train corr acc 49.43, val acc 74.81, val corr acc 50.13\n",
      "Ep 6 \titer 788  \tloss 0.83160, train acc 78.65, train corr acc 53.93, val acc 75.06, val corr acc 50.63\n",
      "Ep 6 \titer 789  \tloss 0.90762, train acc 78.12, train corr acc 57.14, val acc 75.19, val corr acc 50.88\n",
      "Ep 6 \titer 790  \tloss 0.91297, train acc 78.65, train corr acc 59.41, val acc 75.13, val corr acc 50.76\n",
      "Ep 6 \titer 791  \tloss 0.78166, train acc 80.73, train corr acc 56.98, val acc 74.87, val corr acc 50.25\n",
      "Ep 6 \titer 792  \tloss 0.96619, train acc 76.56, train corr acc 53.61, val acc 74.87, val corr acc 50.25\n",
      "Ep 6 \titer 793  \tloss 0.76526, train acc 79.17, train corr acc 57.89, val acc 76.08, val corr acc 52.64\n",
      "Ep 6 \titer 794  \tloss 0.95946, train acc 77.08, train corr acc 51.11, val acc 75.38, val corr acc 51.26\n",
      "Ep 6 \titer 795  \tloss 0.84929, train acc 77.08, train corr acc 54.17, val acc 75.57, val corr acc 51.64\n",
      "Ep 6 \titer 796  \tloss 0.84834, train acc 78.65, train corr acc 58.16, val acc 75.32, val corr acc 51.13\n",
      "Ep 6 \titer 797  \tloss 1.03331, train acc 69.79, train corr acc 45.79, val acc 75.64, val corr acc 51.76\n",
      "Ep 6 \titer 798  \tloss 0.84527, train acc 78.12, train corr acc 55.32, val acc 75.06, val corr acc 50.63\n",
      "\n",
      "Epoch 7 of 10 took 65.258s\n",
      "  training loss:\t\t0.951748\n",
      "  training raw accuracy:\t\t76.05 %\n",
      "  training corrected acc:\t\t53.36 %\n",
      "  validation loss:\t\t1.144630\n",
      "  validation raw accuracy:\t\t74.87 %\n",
      "  validation corrected acc:\t\t50.25 % \n",
      "\n",
      "Ep 7 \titer 799  \tloss 1.02951, train acc 73.44, train corr acc 52.78, val acc 75.32, val corr acc 51.13\n",
      "Ep 7 \titer 800  \tloss 0.86603, train acc 80.21, train corr acc 58.70, val acc 75.51, val corr acc 51.51\n",
      "Ep 7 \titer 801  \tloss 0.98756, train acc 75.00, train corr acc 51.02, val acc 75.64, val corr acc 51.76\n",
      "Ep 7 \titer 802  \tloss 1.05565, train acc 73.44, train corr acc 47.96, val acc 75.70, val corr acc 51.89\n",
      "Ep 7 \titer 803  \tloss 1.02042, train acc 73.96, train corr acc 50.00, val acc 75.57, val corr acc 51.64\n",
      "Ep 7 \titer 804  \tloss 0.98067, train acc 73.96, train corr acc 54.13, val acc 75.06, val corr acc 50.63\n",
      "Ep 7 \titer 805  \tloss 1.01525, train acc 73.96, train corr acc 49.49, val acc 75.13, val corr acc 50.76\n",
      "Ep 7 \titer 806  \tloss 0.99547, train acc 76.04, train corr acc 52.58, val acc 75.38, val corr acc 51.26\n",
      "Ep 7 \titer 807  \tloss 0.93254, train acc 75.00, train corr acc 52.94, val acc 75.25, val corr acc 51.01\n",
      "Ep 7 \titer 808  \tloss 1.12089, train acc 72.40, train corr acc 50.93, val acc 75.25, val corr acc 51.01\n",
      "Ep 7 \titer 809  \tloss 0.97105, train acc 73.44, train corr acc 50.49, val acc 75.25, val corr acc 51.01\n",
      "Ep 7 \titer 810  \tloss 0.93874, train acc 77.08, train corr acc 53.19, val acc 75.19, val corr acc 50.88\n",
      "Ep 7 \titer 811  \tloss 0.88162, train acc 77.60, train corr acc 52.22, val acc 75.95, val corr acc 52.39\n",
      "Ep 7 \titer 812  \tloss 0.93659, train acc 76.56, train corr acc 53.12, val acc 76.08, val corr acc 52.64\n",
      "Ep 7 \titer 813  \tloss 1.03113, train acc 75.52, train corr acc 57.27, val acc 75.95, val corr acc 52.39\n",
      "Ep 7 \titer 814  \tloss 0.85776, train acc 80.21, train corr acc 59.57, val acc 76.02, val corr acc 52.52\n",
      "Ep 7 \titer 815  \tloss 0.93395, train acc 72.92, train corr acc 49.51, val acc 75.70, val corr acc 51.89\n",
      "Ep 7 \titer 816  \tloss 0.93751, train acc 75.52, train corr acc 54.81, val acc 76.15, val corr acc 52.77\n",
      "Ep 7 \titer 817  \tloss 0.95721, train acc 73.44, train corr acc 46.88, val acc 75.45, val corr acc 51.39\n",
      "Ep 7 \titer 818  \tloss 0.83823, train acc 78.12, train corr acc 56.25, val acc 75.83, val corr acc 52.14\n",
      "Ep 7 \titer 819  \tloss 0.78495, train acc 79.69, train corr acc 54.65, val acc 76.21, val corr acc 52.90\n",
      "Ep 7 \titer 820  \tloss 0.99068, train acc 75.00, train corr acc 53.85, val acc 75.64, val corr acc 51.76\n",
      "Ep 7 \titer 821  \tloss 0.81475, train acc 77.60, train corr acc 49.41, val acc 75.51, val corr acc 51.51\n",
      "Ep 7 \titer 822  \tloss 0.92945, train acc 77.08, train corr acc 56.44, val acc 76.02, val corr acc 52.52\n",
      "Ep 7 \titer 823  \tloss 0.87388, train acc 77.08, train corr acc 54.64, val acc 75.83, val corr acc 52.14\n",
      "Ep 7 \titer 824  \tloss 0.86368, train acc 76.56, train corr acc 54.08, val acc 75.51, val corr acc 51.51\n",
      "Ep 7 \titer 825  \tloss 1.05056, train acc 72.92, train corr acc 49.51, val acc 75.32, val corr acc 51.13\n",
      "Ep 7 \titer 826  \tloss 0.95733, train acc 75.52, train corr acc 52.53, val acc 75.25, val corr acc 51.01\n",
      "Ep 7 \titer 827  \tloss 0.99862, train acc 76.56, train corr acc 54.55, val acc 75.51, val corr acc 51.51\n",
      "Ep 7 \titer 828  \tloss 1.04720, train acc 72.40, train corr acc 48.04, val acc 75.00, val corr acc 50.50\n",
      "Ep 7 \titer 829  \tloss 0.96607, train acc 74.48, train corr acc 48.96, val acc 75.51, val corr acc 51.51\n",
      "Ep 7 \titer 830  \tloss 0.83381, train acc 80.73, train corr acc 60.22, val acc 75.32, val corr acc 51.13\n",
      "Ep 7 \titer 831  \tloss 0.77313, train acc 79.69, train corr acc 57.61, val acc 75.45, val corr acc 51.39\n",
      "Ep 7 \titer 832  \tloss 0.79316, train acc 78.65, train corr acc 58.16, val acc 75.51, val corr acc 51.51\n",
      "Ep 7 \titer 833  \tloss 0.93414, train acc 75.52, train corr acc 56.07, val acc 75.38, val corr acc 51.26\n",
      "Ep 7 \titer 834  \tloss 0.97962, train acc 73.44, train corr acc 50.49, val acc 74.62, val corr acc 49.75\n",
      "Ep 7 \titer 835  \tloss 0.98494, train acc 79.17, train corr acc 61.17, val acc 75.57, val corr acc 51.64\n",
      "Ep 7 \titer 836  \tloss 1.05916, train acc 74.48, train corr acc 51.96, val acc 75.70, val corr acc 51.89\n",
      "Ep 7 \titer 837  \tloss 0.81775, train acc 80.73, train corr acc 58.43, val acc 75.06, val corr acc 50.63\n",
      "Ep 7 \titer 838  \tloss 1.01758, train acc 75.00, train corr acc 52.00, val acc 75.45, val corr acc 51.39\n",
      "Ep 7 \titer 839  \tloss 0.94198, train acc 73.96, train corr acc 50.98, val acc 75.25, val corr acc 51.01\n",
      "Ep 7 \titer 840  \tloss 1.04485, train acc 72.40, train corr acc 50.00, val acc 75.76, val corr acc 52.02\n",
      "Ep 7 \titer 841  \tloss 0.92583, train acc 77.60, train corr acc 55.67, val acc 75.95, val corr acc 52.39\n",
      "Ep 7 \titer 842  \tloss 0.91491, train acc 77.60, train corr acc 57.43, val acc 75.57, val corr acc 51.64\n",
      "Ep 7 \titer 843  \tloss 0.95370, train acc 76.56, train corr acc 56.31, val acc 75.76, val corr acc 52.02\n",
      "Ep 7 \titer 844  \tloss 0.97060, train acc 75.00, train corr acc 53.40, val acc 74.68, val corr acc 49.87\n",
      "Ep 7 \titer 845  \tloss 0.84677, train acc 75.52, train corr acc 51.04, val acc 75.83, val corr acc 52.14\n",
      "Ep 7 \titer 846  \tloss 0.96645, train acc 73.44, train corr acc 50.96, val acc 75.64, val corr acc 51.76\n",
      "Ep 7 \titer 847  \tloss 0.93582, train acc 74.48, train corr acc 49.48, val acc 76.15, val corr acc 52.77\n",
      "Ep 7 \titer 848  \tloss 0.84625, train acc 77.60, train corr acc 56.57, val acc 75.70, val corr acc 51.89\n",
      "Ep 7 \titer 849  \tloss 0.94237, train acc 78.12, train corr acc 59.62, val acc 75.45, val corr acc 51.39\n",
      "Ep 7 \titer 850  \tloss 0.99718, train acc 73.44, train corr acc 53.64, val acc 75.38, val corr acc 51.26\n",
      "Ep 7 \titer 851  \tloss 0.98732, train acc 77.60, train corr acc 55.67, val acc 75.76, val corr acc 52.02\n",
      "Ep 7 \titer 852  \tloss 0.74292, train acc 79.69, train corr acc 57.61, val acc 75.70, val corr acc 51.89\n",
      "Ep 7 \titer 853  \tloss 0.87460, train acc 77.60, train corr acc 56.57, val acc 75.32, val corr acc 51.13\n",
      "Ep 7 \titer 854  \tloss 0.90136, train acc 77.08, train corr acc 53.19, val acc 75.57, val corr acc 51.64\n",
      "Ep 7 \titer 855  \tloss 0.91015, train acc 73.44, train corr acc 46.32, val acc 75.13, val corr acc 50.76\n",
      "Ep 7 \titer 856  \tloss 0.94704, train acc 75.52, train corr acc 52.53, val acc 75.06, val corr acc 50.63\n",
      "Ep 7 \titer 857  \tloss 0.73373, train acc 78.65, train corr acc 54.95, val acc 74.87, val corr acc 50.25\n",
      "Ep 7 \titer 858  \tloss 0.84123, train acc 78.12, train corr acc 51.72, val acc 74.68, val corr acc 49.87\n",
      "Ep 7 \titer 859  \tloss 0.75785, train acc 80.21, train corr acc 57.30, val acc 74.94, val corr acc 50.38\n",
      "Ep 7 \titer 860  \tloss 0.87908, train acc 78.12, train corr acc 58.42, val acc 74.75, val corr acc 50.00\n",
      "Ep 7 \titer 861  \tloss 0.94454, train acc 76.04, train corr acc 55.77, val acc 75.13, val corr acc 50.76\n",
      "Ep 7 \titer 862  \tloss 0.77269, train acc 80.73, train corr acc 63.73, val acc 74.94, val corr acc 50.38\n",
      "Ep 7 \titer 863  \tloss 0.83759, train acc 76.56, train corr acc 54.55, val acc 75.13, val corr acc 50.76\n",
      "Ep 7 \titer 864  \tloss 0.76970, train acc 78.12, train corr acc 55.32, val acc 75.13, val corr acc 50.76\n",
      "Ep 7 \titer 865  \tloss 0.88194, train acc 77.08, train corr acc 54.17, val acc 75.25, val corr acc 51.01\n",
      "Ep 7 \titer 866  \tloss 0.91612, train acc 76.04, train corr acc 52.58, val acc 75.38, val corr acc 51.26\n",
      "Ep 7 \titer 867  \tloss 0.93131, train acc 74.48, train corr acc 47.87, val acc 75.89, val corr acc 52.27\n",
      "Ep 7 \titer 868  \tloss 0.91674, train acc 73.96, train corr acc 53.27, val acc 75.57, val corr acc 51.64\n",
      "Ep 7 \titer 869  \tloss 0.89159, train acc 78.65, train corr acc 56.38, val acc 75.51, val corr acc 51.51\n",
      "Ep 7 \titer 870  \tloss 0.94470, train acc 75.52, train corr acc 54.37, val acc 75.25, val corr acc 51.01\n",
      "Ep 7 \titer 871  \tloss 0.95945, train acc 76.56, train corr acc 54.08, val acc 75.57, val corr acc 51.64\n",
      "Ep 7 \titer 872  \tloss 0.86668, train acc 78.12, train corr acc 54.35, val acc 75.51, val corr acc 51.51\n",
      "Ep 7 \titer 873  \tloss 0.93018, train acc 75.00, train corr acc 53.40, val acc 75.51, val corr acc 51.51\n",
      "Ep 7 \titer 874  \tloss 0.96278, train acc 74.48, train corr acc 51.96, val acc 75.64, val corr acc 51.76\n",
      "Ep 7 \titer 875  \tloss 0.94241, train acc 73.96, train corr acc 53.27, val acc 75.45, val corr acc 51.39\n",
      "Ep 7 \titer 876  \tloss 0.86475, train acc 76.56, train corr acc 54.55, val acc 75.19, val corr acc 50.88\n",
      "Ep 7 \titer 877  \tloss 0.85782, train acc 78.12, train corr acc 55.79, val acc 75.76, val corr acc 52.02\n",
      "Ep 7 \titer 878  \tloss 0.83307, train acc 78.65, train corr acc 56.38, val acc 75.64, val corr acc 51.76\n",
      "Ep 7 \titer 879  \tloss 0.95162, train acc 74.48, train corr acc 57.39, val acc 75.57, val corr acc 51.64\n",
      "Ep 7 \titer 880  \tloss 0.95485, train acc 72.40, train corr acc 46.46, val acc 75.51, val corr acc 51.51\n",
      "Ep 7 \titer 881  \tloss 0.87742, train acc 76.56, train corr acc 56.31, val acc 75.70, val corr acc 51.89\n",
      "Ep 7 \titer 882  \tloss 0.98829, train acc 72.40, train corr acc 45.92, val acc 75.57, val corr acc 51.64\n",
      "Ep 7 \titer 883  \tloss 0.84904, train acc 78.12, train corr acc 56.70, val acc 75.70, val corr acc 51.89\n",
      "Ep 7 \titer 884  \tloss 0.94863, train acc 72.92, train corr acc 48.00, val acc 75.57, val corr acc 51.64\n",
      "Ep 7 \titer 885  \tloss 0.91189, train acc 75.00, train corr acc 53.40, val acc 75.19, val corr acc 50.88\n",
      "Ep 7 \titer 886  \tloss 0.88775, train acc 76.04, train corr acc 51.06, val acc 75.51, val corr acc 51.51\n",
      "Ep 7 \titer 887  \tloss 0.92766, train acc 75.52, train corr acc 53.47, val acc 75.06, val corr acc 50.63\n",
      "Ep 7 \titer 888  \tloss 0.97834, train acc 74.48, train corr acc 53.77, val acc 75.19, val corr acc 50.88\n",
      "Ep 7 \titer 889  \tloss 0.91410, train acc 77.08, train corr acc 54.64, val acc 75.83, val corr acc 52.14\n",
      "Ep 7 \titer 890  \tloss 1.00083, train acc 74.48, train corr acc 50.51, val acc 75.64, val corr acc 51.76\n",
      "Ep 7 \titer 891  \tloss 0.93950, train acc 76.04, train corr acc 57.01, val acc 75.83, val corr acc 52.14\n",
      "Ep 7 \titer 892  \tloss 0.83627, train acc 78.12, train corr acc 56.70, val acc 75.83, val corr acc 52.14\n",
      "Ep 7 \titer 893  \tloss 0.85941, train acc 77.60, train corr acc 54.26, val acc 76.27, val corr acc 53.02\n",
      "Ep 7 \titer 894  \tloss 1.00825, train acc 72.92, train corr acc 49.51, val acc 76.34, val corr acc 53.15\n",
      "Ep 7 \titer 895  \tloss 0.79792, train acc 80.73, train corr acc 58.89, val acc 75.95, val corr acc 52.39\n",
      "Ep 7 \titer 896  \tloss 0.83251, train acc 77.60, train corr acc 55.21, val acc 76.59, val corr acc 53.65\n",
      "Ep 7 \titer 897  \tloss 0.98751, train acc 73.96, train corr acc 50.00, val acc 76.08, val corr acc 52.64\n",
      "Ep 7 \titer 898  \tloss 0.91313, train acc 75.52, train corr acc 51.55, val acc 75.38, val corr acc 51.26\n",
      "Ep 7 \titer 899  \tloss 0.88316, train acc 78.12, train corr acc 57.14, val acc 75.45, val corr acc 51.39\n",
      "Ep 7 \titer 900  \tloss 1.01381, train acc 71.35, train corr acc 49.54, val acc 75.19, val corr acc 50.88\n",
      "Ep 7 \titer 901  \tloss 0.81439, train acc 77.60, train corr acc 50.57, val acc 75.64, val corr acc 51.76\n",
      "Ep 7 \titer 902  \tloss 0.82623, train acc 78.12, train corr acc 52.81, val acc 74.68, val corr acc 49.87\n",
      "Ep 7 \titer 903  \tloss 0.82963, train acc 77.08, train corr acc 55.10, val acc 75.19, val corr acc 50.88\n",
      "Ep 7 \titer 904  \tloss 0.89628, train acc 76.04, train corr acc 54.46, val acc 74.81, val corr acc 50.13\n",
      "Ep 7 \titer 905  \tloss 0.74008, train acc 80.21, train corr acc 55.81, val acc 74.68, val corr acc 49.87\n",
      "Ep 7 \titer 906  \tloss 0.91879, train acc 75.52, train corr acc 51.55, val acc 75.38, val corr acc 51.26\n",
      "Ep 7 \titer 907  \tloss 0.73644, train acc 79.69, train corr acc 58.95, val acc 74.81, val corr acc 50.13\n",
      "Ep 7 \titer 908  \tloss 0.95396, train acc 76.04, train corr acc 48.89, val acc 75.83, val corr acc 52.14\n",
      "Ep 7 \titer 909  \tloss 0.83455, train acc 78.12, train corr acc 56.25, val acc 75.51, val corr acc 51.51\n",
      "Ep 7 \titer 910  \tloss 0.80366, train acc 77.60, train corr acc 56.12, val acc 74.94, val corr acc 50.38\n",
      "Ep 7 \titer 911  \tloss 1.02105, train acc 69.79, train corr acc 45.79, val acc 75.57, val corr acc 51.64\n",
      "Ep 7 \titer 912  \tloss 0.84896, train acc 78.12, train corr acc 55.32, val acc 76.15, val corr acc 52.77\n",
      "\n",
      "Epoch 8 of 10 took 55.970s\n",
      "  training loss:\t\t0.913423\n",
      "  training raw accuracy:\t\t76.19 %\n",
      "  training corrected acc:\t\t53.66 %\n",
      "  validation loss:\t\t1.127358\n",
      "  validation raw accuracy:\t\t75.13 %\n",
      "  validation corrected acc:\t\t50.76 % \n",
      "\n",
      "Ep 8 \titer 913  \tloss 1.02629, train acc 75.52, train corr acc 56.48, val acc 75.32, val corr acc 51.13\n",
      "Ep 8 \titer 914  \tloss 0.83144, train acc 77.60, train corr acc 53.26, val acc 75.64, val corr acc 51.76\n",
      "Ep 8 \titer 915  \tloss 0.91497, train acc 76.04, train corr acc 53.06, val acc 75.19, val corr acc 50.88\n",
      "Ep 8 \titer 916  \tloss 1.03095, train acc 72.92, train corr acc 46.94, val acc 75.00, val corr acc 50.50\n",
      "Ep 8 \titer 917  \tloss 0.97600, train acc 74.48, train corr acc 51.00, val acc 74.30, val corr acc 49.12\n",
      "Ep 8 \titer 918  \tloss 0.96192, train acc 72.40, train corr acc 51.38, val acc 74.75, val corr acc 50.00\n",
      "Ep 8 \titer 919  \tloss 0.96809, train acc 76.04, train corr acc 53.54, val acc 75.00, val corr acc 50.50\n",
      "Ep 8 \titer 920  \tloss 0.94354, train acc 75.00, train corr acc 50.52, val acc 75.32, val corr acc 51.13\n",
      "Ep 8 \titer 921  \tloss 0.90089, train acc 75.00, train corr acc 52.94, val acc 75.13, val corr acc 50.76\n",
      "Ep 8 \titer 922  \tloss 1.02727, train acc 72.92, train corr acc 51.85, val acc 75.00, val corr acc 50.50\n",
      "Ep 8 \titer 923  \tloss 0.95408, train acc 73.96, train corr acc 51.46, val acc 75.57, val corr acc 51.64\n",
      "Ep 8 \titer 924  \tloss 0.92876, train acc 77.60, train corr acc 54.26, val acc 75.00, val corr acc 50.50\n",
      "Ep 8 \titer 925  \tloss 0.83659, train acc 76.04, train corr acc 48.89, val acc 74.81, val corr acc 50.13\n",
      "Ep 8 \titer 926  \tloss 0.93943, train acc 76.04, train corr acc 52.08, val acc 74.81, val corr acc 50.13\n",
      "Ep 8 \titer 927  \tloss 0.95032, train acc 76.04, train corr acc 58.18, val acc 75.64, val corr acc 51.76\n",
      "Ep 8 \titer 928  \tloss 0.81849, train acc 79.17, train corr acc 57.45, val acc 75.32, val corr acc 51.13\n",
      "Ep 8 \titer 929  \tloss 0.87591, train acc 75.00, train corr acc 53.40, val acc 74.94, val corr acc 50.38\n",
      "Ep 8 \titer 930  \tloss 0.91246, train acc 74.48, train corr acc 52.88, val acc 74.94, val corr acc 50.38\n",
      "Ep 8 \titer 931  \tloss 0.97217, train acc 72.40, train corr acc 44.79, val acc 74.55, val corr acc 49.62\n",
      "Ep 8 \titer 932  \tloss 0.80821, train acc 79.17, train corr acc 58.33, val acc 74.68, val corr acc 49.87\n",
      "Ep 8 \titer 933  \tloss 0.75220, train acc 80.73, train corr acc 56.98, val acc 74.49, val corr acc 49.50\n",
      "Ep 8 \titer 934  \tloss 0.96498, train acc 73.96, train corr acc 51.92, val acc 74.87, val corr acc 50.25\n",
      "Ep 8 \titer 935  \tloss 0.78155, train acc 78.12, train corr acc 50.59, val acc 75.13, val corr acc 50.76\n",
      "Ep 8 \titer 936  \tloss 0.89311, train acc 78.12, train corr acc 58.42, val acc 75.32, val corr acc 51.13\n",
      "Ep 8 \titer 937  \tloss 0.86973, train acc 77.08, train corr acc 54.64, val acc 74.87, val corr acc 50.25\n",
      "Ep 8 \titer 938  \tloss 0.82658, train acc 79.69, train corr acc 60.20, val acc 74.87, val corr acc 50.25\n",
      "Ep 8 \titer 939  \tloss 0.96646, train acc 75.52, train corr acc 54.37, val acc 75.51, val corr acc 51.51\n",
      "Ep 8 \titer 940  \tloss 0.92952, train acc 75.00, train corr acc 51.52, val acc 74.68, val corr acc 49.87\n",
      "Ep 8 \titer 941  \tloss 0.88284, train acc 76.56, train corr acc 54.55, val acc 74.75, val corr acc 50.00\n",
      "Ep 8 \titer 942  \tloss 0.98610, train acc 73.44, train corr acc 50.00, val acc 75.32, val corr acc 51.13\n",
      "Ep 8 \titer 943  \tloss 0.89981, train acc 75.52, train corr acc 51.04, val acc 75.32, val corr acc 51.13\n",
      "Ep 8 \titer 944  \tloss 0.79022, train acc 79.17, train corr acc 56.99, val acc 74.81, val corr acc 50.13\n",
      "Ep 8 \titer 945  \tloss 0.75418, train acc 79.17, train corr acc 56.52, val acc 75.25, val corr acc 51.01\n",
      "Ep 8 \titer 946  \tloss 0.78753, train acc 77.08, train corr acc 55.10, val acc 75.00, val corr acc 50.50\n",
      "Ep 8 \titer 947  \tloss 0.92404, train acc 77.60, train corr acc 59.81, val acc 75.25, val corr acc 51.01\n",
      "Ep 8 \titer 948  \tloss 0.99455, train acc 71.88, train corr acc 47.57, val acc 75.45, val corr acc 51.39\n",
      "Ep 8 \titer 949  \tloss 0.95341, train acc 78.65, train corr acc 60.19, val acc 75.83, val corr acc 52.14\n",
      "Ep 8 \titer 950  \tloss 0.97306, train acc 77.60, train corr acc 57.84, val acc 75.38, val corr acc 51.26\n",
      "Ep 8 \titer 951  \tloss 0.76072, train acc 79.69, train corr acc 56.18, val acc 75.89, val corr acc 52.27\n",
      "Ep 8 \titer 952  \tloss 0.93766, train acc 73.96, train corr acc 50.00, val acc 74.81, val corr acc 50.13\n",
      "Ep 8 \titer 953  \tloss 0.86084, train acc 74.48, train corr acc 51.96, val acc 75.25, val corr acc 51.01\n",
      "Ep 8 \titer 954  \tloss 0.97743, train acc 74.48, train corr acc 53.77, val acc 76.34, val corr acc 53.15\n",
      "Ep 8 \titer 955  \tloss 0.84270, train acc 78.12, train corr acc 56.70, val acc 75.95, val corr acc 52.39\n",
      "Ep 8 \titer 956  \tloss 0.87462, train acc 76.56, train corr acc 55.45, val acc 76.21, val corr acc 52.90\n",
      "Ep 8 \titer 957  \tloss 0.84270, train acc 76.04, train corr acc 55.34, val acc 75.38, val corr acc 51.26\n",
      "Ep 8 \titer 958  \tloss 0.95103, train acc 76.04, train corr acc 55.34, val acc 75.83, val corr acc 52.14\n",
      "Ep 8 \titer 959  \tloss 0.85903, train acc 77.60, train corr acc 55.21, val acc 76.08, val corr acc 52.64\n",
      "Ep 8 \titer 960  \tloss 0.93440, train acc 73.96, train corr acc 51.92, val acc 75.32, val corr acc 51.13\n",
      "Ep 8 \titer 961  \tloss 0.94469, train acc 75.00, train corr acc 50.52, val acc 75.76, val corr acc 52.02\n",
      "Ep 8 \titer 962  \tloss 0.84684, train acc 76.56, train corr acc 54.55, val acc 76.15, val corr acc 52.77\n",
      "Ep 8 \titer 963  \tloss 0.92941, train acc 76.04, train corr acc 55.77, val acc 75.83, val corr acc 52.14\n",
      "Ep 8 \titer 964  \tloss 0.96124, train acc 75.00, train corr acc 56.36, val acc 76.34, val corr acc 53.15\n",
      "Ep 8 \titer 965  \tloss 0.93752, train acc 77.60, train corr acc 55.67, val acc 75.70, val corr acc 51.89\n",
      "Ep 8 \titer 966  \tloss 0.71270, train acc 79.17, train corr acc 56.52, val acc 76.27, val corr acc 53.02\n",
      "Ep 8 \titer 967  \tloss 0.81079, train acc 77.60, train corr acc 56.57, val acc 76.21, val corr acc 52.90\n",
      "Ep 8 \titer 968  \tloss 0.86273, train acc 77.60, train corr acc 55.32, val acc 75.64, val corr acc 51.76\n",
      "Ep 8 \titer 969  \tloss 0.94453, train acc 78.12, train corr acc 55.79, val acc 76.21, val corr acc 52.90\n",
      "Ep 8 \titer 970  \tloss 0.86587, train acc 75.52, train corr acc 52.53, val acc 75.76, val corr acc 52.02\n",
      "Ep 8 \titer 971  \tloss 0.70528, train acc 78.12, train corr acc 53.85, val acc 75.70, val corr acc 51.89\n",
      "Ep 8 \titer 972  \tloss 0.78205, train acc 79.69, train corr acc 55.17, val acc 75.51, val corr acc 51.51\n",
      "Ep 8 \titer 973  \tloss 0.77239, train acc 79.69, train corr acc 56.18, val acc 74.68, val corr acc 49.87\n",
      "Ep 8 \titer 974  \tloss 0.88902, train acc 77.08, train corr acc 56.44, val acc 75.13, val corr acc 50.76\n",
      "Ep 8 \titer 975  \tloss 0.93780, train acc 74.48, train corr acc 52.88, val acc 75.00, val corr acc 50.50\n",
      "Ep 8 \titer 976  \tloss 0.73718, train acc 80.21, train corr acc 62.75, val acc 75.06, val corr acc 50.63\n",
      "Ep 8 \titer 977  \tloss 0.83037, train acc 77.60, train corr acc 56.57, val acc 74.75, val corr acc 50.00\n",
      "Ep 8 \titer 978  \tloss 0.79384, train acc 77.08, train corr acc 53.19, val acc 75.13, val corr acc 50.76\n",
      "Ep 8 \titer 979  \tloss 0.87622, train acc 78.65, train corr acc 57.29, val acc 75.38, val corr acc 51.26\n",
      "Ep 8 \titer 980  \tloss 0.90033, train acc 76.56, train corr acc 53.61, val acc 75.45, val corr acc 51.39\n",
      "Ep 8 \titer 981  \tloss 0.93643, train acc 75.00, train corr acc 48.94, val acc 75.57, val corr acc 51.64\n",
      "Ep 8 \titer 982  \tloss 0.85335, train acc 72.40, train corr acc 50.47, val acc 75.64, val corr acc 51.76\n",
      "Ep 8 \titer 983  \tloss 0.83847, train acc 79.69, train corr acc 58.51, val acc 75.83, val corr acc 52.14\n",
      "Ep 8 \titer 984  \tloss 0.88611, train acc 75.52, train corr acc 54.37, val acc 75.89, val corr acc 52.27\n",
      "Ep 8 \titer 985  \tloss 0.84044, train acc 78.12, train corr acc 57.14, val acc 75.76, val corr acc 52.02\n",
      "Ep 8 \titer 986  \tloss 0.86111, train acc 77.60, train corr acc 53.26, val acc 75.19, val corr acc 50.88\n",
      "Ep 8 \titer 987  \tloss 0.93730, train acc 73.96, train corr acc 51.46, val acc 75.25, val corr acc 51.01\n",
      "Ep 8 \titer 988  \tloss 0.91237, train acc 75.52, train corr acc 53.92, val acc 75.32, val corr acc 51.13\n",
      "Ep 8 \titer 989  \tloss 0.88815, train acc 76.56, train corr acc 57.94, val acc 74.62, val corr acc 49.75\n",
      "Ep 8 \titer 990  \tloss 0.81845, train acc 75.52, train corr acc 52.53, val acc 74.81, val corr acc 50.13\n",
      "Ep 8 \titer 991  \tloss 0.82867, train acc 77.60, train corr acc 54.74, val acc 75.00, val corr acc 50.50\n",
      "Ep 8 \titer 992  \tloss 0.81851, train acc 78.65, train corr acc 56.38, val acc 75.00, val corr acc 50.50\n",
      "Ep 8 \titer 993  \tloss 0.91179, train acc 75.00, train corr acc 58.26, val acc 75.57, val corr acc 51.64\n",
      "Ep 8 \titer 994  \tloss 0.90637, train acc 75.00, train corr acc 51.52, val acc 75.19, val corr acc 50.88\n",
      "Ep 8 \titer 995  \tloss 0.85962, train acc 77.08, train corr acc 57.28, val acc 75.06, val corr acc 50.63\n",
      "Ep 8 \titer 996  \tloss 0.96384, train acc 72.92, train corr acc 46.94, val acc 74.36, val corr acc 49.24\n",
      "Ep 8 \titer 997  \tloss 0.80646, train acc 75.52, train corr acc 51.55, val acc 75.19, val corr acc 50.88\n",
      "Ep 8 \titer 998  \tloss 0.96021, train acc 73.96, train corr acc 50.00, val acc 75.06, val corr acc 50.63\n",
      "Ep 8 \titer 999  \tloss 0.88420, train acc 76.56, train corr acc 56.31, val acc 75.51, val corr acc 51.51\n",
      "Ep 8 \titer 1000  \tloss 0.88916, train acc 76.04, train corr acc 51.06, val acc 75.51, val corr acc 51.51\n",
      "Ep 8 \titer 1001  \tloss 0.91468, train acc 75.00, train corr acc 52.48, val acc 75.83, val corr acc 52.14\n",
      "Ep 8 \titer 1002  \tloss 0.89815, train acc 75.52, train corr acc 55.66, val acc 76.21, val corr acc 52.90\n",
      "Ep 8 \titer 1003  \tloss 0.86215, train acc 76.56, train corr acc 53.61, val acc 76.21, val corr acc 52.90\n",
      "Ep 8 \titer 1004  \tloss 0.97659, train acc 72.40, train corr acc 46.46, val acc 75.95, val corr acc 52.39\n",
      "Ep 8 \titer 1005  \tloss 0.91083, train acc 75.00, train corr acc 55.14, val acc 74.68, val corr acc 49.87\n",
      "Ep 8 \titer 1006  \tloss 0.78247, train acc 75.00, train corr acc 50.52, val acc 74.87, val corr acc 50.25\n",
      "Ep 8 \titer 1007  \tloss 0.85002, train acc 76.04, train corr acc 51.06, val acc 75.45, val corr acc 51.39\n",
      "Ep 8 \titer 1008  \tloss 0.96839, train acc 71.35, train corr acc 46.60, val acc 75.45, val corr acc 51.39\n",
      "Ep 8 \titer 1009  \tloss 0.82481, train acc 79.69, train corr acc 56.67, val acc 75.64, val corr acc 51.76\n",
      "Ep 8 \titer 1010  \tloss 0.79766, train acc 76.56, train corr acc 53.12, val acc 75.64, val corr acc 51.76\n",
      "Ep 8 \titer 1011  \tloss 0.91696, train acc 74.48, train corr acc 51.00, val acc 76.15, val corr acc 52.77\n",
      "Ep 8 \titer 1012  \tloss 0.86594, train acc 75.00, train corr acc 50.52, val acc 75.64, val corr acc 51.76\n",
      "Ep 8 \titer 1013  \tloss 0.87519, train acc 76.56, train corr acc 54.08, val acc 75.70, val corr acc 51.89\n",
      "Ep 8 \titer 1014  \tloss 0.98931, train acc 71.35, train corr acc 49.54, val acc 75.45, val corr acc 51.39\n",
      "Ep 8 \titer 1015  \tloss 0.78769, train acc 77.60, train corr acc 50.57, val acc 75.51, val corr acc 51.51\n",
      "Ep 8 \titer 1016  \tloss 0.75493, train acc 80.21, train corr acc 57.30, val acc 75.38, val corr acc 51.26\n",
      "Ep 8 \titer 1017  \tloss 0.81258, train acc 78.65, train corr acc 58.16, val acc 75.19, val corr acc 50.88\n",
      "Ep 8 \titer 1018  \tloss 0.85136, train acc 77.08, train corr acc 56.44, val acc 74.36, val corr acc 49.24\n",
      "Ep 8 \titer 1019  \tloss 0.72443, train acc 80.21, train corr acc 55.81, val acc 75.57, val corr acc 51.64\n",
      "Ep 8 \titer 1020  \tloss 0.81659, train acc 80.21, train corr acc 60.82, val acc 75.38, val corr acc 51.26\n",
      "Ep 8 \titer 1021  \tloss 0.71505, train acc 82.29, train corr acc 64.21, val acc 75.00, val corr acc 50.50\n",
      "Ep 8 \titer 1022  \tloss 0.87538, train acc 76.56, train corr acc 50.00, val acc 74.81, val corr acc 50.13\n",
      "Ep 8 \titer 1023  \tloss 0.83041, train acc 77.08, train corr acc 54.17, val acc 75.25, val corr acc 51.01\n",
      "Ep 8 \titer 1024  \tloss 0.79132, train acc 77.60, train corr acc 56.12, val acc 75.13, val corr acc 50.76\n",
      "Ep 8 \titer 1025  \tloss 1.00288, train acc 70.31, train corr acc 46.73, val acc 75.19, val corr acc 50.88\n",
      "Ep 8 \titer 1026  \tloss 0.86072, train acc 79.17, train corr acc 57.45, val acc 75.06, val corr acc 50.63\n",
      "\n",
      "Epoch 9 of 10 took 61.385s\n",
      "  training loss:\t\t0.879361\n",
      "  training raw accuracy:\t\t76.38 %\n",
      "  training corrected acc:\t\t54.01 %\n",
      "  validation loss:\t\t1.161455\n",
      "  validation raw accuracy:\t\t74.75 %\n",
      "  validation corrected acc:\t\t50.00 % \n",
      "\n",
      "Ep 9 \titer 1027  \tloss 0.98665, train acc 73.44, train corr acc 52.78, val acc 75.57, val corr acc 51.64\n",
      "Ep 9 \titer 1028  \tloss 0.83193, train acc 79.17, train corr acc 56.52, val acc 75.19, val corr acc 50.88\n",
      "Ep 9 \titer 1029  \tloss 0.86729, train acc 75.52, train corr acc 52.04, val acc 75.32, val corr acc 51.13\n",
      "Ep 9 \titer 1030  \tloss 0.98797, train acc 73.44, train corr acc 47.96, val acc 75.06, val corr acc 50.63\n",
      "Ep 9 \titer 1031  \tloss 0.94591, train acc 71.88, train corr acc 46.00, val acc 75.13, val corr acc 50.76\n",
      "Ep 9 \titer 1032  \tloss 0.90042, train acc 75.52, train corr acc 56.88, val acc 74.11, val corr acc 48.74\n",
      "Ep 9 \titer 1033  \tloss 0.92426, train acc 75.00, train corr acc 51.52, val acc 74.17, val corr acc 48.87\n",
      "Ep 9 \titer 1034  \tloss 0.95899, train acc 75.00, train corr acc 50.52, val acc 74.55, val corr acc 49.62\n",
      "Ep 9 \titer 1035  \tloss 0.82677, train acc 76.56, train corr acc 55.88, val acc 74.55, val corr acc 49.62\n",
      "Ep 9 \titer 1036  \tloss 1.08767, train acc 72.92, train corr acc 51.85, val acc 74.81, val corr acc 50.13\n",
      "Ep 9 \titer 1037  \tloss 0.93695, train acc 73.96, train corr acc 51.46, val acc 74.62, val corr acc 49.75\n",
      "Ep 9 \titer 1038  \tloss 0.85240, train acc 76.04, train corr acc 51.06, val acc 74.81, val corr acc 50.13\n",
      "Ep 9 \titer 1039  \tloss 0.84158, train acc 77.08, train corr acc 51.11, val acc 75.13, val corr acc 50.76\n",
      "Ep 9 \titer 1040  \tloss 0.88558, train acc 75.52, train corr acc 51.04, val acc 75.06, val corr acc 50.63\n",
      "Ep 9 \titer 1041  \tloss 0.89953, train acc 73.44, train corr acc 53.64, val acc 74.55, val corr acc 49.62\n",
      "Ep 9 \titer 1042  \tloss 0.78064, train acc 80.21, train corr acc 59.57, val acc 74.94, val corr acc 50.38\n",
      "Ep 9 \titer 1043  \tloss 0.85381, train acc 72.92, train corr acc 49.51, val acc 74.62, val corr acc 49.75\n",
      "Ep 9 \titer 1044  \tloss 0.86406, train acc 76.56, train corr acc 56.73, val acc 74.94, val corr acc 50.38\n",
      "Ep 9 \titer 1045  \tloss 0.96481, train acc 73.44, train corr acc 46.88, val acc 74.68, val corr acc 49.87\n",
      "Ep 9 \titer 1046  \tloss 0.79405, train acc 78.65, train corr acc 57.29, val acc 74.43, val corr acc 49.37\n",
      "Ep 9 \titer 1047  \tloss 0.73156, train acc 79.69, train corr acc 54.65, val acc 74.87, val corr acc 50.25\n",
      "Ep 9 \titer 1048  \tloss 0.96190, train acc 73.44, train corr acc 50.96, val acc 75.51, val corr acc 51.51\n",
      "Ep 9 \titer 1049  \tloss 0.72783, train acc 78.65, train corr acc 51.76, val acc 74.94, val corr acc 50.38\n",
      "Ep 9 \titer 1050  \tloss 0.85528, train acc 78.65, train corr acc 59.41, val acc 75.51, val corr acc 51.51\n",
      "Ep 9 \titer 1051  \tloss 0.86763, train acc 78.65, train corr acc 57.73, val acc 74.55, val corr acc 49.62\n",
      "Ep 9 \titer 1052  \tloss 0.79956, train acc 79.17, train corr acc 59.18, val acc 74.81, val corr acc 50.13\n",
      "Ep 9 \titer 1053  \tloss 0.97132, train acc 78.65, train corr acc 60.19, val acc 74.55, val corr acc 49.62\n",
      "Ep 9 \titer 1054  \tloss 0.91137, train acc 76.04, train corr acc 53.54, val acc 74.68, val corr acc 49.87\n",
      "Ep 9 \titer 1055  \tloss 0.88948, train acc 78.12, train corr acc 57.58, val acc 74.68, val corr acc 49.87\n",
      "Ep 9 \titer 1056  \tloss 0.97002, train acc 74.48, train corr acc 51.96, val acc 75.25, val corr acc 51.01\n",
      "Ep 9 \titer 1057  \tloss 0.88576, train acc 77.08, train corr acc 54.17, val acc 75.45, val corr acc 51.39\n",
      "Ep 9 \titer 1058  \tloss 0.77131, train acc 78.12, train corr acc 54.84, val acc 75.06, val corr acc 50.63\n",
      "Ep 9 \titer 1059  \tloss 0.72582, train acc 80.73, train corr acc 59.78, val acc 75.00, val corr acc 50.50\n",
      "Ep 9 \titer 1060  \tloss 0.77518, train acc 79.69, train corr acc 60.20, val acc 74.94, val corr acc 50.38\n",
      "Ep 9 \titer 1061  \tloss 0.88130, train acc 77.60, train corr acc 59.81, val acc 74.81, val corr acc 50.13\n",
      "Ep 9 \titer 1062  \tloss 0.99839, train acc 71.35, train corr acc 46.60, val acc 74.68, val corr acc 49.87\n",
      "Ep 9 \titer 1063  \tloss 0.96499, train acc 76.56, train corr acc 56.31, val acc 75.25, val corr acc 51.01\n",
      "Ep 9 \titer 1064  \tloss 0.97006, train acc 75.52, train corr acc 53.92, val acc 75.00, val corr acc 50.50\n",
      "Ep 9 \titer 1065  \tloss 0.73217, train acc 79.17, train corr acc 55.06, val acc 75.64, val corr acc 51.76\n",
      "Ep 9 \titer 1066  \tloss 0.86451, train acc 77.60, train corr acc 57.00, val acc 75.38, val corr acc 51.26\n",
      "Ep 9 \titer 1067  \tloss 0.87560, train acc 76.56, train corr acc 55.88, val acc 75.32, val corr acc 51.13\n",
      "Ep 9 \titer 1068  \tloss 0.96381, train acc 72.92, train corr acc 50.94, val acc 75.19, val corr acc 50.88\n",
      "Ep 9 \titer 1069  \tloss 0.85720, train acc 79.17, train corr acc 58.76, val acc 75.32, val corr acc 51.13\n",
      "Ep 9 \titer 1070  \tloss 0.83158, train acc 77.60, train corr acc 57.43, val acc 75.57, val corr acc 51.64\n",
      "Ep 9 \titer 1071  \tloss 0.91006, train acc 74.48, train corr acc 52.43, val acc 75.00, val corr acc 50.50\n",
      "Ep 9 \titer 1072  \tloss 0.91239, train acc 73.96, train corr acc 51.46, val acc 75.19, val corr acc 50.88\n",
      "Ep 9 \titer 1073  \tloss 0.79566, train acc 78.12, train corr acc 56.25, val acc 74.75, val corr acc 50.00\n",
      "Ep 9 \titer 1074  \tloss 0.93797, train acc 74.48, train corr acc 52.88, val acc 75.70, val corr acc 51.89\n",
      "Ep 9 \titer 1075  \tloss 0.92376, train acc 76.04, train corr acc 52.58, val acc 75.64, val corr acc 51.76\n",
      "Ep 9 \titer 1076  \tloss 0.80062, train acc 78.65, train corr acc 58.59, val acc 75.89, val corr acc 52.27\n",
      "Ep 9 \titer 1077  \tloss 0.88491, train acc 77.08, train corr acc 57.69, val acc 75.64, val corr acc 51.76\n",
      "Ep 9 \titer 1078  \tloss 0.92271, train acc 76.04, train corr acc 58.18, val acc 75.83, val corr acc 52.14\n",
      "Ep 9 \titer 1079  \tloss 0.88805, train acc 76.04, train corr acc 52.58, val acc 74.87, val corr acc 50.25\n",
      "Ep 9 \titer 1080  \tloss 0.73222, train acc 82.29, train corr acc 63.04, val acc 75.57, val corr acc 51.64\n",
      "Ep 9 \titer 1081  \tloss 0.72666, train acc 80.73, train corr acc 62.63, val acc 75.89, val corr acc 52.27\n",
      "Ep 9 \titer 1082  \tloss 0.86081, train acc 77.08, train corr acc 53.19, val acc 74.94, val corr acc 50.38\n",
      "Ep 9 \titer 1083  \tloss 0.90256, train acc 76.04, train corr acc 51.58, val acc 75.00, val corr acc 50.50\n",
      "Ep 9 \titer 1084  \tloss 0.91896, train acc 75.52, train corr acc 52.53, val acc 74.94, val corr acc 50.38\n",
      "Ep 9 \titer 1085  \tloss 0.65920, train acc 80.21, train corr acc 58.24, val acc 74.75, val corr acc 50.00\n",
      "Ep 9 \titer 1086  \tloss 0.79521, train acc 79.17, train corr acc 54.02, val acc 74.68, val corr acc 49.87\n",
      "Ep 9 \titer 1087  \tloss 0.75303, train acc 80.73, train corr acc 58.43, val acc 74.62, val corr acc 49.75\n",
      "Ep 9 \titer 1088  \tloss 0.81561, train acc 78.65, train corr acc 59.41, val acc 74.49, val corr acc 49.50\n",
      "Ep 9 \titer 1089  \tloss 0.88500, train acc 79.17, train corr acc 61.54, val acc 74.30, val corr acc 49.12\n",
      "Ep 9 \titer 1090  \tloss 0.74161, train acc 81.25, train corr acc 64.71, val acc 74.55, val corr acc 49.62\n",
      "Ep 9 \titer 1091  \tloss 0.77886, train acc 77.08, train corr acc 55.56, val acc 74.36, val corr acc 49.24\n",
      "Ep 9 \titer 1092  \tloss 0.74282, train acc 78.12, train corr acc 55.32, val acc 74.43, val corr acc 49.37\n",
      "Ep 9 \titer 1093  \tloss 0.83334, train acc 79.17, train corr acc 58.33, val acc 74.87, val corr acc 50.25\n",
      "Ep 9 \titer 1094  \tloss 0.84672, train acc 76.56, train corr acc 53.61, val acc 74.62, val corr acc 49.75\n",
      "Ep 9 \titer 1095  \tloss 0.91622, train acc 78.12, train corr acc 55.32, val acc 75.06, val corr acc 50.63\n",
      "Ep 9 \titer 1096  \tloss 0.83037, train acc 77.60, train corr acc 59.81, val acc 75.25, val corr acc 51.01\n",
      "Ep 9 \titer 1097  \tloss 0.81241, train acc 79.17, train corr acc 57.45, val acc 75.25, val corr acc 51.01\n",
      "Ep 9 \titer 1098  \tloss 0.90928, train acc 76.04, train corr acc 55.34, val acc 75.00, val corr acc 50.50\n",
      "Ep 9 \titer 1099  \tloss 0.84926, train acc 77.60, train corr acc 56.12, val acc 75.06, val corr acc 50.63\n",
      "Ep 9 \titer 1100  \tloss 0.79660, train acc 79.69, train corr acc 57.61, val acc 73.66, val corr acc 47.86\n",
      "Ep 9 \titer 1101  \tloss 0.92628, train acc 75.52, train corr acc 54.37, val acc 74.62, val corr acc 49.75\n",
      "Ep 9 \titer 1102  \tloss 0.89208, train acc 74.48, train corr acc 51.96, val acc 74.62, val corr acc 49.75\n",
      "Ep 9 \titer 1103  \tloss 0.83910, train acc 76.04, train corr acc 57.01, val acc 74.94, val corr acc 50.38\n",
      "Ep 9 \titer 1104  \tloss 0.78193, train acc 75.52, train corr acc 52.53, val acc 75.64, val corr acc 51.76\n",
      "Ep 9 \titer 1105  \tloss 0.78447, train acc 77.60, train corr acc 54.74, val acc 75.00, val corr acc 50.50\n",
      "Ep 9 \titer 1106  \tloss 0.80972, train acc 80.21, train corr acc 59.57, val acc 75.70, val corr acc 51.89\n",
      "Ep 9 \titer 1107  \tloss 0.87989, train acc 77.08, train corr acc 61.74, val acc 75.51, val corr acc 51.51\n",
      "Ep 9 \titer 1108  \tloss 0.87533, train acc 75.00, train corr acc 51.52, val acc 75.19, val corr acc 50.88\n",
      "Ep 9 \titer 1109  \tloss 0.85057, train acc 78.12, train corr acc 59.22, val acc 75.38, val corr acc 51.26\n",
      "Ep 9 \titer 1110  \tloss 0.91157, train acc 75.00, train corr acc 51.02, val acc 75.32, val corr acc 51.13\n",
      "Ep 9 \titer 1111  \tloss 0.75823, train acc 75.52, train corr acc 51.55, val acc 75.57, val corr acc 51.64\n",
      "Ep 9 \titer 1112  \tloss 0.89141, train acc 73.96, train corr acc 50.00, val acc 74.81, val corr acc 50.13\n",
      "Ep 9 \titer 1113  \tloss 0.85550, train acc 78.12, train corr acc 59.22, val acc 75.13, val corr acc 50.76\n",
      "Ep 9 \titer 1114  \tloss 0.87556, train acc 77.08, train corr acc 53.19, val acc 75.00, val corr acc 50.50\n",
      "Ep 9 \titer 1115  \tloss 0.83225, train acc 76.04, train corr acc 54.46, val acc 75.51, val corr acc 51.51\n",
      "Ep 9 \titer 1116  \tloss 0.91674, train acc 76.04, train corr acc 56.60, val acc 74.81, val corr acc 50.13\n",
      "Ep 9 \titer 1117  \tloss 0.84996, train acc 76.04, train corr acc 52.58, val acc 74.75, val corr acc 50.00\n",
      "Ep 9 \titer 1118  \tloss 0.91038, train acc 72.92, train corr acc 47.47, val acc 74.55, val corr acc 49.62\n",
      "Ep 9 \titer 1119  \tloss 0.90114, train acc 75.52, train corr acc 56.07, val acc 74.81, val corr acc 50.13\n",
      "Ep 9 \titer 1120  \tloss 0.81905, train acc 75.00, train corr acc 50.52, val acc 74.75, val corr acc 50.00\n",
      "Ep 9 \titer 1121  \tloss 0.79849, train acc 79.17, train corr acc 57.45, val acc 74.87, val corr acc 50.25\n",
      "Ep 9 \titer 1122  \tloss 0.97586, train acc 72.40, train corr acc 48.54, val acc 75.06, val corr acc 50.63\n",
      "Ep 9 \titer 1123  \tloss 0.78970, train acc 81.25, train corr acc 60.00, val acc 75.83, val corr acc 52.14\n",
      "Ep 9 \titer 1124  \tloss 0.80204, train acc 76.56, train corr acc 53.12, val acc 75.13, val corr acc 50.76\n",
      "Ep 9 \titer 1125  \tloss 0.88409, train acc 75.52, train corr acc 53.00, val acc 75.19, val corr acc 50.88\n",
      "Ep 9 \titer 1126  \tloss 0.85618, train acc 76.56, train corr acc 53.61, val acc 75.00, val corr acc 50.50\n",
      "Ep 9 \titer 1127  \tloss 0.86021, train acc 78.12, train corr acc 57.14, val acc 75.32, val corr acc 51.13\n",
      "Ep 9 \titer 1128  \tloss 0.99057, train acc 72.40, train corr acc 51.38, val acc 75.25, val corr acc 51.01\n",
      "Ep 9 \titer 1129  \tloss 0.77189, train acc 78.12, train corr acc 51.72, val acc 75.19, val corr acc 50.88\n",
      "Ep 9 \titer 1130  \tloss 0.77573, train acc 76.04, train corr acc 48.31, val acc 75.25, val corr acc 51.01\n",
      "Ep 9 \titer 1131  \tloss 0.80359, train acc 81.77, train corr acc 64.29, val acc 74.55, val corr acc 49.62\n",
      "Ep 9 \titer 1132  \tloss 0.86240, train acc 77.60, train corr acc 57.43, val acc 75.32, val corr acc 51.13\n",
      "Ep 9 \titer 1133  \tloss 0.76282, train acc 78.65, train corr acc 52.33, val acc 75.25, val corr acc 51.01\n",
      "Ep 9 \titer 1134  \tloss 0.88088, train acc 77.08, train corr acc 54.64, val acc 74.24, val corr acc 48.99\n",
      "Ep 9 \titer 1135  \tloss 0.72443, train acc 80.21, train corr acc 60.00, val acc 75.00, val corr acc 50.50\n",
      "Ep 9 \titer 1136  \tloss 0.82306, train acc 78.65, train corr acc 54.44, val acc 75.19, val corr acc 50.88\n",
      "Ep 9 \titer 1137  \tloss 0.77882, train acc 76.04, train corr acc 52.08, val acc 74.68, val corr acc 49.87\n",
      "Ep 9 \titer 1138  \tloss 0.79324, train acc 76.04, train corr acc 53.06, val acc 74.17, val corr acc 48.87\n",
      "Ep 9 \titer 1139  \tloss 0.98931, train acc 72.40, train corr acc 50.47, val acc 75.06, val corr acc 50.63\n",
      "Ep 9 \titer 1140  \tloss 0.78615, train acc 79.17, train corr acc 57.45, val acc 74.87, val corr acc 50.25\n",
      "\n",
      "Epoch 10 of 10 took 82.187s\n",
      "  training loss:\t\t0.857266\n",
      "  training raw accuracy:\t\t76.85 %\n",
      "  training corrected acc:\t\t54.91 %\n",
      "  validation loss:\t\t1.159733\n",
      "  validation raw accuracy:\t\t74.49 %\n",
      "  validation corrected acc:\t\t49.50 % \n",
      "\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Training!\n",
    "train_losses, train_accs, train_corrected_accs, val_losses, val_accs, val_corrected_accs = model.train(train_data, val_data, train_loss_acc, compute_loss_acc, num_epochs=num_epochs, batchsize=batchsize, record_per_iter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "Final results:\n",
      "  test loss:\t\t\t1.107700\n",
      "  test raw accuracy:\t\t74.59 %\n",
      "  test corrected accuracy:\t51.04 %\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_raw_acc, test_corrected_acc, pred_test = model.check_accuracy(test_data, compute_loss_acc, row_to_ast_id_map, dataset_name='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X AST IDs\n",
      "[[   1.   75.   29.   -1.   -1.   -1.]\n",
      " [  13.   74.    0.   -1.   -1.   -1.]\n",
      " [ 214.   14.   -1.   -1.   -1.   -1.]\n",
      " [   1.    8.    3.    0.   -1.   -1.]\n",
      " [   1.    3.    7.    9.   -1.   -1.]\n",
      " [   5.    1.    5.    0.   -1.   -1.]\n",
      " [  38.    1.   -1.   -1.   -1.   -1.]\n",
      " [   2.   27.    0.   -1.   -1.   -1.]\n",
      " [   1.    4.   11.    2.    0.   -1.]\n",
      " [ 498.    0.   -1.   -1.   -1.   -1.]]\n",
      "Truth AST IDs\n",
      "[[ 75.  29.  -1.  -1.  -1.  -1.]\n",
      " [ 74.   0.  -1.  -1.  -1.  -1.]\n",
      " [ 14.  -1.  -1.  -1.  -1.  -1.]\n",
      " [  8.   3.   0.  -1.  -1.  -1.]\n",
      " [  3.   7.   9.  -1.  -1.  -1.]\n",
      " [  1.   5.   0.  -1.  -1.  -1.]\n",
      " [  1.  -1.  -1.  -1.  -1.  -1.]\n",
      " [ 27.   0.  -1.  -1.  -1.  -1.]\n",
      " [  4.  11.   2.   0.  -1.  -1.]\n",
      " [  0.  -1.  -1.  -1.  -1.  -1.]]\n",
      "Predicted AST IDs\n",
      "[[   4.   66.    0.   -1.   -1.   -1.]\n",
      " [  74.   27.   -1.   -1.   -1.   -1.]\n",
      " [   0.   -1.   -1.   -1.   -1.   -1.]\n",
      " [   4.    3.    0.   -1.   -1.   -1.]\n",
      " [   4.   11.    0.   -1.   -1.   -1.]\n",
      " [   3.    0.    0.   -1.   -1.   -1.]\n",
      " [  20.    0.   -1.   -1.   -1.   -1.]\n",
      " [ 108.    0.   -1.   -1.   -1.   -1.]\n",
      " [   4.    3.    3.    0.   -1.   -1.]\n",
      " [  -1.   -1.   -1.   -1.   -1.   -1.]]\n"
     ]
    }
   ],
   "source": [
    "# Convert to AST IDs so we can look at the AST json files\n",
    "X_test_ast_ids, y_test_ast_ids = utils.convert_data_to_ast_ids(test_data, row_to_ast_id_map)\n",
    "pred_test_ast_ids = utils.convert_pred_to_ast_ids(pred_test, row_to_ast_id_map)\n",
    "print(\"X AST IDs\")\n",
    "print X_test_ast_ids[:10,:]\n",
    "print (\"Truth AST IDs\")\n",
    "print y_test_ast_ids[:10, :]\n",
    "print(\"Predicted AST IDs\")\n",
    "print pred_test_ast_ids[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAE+CAYAAABSoh3fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n71jhY7FYLJZ6xwofi8VisdQ7/x9xvHy8Zcm+7AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1277ac510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the loss and the accuracies for both training and validation sets for each epoch\n",
    "visualize.plot_loss_acc(DATA_SET + '_train', train_losses, train_corrected_accs, val_corrected_accs, learning_rate, reg_strength, num_epochs, num_train, xlabel='iterations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are more trial runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "hidden_size = 256 # size of hidden layer of neurons\n",
    "learning_rate = 1e-2\n",
    "lr_decay = 0.95\n",
    "reg_strength = 2e-2\n",
    "grad_clip = 10\n",
    "batchsize = 32\n",
    "num_epochs = 4\n",
    "dropout_p = 0.2\n",
    "num_lstm_layers = 2\n",
    "theano.config.optimizer='fast_compile'\n",
    "theano.config.exception_verbosity='high'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building network ...\n",
      "Computing updates ...\n",
      "Compiling functions ...\n",
      "Compiling done!\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "train_loss_acc, compute_loss_acc, probs = model.create_model(num_timesteps, num_asts, hidden_size, learning_rate, grad_clip, dropout_p, num_lstm_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Total training iterations: 912\n",
      "Ep 0 \titer 1  \tloss 6.06737, train acc 0.00, train corr acc 0.00, val acc 65.97, val corr acc 32.62\n",
      "Ep 0 \titer 2  \tloss 5.89079, train acc 68.75, train corr acc 34.78, val acc 66.16, val corr acc 33.00\n",
      "Ep 0 \titer 3  \tloss 4.46106, train acc 65.62, train corr acc 32.65, val acc 66.16, val corr acc 33.00\n",
      "Ep 0 \titer 4  \tloss 2.31920, train acc 65.62, train corr acc 32.65, val acc 66.16, val corr acc 33.00\n",
      "Ep 0 \titer 5  \tloss 1.96573, train acc 64.58, train corr acc 32.00, val acc 66.16, val corr acc 33.00\n",
      "Ep 0 \titer 6  \tloss 2.29655, train acc 59.90, train corr acc 29.36, val acc 66.09, val corr acc 32.87\n",
      "Ep 0 \titer 7  \tloss 2.37445, train acc 64.58, train corr acc 31.31, val acc 66.16, val corr acc 33.00\n",
      "Ep 0 \titer 8  \tloss 1.81655, train acc 66.15, train corr acc 32.99, val acc 66.16, val corr acc 33.00\n",
      "Ep 0 \titer 9  \tloss 1.74316, train acc 63.54, train corr acc 31.37, val acc 66.98, val corr acc 34.63\n",
      "Ep 0 \titer 10  \tloss 2.11811, train acc 64.06, train corr acc 36.11, val acc 66.98, val corr acc 34.63\n",
      "Ep 0 \titer 11  \tloss 1.89048, train acc 64.58, train corr acc 33.98, val acc 66.54, val corr acc 33.75\n",
      "Ep 0 \titer 12  \tloss 1.70599, train acc 68.23, train corr acc 35.11, val acc 66.28, val corr acc 33.25\n",
      "Ep 0 \titer 13  \tloss 1.55139, train acc 71.35, train corr acc 38.89, val acc 66.28, val corr acc 33.25\n",
      "Ep 0 \titer 14  \tloss 1.62566, train acc 66.67, train corr acc 33.33, val acc 66.28, val corr acc 33.25\n",
      "Ep 0 \titer 15  \tloss 2.09133, train acc 60.94, train corr acc 31.82, val acc 65.14, val corr acc 32.87\n",
      "Ep 0 \titer 16  \tloss 1.56171, train acc 64.58, train corr acc 30.85, val acc 65.52, val corr acc 33.88\n",
      "Ep 0 \titer 17  \tloss 1.67443, train acc 63.54, train corr acc 33.98, val acc 64.95, val corr acc 32.49\n",
      "Ep 0 \titer 18  \tloss 1.82348, train acc 59.38, train corr acc 26.92, val acc 65.27, val corr acc 32.87\n",
      "Ep 0 \titer 19  \tloss 1.53050, train acc 65.10, train corr acc 31.25, val acc 66.54, val corr acc 34.13\n",
      "Ep 0 \titer 20  \tloss 1.37195, train acc 70.83, train corr acc 41.67, val acc 66.54, val corr acc 34.01\n",
      "Ep 0 \titer 21  \tloss 1.31500, train acc 72.40, train corr acc 38.37, val acc 67.62, val corr acc 35.89\n",
      "Ep 0 \titer 22  \tloss 1.71790, train acc 65.10, train corr acc 35.58, val acc 67.43, val corr acc 36.15\n",
      "Ep 0 \titer 23  \tloss 1.37021, train acc 71.35, train corr acc 35.29, val acc 67.62, val corr acc 36.02\n",
      "Ep 0 \titer 24  \tloss 1.42222, train acc 67.19, train corr acc 37.62, val acc 67.30, val corr acc 35.26\n",
      "Ep 0 \titer 25  \tloss 1.62022, train acc 66.15, train corr acc 34.02, val acc 67.37, val corr acc 35.39\n",
      "Ep 0 \titer 26  \tloss 1.50556, train acc 65.10, train corr acc 31.63, val acc 67.18, val corr acc 35.01\n",
      "Ep 0 \titer 27  \tloss 1.61226, train acc 61.98, train corr acc 29.13, val acc 59.92, val corr acc 28.21\n",
      "Ep 0 \titer 28  \tloss 1.79112, train acc 52.60, train corr acc 19.19, val acc 67.81, val corr acc 36.40\n",
      "Ep 0 \titer 29  \tloss 1.46754, train acc 67.71, train corr acc 37.37, val acc 67.11, val corr acc 34.89\n",
      "Ep 0 \titer 30  \tloss 1.75400, train acc 64.58, train corr acc 33.33, val acc 67.05, val corr acc 34.76\n",
      "Ep 0 \titer 31  \tloss 1.60827, train acc 66.67, train corr acc 33.33, val acc 66.67, val corr acc 34.01\n",
      "Ep 0 \titer 32  \tloss 1.50655, train acc 69.27, train corr acc 36.56, val acc 67.68, val corr acc 36.02\n",
      "Ep 0 \titer 33  \tloss 1.17638, train acc 70.83, train corr acc 39.13, val acc 67.43, val corr acc 35.64\n",
      "Ep 0 \titer 34  \tloss 1.47299, train acc 66.15, train corr acc 33.67, val acc 67.81, val corr acc 36.78\n",
      "Ep 0 \titer 35  \tloss 1.66705, train acc 64.58, train corr acc 36.45, val acc 65.97, val corr acc 34.01\n",
      "Ep 0 \titer 36  \tloss 1.59361, train acc 63.54, train corr acc 33.01, val acc 66.73, val corr acc 35.52\n",
      "Ep 0 \titer 37  \tloss 1.57839, train acc 64.58, train corr acc 35.92, val acc 67.94, val corr acc 37.03\n",
      "Ep 0 \titer 38  \tloss 1.59253, train acc 64.06, train corr acc 33.33, val acc 67.75, val corr acc 36.27\n",
      "Ep 0 \titer 39  \tloss 1.29274, train acc 70.83, train corr acc 37.08, val acc 66.92, val corr acc 34.63\n",
      "Ep 0 \titer 40  \tloss 1.54561, train acc 65.10, train corr acc 33.00, val acc 67.49, val corr acc 35.77\n",
      "Ep 0 \titer 41  \tloss 1.61178, train acc 64.06, train corr acc 32.35, val acc 67.75, val corr acc 36.15\n",
      "Ep 0 \titer 42  \tloss 1.61821, train acc 63.02, train corr acc 33.02, val acc 67.56, val corr acc 35.89\n",
      "Ep 0 \titer 43  \tloss 1.44505, train acc 68.23, train corr acc 37.11, val acc 67.81, val corr acc 36.40\n",
      "Ep 0 \titer 44  \tloss 1.50518, train acc 66.67, train corr acc 36.63, val acc 68.19, val corr acc 37.15\n",
      "Ep 0 \titer 45  \tloss 1.43470, train acc 65.62, train corr acc 35.92, val acc 68.32, val corr acc 37.53\n",
      "Ep 0 \titer 46  \tloss 1.51193, train acc 63.54, train corr acc 33.01, val acc 68.96, val corr acc 38.79\n",
      "Ep 0 \titer 47  \tloss 1.32590, train acc 69.27, train corr acc 38.54, val acc 68.77, val corr acc 38.54\n",
      "Ep 0 \titer 48  \tloss 1.42249, train acc 60.94, train corr acc 28.85, val acc 69.02, val corr acc 38.92\n",
      "Ep 0 \titer 49  \tloss 1.44401, train acc 67.71, train corr acc 36.08, val acc 68.96, val corr acc 38.54\n",
      "Ep 0 \titer 50  \tloss 1.30560, train acc 66.15, train corr acc 34.34, val acc 69.08, val corr acc 38.79\n",
      "Ep 0 \titer 51  \tloss 1.56989, train acc 66.15, train corr acc 37.50, val acc 69.21, val corr acc 39.17\n",
      "Ep 0 \titer 52  \tloss 1.41107, train acc 65.10, train corr acc 39.09, val acc 69.02, val corr acc 38.79\n",
      "Ep 0 \titer 53  \tloss 1.58142, train acc 67.71, train corr acc 37.11, val acc 69.08, val corr acc 38.92\n",
      "Ep 0 \titer 54  \tloss 1.31931, train acc 70.83, train corr acc 39.13, val acc 69.53, val corr acc 39.67\n",
      "Ep 0 \titer 55  \tloss 1.40579, train acc 71.35, train corr acc 44.44, val acc 69.34, val corr acc 39.42\n",
      "Ep 0 \titer 56  \tloss 1.25711, train acc 69.27, train corr acc 37.23, val acc 69.34, val corr acc 39.42\n",
      "Ep 0 \titer 57  \tloss 1.44579, train acc 67.19, train corr acc 33.68, val acc 69.78, val corr acc 40.18\n",
      "Ep 0 \titer 58  \tloss 1.31226, train acc 67.71, train corr acc 37.37, val acc 69.72, val corr acc 40.05\n",
      "Ep 0 \titer 59  \tloss 1.22511, train acc 70.31, train corr acc 37.36, val acc 69.72, val corr acc 40.05\n",
      "Ep 0 \titer 60  \tloss 1.21621, train acc 72.92, train corr acc 40.23, val acc 70.36, val corr acc 41.31\n",
      "Ep 0 \titer 61  \tloss 1.19508, train acc 71.88, train corr acc 39.33, val acc 70.99, val corr acc 42.57\n",
      "Ep 0 \titer 62  \tloss 1.41512, train acc 70.83, train corr acc 45.54, val acc 70.93, val corr acc 42.70\n",
      "Ep 0 \titer 63  \tloss 1.37197, train acc 66.15, train corr acc 37.50, val acc 71.25, val corr acc 43.58\n",
      "Ep 0 \titer 64  \tloss 1.35398, train acc 71.35, train corr acc 47.06, val acc 70.55, val corr acc 42.44\n",
      "Ep 0 \titer 65  \tloss 1.41840, train acc 67.19, train corr acc 37.37, val acc 70.48, val corr acc 41.94\n",
      "Ep 0 \titer 66  \tloss 1.27005, train acc 72.40, train corr acc 43.62, val acc 70.99, val corr acc 42.57\n",
      "Ep 0 \titer 67  \tloss 1.34288, train acc 72.92, train corr acc 45.83, val acc 71.44, val corr acc 43.58\n",
      "Ep 0 \titer 68  \tloss 1.55816, train acc 68.75, train corr acc 38.14, val acc 71.25, val corr acc 43.07\n",
      "Ep 0 \titer 69  \tloss 1.29285, train acc 71.35, train corr acc 41.49, val acc 70.99, val corr acc 42.57\n",
      "Ep 0 \titer 70  \tloss 1.41908, train acc 65.62, train corr acc 38.32, val acc 71.18, val corr acc 42.95\n",
      "Ep 0 \titer 71  \tloss 1.25642, train acc 71.88, train corr acc 42.55, val acc 71.63, val corr acc 43.83\n",
      "Ep 0 \titer 72  \tloss 1.44274, train acc 67.19, train corr acc 38.83, val acc 71.56, val corr acc 44.08\n",
      "Ep 0 \titer 73  \tloss 1.52086, train acc 67.19, train corr acc 38.78, val acc 72.46, val corr acc 45.84\n",
      "Ep 0 \titer 74  \tloss 1.26735, train acc 71.35, train corr acc 41.30, val acc 72.20, val corr acc 44.96\n",
      "Ep 0 \titer 75  \tloss 1.47379, train acc 68.75, train corr acc 41.75, val acc 71.50, val corr acc 43.58\n",
      "Ep 0 \titer 76  \tloss 1.47905, train acc 71.88, train corr acc 47.06, val acc 71.31, val corr acc 43.20\n",
      "Ep 0 \titer 77  \tloss 1.40445, train acc 67.71, train corr acc 42.06, val acc 71.44, val corr acc 43.45\n",
      "Ep 0 \titer 78  \tloss 1.50133, train acc 69.79, train corr acc 41.41, val acc 70.80, val corr acc 42.82\n",
      "Ep 0 \titer 79  \tloss 1.33948, train acc 71.88, train corr acc 43.16, val acc 71.25, val corr acc 43.07\n",
      "Ep 0 \titer 80  \tloss 1.20133, train acc 76.56, train corr acc 52.13, val acc 69.91, val corr acc 40.43\n",
      "Ep 0 \titer 81  \tloss 1.70102, train acc 62.50, train corr acc 37.39, val acc 70.42, val corr acc 41.44\n",
      "Ep 0 \titer 82  \tloss 1.44355, train acc 67.71, train corr acc 37.37, val acc 71.76, val corr acc 44.08\n",
      "Ep 0 \titer 83  \tloss 1.48435, train acc 68.23, train corr acc 40.78, val acc 71.31, val corr acc 43.20\n",
      "Ep 0 \titer 84  \tloss 1.42502, train acc 67.71, train corr acc 36.73, val acc 70.17, val corr acc 40.93\n",
      "Ep 0 \titer 85  \tloss 1.38180, train acc 67.71, train corr acc 36.08, val acc 70.17, val corr acc 40.93\n",
      "Ep 0 \titer 86  \tloss 1.29975, train acc 69.79, train corr acc 42.00, val acc 70.67, val corr acc 41.94\n",
      "Ep 0 \titer 87  \tloss 1.55712, train acc 66.67, train corr acc 37.86, val acc 72.26, val corr acc 45.21\n",
      "Ep 0 \titer 88  \tloss 1.33710, train acc 71.88, train corr acc 42.55, val acc 71.76, val corr acc 44.08\n",
      "Ep 0 \titer 89  \tloss 1.35519, train acc 69.27, train corr acc 41.58, val acc 72.14, val corr acc 44.84\n",
      "Ep 0 \titer 90  \tloss 1.44689, train acc 67.71, train corr acc 41.51, val acc 72.58, val corr acc 45.84\n",
      "Ep 0 \titer 91  \tloss 1.28669, train acc 69.79, train corr acc 40.21, val acc 72.01, val corr acc 44.58\n",
      "Ep 0 \titer 92  \tloss 1.46783, train acc 67.71, train corr acc 37.37, val acc 71.76, val corr acc 44.08\n",
      "Ep 0 \titer 93  \tloss 1.40989, train acc 66.67, train corr acc 40.19, val acc 71.69, val corr acc 43.95\n",
      "Ep 0 \titer 94  \tloss 1.15294, train acc 72.92, train corr acc 46.39, val acc 72.39, val corr acc 45.34\n",
      "Ep 0 \titer 95  \tloss 1.32398, train acc 72.40, train corr acc 43.62, val acc 72.71, val corr acc 45.97\n",
      "Ep 0 \titer 96  \tloss 1.49512, train acc 68.75, train corr acc 41.75, val acc 73.54, val corr acc 47.61\n",
      "Ep 0 \titer 97  \tloss 1.14954, train acc 77.08, train corr acc 51.11, val acc 72.84, val corr acc 46.22\n",
      "Ep 0 \titer 98  \tloss 1.23005, train acc 71.35, train corr acc 42.71, val acc 72.52, val corr acc 45.59\n",
      "Ep 0 \titer 99  \tloss 1.41673, train acc 71.35, train corr acc 45.00, val acc 73.16, val corr acc 46.85\n",
      "Ep 0 \titer 100  \tloss 1.35700, train acc 73.96, train corr acc 48.45, val acc 73.16, val corr acc 46.85\n",
      "Ep 0 \titer 101  \tloss 1.35228, train acc 70.83, train corr acc 42.86, val acc 72.96, val corr acc 46.47\n",
      "Ep 0 \titer 102  \tloss 1.49453, train acc 67.71, train corr acc 43.12, val acc 72.77, val corr acc 46.10\n",
      "Ep 0 \titer 103  \tloss 1.13325, train acc 74.48, train corr acc 43.68, val acc 71.12, val corr acc 42.82\n",
      "Ep 0 \titer 104  \tloss 1.27267, train acc 75.52, train corr acc 47.19, val acc 72.39, val corr acc 45.34\n",
      "Ep 0 \titer 105  \tloss 1.35002, train acc 71.88, train corr acc 44.90, val acc 73.16, val corr acc 46.85\n",
      "Ep 0 \titer 106  \tloss 1.24559, train acc 72.40, train corr acc 47.52, val acc 71.88, val corr acc 44.58\n",
      "Ep 0 \titer 107  \tloss 1.20013, train acc 77.08, train corr acc 48.84, val acc 73.35, val corr acc 47.23\n",
      "Ep 0 \titer 108  \tloss 1.29163, train acc 71.88, train corr acc 44.33, val acc 72.01, val corr acc 44.58\n",
      "Ep 0 \titer 109  \tloss 1.01239, train acc 76.04, train corr acc 51.58, val acc 73.41, val corr acc 47.36\n",
      "Ep 0 \titer 110  \tloss 1.30462, train acc 72.40, train corr acc 41.11, val acc 73.41, val corr acc 47.36\n",
      "Ep 0 \titer 111  \tloss 1.10559, train acc 73.96, train corr acc 47.92, val acc 72.71, val corr acc 45.97\n",
      "Ep 0 \titer 112  \tloss 1.19162, train acc 73.96, train corr acc 48.98, val acc 73.16, val corr acc 46.85\n",
      "Ep 0 \titer 113  \tloss 1.31555, train acc 67.19, train corr acc 41.12, val acc 73.85, val corr acc 48.24\n",
      "Ep 0 \titer 114  \tloss 1.25751, train acc 72.92, train corr acc 44.68, val acc 73.85, val corr acc 48.24\n",
      "\n",
      "Epoch 1 of 8 took 62.427s\n",
      "  training loss:\t\t1.575721\n",
      "  training raw accuracy:\t\t67.66 %\n",
      "  training corrected acc:\t\t38.20 %\n",
      "  validation loss:\t\t1.220076\n",
      "  validation raw accuracy:\t\t73.60 %\n",
      "  validation corrected acc:\t\t47.73 % \n",
      "\n",
      "Ep 1 \titer 115  \tloss 1.29299, train acc 71.35, train corr acc 49.07, val acc 73.85, val corr acc 48.24\n",
      "Ep 1 \titer 116  \tloss 1.06041, train acc 75.52, train corr acc 48.91, val acc 73.73, val corr acc 47.98\n",
      "Ep 1 \titer 117  \tloss 1.20872, train acc 73.44, train corr acc 47.96, val acc 73.22, val corr acc 46.98\n",
      "Ep 1 \titer 118  \tloss 1.30506, train acc 69.27, train corr acc 39.80, val acc 73.60, val corr acc 47.73\n",
      "Ep 1 \titer 119  \tloss 1.34210, train acc 68.23, train corr acc 39.00, val acc 73.28, val corr acc 47.10\n",
      "Ep 1 \titer 120  \tloss 1.30497, train acc 70.31, train corr acc 47.71, val acc 72.77, val corr acc 46.10\n",
      "Ep 1 \titer 121  \tloss 1.34425, train acc 71.88, train corr acc 45.45, val acc 73.28, val corr acc 47.10\n",
      "Ep 1 \titer 122  \tloss 1.22367, train acc 71.88, train corr acc 44.33, val acc 73.03, val corr acc 46.60\n",
      "Ep 1 \titer 123  \tloss 1.16671, train acc 71.35, train corr acc 46.08, val acc 73.41, val corr acc 47.36\n",
      "Ep 1 \titer 124  \tloss 1.40862, train acc 68.23, train corr acc 43.52, val acc 74.17, val corr acc 48.87\n",
      "Ep 1 \titer 125  \tloss 1.22469, train acc 70.83, train corr acc 45.63, val acc 74.11, val corr acc 48.74\n",
      "Ep 1 \titer 126  \tloss 1.11433, train acc 76.04, train corr acc 51.06, val acc 74.24, val corr acc 48.99\n",
      "Ep 1 \titer 127  \tloss 1.23441, train acc 72.40, train corr acc 41.11, val acc 73.66, val corr acc 47.86\n",
      "Ep 1 \titer 128  \tloss 1.21892, train acc 74.48, train corr acc 48.96, val acc 74.05, val corr acc 48.61\n",
      "Ep 1 \titer 129  \tloss 1.59603, train acc 66.67, train corr acc 41.82, val acc 74.11, val corr acc 48.74\n",
      "Ep 1 \titer 130  \tloss 1.11730, train acc 74.48, train corr acc 47.87, val acc 74.24, val corr acc 48.99\n",
      "Ep 1 \titer 131  \tloss 1.28201, train acc 69.79, train corr acc 43.69, val acc 74.49, val corr acc 49.50\n",
      "Ep 1 \titer 132  \tloss 1.32640, train acc 68.23, train corr acc 41.35, val acc 74.05, val corr acc 48.61\n",
      "Ep 1 \titer 133  \tloss 1.27164, train acc 70.83, train corr acc 41.67, val acc 74.30, val corr acc 49.12\n",
      "Ep 1 \titer 134  \tloss 1.10038, train acc 75.52, train corr acc 51.04, val acc 73.09, val corr acc 46.73\n",
      "Ep 1 \titer 135  \tloss 1.00639, train acc 76.56, train corr acc 47.67, val acc 72.90, val corr acc 46.35\n",
      "Ep 1 \titer 136  \tloss 1.42038, train acc 70.83, train corr acc 46.15, val acc 73.98, val corr acc 48.49\n",
      "Ep 1 \titer 137  \tloss 1.04491, train acc 77.08, train corr acc 48.24, val acc 74.05, val corr acc 48.61\n",
      "Ep 1 \titer 138  \tloss 1.12165, train acc 72.40, train corr acc 47.52, val acc 74.30, val corr acc 49.12\n",
      "Ep 1 \titer 139  \tloss 1.25942, train acc 73.44, train corr acc 47.42, val acc 73.79, val corr acc 48.11\n",
      "Ep 1 \titer 140  \tloss 1.12911, train acc 76.04, train corr acc 53.06, val acc 73.79, val corr acc 48.11\n",
      "Ep 1 \titer 141  \tloss 1.26635, train acc 71.35, train corr acc 46.60, val acc 74.24, val corr acc 48.99\n",
      "Ep 1 \titer 142  \tloss 1.24423, train acc 71.35, train corr acc 44.44, val acc 73.73, val corr acc 47.98\n",
      "Ep 1 \titer 143  \tloss 1.21787, train acc 74.48, train corr acc 50.51, val acc 73.79, val corr acc 48.11\n",
      "Ep 1 \titer 144  \tloss 1.34672, train acc 72.40, train corr acc 48.04, val acc 73.41, val corr acc 47.36\n",
      "Ep 1 \titer 145  \tloss 1.23828, train acc 68.75, train corr acc 37.50, val acc 73.92, val corr acc 48.36\n",
      "Ep 1 \titer 146  \tloss 1.18855, train acc 75.00, train corr acc 48.39, val acc 73.98, val corr acc 48.49\n",
      "Ep 1 \titer 147  \tloss 1.00786, train acc 78.12, train corr acc 54.35, val acc 74.05, val corr acc 48.61\n",
      "Ep 1 \titer 148  \tloss 1.18919, train acc 71.35, train corr acc 43.88, val acc 74.30, val corr acc 49.12\n",
      "Ep 1 \titer 149  \tloss 1.30184, train acc 71.88, train corr acc 49.53, val acc 74.43, val corr acc 49.37\n",
      "Ep 1 \titer 150  \tloss 1.25934, train acc 72.40, train corr acc 48.54, val acc 74.24, val corr acc 48.99\n",
      "Ep 1 \titer 151  \tloss 1.23763, train acc 73.96, train corr acc 51.46, val acc 74.17, val corr acc 48.87\n",
      "Ep 1 \titer 152  \tloss 1.39593, train acc 71.88, train corr acc 47.06, val acc 74.05, val corr acc 48.61\n",
      "Ep 1 \titer 153  \tloss 1.09094, train acc 76.04, train corr acc 48.31, val acc 74.24, val corr acc 48.99\n",
      "Ep 1 \titer 154  \tloss 1.29881, train acc 69.79, train corr acc 42.00, val acc 73.98, val corr acc 48.49\n",
      "Ep 1 \titer 155  \tloss 1.29929, train acc 71.35, train corr acc 46.08, val acc 74.24, val corr acc 48.99\n",
      "Ep 1 \titer 156  \tloss 1.41056, train acc 68.75, train corr acc 43.40, val acc 74.05, val corr acc 48.61\n",
      "Ep 1 \titer 157  \tloss 1.21591, train acc 72.92, train corr acc 46.39, val acc 73.79, val corr acc 48.11\n",
      "Ep 1 \titer 158  \tloss 1.24826, train acc 73.44, train corr acc 49.50, val acc 74.05, val corr acc 48.61\n",
      "Ep 1 \titer 159  \tloss 1.26934, train acc 71.35, train corr acc 46.60, val acc 73.54, val corr acc 47.61\n",
      "Ep 1 \titer 160  \tloss 1.25302, train acc 68.75, train corr acc 41.75, val acc 74.17, val corr acc 48.87\n",
      "Ep 1 \titer 161  \tloss 1.11542, train acc 74.48, train corr acc 48.96, val acc 73.98, val corr acc 48.49\n",
      "Ep 1 \titer 162  \tloss 1.23310, train acc 69.27, train corr acc 43.27, val acc 74.36, val corr acc 49.24\n",
      "Ep 1 \titer 163  \tloss 1.25673, train acc 71.88, train corr acc 44.33, val acc 74.05, val corr acc 48.61\n",
      "Ep 1 \titer 164  \tloss 1.08014, train acc 73.44, train corr acc 48.48, val acc 73.85, val corr acc 48.24\n",
      "Ep 1 \titer 165  \tloss 1.39793, train acc 70.31, train corr acc 45.19, val acc 74.30, val corr acc 49.12\n",
      "Ep 1 \titer 166  \tloss 1.25112, train acc 69.79, train corr acc 47.27, val acc 74.36, val corr acc 49.24\n",
      "Ep 1 \titer 167  \tloss 1.39135, train acc 70.83, train corr acc 42.27, val acc 74.24, val corr acc 48.99\n",
      "Ep 1 \titer 168  \tloss 1.05546, train acc 76.56, train corr acc 51.09, val acc 74.36, val corr acc 49.24\n",
      "Ep 1 \titer 169  \tloss 1.24823, train acc 72.40, train corr acc 46.46, val acc 74.30, val corr acc 49.12\n",
      "Ep 1 \titer 170  \tloss 1.10911, train acc 74.48, train corr acc 47.87, val acc 73.79, val corr acc 48.11\n",
      "Ep 1 \titer 171  \tloss 1.26931, train acc 70.83, train corr acc 41.05, val acc 73.98, val corr acc 48.49\n",
      "Ep 1 \titer 172  \tloss 1.15579, train acc 72.40, train corr acc 46.46, val acc 73.92, val corr acc 48.36\n",
      "Ep 1 \titer 173  \tloss 1.08110, train acc 76.04, train corr acc 49.45, val acc 73.79, val corr acc 48.11\n",
      "Ep 1 \titer 174  \tloss 1.10075, train acc 76.04, train corr acc 47.13, val acc 73.79, val corr acc 48.11\n",
      "Ep 1 \titer 175  \tloss 1.05903, train acc 78.65, train corr acc 53.93, val acc 73.79, val corr acc 48.11\n",
      "Ep 1 \titer 176  \tloss 1.21550, train acc 73.44, train corr acc 49.50, val acc 73.92, val corr acc 48.36\n",
      "Ep 1 \titer 177  \tloss 1.18012, train acc 71.35, train corr acc 47.12, val acc 73.98, val corr acc 48.49\n",
      "Ep 1 \titer 178  \tloss 1.18142, train acc 72.92, train corr acc 49.02, val acc 73.66, val corr acc 47.86\n",
      "Ep 1 \titer 179  \tloss 1.17166, train acc 72.92, train corr acc 47.47, val acc 74.11, val corr acc 48.74\n",
      "Ep 1 \titer 180  \tloss 1.12260, train acc 74.48, train corr acc 47.87, val acc 73.92, val corr acc 48.36\n",
      "Ep 1 \titer 181  \tloss 1.13757, train acc 75.52, train corr acc 51.04, val acc 74.11, val corr acc 48.74\n",
      "Ep 1 \titer 182  \tloss 1.33040, train acc 70.83, train corr acc 42.27, val acc 74.17, val corr acc 48.87\n",
      "Ep 1 \titer 183  \tloss 1.20663, train acc 74.48, train corr acc 47.87, val acc 74.17, val corr acc 48.87\n",
      "Ep 1 \titer 184  \tloss 1.24121, train acc 71.88, train corr acc 49.53, val acc 74.43, val corr acc 49.37\n",
      "Ep 1 \titer 185  \tloss 1.10078, train acc 75.52, train corr acc 50.00, val acc 74.24, val corr acc 48.99\n",
      "Ep 1 \titer 186  \tloss 1.29869, train acc 69.79, train corr acc 43.69, val acc 74.17, val corr acc 48.87\n",
      "Ep 1 \titer 187  \tloss 1.21863, train acc 72.92, train corr acc 46.94, val acc 74.30, val corr acc 49.12\n",
      "Ep 1 \titer 188  \tloss 1.10800, train acc 73.96, train corr acc 45.65, val acc 74.49, val corr acc 49.50\n",
      "Ep 1 \titer 189  \tloss 1.29303, train acc 72.40, train corr acc 48.54, val acc 74.68, val corr acc 49.87\n",
      "Ep 1 \titer 190  \tloss 1.30470, train acc 72.40, train corr acc 48.04, val acc 74.87, val corr acc 50.25\n",
      "Ep 1 \titer 191  \tloss 1.18908, train acc 72.92, train corr acc 51.40, val acc 74.75, val corr acc 50.00\n",
      "Ep 1 \titer 192  \tloss 1.25505, train acc 71.88, train corr acc 45.45, val acc 74.68, val corr acc 49.87\n",
      "Ep 1 \titer 193  \tloss 1.17088, train acc 75.00, train corr acc 49.47, val acc 74.36, val corr acc 49.24\n",
      "Ep 1 \titer 194  \tloss 1.05194, train acc 77.08, train corr acc 53.19, val acc 74.43, val corr acc 49.37\n",
      "Ep 1 \titer 195  \tloss 1.29862, train acc 69.27, train corr acc 48.70, val acc 74.68, val corr acc 49.87\n",
      "Ep 1 \titer 196  \tloss 1.19927, train acc 70.83, train corr acc 43.43, val acc 74.68, val corr acc 49.87\n",
      "Ep 1 \titer 197  \tloss 1.22106, train acc 71.35, train corr acc 46.60, val acc 74.75, val corr acc 50.00\n",
      "Ep 1 \titer 198  \tloss 1.27383, train acc 70.83, train corr acc 42.86, val acc 74.68, val corr acc 49.87\n",
      "Ep 1 \titer 199  \tloss 1.15784, train acc 72.92, train corr acc 46.39, val acc 74.62, val corr acc 49.75\n",
      "Ep 1 \titer 200  \tloss 1.23271, train acc 71.88, train corr acc 46.00, val acc 74.94, val corr acc 50.38\n",
      "Ep 1 \titer 201  \tloss 1.28564, train acc 72.92, train corr acc 49.51, val acc 74.81, val corr acc 50.13\n",
      "Ep 1 \titer 202  \tloss 1.14058, train acc 75.00, train corr acc 48.94, val acc 74.55, val corr acc 49.62\n",
      "Ep 1 \titer 203  \tloss 1.19275, train acc 72.92, train corr acc 48.51, val acc 73.98, val corr acc 48.49\n",
      "Ep 1 \titer 204  \tloss 1.19106, train acc 70.83, train corr acc 47.17, val acc 74.55, val corr acc 49.62\n",
      "Ep 1 \titer 205  \tloss 1.18057, train acc 73.44, train corr acc 47.42, val acc 74.62, val corr acc 49.75\n",
      "Ep 1 \titer 206  \tloss 1.31633, train acc 67.71, train corr acc 37.37, val acc 74.87, val corr acc 50.25\n",
      "Ep 1 \titer 207  \tloss 1.21303, train acc 72.40, train corr acc 50.47, val acc 74.55, val corr acc 49.62\n",
      "Ep 1 \titer 208  \tloss 1.04090, train acc 77.08, train corr acc 54.64, val acc 74.87, val corr acc 50.25\n",
      "Ep 1 \titer 209  \tloss 1.12742, train acc 76.56, train corr acc 52.13, val acc 74.87, val corr acc 50.25\n",
      "Ep 1 \titer 210  \tloss 1.34203, train acc 70.83, train corr acc 45.63, val acc 74.68, val corr acc 49.87\n",
      "Ep 1 \titer 211  \tloss 1.07541, train acc 78.12, train corr acc 53.33, val acc 74.68, val corr acc 49.87\n",
      "Ep 1 \titer 212  \tloss 1.07033, train acc 72.40, train corr acc 44.79, val acc 74.94, val corr acc 50.38\n",
      "Ep 1 \titer 213  \tloss 1.24967, train acc 72.40, train corr acc 47.00, val acc 74.87, val corr acc 50.25\n",
      "Ep 1 \titer 214  \tloss 1.22898, train acc 73.44, train corr acc 47.42, val acc 75.06, val corr acc 50.63\n",
      "Ep 1 \titer 215  \tloss 1.19624, train acc 72.92, train corr acc 46.94, val acc 74.36, val corr acc 49.24\n",
      "Ep 1 \titer 216  \tloss 1.33570, train acc 66.67, train corr acc 42.20, val acc 74.43, val corr acc 49.37\n",
      "Ep 1 \titer 217  \tloss 1.00629, train acc 76.04, train corr acc 47.13, val acc 74.81, val corr acc 50.13\n",
      "Ep 1 \titer 218  \tloss 1.08949, train acc 76.04, train corr acc 48.31, val acc 75.38, val corr acc 51.26\n",
      "Ep 1 \titer 219  \tloss 1.11424, train acc 74.48, train corr acc 50.00, val acc 74.68, val corr acc 49.87\n",
      "Ep 1 \titer 220  \tloss 1.06354, train acc 75.00, train corr acc 52.48, val acc 74.75, val corr acc 50.00\n",
      "Ep 1 \titer 221  \tloss 0.99252, train acc 80.21, train corr acc 55.81, val acc 74.81, val corr acc 50.13\n",
      "Ep 1 \titer 222  \tloss 1.11993, train acc 75.52, train corr acc 51.55, val acc 74.62, val corr acc 49.75\n",
      "Ep 1 \titer 223  \tloss 0.87835, train acc 77.60, train corr acc 54.74, val acc 74.62, val corr acc 49.75\n",
      "Ep 1 \titer 224  \tloss 1.16186, train acc 76.04, train corr acc 48.89, val acc 74.36, val corr acc 49.24\n",
      "Ep 1 \titer 225  \tloss 1.02261, train acc 73.96, train corr acc 47.92, val acc 74.81, val corr acc 50.13\n",
      "Ep 1 \titer 226  \tloss 1.10141, train acc 73.96, train corr acc 48.98, val acc 74.62, val corr acc 49.75\n",
      "Ep 1 \titer 227  \tloss 1.20827, train acc 68.75, train corr acc 43.93, val acc 74.81, val corr acc 50.13\n",
      "Ep 1 \titer 228  \tloss 1.09257, train acc 75.00, train corr acc 48.94, val acc 74.94, val corr acc 50.38\n",
      "\n",
      "Epoch 2 of 8 took 61.577s\n",
      "  training loss:\t\t1.202709\n",
      "  training raw accuracy:\t\t72.87 %\n",
      "  training corrected acc:\t\t47.23 %\n",
      "  validation loss:\t\t1.151371\n",
      "  validation raw accuracy:\t\t74.30 %\n",
      "  validation corrected acc:\t\t49.12 % \n",
      "\n",
      "Ep 2 \titer 229  \tloss 1.20624, train acc 72.92, train corr acc 51.85, val acc 74.68, val corr acc 49.87\n",
      "Ep 2 \titer 230  \tloss 0.98044, train acc 78.12, train corr acc 54.35, val acc 74.17, val corr acc 48.87\n",
      "Ep 2 \titer 231  \tloss 1.12157, train acc 73.96, train corr acc 48.98, val acc 74.68, val corr acc 49.87\n",
      "Ep 2 \titer 232  \tloss 1.18874, train acc 73.44, train corr acc 47.96, val acc 74.62, val corr acc 49.75\n",
      "Ep 2 \titer 233  \tloss 1.22466, train acc 72.40, train corr acc 47.00, val acc 74.17, val corr acc 48.87\n",
      "Ep 2 \titer 234  \tloss 1.24342, train acc 72.40, train corr acc 51.38, val acc 74.24, val corr acc 48.99\n",
      "Ep 2 \titer 235  \tloss 1.23583, train acc 72.92, train corr acc 47.47, val acc 74.36, val corr acc 49.24\n",
      "Ep 2 \titer 236  \tloss 1.12818, train acc 72.40, train corr acc 45.36, val acc 73.79, val corr acc 48.11\n",
      "Ep 2 \titer 237  \tloss 1.05406, train acc 76.56, train corr acc 55.88, val acc 73.79, val corr acc 48.11\n",
      "Ep 2 \titer 238  \tloss 1.28415, train acc 68.75, train corr acc 44.44, val acc 73.60, val corr acc 47.73\n",
      "Ep 2 \titer 239  \tloss 1.13324, train acc 73.44, train corr acc 50.49, val acc 74.17, val corr acc 48.87\n",
      "Ep 2 \titer 240  \tloss 1.03725, train acc 75.52, train corr acc 50.00, val acc 74.30, val corr acc 49.12\n",
      "Ep 2 \titer 241  \tloss 1.16485, train acc 75.52, train corr acc 47.78, val acc 74.62, val corr acc 49.75\n",
      "Ep 2 \titer 242  \tloss 1.17678, train acc 73.96, train corr acc 47.92, val acc 74.43, val corr acc 49.37\n",
      "Ep 2 \titer 243  \tloss 1.37512, train acc 69.79, train corr acc 47.27, val acc 74.55, val corr acc 49.62\n",
      "Ep 2 \titer 244  \tloss 1.04013, train acc 76.04, train corr acc 51.06, val acc 74.17, val corr acc 48.87\n",
      "Ep 2 \titer 245  \tloss 1.10775, train acc 75.00, train corr acc 53.40, val acc 73.73, val corr acc 47.98\n",
      "Ep 2 \titer 246  \tloss 1.23425, train acc 70.31, train corr acc 45.19, val acc 73.28, val corr acc 47.10\n",
      "Ep 2 \titer 247  \tloss 1.21245, train acc 70.83, train corr acc 41.67, val acc 73.54, val corr acc 47.61\n",
      "Ep 2 \titer 248  \tloss 1.06957, train acc 75.52, train corr acc 51.04, val acc 74.30, val corr acc 49.12\n",
      "Ep 2 \titer 249  \tloss 0.99360, train acc 77.08, train corr acc 48.84, val acc 74.81, val corr acc 50.13\n",
      "Ep 2 \titer 250  \tloss 1.19584, train acc 74.48, train corr acc 52.88, val acc 74.17, val corr acc 48.87\n",
      "Ep 2 \titer 251  \tloss 1.00083, train acc 76.56, train corr acc 47.06, val acc 74.49, val corr acc 49.50\n",
      "Ep 2 \titer 252  \tloss 1.05522, train acc 75.52, train corr acc 53.47, val acc 74.17, val corr acc 48.87\n",
      "Ep 2 \titer 253  \tloss 1.14518, train acc 75.52, train corr acc 51.55, val acc 74.36, val corr acc 49.24\n",
      "Ep 2 \titer 254  \tloss 1.04676, train acc 75.52, train corr acc 52.04, val acc 74.81, val corr acc 50.13\n",
      "Ep 2 \titer 255  \tloss 1.30381, train acc 71.35, train corr acc 46.60, val acc 74.87, val corr acc 50.25\n",
      "Ep 2 \titer 256  \tloss 1.17122, train acc 72.40, train corr acc 46.46, val acc 74.55, val corr acc 49.62\n",
      "Ep 2 \titer 257  \tloss 1.14673, train acc 74.48, train corr acc 50.51, val acc 74.30, val corr acc 49.12\n",
      "Ep 2 \titer 258  \tloss 1.27225, train acc 73.44, train corr acc 50.00, val acc 74.24, val corr acc 48.99\n",
      "Ep 2 \titer 259  \tloss 1.13518, train acc 72.92, train corr acc 45.83, val acc 74.75, val corr acc 50.00\n",
      "Ep 2 \titer 260  \tloss 1.10094, train acc 76.04, train corr acc 50.54, val acc 74.62, val corr acc 49.75\n",
      "Ep 2 \titer 261  \tloss 0.92178, train acc 79.17, train corr acc 56.52, val acc 74.05, val corr acc 48.61\n",
      "Ep 2 \titer 262  \tloss 1.08419, train acc 72.92, train corr acc 46.94, val acc 74.30, val corr acc 49.12\n",
      "Ep 2 \titer 263  \tloss 1.23501, train acc 70.83, train corr acc 47.66, val acc 74.68, val corr acc 49.87\n",
      "Ep 2 \titer 264  \tloss 1.24336, train acc 70.83, train corr acc 45.63, val acc 75.00, val corr acc 50.50\n",
      "Ep 2 \titer 265  \tloss 1.20542, train acc 73.44, train corr acc 50.49, val acc 74.55, val corr acc 49.62\n",
      "Ep 2 \titer 266  \tloss 1.30791, train acc 71.35, train corr acc 46.08, val acc 74.36, val corr acc 49.24\n",
      "Ep 2 \titer 267  \tloss 0.95695, train acc 78.65, train corr acc 53.93, val acc 74.30, val corr acc 49.12\n",
      "Ep 2 \titer 268  \tloss 1.23521, train acc 71.88, train corr acc 46.00, val acc 74.36, val corr acc 49.24\n",
      "Ep 2 \titer 269  \tloss 1.16302, train acc 73.44, train corr acc 50.00, val acc 74.36, val corr acc 49.24\n",
      "Ep 2 \titer 270  \tloss 1.29184, train acc 70.83, train corr acc 47.17, val acc 74.62, val corr acc 49.75\n",
      "Ep 2 \titer 271  \tloss 1.06908, train acc 74.48, train corr acc 49.48, val acc 74.11, val corr acc 48.74\n",
      "Ep 2 \titer 272  \tloss 1.15183, train acc 74.48, train corr acc 51.49, val acc 74.11, val corr acc 48.74\n",
      "Ep 2 \titer 273  \tloss 1.14988, train acc 72.92, train corr acc 49.51, val acc 74.43, val corr acc 49.37\n",
      "Ep 2 \titer 274  \tloss 1.19739, train acc 70.83, train corr acc 45.63, val acc 74.24, val corr acc 48.99\n",
      "Ep 2 \titer 275  \tloss 0.99878, train acc 75.52, train corr acc 51.04, val acc 75.13, val corr acc 50.76\n",
      "Ep 2 \titer 276  \tloss 1.15563, train acc 70.83, train corr acc 46.15, val acc 74.81, val corr acc 50.13\n",
      "Ep 2 \titer 277  \tloss 1.16701, train acc 72.92, train corr acc 46.39, val acc 74.68, val corr acc 49.87\n",
      "Ep 2 \titer 278  \tloss 0.97466, train acc 78.12, train corr acc 57.58, val acc 74.75, val corr acc 50.00\n",
      "Ep 2 \titer 279  \tloss 1.31567, train acc 70.83, train corr acc 46.15, val acc 74.30, val corr acc 49.12\n",
      "Ep 2 \titer 280  \tloss 1.14359, train acc 71.35, train corr acc 50.00, val acc 74.55, val corr acc 49.62\n",
      "Ep 2 \titer 281  \tloss 1.27244, train acc 72.40, train corr acc 45.36, val acc 74.62, val corr acc 49.75\n",
      "Ep 2 \titer 282  \tloss 0.97308, train acc 78.65, train corr acc 55.43, val acc 74.55, val corr acc 49.62\n",
      "Ep 2 \titer 283  \tloss 1.12105, train acc 76.56, train corr acc 54.55, val acc 74.49, val corr acc 49.50\n",
      "Ep 2 \titer 284  \tloss 1.02389, train acc 76.04, train corr acc 51.06, val acc 74.49, val corr acc 49.50\n",
      "Ep 2 \titer 285  \tloss 1.17110, train acc 73.96, train corr acc 47.37, val acc 74.55, val corr acc 49.62\n",
      "Ep 2 \titer 286  \tloss 1.05473, train acc 70.83, train corr acc 43.43, val acc 74.75, val corr acc 50.00\n",
      "Ep 2 \titer 287  \tloss 0.93963, train acc 78.12, train corr acc 53.85, val acc 74.81, val corr acc 50.13\n",
      "Ep 2 \titer 288  \tloss 1.01670, train acc 76.56, train corr acc 48.28, val acc 74.87, val corr acc 50.25\n",
      "Ep 2 \titer 289  \tloss 0.96006, train acc 77.60, train corr acc 51.69, val acc 74.94, val corr acc 50.38\n",
      "Ep 2 \titer 290  \tloss 1.10464, train acc 75.52, train corr acc 53.47, val acc 75.06, val corr acc 50.63\n",
      "Ep 2 \titer 291  \tloss 1.05613, train acc 74.48, train corr acc 52.88, val acc 74.81, val corr acc 50.13\n",
      "Ep 2 \titer 292  \tloss 1.02608, train acc 75.52, train corr acc 53.92, val acc 74.75, val corr acc 50.00\n",
      "Ep 2 \titer 293  \tloss 1.07914, train acc 74.48, train corr acc 50.51, val acc 75.51, val corr acc 51.51\n",
      "Ep 2 \titer 294  \tloss 0.98507, train acc 77.08, train corr acc 53.19, val acc 74.62, val corr acc 49.75\n",
      "Ep 2 \titer 295  \tloss 1.03625, train acc 78.12, train corr acc 56.25, val acc 75.19, val corr acc 50.88\n",
      "Ep 2 \titer 296  \tloss 1.19246, train acc 71.88, train corr acc 44.33, val acc 75.38, val corr acc 51.26\n",
      "Ep 2 \titer 297  \tloss 1.11732, train acc 75.52, train corr acc 50.00, val acc 75.13, val corr acc 50.76\n",
      "Ep 2 \titer 298  \tloss 1.09137, train acc 75.00, train corr acc 55.14, val acc 75.32, val corr acc 51.13\n",
      "Ep 2 \titer 299  \tloss 1.01006, train acc 75.00, train corr acc 48.94, val acc 75.38, val corr acc 51.26\n",
      "Ep 2 \titer 300  \tloss 1.17091, train acc 73.44, train corr acc 50.49, val acc 74.94, val corr acc 50.38\n",
      "Ep 2 \titer 301  \tloss 1.09501, train acc 75.00, train corr acc 51.02, val acc 74.75, val corr acc 50.00\n",
      "Ep 2 \titer 302  \tloss 0.98180, train acc 76.04, train corr acc 50.00, val acc 75.32, val corr acc 51.13\n",
      "Ep 2 \titer 303  \tloss 1.22948, train acc 70.83, train corr acc 45.63, val acc 75.32, val corr acc 51.13\n",
      "Ep 2 \titer 304  \tloss 1.21601, train acc 71.35, train corr acc 46.08, val acc 74.94, val corr acc 50.38\n",
      "Ep 2 \titer 305  \tloss 1.07470, train acc 73.96, train corr acc 53.27, val acc 75.57, val corr acc 51.64\n",
      "Ep 2 \titer 306  \tloss 1.11885, train acc 73.96, train corr acc 49.49, val acc 75.13, val corr acc 50.76\n",
      "Ep 2 \titer 307  \tloss 1.12227, train acc 75.00, train corr acc 49.47, val acc 75.06, val corr acc 50.63\n",
      "Ep 2 \titer 308  \tloss 1.00651, train acc 76.56, train corr acc 52.13, val acc 75.06, val corr acc 50.63\n",
      "Ep 2 \titer 309  \tloss 1.19760, train acc 72.92, train corr acc 54.78, val acc 75.25, val corr acc 51.01\n",
      "Ep 2 \titer 310  \tloss 1.16075, train acc 71.88, train corr acc 45.45, val acc 74.30, val corr acc 49.12\n",
      "Ep 2 \titer 311  \tloss 1.08590, train acc 75.00, train corr acc 53.40, val acc 75.13, val corr acc 50.76\n",
      "Ep 2 \titer 312  \tloss 1.16468, train acc 71.88, train corr acc 44.90, val acc 74.68, val corr acc 49.87\n",
      "Ep 2 \titer 313  \tloss 1.05463, train acc 73.44, train corr acc 47.42, val acc 75.00, val corr acc 50.50\n",
      "Ep 2 \titer 314  \tloss 1.13861, train acc 72.40, train corr acc 47.00, val acc 75.57, val corr acc 51.64\n",
      "Ep 2 \titer 315  \tloss 1.16837, train acc 73.44, train corr acc 50.49, val acc 74.81, val corr acc 50.13\n",
      "Ep 2 \titer 316  \tloss 1.07596, train acc 73.96, train corr acc 46.81, val acc 75.19, val corr acc 50.88\n",
      "Ep 2 \titer 317  \tloss 1.09571, train acc 73.44, train corr acc 49.50, val acc 75.06, val corr acc 50.63\n",
      "Ep 2 \titer 318  \tloss 1.11727, train acc 72.92, train corr acc 50.94, val acc 74.81, val corr acc 50.13\n",
      "Ep 2 \titer 319  \tloss 1.05106, train acc 73.96, train corr acc 48.45, val acc 75.32, val corr acc 51.13\n",
      "Ep 2 \titer 320  \tloss 1.20844, train acc 70.31, train corr acc 42.42, val acc 75.13, val corr acc 50.76\n",
      "Ep 2 \titer 321  \tloss 1.10138, train acc 74.48, train corr acc 54.21, val acc 75.19, val corr acc 50.88\n",
      "Ep 2 \titer 322  \tloss 0.94708, train acc 79.69, train corr acc 59.79, val acc 75.19, val corr acc 50.88\n",
      "Ep 2 \titer 323  \tloss 1.02082, train acc 77.60, train corr acc 54.26, val acc 75.13, val corr acc 50.76\n",
      "Ep 2 \titer 324  \tloss 1.22028, train acc 71.35, train corr acc 46.60, val acc 74.94, val corr acc 50.38\n",
      "Ep 2 \titer 325  \tloss 0.99361, train acc 78.12, train corr acc 53.33, val acc 74.81, val corr acc 50.13\n",
      "Ep 2 \titer 326  \tloss 0.95418, train acc 75.00, train corr acc 50.00, val acc 75.51, val corr acc 51.51\n",
      "Ep 2 \titer 327  \tloss 1.16434, train acc 73.44, train corr acc 49.00, val acc 75.19, val corr acc 50.88\n",
      "Ep 2 \titer 328  \tloss 1.13554, train acc 73.96, train corr acc 48.45, val acc 75.38, val corr acc 51.26\n",
      "Ep 2 \titer 329  \tloss 1.13914, train acc 76.04, train corr acc 53.06, val acc 75.13, val corr acc 50.76\n",
      "Ep 2 \titer 330  \tloss 1.20642, train acc 68.75, train corr acc 44.95, val acc 74.68, val corr acc 49.87\n",
      "Ep 2 \titer 331  \tloss 0.93024, train acc 77.60, train corr acc 50.57, val acc 74.68, val corr acc 50.00\n",
      "Ep 2 \titer 332  \tloss 0.99803, train acc 77.60, train corr acc 51.69, val acc 74.87, val corr acc 50.25\n",
      "Ep 2 \titer 333  \tloss 1.01750, train acc 74.48, train corr acc 50.00, val acc 74.94, val corr acc 50.38\n",
      "Ep 2 \titer 334  \tloss 0.97862, train acc 76.04, train corr acc 54.46, val acc 75.38, val corr acc 51.26\n",
      "Ep 2 \titer 335  \tloss 0.94830, train acc 79.17, train corr acc 53.49, val acc 75.32, val corr acc 51.13\n",
      "Ep 2 \titer 336  \tloss 1.07733, train acc 76.04, train corr acc 52.58, val acc 75.25, val corr acc 51.01\n",
      "Ep 2 \titer 337  \tloss 0.81198, train acc 80.21, train corr acc 60.00, val acc 75.13, val corr acc 50.76\n",
      "Ep 2 \titer 338  \tloss 1.09930, train acc 75.00, train corr acc 46.67, val acc 74.94, val corr acc 50.38\n",
      "Ep 2 \titer 339  \tloss 0.94925, train acc 75.52, train corr acc 51.04, val acc 75.25, val corr acc 51.01\n",
      "Ep 2 \titer 340  \tloss 1.03081, train acc 76.04, train corr acc 53.06, val acc 75.70, val corr acc 51.89\n",
      "Ep 2 \titer 341  \tloss 1.13820, train acc 70.31, train corr acc 46.73, val acc 75.00, val corr acc 50.50\n",
      "Ep 2 \titer 342  \tloss 0.99051, train acc 76.04, train corr acc 51.06, val acc 75.38, val corr acc 51.26\n",
      "\n",
      "Epoch 3 of 8 took 62.968s\n",
      "  training loss:\t\t1.108536\n",
      "  training raw accuracy:\t\t74.28 %\n",
      "  training corrected acc:\t\t49.95 %\n",
      "  validation loss:\t\t1.111695\n",
      "  validation raw accuracy:\t\t75.76 %\n",
      "  validation corrected acc:\t\t52.02 % \n",
      "\n",
      "Ep 3 \titer 343  \tloss 1.15092, train acc 72.40, train corr acc 50.93, val acc 75.25, val corr acc 51.01\n",
      "Ep 3 \titer 344  \tloss 0.92257, train acc 77.08, train corr acc 52.17, val acc 75.25, val corr acc 51.01\n",
      "Ep 3 \titer 345  \tloss 1.04326, train acc 76.56, train corr acc 54.08, val acc 75.32, val corr acc 51.13\n",
      "Ep 3 \titer 346  \tloss 1.16727, train acc 70.83, train corr acc 42.86, val acc 75.38, val corr acc 51.26\n",
      "Ep 3 \titer 347  \tloss 1.13865, train acc 74.48, train corr acc 51.00, val acc 74.87, val corr acc 50.25\n",
      "Ep 3 \titer 348  \tloss 1.14725, train acc 72.92, train corr acc 52.29, val acc 74.62, val corr acc 49.75\n",
      "Ep 3 \titer 349  \tloss 1.17947, train acc 72.92, train corr acc 47.47, val acc 75.38, val corr acc 51.26\n",
      "Ep 3 \titer 350  \tloss 1.05013, train acc 74.48, train corr acc 49.48, val acc 75.32, val corr acc 51.13\n",
      "Ep 3 \titer 351  \tloss 0.97752, train acc 75.52, train corr acc 53.92, val acc 75.83, val corr acc 52.14\n",
      "Ep 3 \titer 352  \tloss 1.24062, train acc 70.83, train corr acc 48.15, val acc 75.32, val corr acc 51.13\n",
      "Ep 3 \titer 353  \tloss 1.08306, train acc 73.44, train corr acc 50.49, val acc 75.83, val corr acc 52.14\n",
      "Ep 3 \titer 354  \tloss 0.99248, train acc 76.04, train corr acc 51.06, val acc 75.19, val corr acc 50.88\n",
      "Ep 3 \titer 355  \tloss 1.08027, train acc 79.17, train corr acc 55.56, val acc 75.25, val corr acc 51.01\n",
      "Ep 3 \titer 356  \tloss 1.14449, train acc 73.44, train corr acc 46.88, val acc 75.51, val corr acc 51.51\n",
      "Ep 3 \titer 357  \tloss 1.20345, train acc 73.96, train corr acc 54.55, val acc 75.45, val corr acc 51.39\n",
      "Ep 3 \titer 358  \tloss 0.93518, train acc 78.65, train corr acc 56.38, val acc 74.94, val corr acc 50.38\n",
      "Ep 3 \titer 359  \tloss 1.07099, train acc 71.88, train corr acc 47.57, val acc 74.68, val corr acc 49.87\n",
      "Ep 3 \titer 360  \tloss 1.10635, train acc 75.00, train corr acc 53.85, val acc 75.25, val corr acc 51.01\n",
      "Ep 3 \titer 361  \tloss 1.12973, train acc 71.88, train corr acc 43.75, val acc 75.13, val corr acc 50.76\n",
      "Ep 3 \titer 362  \tloss 0.96937, train acc 76.56, train corr acc 53.12, val acc 75.64, val corr acc 51.76\n",
      "Ep 3 \titer 363  \tloss 0.89571, train acc 76.04, train corr acc 46.51, val acc 75.70, val corr acc 51.89\n",
      "Ep 3 \titer 364  \tloss 1.15006, train acc 71.35, train corr acc 47.12, val acc 75.38, val corr acc 51.26\n",
      "Ep 3 \titer 365  \tloss 0.90351, train acc 76.56, train corr acc 47.06, val acc 75.19, val corr acc 50.88\n",
      "Ep 3 \titer 366  \tloss 1.01471, train acc 75.00, train corr acc 52.48, val acc 75.38, val corr acc 51.26\n",
      "Ep 3 \titer 367  \tloss 0.99282, train acc 78.12, train corr acc 56.70, val acc 75.45, val corr acc 51.39\n",
      "Ep 3 \titer 368  \tloss 0.98141, train acc 77.08, train corr acc 55.10, val acc 75.06, val corr acc 50.63\n",
      "Ep 3 \titer 369  \tloss 1.19876, train acc 71.35, train corr acc 46.60, val acc 75.32, val corr acc 51.13\n",
      "Ep 3 \titer 370  \tloss 1.06554, train acc 72.92, train corr acc 47.47, val acc 75.64, val corr acc 51.76\n",
      "Ep 3 \titer 371  \tloss 1.06491, train acc 77.08, train corr acc 55.56, val acc 75.70, val corr acc 51.89\n",
      "Ep 3 \titer 372  \tloss 1.15893, train acc 73.96, train corr acc 50.98, val acc 75.13, val corr acc 50.76\n",
      "Ep 3 \titer 373  \tloss 1.09920, train acc 73.44, train corr acc 46.88, val acc 75.32, val corr acc 51.13\n",
      "Ep 3 \titer 374  \tloss 1.01951, train acc 77.08, train corr acc 52.69, val acc 75.32, val corr acc 51.13\n",
      "Ep 3 \titer 375  \tloss 0.90495, train acc 77.08, train corr acc 52.17, val acc 75.57, val corr acc 51.64\n",
      "Ep 3 \titer 376  \tloss 1.00844, train acc 76.56, train corr acc 54.08, val acc 75.45, val corr acc 51.39\n",
      "Ep 3 \titer 377  \tloss 1.12190, train acc 75.00, train corr acc 55.14, val acc 75.83, val corr acc 52.14\n",
      "Ep 3 \titer 378  \tloss 1.16212, train acc 71.88, train corr acc 47.57, val acc 75.51, val corr acc 51.51\n",
      "Ep 3 \titer 379  \tloss 1.12240, train acc 75.52, train corr acc 54.37, val acc 75.19, val corr acc 50.88\n",
      "Ep 3 \titer 380  \tloss 1.17342, train acc 73.44, train corr acc 50.00, val acc 75.57, val corr acc 51.64\n",
      "Ep 3 \titer 381  \tloss 0.89553, train acc 80.21, train corr acc 57.30, val acc 75.25, val corr acc 51.01\n",
      "Ep 3 \titer 382  \tloss 1.13598, train acc 74.48, train corr acc 51.00, val acc 75.25, val corr acc 51.01\n",
      "Ep 3 \titer 383  \tloss 1.05916, train acc 75.00, train corr acc 52.94, val acc 74.68, val corr acc 49.87\n",
      "Ep 3 \titer 384  \tloss 1.18472, train acc 72.40, train corr acc 50.00, val acc 75.00, val corr acc 50.50\n",
      "Ep 3 \titer 385  \tloss 0.95249, train acc 76.04, train corr acc 52.58, val acc 75.38, val corr acc 51.26\n",
      "Ep 3 \titer 386  \tloss 1.08282, train acc 75.52, train corr acc 53.47, val acc 75.13, val corr acc 50.76\n",
      "Ep 3 \titer 387  \tloss 1.06639, train acc 74.48, train corr acc 52.43, val acc 74.87, val corr acc 50.25\n",
      "Ep 3 \titer 388  \tloss 1.06168, train acc 73.96, train corr acc 51.46, val acc 75.25, val corr acc 51.01\n",
      "Ep 3 \titer 389  \tloss 0.90731, train acc 78.12, train corr acc 56.25, val acc 75.25, val corr acc 51.01\n",
      "Ep 3 \titer 390  \tloss 1.07917, train acc 74.48, train corr acc 52.88, val acc 75.32, val corr acc 51.13\n",
      "Ep 3 \titer 391  \tloss 1.06235, train acc 73.96, train corr acc 48.45, val acc 76.02, val corr acc 52.52\n",
      "Ep 3 \titer 392  \tloss 0.89863, train acc 79.69, train corr acc 60.61, val acc 75.76, val corr acc 52.02\n",
      "Ep 3 \titer 393  \tloss 1.17470, train acc 73.96, train corr acc 51.92, val acc 75.70, val corr acc 51.89\n",
      "Ep 3 \titer 394  \tloss 1.06843, train acc 74.48, train corr acc 55.45, val acc 75.89, val corr acc 52.27\n",
      "Ep 3 \titer 395  \tloss 1.22247, train acc 73.44, train corr acc 47.42, val acc 75.51, val corr acc 51.51\n",
      "Ep 3 \titer 396  \tloss 0.87203, train acc 80.73, train corr acc 59.78, val acc 75.19, val corr acc 50.88\n",
      "Ep 3 \titer 397  \tloss 1.01325, train acc 77.08, train corr acc 55.56, val acc 75.89, val corr acc 52.27\n",
      "Ep 3 \titer 398  \tloss 0.96311, train acc 76.04, train corr acc 51.06, val acc 75.64, val corr acc 51.76\n",
      "Ep 3 \titer 399  \tloss 1.14153, train acc 72.92, train corr acc 45.26, val acc 75.83, val corr acc 52.14\n",
      "Ep 3 \titer 400  \tloss 1.00504, train acc 74.48, train corr acc 50.51, val acc 75.89, val corr acc 52.27\n",
      "Ep 3 \titer 401  \tloss 0.85208, train acc 80.73, train corr acc 59.34, val acc 75.64, val corr acc 51.76\n",
      "Ep 3 \titer 402  \tloss 0.92957, train acc 78.12, train corr acc 51.72, val acc 75.95, val corr acc 52.39\n",
      "Ep 3 \titer 403  \tloss 0.88957, train acc 79.69, train corr acc 56.18, val acc 75.95, val corr acc 52.39\n",
      "Ep 3 \titer 404  \tloss 1.02255, train acc 76.04, train corr acc 54.46, val acc 75.25, val corr acc 51.01\n",
      "Ep 3 \titer 405  \tloss 0.98089, train acc 74.48, train corr acc 52.88, val acc 75.83, val corr acc 52.14\n",
      "Ep 3 \titer 406  \tloss 0.91508, train acc 80.21, train corr acc 62.75, val acc 75.51, val corr acc 51.51\n",
      "Ep 3 \titer 407  \tloss 1.03507, train acc 75.00, train corr acc 51.52, val acc 75.83, val corr acc 52.14\n",
      "Ep 3 \titer 408  \tloss 0.89471, train acc 76.56, train corr acc 52.13, val acc 75.45, val corr acc 51.39\n",
      "Ep 3 \titer 409  \tloss 0.94499, train acc 79.17, train corr acc 58.33, val acc 75.64, val corr acc 51.76\n",
      "Ep 3 \titer 410  \tloss 1.06860, train acc 75.00, train corr acc 50.52, val acc 76.02, val corr acc 52.52\n",
      "Ep 3 \titer 411  \tloss 1.05801, train acc 74.48, train corr acc 47.87, val acc 75.83, val corr acc 52.14\n",
      "Ep 3 \titer 412  \tloss 0.98416, train acc 74.48, train corr acc 54.21, val acc 75.76, val corr acc 52.02\n",
      "Ep 3 \titer 413  \tloss 0.96830, train acc 75.52, train corr acc 50.00, val acc 75.45, val corr acc 51.39\n",
      "Ep 3 \titer 414  \tloss 1.06655, train acc 75.52, train corr acc 54.37, val acc 75.83, val corr acc 52.14\n",
      "Ep 3 \titer 415  \tloss 1.01805, train acc 75.52, train corr acc 52.04, val acc 75.76, val corr acc 52.02\n",
      "Ep 3 \titer 416  \tloss 0.91250, train acc 77.08, train corr acc 52.17, val acc 75.38, val corr acc 51.26\n",
      "Ep 3 \titer 417  \tloss 1.10481, train acc 73.96, train corr acc 51.46, val acc 75.45, val corr acc 51.39\n",
      "Ep 3 \titer 418  \tloss 1.10583, train acc 72.40, train corr acc 48.04, val acc 76.02, val corr acc 52.52\n",
      "Ep 3 \titer 419  \tloss 1.02548, train acc 77.08, train corr acc 58.88, val acc 75.51, val corr acc 51.51\n",
      "Ep 3 \titer 420  \tloss 1.01642, train acc 75.52, train corr acc 52.53, val acc 75.32, val corr acc 51.13\n",
      "Ep 3 \titer 421  \tloss 1.02104, train acc 75.52, train corr acc 50.53, val acc 74.94, val corr acc 50.38\n",
      "Ep 3 \titer 422  \tloss 0.94171, train acc 77.60, train corr acc 54.26, val acc 75.45, val corr acc 51.39\n",
      "Ep 3 \titer 423  \tloss 1.09121, train acc 73.96, train corr acc 56.52, val acc 75.64, val corr acc 51.76\n",
      "Ep 3 \titer 424  \tloss 1.07661, train acc 73.44, train corr acc 48.48, val acc 75.76, val corr acc 52.02\n",
      "Ep 3 \titer 425  \tloss 1.04383, train acc 75.52, train corr acc 54.37, val acc 75.95, val corr acc 52.39\n",
      "Ep 3 \titer 426  \tloss 1.10269, train acc 73.44, train corr acc 47.96, val acc 76.53, val corr acc 53.53\n",
      "Ep 3 \titer 427  \tloss 0.95390, train acc 76.04, train corr acc 52.58, val acc 76.27, val corr acc 53.02\n",
      "Ep 3 \titer 428  \tloss 1.04831, train acc 72.40, train corr acc 47.00, val acc 75.89, val corr acc 52.27\n",
      "Ep 3 \titer 429  \tloss 1.06963, train acc 72.92, train corr acc 49.51, val acc 75.64, val corr acc 51.76\n",
      "Ep 3 \titer 430  \tloss 1.03865, train acc 76.56, train corr acc 52.13, val acc 75.64, val corr acc 51.76\n",
      "Ep 3 \titer 431  \tloss 1.04134, train acc 75.00, train corr acc 52.48, val acc 75.70, val corr acc 51.89\n",
      "Ep 3 \titer 432  \tloss 1.04460, train acc 71.35, train corr acc 48.11, val acc 75.57, val corr acc 51.64\n",
      "Ep 3 \titer 433  \tloss 0.96970, train acc 76.56, train corr acc 53.61, val acc 75.76, val corr acc 52.02\n",
      "Ep 3 \titer 434  \tloss 1.09257, train acc 72.92, train corr acc 47.47, val acc 75.25, val corr acc 51.01\n",
      "Ep 3 \titer 435  \tloss 1.05765, train acc 73.44, train corr acc 52.34, val acc 75.32, val corr acc 51.13\n",
      "Ep 3 \titer 436  \tloss 0.93498, train acc 76.04, train corr acc 52.58, val acc 75.89, val corr acc 52.27\n",
      "Ep 3 \titer 437  \tloss 0.95467, train acc 77.08, train corr acc 53.19, val acc 75.57, val corr acc 51.64\n",
      "Ep 3 \titer 438  \tloss 1.16215, train acc 70.31, train corr acc 44.66, val acc 75.89, val corr acc 52.27\n",
      "Ep 3 \titer 439  \tloss 0.89865, train acc 78.65, train corr acc 54.44, val acc 75.70, val corr acc 51.89\n",
      "Ep 3 \titer 440  \tloss 0.90660, train acc 75.52, train corr acc 51.04, val acc 75.25, val corr acc 51.01\n",
      "Ep 3 \titer 441  \tloss 1.10718, train acc 73.44, train corr acc 49.00, val acc 75.38, val corr acc 51.26\n",
      "Ep 3 \titer 442  \tloss 1.04738, train acc 75.52, train corr acc 51.55, val acc 75.45, val corr acc 51.39\n",
      "Ep 3 \titer 443  \tloss 0.99464, train acc 77.60, train corr acc 56.12, val acc 75.83, val corr acc 52.14\n",
      "Ep 3 \titer 444  \tloss 1.17355, train acc 69.79, train corr acc 46.79, val acc 75.25, val corr acc 51.01\n",
      "Ep 3 \titer 445  \tloss 0.89882, train acc 76.56, train corr acc 48.28, val acc 75.70, val corr acc 51.89\n",
      "Ep 3 \titer 446  \tloss 0.93608, train acc 76.04, train corr acc 48.31, val acc 75.70, val corr acc 51.89\n",
      "Ep 3 \titer 447  \tloss 0.95790, train acc 79.17, train corr acc 59.18, val acc 75.06, val corr acc 50.63\n",
      "Ep 3 \titer 448  \tloss 0.98017, train acc 76.56, train corr acc 55.45, val acc 75.19, val corr acc 50.88\n",
      "Ep 3 \titer 449  \tloss 0.89973, train acc 78.65, train corr acc 52.33, val acc 75.25, val corr acc 51.01\n",
      "Ep 3 \titer 450  \tloss 1.01001, train acc 76.56, train corr acc 53.61, val acc 75.38, val corr acc 51.26\n",
      "Ep 3 \titer 451  \tloss 0.77846, train acc 82.29, train corr acc 64.21, val acc 75.13, val corr acc 50.76\n",
      "Ep 3 \titer 452  \tloss 1.04125, train acc 75.52, train corr acc 47.78, val acc 75.70, val corr acc 51.89\n",
      "Ep 3 \titer 453  \tloss 0.89130, train acc 78.12, train corr acc 56.25, val acc 75.51, val corr acc 51.51\n",
      "Ep 3 \titer 454  \tloss 1.00511, train acc 76.04, train corr acc 53.06, val acc 75.25, val corr acc 51.01\n",
      "Ep 3 \titer 455  \tloss 1.11394, train acc 70.31, train corr acc 46.73, val acc 75.57, val corr acc 51.64\n",
      "Ep 3 \titer 456  \tloss 0.92874, train acc 77.60, train corr acc 54.26, val acc 75.64, val corr acc 51.76\n",
      "\n",
      "Epoch 4 of 8 took 72.134s\n",
      "  training loss:\t\t1.031808\n",
      "  training raw accuracy:\t\t75.35 %\n",
      "  training corrected acc:\t\t52.00 %\n",
      "  validation loss:\t\t1.065495\n",
      "  validation raw accuracy:\t\t75.70 %\n",
      "  validation corrected acc:\t\t51.89 % \n",
      "\n",
      "Ep 4 \titer 457  \tloss 1.10581, train acc 75.00, train corr acc 55.56, val acc 75.38, val corr acc 51.26\n",
      "Ep 4 \titer 458  \tloss 0.88692, train acc 78.12, train corr acc 54.35, val acc 75.57, val corr acc 51.64\n",
      "Ep 4 \titer 459  \tloss 1.01144, train acc 75.00, train corr acc 51.02, val acc 74.87, val corr acc 50.25\n",
      "Ep 4 \titer 460  \tloss 1.12950, train acc 72.40, train corr acc 45.92, val acc 75.25, val corr acc 51.01\n",
      "Ep 4 \titer 461  \tloss 1.07563, train acc 73.44, train corr acc 49.00, val acc 74.62, val corr acc 49.75\n",
      "Ep 4 \titer 462  \tloss 1.07829, train acc 73.44, train corr acc 53.21, val acc 74.75, val corr acc 50.00\n",
      "Ep 4 \titer 463  \tloss 1.03612, train acc 75.52, train corr acc 52.53, val acc 74.62, val corr acc 49.75\n",
      "Ep 4 \titer 464  \tloss 1.02285, train acc 74.48, train corr acc 49.48, val acc 74.87, val corr acc 50.25\n",
      "Ep 4 \titer 465  \tloss 0.94158, train acc 75.00, train corr acc 52.94, val acc 75.06, val corr acc 50.63\n",
      "Ep 4 \titer 466  \tloss 1.20401, train acc 70.83, train corr acc 48.15, val acc 75.51, val corr acc 51.51\n",
      "Ep 4 \titer 467  \tloss 0.98118, train acc 74.48, train corr acc 52.43, val acc 75.57, val corr acc 51.64\n",
      "Ep 4 \titer 468  \tloss 0.95168, train acc 76.56, train corr acc 52.13, val acc 75.32, val corr acc 51.13\n",
      "Ep 4 \titer 469  \tloss 1.00695, train acc 78.65, train corr acc 54.44, val acc 75.13, val corr acc 50.76\n",
      "Ep 4 \titer 470  \tloss 1.07741, train acc 73.96, train corr acc 47.92, val acc 75.70, val corr acc 51.89\n",
      "Ep 4 \titer 471  \tloss 1.10629, train acc 73.96, train corr acc 54.55, val acc 75.25, val corr acc 51.01\n",
      "Ep 4 \titer 472  \tloss 0.91165, train acc 77.08, train corr acc 53.19, val acc 75.13, val corr acc 50.76\n",
      "Ep 4 \titer 473  \tloss 0.98988, train acc 73.96, train corr acc 51.46, val acc 75.13, val corr acc 50.76\n",
      "Ep 4 \titer 474  \tloss 1.00906, train acc 77.08, train corr acc 57.69, val acc 75.00, val corr acc 50.50\n",
      "Ep 4 \titer 475  \tloss 1.07094, train acc 72.40, train corr acc 44.79, val acc 75.00, val corr acc 50.50\n",
      "Ep 4 \titer 476  \tloss 0.93050, train acc 76.04, train corr acc 52.08, val acc 75.13, val corr acc 50.76\n",
      "Ep 4 \titer 477  \tloss 0.84103, train acc 79.69, train corr acc 54.65, val acc 74.94, val corr acc 50.38\n",
      "Ep 4 \titer 478  \tloss 1.11280, train acc 72.92, train corr acc 50.00, val acc 75.45, val corr acc 51.39\n",
      "Ep 4 \titer 479  \tloss 0.87535, train acc 77.08, train corr acc 48.24, val acc 74.94, val corr acc 50.38\n",
      "Ep 4 \titer 480  \tloss 1.00342, train acc 75.00, train corr acc 52.48, val acc 74.81, val corr acc 50.13\n",
      "Ep 4 \titer 481  \tloss 0.95987, train acc 76.56, train corr acc 53.61, val acc 75.19, val corr acc 50.88\n",
      "Ep 4 \titer 482  \tloss 0.95845, train acc 75.52, train corr acc 52.04, val acc 74.55, val corr acc 49.62\n",
      "Ep 4 \titer 483  \tloss 1.08658, train acc 72.92, train corr acc 49.51, val acc 75.64, val corr acc 51.76\n",
      "Ep 4 \titer 484  \tloss 1.00306, train acc 75.00, train corr acc 51.52, val acc 75.45, val corr acc 51.39\n",
      "Ep 4 \titer 485  \tloss 1.00872, train acc 76.04, train corr acc 53.54, val acc 75.51, val corr acc 51.51\n",
      "Ep 4 \titer 486  \tloss 1.10068, train acc 72.40, train corr acc 48.04, val acc 75.70, val corr acc 51.89\n",
      "Ep 4 \titer 487  \tloss 1.04104, train acc 73.96, train corr acc 47.92, val acc 75.57, val corr acc 51.64\n",
      "Ep 4 \titer 488  \tloss 0.92682, train acc 78.12, train corr acc 54.84, val acc 75.89, val corr acc 52.27\n",
      "Ep 4 \titer 489  \tloss 0.84096, train acc 79.17, train corr acc 56.52, val acc 75.76, val corr acc 52.02\n",
      "Ep 4 \titer 490  \tloss 0.95749, train acc 77.08, train corr acc 55.10, val acc 75.45, val corr acc 51.39\n",
      "Ep 4 \titer 491  \tloss 1.06570, train acc 76.56, train corr acc 57.94, val acc 76.15, val corr acc 52.77\n",
      "Ep 4 \titer 492  \tloss 1.06932, train acc 74.48, train corr acc 52.43, val acc 76.08, val corr acc 52.64\n",
      "Ep 4 \titer 493  \tloss 1.06274, train acc 77.08, train corr acc 57.28, val acc 75.76, val corr acc 52.02\n",
      "Ep 4 \titer 494  \tloss 1.08410, train acc 73.96, train corr acc 50.98, val acc 75.32, val corr acc 51.13\n",
      "Ep 4 \titer 495  \tloss 0.85227, train acc 79.69, train corr acc 56.18, val acc 75.57, val corr acc 51.64\n",
      "Ep 4 \titer 496  \tloss 1.05855, train acc 74.48, train corr acc 51.00, val acc 75.57, val corr acc 51.64\n",
      "Ep 4 \titer 497  \tloss 0.98060, train acc 74.48, train corr acc 51.96, val acc 75.95, val corr acc 52.39\n",
      "Ep 4 \titer 498  \tloss 1.12856, train acc 72.40, train corr acc 50.00, val acc 75.51, val corr acc 51.51\n",
      "Ep 4 \titer 499  \tloss 0.96300, train acc 73.96, train corr acc 48.45, val acc 75.64, val corr acc 51.76\n",
      "Ep 4 \titer 500  \tloss 0.99209, train acc 75.52, train corr acc 53.47, val acc 75.64, val corr acc 51.76\n",
      "Ep 4 \titer 501  \tloss 0.99967, train acc 76.56, train corr acc 56.31, val acc 75.76, val corr acc 52.02\n",
      "Ep 4 \titer 502  \tloss 0.94745, train acc 75.00, train corr acc 53.40, val acc 75.19, val corr acc 50.88\n",
      "Ep 4 \titer 503  \tloss 0.85332, train acc 77.60, train corr acc 55.21, val acc 75.25, val corr acc 51.01\n",
      "Ep 4 \titer 504  \tloss 0.99542, train acc 73.96, train corr acc 51.92, val acc 75.25, val corr acc 51.01\n",
      "Ep 4 \titer 505  \tloss 1.00043, train acc 74.48, train corr acc 49.48, val acc 75.45, val corr acc 51.39\n",
      "Ep 4 \titer 506  \tloss 0.87617, train acc 80.73, train corr acc 62.63, val acc 75.70, val corr acc 51.89\n",
      "Ep 4 \titer 507  \tloss 1.07616, train acc 74.48, train corr acc 52.88, val acc 75.45, val corr acc 51.39\n",
      "Ep 4 \titer 508  \tloss 1.00617, train acc 75.00, train corr acc 56.36, val acc 76.15, val corr acc 52.77\n",
      "Ep 4 \titer 509  \tloss 1.10386, train acc 74.48, train corr acc 49.48, val acc 75.57, val corr acc 51.64\n",
      "Ep 4 \titer 510  \tloss 0.81941, train acc 80.73, train corr acc 59.78, val acc 75.57, val corr acc 51.64\n",
      "Ep 4 \titer 511  \tloss 0.94919, train acc 77.08, train corr acc 55.56, val acc 76.08, val corr acc 52.64\n",
      "Ep 4 \titer 512  \tloss 0.93834, train acc 77.08, train corr acc 53.19, val acc 75.51, val corr acc 51.51\n",
      "Ep 4 \titer 513  \tloss 1.05980, train acc 75.00, train corr acc 49.47, val acc 75.25, val corr acc 51.01\n",
      "Ep 4 \titer 514  \tloss 0.97875, train acc 73.44, train corr acc 48.48, val acc 75.64, val corr acc 51.76\n",
      "Ep 4 \titer 515  \tloss 0.81492, train acc 80.73, train corr acc 59.34, val acc 75.45, val corr acc 51.39\n",
      "Ep 4 \titer 516  \tloss 0.92953, train acc 77.60, train corr acc 50.57, val acc 75.25, val corr acc 51.01\n",
      "Ep 4 \titer 517  \tloss 0.84396, train acc 81.25, train corr acc 59.55, val acc 75.76, val corr acc 52.02\n",
      "Ep 4 \titer 518  \tloss 0.97450, train acc 78.12, train corr acc 58.42, val acc 75.70, val corr acc 51.89\n",
      "Ep 4 \titer 519  \tloss 0.94921, train acc 76.04, train corr acc 55.77, val acc 75.45, val corr acc 51.76\n",
      "Ep 4 \titer 520  \tloss 0.83897, train acc 81.25, train corr acc 64.71, val acc 75.95, val corr acc 52.77\n",
      "Ep 4 \titer 521  \tloss 0.93712, train acc 77.08, train corr acc 55.56, val acc 75.76, val corr acc 52.02\n",
      "Ep 4 \titer 522  \tloss 0.85487, train acc 76.04, train corr acc 51.06, val acc 75.64, val corr acc 51.76\n",
      "Ep 4 \titer 523  \tloss 0.93191, train acc 78.12, train corr acc 56.25, val acc 75.70, val corr acc 51.89\n",
      "Ep 4 \titer 524  \tloss 0.99027, train acc 74.48, train corr acc 49.48, val acc 75.95, val corr acc 52.39\n",
      "Ep 4 \titer 525  \tloss 1.01108, train acc 75.00, train corr acc 48.94, val acc 75.51, val corr acc 51.51\n",
      "Ep 4 \titer 526  \tloss 0.93424, train acc 77.08, train corr acc 58.88, val acc 75.70, val corr acc 51.89\n",
      "Ep 4 \titer 527  \tloss 0.93016, train acc 77.60, train corr acc 54.26, val acc 76.21, val corr acc 52.90\n",
      "Ep 4 \titer 528  \tloss 1.00700, train acc 75.00, train corr acc 53.40, val acc 76.08, val corr acc 52.64\n",
      "Ep 4 \titer 529  \tloss 0.96595, train acc 78.12, train corr acc 57.14, val acc 75.89, val corr acc 52.27\n",
      "Ep 4 \titer 530  \tloss 0.90813, train acc 77.60, train corr acc 53.26, val acc 76.21, val corr acc 52.90\n",
      "Ep 4 \titer 531  \tloss 1.01894, train acc 75.52, train corr acc 54.37, val acc 76.02, val corr acc 52.52\n",
      "Ep 4 \titer 532  \tloss 1.03658, train acc 72.92, train corr acc 49.02, val acc 75.89, val corr acc 52.27\n",
      "Ep 4 \titer 533  \tloss 0.96233, train acc 75.00, train corr acc 55.14, val acc 76.08, val corr acc 52.64\n",
      "Ep 4 \titer 534  \tloss 0.95148, train acc 75.52, train corr acc 52.53, val acc 75.83, val corr acc 52.14\n",
      "Ep 4 \titer 535  \tloss 0.94543, train acc 78.65, train corr acc 56.84, val acc 75.64, val corr acc 51.76\n",
      "Ep 4 \titer 536  \tloss 0.88918, train acc 78.12, train corr acc 55.32, val acc 75.51, val corr acc 51.51\n",
      "Ep 4 \titer 537  \tloss 0.99631, train acc 75.52, train corr acc 59.13, val acc 75.00, val corr acc 50.50\n",
      "Ep 4 \titer 538  \tloss 1.00534, train acc 72.40, train corr acc 46.46, val acc 75.64, val corr acc 51.76\n",
      "Ep 4 \titer 539  \tloss 0.98692, train acc 76.04, train corr acc 55.34, val acc 75.19, val corr acc 50.88\n",
      "Ep 4 \titer 540  \tloss 1.08023, train acc 71.88, train corr acc 44.90, val acc 75.57, val corr acc 51.64\n",
      "Ep 4 \titer 541  \tloss 0.91965, train acc 76.04, train corr acc 52.58, val acc 75.13, val corr acc 50.76\n",
      "Ep 4 \titer 542  \tloss 1.04905, train acc 71.88, train corr acc 46.00, val acc 75.19, val corr acc 50.88\n",
      "Ep 4 \titer 543  \tloss 1.00689, train acc 75.52, train corr acc 54.37, val acc 75.76, val corr acc 52.02\n",
      "Ep 4 \titer 544  \tloss 0.97440, train acc 76.56, train corr acc 52.13, val acc 75.64, val corr acc 51.76\n",
      "Ep 4 \titer 545  \tloss 0.99200, train acc 75.52, train corr acc 53.47, val acc 75.64, val corr acc 51.76\n",
      "Ep 4 \titer 546  \tloss 1.01232, train acc 73.44, train corr acc 51.89, val acc 75.32, val corr acc 51.13\n",
      "Ep 4 \titer 547  \tloss 0.93547, train acc 78.65, train corr acc 57.73, val acc 76.08, val corr acc 52.64\n",
      "Ep 4 \titer 548  \tloss 1.04123, train acc 73.96, train corr acc 49.49, val acc 76.08, val corr acc 52.64\n",
      "Ep 4 \titer 549  \tloss 0.98607, train acc 77.08, train corr acc 58.88, val acc 75.89, val corr acc 52.27\n",
      "Ep 4 \titer 550  \tloss 0.85845, train acc 77.60, train corr acc 55.67, val acc 75.89, val corr acc 52.27\n",
      "Ep 4 \titer 551  \tloss 0.92537, train acc 77.60, train corr acc 54.26, val acc 75.57, val corr acc 51.64\n",
      "Ep 4 \titer 552  \tloss 1.11233, train acc 71.35, train corr acc 46.60, val acc 75.57, val corr acc 51.64\n",
      "Ep 4 \titer 553  \tloss 0.88273, train acc 78.12, train corr acc 53.33, val acc 75.25, val corr acc 51.01\n",
      "Ep 4 \titer 554  \tloss 0.87892, train acc 77.08, train corr acc 54.17, val acc 75.70, val corr acc 51.89\n",
      "Ep 4 \titer 555  \tloss 1.07101, train acc 73.44, train corr acc 49.00, val acc 76.40, val corr acc 53.27\n",
      "Ep 4 \titer 556  \tloss 0.97814, train acc 74.48, train corr acc 49.48, val acc 75.57, val corr acc 51.64\n",
      "Ep 4 \titer 557  \tloss 0.95932, train acc 76.56, train corr acc 54.08, val acc 75.89, val corr acc 52.27\n",
      "Ep 4 \titer 558  \tloss 1.12295, train acc 69.27, train corr acc 45.87, val acc 76.08, val corr acc 52.64\n",
      "Ep 4 \titer 559  \tloss 0.86639, train acc 77.60, train corr acc 50.57, val acc 75.51, val corr acc 51.51\n",
      "Ep 4 \titer 560  \tloss 0.86493, train acc 78.65, train corr acc 53.93, val acc 75.76, val corr acc 52.02\n",
      "Ep 4 \titer 561  \tloss 0.89996, train acc 76.56, train corr acc 54.08, val acc 75.25, val corr acc 51.01\n",
      "Ep 4 \titer 562  \tloss 0.92568, train acc 78.12, train corr acc 58.42, val acc 75.25, val corr acc 51.01\n",
      "Ep 4 \titer 563  \tloss 0.80321, train acc 79.17, train corr acc 53.49, val acc 75.25, val corr acc 51.13\n",
      "Ep 4 \titer 564  \tloss 0.96359, train acc 76.56, train corr acc 53.61, val acc 75.70, val corr acc 52.02\n",
      "Ep 4 \titer 565  \tloss 0.77340, train acc 81.77, train corr acc 63.16, val acc 75.83, val corr acc 52.14\n",
      "Ep 4 \titer 566  \tloss 0.93965, train acc 76.04, train corr acc 48.89, val acc 75.70, val corr acc 51.89\n",
      "Ep 4 \titer 567  \tloss 0.83710, train acc 78.12, train corr acc 56.25, val acc 76.27, val corr acc 53.02\n",
      "Ep 4 \titer 568  \tloss 0.94334, train acc 76.04, train corr acc 53.06, val acc 75.89, val corr acc 52.27\n",
      "Ep 4 \titer 569  \tloss 1.05113, train acc 70.83, train corr acc 47.66, val acc 75.57, val corr acc 51.64\n",
      "Ep 4 \titer 570  \tloss 0.85760, train acc 76.04, train corr acc 51.06, val acc 75.95, val corr acc 52.39\n",
      "\n",
      "Epoch 5 of 8 took 68.313s\n",
      "  training loss:\t\t0.975718\n",
      "  training raw accuracy:\t\t75.87 %\n",
      "  training corrected acc:\t\t53.01 %\n",
      "  validation loss:\t\t1.046494\n",
      "  validation raw accuracy:\t\t75.83 %\n",
      "  validation corrected acc:\t\t52.14 % \n",
      "\n",
      "Ep 5 \titer 571  \tloss 1.05691, train acc 71.88, train corr acc 50.00, val acc 75.76, val corr acc 52.02\n",
      "Ep 5 \titer 572  \tloss 0.87885, train acc 77.08, train corr acc 52.17, val acc 75.64, val corr acc 51.76\n",
      "Ep 5 \titer 573  \tloss 0.98142, train acc 75.52, train corr acc 52.04, val acc 75.76, val corr acc 52.02\n",
      "Ep 5 \titer 574  \tloss 1.04965, train acc 72.92, train corr acc 46.94, val acc 75.83, val corr acc 52.14\n",
      "Ep 5 \titer 575  \tloss 1.02455, train acc 73.96, train corr acc 50.00, val acc 75.19, val corr acc 50.88\n",
      "Ep 5 \titer 576  \tloss 1.00977, train acc 72.92, train corr acc 52.29, val acc 75.38, val corr acc 51.26\n",
      "Ep 5 \titer 577  \tloss 0.99510, train acc 76.04, train corr acc 53.54, val acc 75.25, val corr acc 51.01\n",
      "Ep 5 \titer 578  \tloss 0.98013, train acc 75.52, train corr acc 51.55, val acc 75.25, val corr acc 51.01\n",
      "Ep 5 \titer 579  \tloss 0.87421, train acc 75.00, train corr acc 52.94, val acc 75.51, val corr acc 51.51\n",
      "Ep 5 \titer 580  \tloss 1.13302, train acc 71.35, train corr acc 49.07, val acc 75.57, val corr acc 51.64\n",
      "Ep 5 \titer 581  \tloss 0.93107, train acc 76.04, train corr acc 55.34, val acc 75.76, val corr acc 52.02\n",
      "Ep 5 \titer 582  \tloss 0.93618, train acc 76.04, train corr acc 51.06, val acc 75.38, val corr acc 51.26\n",
      "Ep 5 \titer 583  \tloss 0.96079, train acc 81.25, train corr acc 60.00, val acc 76.08, val corr acc 52.64\n",
      "Ep 5 \titer 584  \tloss 1.01493, train acc 76.04, train corr acc 52.08, val acc 75.83, val corr acc 52.14\n",
      "Ep 5 \titer 585  \tloss 1.10008, train acc 73.44, train corr acc 53.64, val acc 75.95, val corr acc 52.39\n",
      "Ep 5 \titer 586  \tloss 0.85417, train acc 77.60, train corr acc 54.26, val acc 75.38, val corr acc 51.26\n",
      "Ep 5 \titer 587  \tloss 0.94661, train acc 72.40, train corr acc 48.54, val acc 75.51, val corr acc 51.51\n",
      "Ep 5 \titer 588  \tloss 0.96474, train acc 76.04, train corr acc 55.77, val acc 75.76, val corr acc 52.02\n",
      "Ep 5 \titer 589  \tloss 1.02997, train acc 73.44, train corr acc 46.88, val acc 75.32, val corr acc 51.13\n",
      "Ep 5 \titer 590  \tloss 0.85299, train acc 77.08, train corr acc 54.17, val acc 75.83, val corr acc 52.14\n",
      "Ep 5 \titer 591  \tloss 0.81060, train acc 79.69, train corr acc 54.65, val acc 75.76, val corr acc 52.02\n",
      "Ep 5 \titer 592  \tloss 0.97726, train acc 75.52, train corr acc 54.81, val acc 75.57, val corr acc 51.64\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-79b630acd31e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Training!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_corrected_accs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_corrected_accs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord_per_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/lisa1010/dev/deepcode/code/model_predict_ast.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_data, val_data, train_loss_acc, compute_loss_acc, num_epochs, batchsize, record_per_iter)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_minibatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruth_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0mX_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruth_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loss_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruth_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0mtrain_corrected_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_corrected_acc_on_ast_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruth_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lisa1010/anaconda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lisa1010/anaconda/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    876\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training!\n",
    "train_losses, train_accs, train_corrected_accs, val_losses, val_accs, val_corrected_accs = model.train(train_data, val_data, train_loss_acc, compute_loss_acc, num_epochs=num_epochs, batchsize=batchsize, record_per_iter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Total training iterations: 456\n",
      "Ep 0 \titer 1  \tloss 0.97781, train acc 75.00, train corr acc 55.56, val acc 75.83, val corr acc 52.14\n",
      "Ep 0 \titer 2  \tloss 0.85359, train acc 78.65, train corr acc 55.43, val acc 75.51, val corr acc 51.51\n",
      "Ep 0 \titer 3  \tloss 0.97043, train acc 76.04, train corr acc 53.06, val acc 75.06, val corr acc 50.63\n",
      "Ep 0 \titer 4  \tloss 0.97060, train acc 74.48, train corr acc 50.00, val acc 75.70, val corr acc 51.89\n",
      "Ep 0 \titer 5  \tloss 0.99557, train acc 74.48, train corr acc 51.00, val acc 75.51, val corr acc 51.51\n",
      "Ep 0 \titer 6  \tloss 0.97527, train acc 73.44, train corr acc 53.21, val acc 75.70, val corr acc 51.89\n",
      "Ep 0 \titer 7  \tloss 0.94274, train acc 75.00, train corr acc 51.52, val acc 75.51, val corr acc 51.51\n",
      "Ep 0 \titer 8  \tloss 0.95586, train acc 74.48, train corr acc 49.48, val acc 76.02, val corr acc 52.52\n",
      "Ep 0 \titer 9  \tloss 0.87428, train acc 76.56, train corr acc 55.88, val acc 76.34, val corr acc 53.15\n",
      "Ep 0 \titer 10  \tloss 1.06246, train acc 71.88, train corr acc 50.00, val acc 76.15, val corr acc 52.77\n",
      "Ep 0 \titer 11  \tloss 0.90736, train acc 75.00, train corr acc 53.40, val acc 76.40, val corr acc 53.27\n",
      "Ep 0 \titer 12  \tloss 0.84451, train acc 76.56, train corr acc 52.13, val acc 76.65, val corr acc 53.78\n",
      "Ep 0 \titer 13  \tloss 0.83476, train acc 79.17, train corr acc 55.56, val acc 76.53, val corr acc 53.53\n",
      "Ep 0 \titer 14  \tloss 0.93493, train acc 75.52, train corr acc 51.04, val acc 76.72, val corr acc 53.90\n",
      "Ep 0 \titer 15  \tloss 0.97239, train acc 74.48, train corr acc 55.45, val acc 77.04, val corr acc 54.53\n",
      "Ep 0 \titer 16  \tloss 0.81254, train acc 78.65, train corr acc 56.38, val acc 76.59, val corr acc 53.65\n",
      "Ep 0 \titer 17  \tloss 0.89908, train acc 75.52, train corr acc 54.37, val acc 76.27, val corr acc 53.02\n",
      "Ep 0 \titer 18  \tloss 0.91046, train acc 76.56, train corr acc 56.73, val acc 76.91, val corr acc 54.28\n",
      "Ep 0 \titer 19  \tloss 0.91667, train acc 75.00, train corr acc 50.00, val acc 76.40, val corr acc 53.27\n",
      "Ep 0 \titer 20  \tloss 0.74988, train acc 78.12, train corr acc 56.25, val acc 76.40, val corr acc 53.27\n",
      "Ep 0 \titer 21  \tloss 0.72443, train acc 80.21, train corr acc 55.81, val acc 76.40, val corr acc 53.27\n",
      "Ep 0 \titer 22  \tloss 0.88524, train acc 76.56, train corr acc 56.73, val acc 76.59, val corr acc 53.65\n",
      "Ep 0 \titer 23  \tloss 0.79833, train acc 78.12, train corr acc 50.59, val acc 76.27, val corr acc 53.02\n",
      "Ep 0 \titer 24  \tloss 0.84331, train acc 76.04, train corr acc 54.46, val acc 75.76, val corr acc 52.02\n",
      "Ep 0 \titer 25  \tloss 0.86204, train acc 80.21, train corr acc 60.82, val acc 76.08, val corr acc 52.64\n",
      "Ep 0 \titer 26  \tloss 0.82617, train acc 77.60, train corr acc 56.12, val acc 76.21, val corr acc 52.90\n",
      "Ep 0 \titer 27  \tloss 0.94927, train acc 75.00, train corr acc 53.40, val acc 75.76, val corr acc 52.02\n",
      "Ep 0 \titer 28  \tloss 0.85925, train acc 76.56, train corr acc 54.55, val acc 75.95, val corr acc 52.39\n",
      "Ep 0 \titer 29  \tloss 0.83762, train acc 78.12, train corr acc 57.58, val acc 75.95, val corr acc 52.39\n",
      "Ep 0 \titer 30  \tloss 0.90136, train acc 76.04, train corr acc 54.90, val acc 75.89, val corr acc 52.27\n",
      "Ep 0 \titer 31  \tloss 0.87138, train acc 75.00, train corr acc 50.00, val acc 75.45, val corr acc 51.39\n",
      "Ep 0 \titer 32  \tloss 0.73506, train acc 80.21, train corr acc 59.14, val acc 75.45, val corr acc 51.39\n",
      "Ep 0 \titer 33  \tloss 0.76356, train acc 77.60, train corr acc 53.26, val acc 75.83, val corr acc 52.14\n",
      "Ep 0 \titer 34  \tloss 0.78709, train acc 77.08, train corr acc 55.10, val acc 75.89, val corr acc 52.27\n",
      "Ep 0 \titer 35  \tloss 0.90781, train acc 75.52, train corr acc 56.07, val acc 75.76, val corr acc 52.02\n",
      "Ep 0 \titer 36  \tloss 0.96656, train acc 73.44, train corr acc 50.49, val acc 75.95, val corr acc 52.39\n",
      "Ep 0 \titer 37  \tloss 0.93002, train acc 78.65, train corr acc 60.19, val acc 75.95, val corr acc 52.39\n",
      "Ep 0 \titer 38  \tloss 0.96921, train acc 75.52, train corr acc 53.92, val acc 75.51, val corr acc 51.51\n",
      "Ep 0 \titer 39  \tloss 0.72258, train acc 80.73, train corr acc 58.43, val acc 75.95, val corr acc 52.39\n",
      "Ep 0 \titer 40  \tloss 0.87668, train acc 75.52, train corr acc 53.00, val acc 75.95, val corr acc 52.39\n",
      "Ep 0 \titer 41  \tloss 0.83311, train acc 77.60, train corr acc 57.84, val acc 75.95, val corr acc 52.39\n",
      "Ep 0 \titer 42  \tloss 0.99958, train acc 73.44, train corr acc 51.89, val acc 75.83, val corr acc 52.14\n",
      "Ep 0 \titer 43  \tloss 0.84877, train acc 75.52, train corr acc 51.55, val acc 75.45, val corr acc 51.39\n",
      "Ep 0 \titer 44  \tloss 0.80407, train acc 79.17, train corr acc 60.40, val acc 76.15, val corr acc 52.77\n",
      "Ep 0 \titer 45  \tloss 0.83623, train acc 78.12, train corr acc 59.22, val acc 75.76, val corr acc 52.02\n",
      "Ep 0 \titer 46  \tloss 0.88267, train acc 74.48, train corr acc 52.43, val acc 75.76, val corr acc 52.02\n",
      "Ep 0 \titer 47  \tloss 0.74303, train acc 78.65, train corr acc 57.29, val acc 75.95, val corr acc 52.39\n",
      "Ep 0 \titer 48  \tloss 0.87942, train acc 75.52, train corr acc 54.81, val acc 76.34, val corr acc 53.15\n",
      "Ep 0 \titer 49  \tloss 0.89056, train acc 74.48, train corr acc 49.48, val acc 76.02, val corr acc 52.52\n",
      "Ep 0 \titer 50  \tloss 0.77469, train acc 79.69, train corr acc 60.61, val acc 75.70, val corr acc 51.89\n",
      "Ep 0 \titer 51  \tloss 0.94470, train acc 76.04, train corr acc 55.77, val acc 76.21, val corr acc 52.90\n",
      "Ep 0 \titer 52  \tloss 0.88771, train acc 76.04, train corr acc 58.18, val acc 76.15, val corr acc 52.77\n",
      "Ep 0 \titer 53  \tloss 0.89929, train acc 76.56, train corr acc 53.61, val acc 76.15, val corr acc 52.77\n",
      "Ep 0 \titer 54  \tloss 0.67562, train acc 81.25, train corr acc 60.87, val acc 76.08, val corr acc 52.64\n",
      "Ep 0 \titer 55  \tloss 0.81048, train acc 78.12, train corr acc 57.58, val acc 76.21, val corr acc 52.90\n",
      "Ep 0 \titer 56  \tloss 0.83484, train acc 79.17, train corr acc 57.45, val acc 75.38, val corr acc 51.26\n",
      "Ep 0 \titer 57  \tloss 0.89966, train acc 77.08, train corr acc 53.68, val acc 76.08, val corr acc 52.64\n",
      "Ep 0 \titer 58  \tloss 0.89637, train acc 75.00, train corr acc 51.52, val acc 76.08, val corr acc 52.64\n",
      "Ep 0 \titer 59  \tloss 0.70915, train acc 80.73, train corr acc 59.34, val acc 75.89, val corr acc 52.27\n",
      "Ep 0 \titer 60  \tloss 0.75844, train acc 80.73, train corr acc 57.47, val acc 75.95, val corr acc 52.39\n",
      "Ep 0 \titer 61  \tloss 0.77902, train acc 80.73, train corr acc 58.43, val acc 75.83, val corr acc 52.14\n",
      "Ep 0 \titer 62  \tloss 0.83385, train acc 79.17, train corr acc 60.40, val acc 75.76, val corr acc 52.02\n",
      "Ep 0 \titer 63  \tloss 0.85898, train acc 76.56, train corr acc 56.73, val acc 76.02, val corr acc 52.52\n",
      "Ep 0 \titer 64  \tloss 0.70118, train acc 82.81, train corr acc 67.65, val acc 75.70, val corr acc 51.89\n",
      "Ep 0 \titer 65  \tloss 0.81979, train acc 77.08, train corr acc 55.56, val acc 76.02, val corr acc 52.52\n",
      "Ep 0 \titer 66  \tloss 0.71616, train acc 78.65, train corr acc 56.38, val acc 75.89, val corr acc 52.27\n",
      "Ep 0 \titer 67  \tloss 0.88546, train acc 76.56, train corr acc 53.12, val acc 75.57, val corr acc 51.64\n",
      "Ep 0 \titer 68  \tloss 0.97174, train acc 76.56, train corr acc 53.61, val acc 76.15, val corr acc 52.77\n",
      "Ep 0 \titer 69  \tloss 0.91283, train acc 77.08, train corr acc 53.19, val acc 75.89, val corr acc 52.27\n",
      "Ep 0 \titer 70  \tloss 0.90530, train acc 74.48, train corr acc 54.21, val acc 76.02, val corr acc 52.52\n",
      "Ep 0 \titer 71  \tloss 0.85850, train acc 78.65, train corr acc 56.38, val acc 76.08, val corr acc 52.64\n",
      "Ep 0 \titer 72  \tloss 0.94181, train acc 75.00, train corr acc 53.40, val acc 75.76, val corr acc 52.02\n",
      "Ep 0 \titer 73  \tloss 0.89184, train acc 79.17, train corr acc 59.18, val acc 75.76, val corr acc 52.02\n",
      "Ep 0 \titer 74  \tloss 0.85984, train acc 77.60, train corr acc 53.26, val acc 75.64, val corr acc 51.76\n",
      "Ep 0 \titer 75  \tloss 0.98960, train acc 73.44, train corr acc 50.49, val acc 76.02, val corr acc 52.52\n",
      "Ep 0 \titer 76  \tloss 0.94371, train acc 74.48, train corr acc 51.96, val acc 75.45, val corr acc 51.39\n",
      "Ep 0 \titer 77  \tloss 0.90704, train acc 75.52, train corr acc 56.07, val acc 75.45, val corr acc 51.39\n",
      "Ep 0 \titer 78  \tloss 0.85104, train acc 76.04, train corr acc 53.54, val acc 75.83, val corr acc 52.14\n",
      "Ep 0 \titer 79  \tloss 0.88235, train acc 78.12, train corr acc 55.79, val acc 76.40, val corr acc 53.27\n",
      "Ep 0 \titer 80  \tloss 0.87256, train acc 77.08, train corr acc 53.19, val acc 75.57, val corr acc 51.64\n",
      "Ep 0 \titer 81  \tloss 0.92267, train acc 75.00, train corr acc 58.26, val acc 75.64, val corr acc 51.76\n",
      "Ep 0 \titer 82  \tloss 0.95976, train acc 75.00, train corr acc 51.52, val acc 75.89, val corr acc 52.27\n",
      "Ep 0 \titer 83  \tloss 0.88043, train acc 75.52, train corr acc 54.37, val acc 75.51, val corr acc 51.51\n",
      "Ep 0 \titer 84  \tloss 0.96726, train acc 74.48, train corr acc 50.00, val acc 75.83, val corr acc 52.14\n",
      "Ep 0 \titer 85  \tloss 0.84230, train acc 77.60, train corr acc 55.67, val acc 75.51, val corr acc 51.51\n",
      "Ep 0 \titer 86  \tloss 0.96136, train acc 73.96, train corr acc 50.00, val acc 75.45, val corr acc 51.39\n",
      "Ep 0 \titer 87  \tloss 0.95801, train acc 75.00, train corr acc 53.40, val acc 75.57, val corr acc 51.64\n",
      "Ep 0 \titer 88  \tloss 0.90951, train acc 76.56, train corr acc 52.13, val acc 75.83, val corr acc 52.14\n",
      "Ep 0 \titer 89  \tloss 0.94002, train acc 75.00, train corr acc 52.48, val acc 75.32, val corr acc 51.13\n",
      "Ep 0 \titer 90  \tloss 0.91364, train acc 76.56, train corr acc 57.55, val acc 75.57, val corr acc 51.64\n",
      "Ep 0 \titer 91  \tloss 0.94210, train acc 75.00, train corr acc 50.52, val acc 76.02, val corr acc 52.52\n",
      "Ep 0 \titer 92  \tloss 0.96467, train acc 75.52, train corr acc 52.53, val acc 76.02, val corr acc 52.52\n",
      "Ep 0 \titer 93  \tloss 0.93718, train acc 73.96, train corr acc 53.27, val acc 75.51, val corr acc 51.51\n",
      "Ep 0 \titer 94  \tloss 0.85315, train acc 75.52, train corr acc 51.55, val acc 75.57, val corr acc 51.64\n",
      "Ep 0 \titer 95  \tloss 0.85563, train acc 78.12, train corr acc 55.32, val acc 76.21, val corr acc 52.90\n",
      "Ep 0 \titer 96  \tloss 0.97062, train acc 72.40, train corr acc 48.54, val acc 76.21, val corr acc 52.90\n",
      "Ep 0 \titer 97  \tloss 0.80751, train acc 80.21, train corr acc 57.78, val acc 76.15, val corr acc 52.77\n",
      "Ep 0 \titer 98  \tloss 0.75396, train acc 78.12, train corr acc 56.25, val acc 76.46, val corr acc 53.40\n",
      "Ep 0 \titer 99  \tloss 1.03337, train acc 72.92, train corr acc 48.00, val acc 76.21, val corr acc 52.90\n",
      "Ep 0 \titer 100  \tloss 0.88248, train acc 77.60, train corr acc 55.67, val acc 76.40, val corr acc 53.27\n",
      "Ep 0 \titer 101  \tloss 0.86291, train acc 77.60, train corr acc 56.12, val acc 76.15, val corr acc 52.77\n",
      "Ep 0 \titer 102  \tloss 1.01692, train acc 72.40, train corr acc 51.38, val acc 76.46, val corr acc 53.40\n",
      "Ep 0 \titer 103  \tloss 0.82106, train acc 78.12, train corr acc 51.72, val acc 76.08, val corr acc 52.64\n",
      "Ep 0 \titer 104  \tloss 0.79313, train acc 77.60, train corr acc 51.69, val acc 75.89, val corr acc 52.27\n",
      "Ep 0 \titer 105  \tloss 0.87028, train acc 78.65, train corr acc 58.16, val acc 76.46, val corr acc 53.40\n",
      "Ep 0 \titer 106  \tloss 0.91319, train acc 75.00, train corr acc 52.48, val acc 76.46, val corr acc 53.40\n",
      "Ep 0 \titer 107  \tloss 0.72741, train acc 80.73, train corr acc 56.98, val acc 76.21, val corr acc 52.90\n",
      "Ep 0 \titer 108  \tloss 0.89919, train acc 77.08, train corr acc 54.64, val acc 76.08, val corr acc 52.64\n",
      "Ep 0 \titer 109  \tloss 0.73710, train acc 80.21, train corr acc 60.00, val acc 76.46, val corr acc 53.40\n",
      "Ep 0 \titer 110  \tloss 0.92525, train acc 76.04, train corr acc 48.89, val acc 75.76, val corr acc 52.02\n",
      "Ep 0 \titer 111  \tloss 0.85496, train acc 77.08, train corr acc 54.17, val acc 75.83, val corr acc 52.14\n",
      "Ep 0 \titer 112  \tloss 0.79901, train acc 79.69, train corr acc 60.20, val acc 76.15, val corr acc 52.77\n",
      "Ep 0 \titer 113  \tloss 1.05630, train acc 70.83, train corr acc 47.66, val acc 75.95, val corr acc 52.52\n",
      "Ep 0 \titer 114  \tloss 0.80094, train acc 79.69, train corr acc 58.51, val acc 75.64, val corr acc 51.76\n",
      "\n",
      "Epoch 1 of 4 took 68.024s\n",
      "  training loss:\t\t0.866525\n",
      "  training raw accuracy:\t\t76.53 %\n",
      "  training corrected acc:\t\t54.29 %\n",
      "  validation loss:\t\t1.043154\n",
      "  validation raw accuracy:\t\t75.64 %\n",
      "  validation corrected acc:\t\t51.76 % \n",
      "\n",
      "Ep 1 \titer 115  \tloss 0.99421, train acc 73.44, train corr acc 52.78, val acc 75.95, val corr acc 52.39\n",
      "Ep 1 \titer 116  \tloss 0.80921, train acc 78.12, train corr acc 54.35, val acc 76.72, val corr acc 53.90\n",
      "Ep 1 \titer 117  \tloss 0.95365, train acc 75.00, train corr acc 51.02, val acc 76.46, val corr acc 53.40\n",
      "Ep 1 \titer 118  \tloss 0.96241, train acc 72.92, train corr acc 46.94, val acc 75.83, val corr acc 52.14\n",
      "Ep 1 \titer 119  \tloss 0.98566, train acc 74.48, train corr acc 51.00, val acc 75.89, val corr acc 52.27\n",
      "Ep 1 \titer 120  \tloss 0.91045, train acc 76.04, train corr acc 57.80, val acc 75.95, val corr acc 52.39\n",
      "Ep 1 \titer 121  \tloss 0.90579, train acc 76.56, train corr acc 54.55, val acc 76.46, val corr acc 53.40\n",
      "Ep 1 \titer 122  \tloss 0.91139, train acc 76.04, train corr acc 52.58, val acc 75.95, val corr acc 52.39\n",
      "Ep 1 \titer 123  \tloss 0.84870, train acc 75.00, train corr acc 52.94, val acc 75.76, val corr acc 52.02\n",
      "Ep 1 \titer 124  \tloss 1.04061, train acc 70.83, train corr acc 48.15, val acc 75.64, val corr acc 51.76\n",
      "Ep 1 \titer 125  \tloss 0.87918, train acc 75.00, train corr acc 53.40, val acc 76.21, val corr acc 52.90\n",
      "Ep 1 \titer 126  \tloss 0.83694, train acc 75.52, train corr acc 50.00, val acc 75.89, val corr acc 52.27\n",
      "Ep 1 \titer 127  \tloss 0.79148, train acc 77.08, train corr acc 51.11, val acc 75.57, val corr acc 51.64\n",
      "Ep 1 \titer 128  \tloss 0.89195, train acc 78.12, train corr acc 56.25, val acc 75.64, val corr acc 51.76\n",
      "Ep 1 \titer 129  \tloss 0.96006, train acc 76.04, train corr acc 58.18, val acc 76.15, val corr acc 52.77\n",
      "Ep 1 \titer 130  \tloss 0.79195, train acc 79.69, train corr acc 58.51, val acc 75.83, val corr acc 52.14\n",
      "Ep 1 \titer 131  \tloss 0.87101, train acc 75.52, train corr acc 54.37, val acc 76.02, val corr acc 52.52\n",
      "Ep 1 \titer 132  \tloss 0.87581, train acc 78.12, train corr acc 59.62, val acc 76.15, val corr acc 52.77\n",
      "Ep 1 \titer 133  \tloss 0.91915, train acc 75.52, train corr acc 51.04, val acc 76.65, val corr acc 53.78\n",
      "Ep 1 \titer 134  \tloss 0.77387, train acc 78.65, train corr acc 57.29, val acc 76.21, val corr acc 52.90\n",
      "Ep 1 \titer 135  \tloss 0.71658, train acc 80.21, train corr acc 55.81, val acc 76.34, val corr acc 53.15\n",
      "Ep 1 \titer 136  \tloss 0.87582, train acc 78.12, train corr acc 59.62, val acc 76.27, val corr acc 53.02\n",
      "Ep 1 \titer 137  \tloss 0.78004, train acc 78.65, train corr acc 51.76, val acc 76.34, val corr acc 53.15\n",
      "Ep 1 \titer 138  \tloss 0.85821, train acc 80.73, train corr acc 63.37, val acc 76.59, val corr acc 53.65\n",
      "Ep 1 \titer 139  \tloss 0.86492, train acc 78.65, train corr acc 57.73, val acc 76.08, val corr acc 52.64\n",
      "Ep 1 \titer 140  \tloss 0.78352, train acc 78.65, train corr acc 58.16, val acc 76.27, val corr acc 53.02\n",
      "Ep 1 \titer 141  \tloss 0.91403, train acc 76.04, train corr acc 55.34, val acc 76.15, val corr acc 52.77\n",
      "Ep 1 \titer 142  \tloss 0.85028, train acc 77.60, train corr acc 56.57, val acc 76.21, val corr acc 52.90\n",
      "Ep 1 \titer 143  \tloss 0.85802, train acc 77.60, train corr acc 56.57, val acc 75.95, val corr acc 52.39\n",
      "Ep 1 \titer 144  \tloss 0.88990, train acc 75.00, train corr acc 52.94, val acc 75.64, val corr acc 51.76\n",
      "Ep 1 \titer 145  \tloss 0.89610, train acc 76.04, train corr acc 52.08, val acc 75.89, val corr acc 52.27\n",
      "Ep 1 \titer 146  \tloss 0.72084, train acc 81.25, train corr acc 61.29, val acc 75.64, val corr acc 51.76\n",
      "Ep 1 \titer 147  \tloss 0.73206, train acc 79.17, train corr acc 56.52, val acc 75.32, val corr acc 51.13\n",
      "Ep 1 \titer 148  \tloss 0.76162, train acc 78.12, train corr acc 57.14, val acc 75.25, val corr acc 51.01\n",
      "Ep 1 \titer 149  \tloss 0.90679, train acc 78.12, train corr acc 60.75, val acc 75.64, val corr acc 51.76\n",
      "Ep 1 \titer 150  \tloss 0.92947, train acc 74.48, train corr acc 52.43, val acc 75.76, val corr acc 52.02\n",
      "Ep 1 \titer 151  \tloss 0.91514, train acc 79.17, train corr acc 61.17, val acc 75.51, val corr acc 51.51\n",
      "Ep 1 \titer 152  \tloss 0.95847, train acc 76.04, train corr acc 54.90, val acc 75.76, val corr acc 52.02\n",
      "Ep 1 \titer 153  \tloss 0.72191, train acc 80.73, train corr acc 58.43, val acc 75.89, val corr acc 52.27\n",
      "Ep 1 \titer 154  \tloss 0.85852, train acc 75.00, train corr acc 52.00, val acc 75.57, val corr acc 51.64\n",
      "Ep 1 \titer 155  \tloss 0.81761, train acc 76.56, train corr acc 55.88, val acc 76.08, val corr acc 52.64\n",
      "Ep 1 \titer 156  \tloss 0.95596, train acc 73.44, train corr acc 51.89, val acc 75.70, val corr acc 51.89\n",
      "Ep 1 \titer 157  \tloss 0.85107, train acc 76.04, train corr acc 52.58, val acc 76.34, val corr acc 53.15\n",
      "Ep 1 \titer 158  \tloss 0.80784, train acc 79.17, train corr acc 60.40, val acc 75.83, val corr acc 52.14\n",
      "Ep 1 \titer 159  \tloss 0.82883, train acc 77.08, train corr acc 57.28, val acc 75.38, val corr acc 51.26\n",
      "Ep 1 \titer 160  \tloss 0.89466, train acc 72.92, train corr acc 49.51, val acc 75.76, val corr acc 52.02\n",
      "Ep 1 \titer 161  \tloss 0.76089, train acc 79.69, train corr acc 59.38, val acc 75.64, val corr acc 51.76\n",
      "Ep 1 \titer 162  \tloss 0.86593, train acc 75.00, train corr acc 53.85, val acc 75.95, val corr acc 52.39\n",
      "Ep 1 \titer 163  \tloss 0.90474, train acc 74.48, train corr acc 49.48, val acc 75.89, val corr acc 52.27\n",
      "Ep 1 \titer 164  \tloss 0.78286, train acc 79.17, train corr acc 59.60, val acc 76.02, val corr acc 52.52\n",
      "Ep 1 \titer 165  \tloss 0.89477, train acc 76.56, train corr acc 56.73, val acc 75.51, val corr acc 51.51\n",
      "Ep 1 \titer 166  \tloss 0.87568, train acc 77.60, train corr acc 60.91, val acc 75.83, val corr acc 52.14\n",
      "Ep 1 \titer 167  \tloss 0.90929, train acc 75.52, train corr acc 51.55, val acc 75.76, val corr acc 52.02\n",
      "Ep 1 \titer 168  \tloss 0.66704, train acc 81.25, train corr acc 60.87, val acc 75.95, val corr acc 52.39\n",
      "Ep 1 \titer 169  \tloss 0.81188, train acc 78.65, train corr acc 58.59, val acc 75.83, val corr acc 52.14\n",
      "Ep 1 \titer 170  \tloss 0.83311, train acc 78.65, train corr acc 56.38, val acc 75.95, val corr acc 52.39\n",
      "Ep 1 \titer 171  \tloss 0.91006, train acc 76.56, train corr acc 52.63, val acc 76.27, val corr acc 53.02\n",
      "Ep 1 \titer 172  \tloss 0.86795, train acc 74.48, train corr acc 50.51, val acc 75.45, val corr acc 51.39\n",
      "Ep 1 \titer 173  \tloss 0.69226, train acc 81.25, train corr acc 60.44, val acc 75.95, val corr acc 52.39\n",
      "Ep 1 \titer 174  \tloss 0.75240, train acc 81.77, train corr acc 59.77, val acc 75.00, val corr acc 50.50\n",
      "Ep 1 \titer 175  \tloss 0.77922, train acc 79.69, train corr acc 56.18, val acc 75.38, val corr acc 51.26\n",
      "Ep 1 \titer 176  \tloss 0.83729, train acc 78.65, train corr acc 59.41, val acc 75.51, val corr acc 51.51\n",
      "Ep 1 \titer 177  \tloss 0.84855, train acc 77.60, train corr acc 58.65, val acc 75.89, val corr acc 52.27\n",
      "Ep 1 \titer 178  \tloss 0.71171, train acc 83.33, train corr acc 68.63, val acc 75.64, val corr acc 51.76\n",
      "Ep 1 \titer 179  \tloss 0.82320, train acc 77.08, train corr acc 55.56, val acc 75.45, val corr acc 51.39\n",
      "Ep 1 \titer 180  \tloss 0.71430, train acc 79.69, train corr acc 58.51, val acc 75.45, val corr acc 51.39\n",
      "Ep 1 \titer 181  \tloss 0.83332, train acc 79.69, train corr acc 59.38, val acc 75.45, val corr acc 51.39\n",
      "Ep 1 \titer 182  \tloss 0.95210, train acc 75.00, train corr acc 50.52, val acc 75.57, val corr acc 51.64\n",
      "Ep 1 \titer 183  \tloss 0.84268, train acc 78.12, train corr acc 55.32, val acc 76.02, val corr acc 52.52\n",
      "Ep 1 \titer 184  \tloss 0.90883, train acc 75.00, train corr acc 55.14, val acc 76.02, val corr acc 52.52\n",
      "Ep 1 \titer 185  \tloss 0.87350, train acc 78.65, train corr acc 56.38, val acc 75.51, val corr acc 51.51\n",
      "Ep 1 \titer 186  \tloss 0.91223, train acc 73.96, train corr acc 51.46, val acc 75.89, val corr acc 52.27\n",
      "Ep 1 \titer 187  \tloss 0.86924, train acc 77.60, train corr acc 56.12, val acc 76.08, val corr acc 52.64\n",
      "Ep 1 \titer 188  \tloss 0.79518, train acc 81.25, train corr acc 60.87, val acc 76.08, val corr acc 52.64\n",
      "Ep 1 \titer 189  \tloss 0.96687, train acc 73.96, train corr acc 51.46, val acc 75.19, val corr acc 50.88\n",
      "Ep 1 \titer 190  \tloss 0.90430, train acc 76.56, train corr acc 55.88, val acc 75.64, val corr acc 51.76\n",
      "Ep 1 \titer 191  \tloss 0.90132, train acc 73.96, train corr acc 53.27, val acc 76.02, val corr acc 52.52\n",
      "Ep 1 \titer 192  \tloss 0.81265, train acc 77.60, train corr acc 56.57, val acc 75.95, val corr acc 52.39\n",
      "Ep 1 \titer 193  \tloss 0.83369, train acc 77.60, train corr acc 54.74, val acc 75.38, val corr acc 51.26\n",
      "Ep 1 \titer 194  \tloss 0.84904, train acc 79.69, train corr acc 58.51, val acc 76.02, val corr acc 52.52\n",
      "Ep 1 \titer 195  \tloss 0.90487, train acc 76.04, train corr acc 60.00, val acc 76.02, val corr acc 52.52\n",
      "Ep 1 \titer 196  \tloss 0.94345, train acc 73.44, train corr acc 48.48, val acc 76.02, val corr acc 52.52\n",
      "Ep 1 \titer 197  \tloss 0.92363, train acc 75.52, train corr acc 54.37, val acc 75.38, val corr acc 51.26\n",
      "Ep 1 \titer 198  \tloss 0.95940, train acc 72.40, train corr acc 45.92, val acc 75.64, val corr acc 51.76\n",
      "Ep 1 \titer 199  \tloss 0.80259, train acc 78.12, train corr acc 56.70, val acc 75.95, val corr acc 52.39\n",
      "Ep 1 \titer 200  \tloss 0.95281, train acc 75.52, train corr acc 53.00, val acc 75.83, val corr acc 52.14\n",
      "Ep 1 \titer 201  \tloss 0.86463, train acc 77.08, train corr acc 57.28, val acc 75.76, val corr acc 52.02\n",
      "Ep 1 \titer 202  \tloss 0.86014, train acc 76.04, train corr acc 51.06, val acc 75.64, val corr acc 51.76\n",
      "Ep 1 \titer 203  \tloss 0.84878, train acc 76.56, train corr acc 55.45, val acc 75.51, val corr acc 51.51\n",
      "Ep 1 \titer 204  \tloss 0.89373, train acc 73.44, train corr acc 51.89, val acc 75.64, val corr acc 51.76\n",
      "Ep 1 \titer 205  \tloss 0.88574, train acc 75.52, train corr acc 51.55, val acc 75.83, val corr acc 52.14\n",
      "Ep 1 \titer 206  \tloss 0.91245, train acc 76.04, train corr acc 53.54, val acc 75.89, val corr acc 52.27\n",
      "Ep 1 \titer 207  \tloss 0.86630, train acc 77.08, train corr acc 58.88, val acc 75.51, val corr acc 51.51\n",
      "Ep 1 \titer 208  \tloss 0.80735, train acc 78.12, train corr acc 56.70, val acc 74.94, val corr acc 50.38\n",
      "Ep 1 \titer 209  \tloss 0.83451, train acc 77.60, train corr acc 54.26, val acc 75.76, val corr acc 52.02\n",
      "Ep 1 \titer 210  \tloss 0.95142, train acc 71.88, train corr acc 47.57, val acc 74.87, val corr acc 50.25\n",
      "Ep 1 \titer 211  \tloss 0.78492, train acc 80.21, train corr acc 57.78, val acc 75.45, val corr acc 51.39\n",
      "Ep 1 \titer 212  \tloss 0.75499, train acc 78.65, train corr acc 57.29, val acc 75.64, val corr acc 51.76\n",
      "Ep 1 \titer 213  \tloss 0.97998, train acc 75.00, train corr acc 52.00, val acc 75.83, val corr acc 52.14\n",
      "Ep 1 \titer 214  \tloss 0.81601, train acc 78.12, train corr acc 56.70, val acc 76.34, val corr acc 53.15\n",
      "Ep 1 \titer 215  \tloss 0.82653, train acc 77.60, train corr acc 56.12, val acc 75.95, val corr acc 52.39\n",
      "Ep 1 \titer 216  \tloss 0.94701, train acc 71.88, train corr acc 50.46, val acc 75.95, val corr acc 52.39\n",
      "Ep 1 \titer 217  \tloss 0.78005, train acc 78.12, train corr acc 51.72, val acc 75.57, val corr acc 51.64\n",
      "Ep 1 \titer 218  \tloss 0.74194, train acc 79.17, train corr acc 55.06, val acc 76.21, val corr acc 52.90\n",
      "Ep 1 \titer 219  \tloss 0.78087, train acc 79.17, train corr acc 59.18, val acc 76.40, val corr acc 53.27\n",
      "Ep 1 \titer 220  \tloss 0.89811, train acc 76.56, train corr acc 55.45, val acc 76.34, val corr acc 53.15\n",
      "Ep 1 \titer 221  \tloss 0.68381, train acc 81.77, train corr acc 59.30, val acc 75.76, val corr acc 52.02\n",
      "Ep 1 \titer 222  \tloss 0.87346, train acc 77.60, train corr acc 55.67, val acc 76.46, val corr acc 53.40\n",
      "Ep 1 \titer 223  \tloss 0.73575, train acc 81.25, train corr acc 62.11, val acc 76.15, val corr acc 52.77\n",
      "Ep 1 \titer 224  \tloss 0.89004, train acc 77.08, train corr acc 51.11, val acc 75.38, val corr acc 51.26\n",
      "Ep 1 \titer 225  \tloss 0.78607, train acc 78.65, train corr acc 57.29, val acc 75.95, val corr acc 52.39\n",
      "Ep 1 \titer 226  \tloss 0.75597, train acc 79.17, train corr acc 59.18, val acc 75.70, val corr acc 51.89\n",
      "Ep 1 \titer 227  \tloss 0.99359, train acc 69.27, train corr acc 44.86, val acc 76.02, val corr acc 52.52\n",
      "Ep 1 \titer 228  \tloss 0.77850, train acc 79.69, train corr acc 58.51, val acc 76.15, val corr acc 52.77\n",
      "\n",
      "Epoch 2 of 4 took 66.217s\n",
      "  training loss:\t\t0.854926\n",
      "  training raw accuracy:\t\t76.80 %\n",
      "  training corrected acc:\t\t54.81 %\n",
      "  validation loss:\t\t1.063207\n",
      "  validation raw accuracy:\t\t76.15 %\n",
      "  validation corrected acc:\t\t52.77 % \n",
      "\n",
      "Ep 2 \titer 229  \tloss 0.95877, train acc 75.00, train corr acc 55.56, val acc 76.27, val corr acc 53.02\n",
      "Ep 2 \titer 230  \tloss 0.79822, train acc 78.12, train corr acc 54.35, val acc 75.38, val corr acc 51.26\n",
      "Ep 2 \titer 231  \tloss 0.91550, train acc 75.00, train corr acc 51.02, val acc 75.70, val corr acc 51.89\n",
      "Ep 2 \titer 232  \tloss 0.94659, train acc 73.96, train corr acc 48.98, val acc 75.64, val corr acc 51.76\n",
      "Ep 2 \titer 233  \tloss 0.96963, train acc 72.92, train corr acc 48.00, val acc 76.15, val corr acc 52.77\n",
      "Ep 2 \titer 234  \tloss 0.91180, train acc 75.00, train corr acc 55.96, val acc 75.64, val corr acc 51.76\n",
      "Ep 2 \titer 235  \tloss 0.88572, train acc 77.08, train corr acc 55.56, val acc 76.21, val corr acc 52.90\n",
      "Ep 2 \titer 236  \tloss 0.91951, train acc 73.44, train corr acc 47.42, val acc 76.02, val corr acc 52.52\n",
      "Ep 2 \titer 237  \tloss 0.82820, train acc 75.52, train corr acc 53.92, val acc 75.83, val corr acc 52.14\n",
      "Ep 2 \titer 238  \tloss 1.01720, train acc 71.88, train corr acc 50.00, val acc 76.91, val corr acc 54.28\n",
      "Ep 2 \titer 239  \tloss 0.90525, train acc 75.52, train corr acc 54.37, val acc 75.76, val corr acc 52.02\n",
      "Ep 2 \titer 240  \tloss 0.80491, train acc 76.56, train corr acc 52.13, val acc 76.27, val corr acc 53.02\n",
      "Ep 2 \titer 241  \tloss 0.81126, train acc 80.21, train corr acc 57.78, val acc 76.08, val corr acc 52.64\n",
      "Ep 2 \titer 242  \tloss 0.84939, train acc 78.12, train corr acc 56.25, val acc 76.65, val corr acc 53.78\n",
      "Ep 2 \titer 243  \tloss 0.91585, train acc 75.52, train corr acc 57.27, val acc 76.72, val corr acc 53.90\n",
      "Ep 2 \titer 244  \tloss 0.76783, train acc 79.17, train corr acc 57.45, val acc 76.02, val corr acc 52.52\n",
      "Ep 2 \titer 245  \tloss 0.86833, train acc 76.04, train corr acc 55.34, val acc 75.95, val corr acc 52.39\n",
      "Ep 2 \titer 246  \tloss 0.88601, train acc 77.08, train corr acc 57.69, val acc 75.76, val corr acc 52.02\n",
      "Ep 2 \titer 247  \tloss 0.91060, train acc 75.52, train corr acc 51.04, val acc 76.08, val corr acc 52.64\n",
      "Ep 2 \titer 248  \tloss 0.77005, train acc 77.08, train corr acc 54.17, val acc 76.59, val corr acc 53.65\n",
      "Ep 2 \titer 249  \tloss 0.71508, train acc 79.69, train corr acc 54.65, val acc 76.72, val corr acc 53.90\n",
      "Ep 2 \titer 250  \tloss 0.87911, train acc 77.60, train corr acc 58.65, val acc 76.08, val corr acc 52.64\n",
      "Ep 2 \titer 251  \tloss 0.72468, train acc 78.12, train corr acc 50.59, val acc 75.95, val corr acc 52.39\n",
      "Ep 2 \titer 252  \tloss 0.84682, train acc 79.69, train corr acc 61.39, val acc 76.53, val corr acc 53.53\n",
      "Ep 2 \titer 253  \tloss 0.81782, train acc 80.73, train corr acc 61.86, val acc 76.27, val corr acc 53.02\n",
      "Ep 2 \titer 254  \tloss 0.76853, train acc 79.69, train corr acc 60.20, val acc 76.27, val corr acc 53.02\n",
      "Ep 2 \titer 255  \tloss 0.89632, train acc 75.00, train corr acc 53.40, val acc 76.02, val corr acc 52.52\n",
      "Ep 2 \titer 256  \tloss 0.83772, train acc 76.56, train corr acc 54.55, val acc 76.08, val corr acc 52.64\n",
      "Ep 2 \titer 257  \tloss 0.84153, train acc 76.56, train corr acc 54.55, val acc 75.76, val corr acc 52.02\n",
      "Ep 2 \titer 258  \tloss 0.90674, train acc 74.48, train corr acc 51.96, val acc 76.27, val corr acc 53.02\n",
      "Ep 2 \titer 259  \tloss 0.87998, train acc 75.00, train corr acc 50.00, val acc 75.70, val corr acc 51.89\n",
      "Ep 2 \titer 260  \tloss 0.72064, train acc 81.25, train corr acc 61.29, val acc 76.02, val corr acc 52.52\n",
      "Ep 2 \titer 261  \tloss 0.71522, train acc 79.69, train corr acc 57.61, val acc 75.76, val corr acc 52.02\n",
      "Ep 2 \titer 262  \tloss 0.75138, train acc 77.08, train corr acc 55.10, val acc 76.02, val corr acc 52.52\n",
      "Ep 2 \titer 263  \tloss 0.90036, train acc 79.17, train corr acc 62.62, val acc 75.95, val corr acc 52.39\n",
      "Ep 2 \titer 264  \tloss 0.89671, train acc 75.00, train corr acc 53.40, val acc 76.02, val corr acc 52.52\n",
      "Ep 2 \titer 265  \tloss 0.90265, train acc 77.60, train corr acc 58.25, val acc 75.64, val corr acc 51.76\n",
      "Ep 2 \titer 266  \tloss 0.93800, train acc 77.08, train corr acc 56.86, val acc 75.76, val corr acc 52.02\n",
      "Ep 2 \titer 267  \tloss 0.75000, train acc 79.69, train corr acc 56.18, val acc 76.21, val corr acc 52.90\n",
      "Ep 2 \titer 268  \tloss 0.85485, train acc 73.96, train corr acc 50.00, val acc 76.15, val corr acc 52.77\n",
      "Ep 2 \titer 269  \tloss 0.83361, train acc 76.04, train corr acc 54.90, val acc 75.64, val corr acc 51.76\n",
      "Ep 2 \titer 270  \tloss 0.92331, train acc 76.56, train corr acc 57.55, val acc 75.83, val corr acc 52.14\n",
      "Ep 2 \titer 271  \tloss 0.83362, train acc 79.17, train corr acc 58.76, val acc 76.15, val corr acc 52.77\n",
      "Ep 2 \titer 272  \tloss 0.80200, train acc 78.65, train corr acc 59.41, val acc 76.02, val corr acc 52.52\n",
      "Ep 2 \titer 273  \tloss 0.85592, train acc 77.08, train corr acc 57.28, val acc 76.08, val corr acc 52.64\n",
      "Ep 2 \titer 274  \tloss 0.89136, train acc 73.44, train corr acc 50.49, val acc 75.76, val corr acc 52.02\n",
      "Ep 2 \titer 275  \tloss 0.73623, train acc 79.69, train corr acc 59.38, val acc 75.32, val corr acc 51.13\n",
      "Ep 2 \titer 276  \tloss 0.88427, train acc 73.96, train corr acc 51.92, val acc 75.45, val corr acc 51.39\n",
      "Ep 2 \titer 277  \tloss 0.88654, train acc 76.56, train corr acc 53.61, val acc 76.08, val corr acc 52.64\n",
      "Ep 2 \titer 278  \tloss 0.79087, train acc 78.65, train corr acc 58.59, val acc 75.95, val corr acc 52.39\n",
      "Ep 2 \titer 279  \tloss 0.87113, train acc 77.60, train corr acc 58.65, val acc 75.83, val corr acc 52.14\n",
      "Ep 2 \titer 280  \tloss 0.85779, train acc 76.04, train corr acc 58.18, val acc 76.34, val corr acc 53.15\n",
      "Ep 2 \titer 281  \tloss 0.87166, train acc 77.08, train corr acc 54.64, val acc 76.21, val corr acc 52.90\n",
      "Ep 2 \titer 282  \tloss 0.65937, train acc 82.29, train corr acc 63.04, val acc 76.02, val corr acc 52.52\n",
      "Ep 2 \titer 283  \tloss 0.78896, train acc 79.69, train corr acc 60.61, val acc 76.34, val corr acc 53.15\n",
      "Ep 2 \titer 284  \tloss 0.84375, train acc 78.12, train corr acc 55.32, val acc 76.08, val corr acc 52.64\n",
      "Ep 2 \titer 285  \tloss 0.88702, train acc 78.12, train corr acc 55.79, val acc 76.46, val corr acc 53.40\n",
      "Ep 2 \titer 286  \tloss 0.91014, train acc 75.00, train corr acc 51.52, val acc 76.02, val corr acc 52.52\n",
      "Ep 2 \titer 287  \tloss 0.66506, train acc 81.25, train corr acc 60.44, val acc 75.95, val corr acc 52.39\n",
      "Ep 2 \titer 288  \tloss 0.76959, train acc 81.25, train corr acc 58.62, val acc 76.15, val corr acc 52.77\n",
      "Ep 2 \titer 289  \tloss 0.72138, train acc 81.25, train corr acc 59.55, val acc 76.02, val corr acc 52.52\n",
      "Ep 2 \titer 290  \tloss 0.79758, train acc 79.17, train corr acc 60.40, val acc 75.13, val corr acc 50.76\n",
      "Ep 2 \titer 291  \tloss 0.80102, train acc 77.60, train corr acc 58.65, val acc 75.57, val corr acc 51.64\n",
      "Ep 2 \titer 292  \tloss 0.68890, train acc 83.33, train corr acc 68.63, val acc 75.00, val corr acc 50.50\n",
      "Ep 2 \titer 293  \tloss 0.78148, train acc 78.65, train corr acc 58.59, val acc 75.19, val corr acc 50.88\n",
      "Ep 2 \titer 294  \tloss 0.66764, train acc 80.21, train corr acc 59.57, val acc 75.38, val corr acc 51.26\n",
      "Ep 2 \titer 295  \tloss 0.79885, train acc 79.69, train corr acc 59.38, val acc 75.89, val corr acc 52.27\n",
      "Ep 2 \titer 296  \tloss 0.86679, train acc 78.12, train corr acc 56.70, val acc 75.25, val corr acc 51.01\n",
      "Ep 2 \titer 297  \tloss 0.85320, train acc 77.60, train corr acc 54.26, val acc 75.76, val corr acc 52.02\n",
      "Ep 2 \titer 298  \tloss 0.81912, train acc 75.52, train corr acc 56.07, val acc 75.19, val corr acc 50.88\n",
      "Ep 2 \titer 299  \tloss 0.85755, train acc 77.08, train corr acc 53.19, val acc 75.95, val corr acc 52.39\n",
      "Ep 2 \titer 300  \tloss 0.87149, train acc 75.52, train corr acc 54.37, val acc 75.76, val corr acc 52.02\n",
      "Ep 2 \titer 301  \tloss 0.81489, train acc 78.12, train corr acc 57.14, val acc 76.08, val corr acc 52.64\n",
      "Ep 2 \titer 302  \tloss 0.81105, train acc 77.60, train corr acc 53.26, val acc 75.64, val corr acc 51.76\n",
      "Ep 2 \titer 303  \tloss 0.92855, train acc 72.92, train corr acc 49.51, val acc 75.38, val corr acc 51.26\n",
      "Ep 2 \titer 304  \tloss 0.85191, train acc 77.60, train corr acc 57.84, val acc 75.89, val corr acc 52.27\n",
      "Ep 2 \titer 305  \tloss 0.85062, train acc 73.96, train corr acc 53.27, val acc 75.70, val corr acc 51.89\n",
      "Ep 2 \titer 306  \tloss 0.80257, train acc 75.52, train corr acc 52.53, val acc 75.64, val corr acc 51.76\n",
      "Ep 2 \titer 307  \tloss 0.81200, train acc 79.69, train corr acc 58.95, val acc 75.25, val corr acc 51.01\n",
      "Ep 2 \titer 308  \tloss 0.83393, train acc 79.17, train corr acc 57.45, val acc 75.32, val corr acc 51.13\n",
      "Ep 2 \titer 309  \tloss 0.87826, train acc 76.04, train corr acc 60.00, val acc 75.51, val corr acc 51.51\n",
      "Ep 2 \titer 310  \tloss 0.88534, train acc 73.44, train corr acc 48.48, val acc 75.00, val corr acc 50.50\n",
      "Ep 2 \titer 311  \tloss 0.88755, train acc 79.17, train corr acc 61.17, val acc 75.57, val corr acc 51.64\n",
      "Ep 2 \titer 312  \tloss 0.90400, train acc 73.44, train corr acc 47.96, val acc 75.64, val corr acc 51.76\n",
      "Ep 2 \titer 313  \tloss 0.81094, train acc 76.04, train corr acc 52.58, val acc 75.51, val corr acc 51.51\n",
      "Ep 2 \titer 314  \tloss 0.91062, train acc 74.48, train corr acc 51.00, val acc 75.45, val corr acc 51.39\n",
      "Ep 2 \titer 315  \tloss 0.83102, train acc 77.08, train corr acc 57.28, val acc 75.51, val corr acc 51.51\n",
      "Ep 2 \titer 316  \tloss 0.85140, train acc 77.60, train corr acc 54.26, val acc 75.13, val corr acc 50.76\n",
      "Ep 2 \titer 317  \tloss 0.86597, train acc 77.08, train corr acc 56.44, val acc 76.02, val corr acc 52.52\n",
      "Ep 2 \titer 318  \tloss 0.85670, train acc 75.00, train corr acc 54.72, val acc 75.00, val corr acc 50.50\n",
      "Ep 2 \titer 319  \tloss 0.87659, train acc 75.00, train corr acc 50.52, val acc 75.57, val corr acc 51.64\n",
      "Ep 2 \titer 320  \tloss 0.93354, train acc 75.52, train corr acc 52.53, val acc 75.45, val corr acc 51.39\n",
      "Ep 2 \titer 321  \tloss 0.84093, train acc 77.08, train corr acc 58.88, val acc 75.32, val corr acc 51.13\n",
      "Ep 2 \titer 322  \tloss 0.81220, train acc 77.60, train corr acc 55.67, val acc 75.00, val corr acc 50.50\n",
      "Ep 2 \titer 323  \tloss 0.81588, train acc 76.04, train corr acc 51.06, val acc 74.49, val corr acc 49.50\n",
      "Ep 2 \titer 324  \tloss 0.95781, train acc 73.44, train corr acc 50.49, val acc 75.76, val corr acc 52.02\n",
      "Ep 2 \titer 325  \tloss 0.76477, train acc 80.73, train corr acc 58.89, val acc 75.64, val corr acc 51.76\n",
      "Ep 2 \titer 326  \tloss 0.73327, train acc 80.21, train corr acc 60.42, val acc 75.51, val corr acc 51.51\n",
      "Ep 2 \titer 327  \tloss 0.94392, train acc 73.96, train corr acc 50.00, val acc 75.89, val corr acc 52.27\n",
      "Ep 2 \titer 328  \tloss 0.81990, train acc 78.65, train corr acc 57.73, val acc 75.64, val corr acc 51.76\n",
      "Ep 2 \titer 329  \tloss 0.80727, train acc 76.56, train corr acc 54.08, val acc 75.89, val corr acc 52.27\n",
      "Ep 2 \titer 330  \tloss 0.94950, train acc 73.96, train corr acc 54.13, val acc 76.15, val corr acc 52.77\n",
      "Ep 2 \titer 331  \tloss 0.78723, train acc 77.08, train corr acc 49.43, val acc 76.53, val corr acc 53.53\n",
      "Ep 2 \titer 332  \tloss 0.77505, train acc 76.56, train corr acc 49.44, val acc 75.95, val corr acc 52.39\n",
      "Ep 2 \titer 333  \tloss 0.81288, train acc 79.69, train corr acc 60.20, val acc 76.08, val corr acc 52.64\n",
      "Ep 2 \titer 334  \tloss 0.85934, train acc 77.60, train corr acc 57.43, val acc 75.70, val corr acc 51.89\n",
      "Ep 2 \titer 335  \tloss 0.70172, train acc 81.77, train corr acc 59.30, val acc 75.25, val corr acc 51.01\n",
      "Ep 2 \titer 336  \tloss 0.84976, train acc 78.12, train corr acc 56.70, val acc 75.19, val corr acc 50.88\n",
      "Ep 2 \titer 337  \tloss 0.73121, train acc 80.21, train corr acc 60.00, val acc 76.08, val corr acc 52.64\n",
      "Ep 2 \titer 338  \tloss 0.83846, train acc 77.60, train corr acc 52.22, val acc 75.95, val corr acc 52.39\n",
      "Ep 2 \titer 339  \tloss 0.80049, train acc 78.12, train corr acc 56.25, val acc 75.25, val corr acc 51.01\n",
      "Ep 2 \titer 340  \tloss 0.78751, train acc 77.08, train corr acc 55.10, val acc 75.57, val corr acc 51.64\n",
      "Ep 2 \titer 341  \tloss 0.95978, train acc 69.27, train corr acc 44.86, val acc 75.45, val corr acc 51.39\n",
      "Ep 2 \titer 342  \tloss 0.73986, train acc 79.17, train corr acc 57.45, val acc 74.49, val corr acc 49.50\n",
      "\n",
      "Epoch 3 of 4 took 66.943s\n",
      "  training loss:\t\t0.833605\n",
      "  training raw accuracy:\t\t76.79 %\n",
      "  training corrected acc:\t\t54.79 %\n",
      "  validation loss:\t\t1.061423\n",
      "  validation raw accuracy:\t\t74.49 %\n",
      "  validation corrected acc:\t\t49.50 % \n",
      "\n",
      "Ep 3 \titer 343  \tloss 0.91944, train acc 76.04, train corr acc 57.41, val acc 75.76, val corr acc 52.02\n",
      "Ep 3 \titer 344  \tloss 0.72580, train acc 78.65, train corr acc 55.43, val acc 75.89, val corr acc 52.27\n",
      "Ep 3 \titer 345  \tloss 0.91902, train acc 72.92, train corr acc 46.94, val acc 75.57, val corr acc 51.64\n",
      "Ep 3 \titer 346  \tloss 0.91894, train acc 74.48, train corr acc 50.00, val acc 76.02, val corr acc 52.52\n",
      "Ep 3 \titer 347  \tloss 0.94281, train acc 73.96, train corr acc 50.00, val acc 75.95, val corr acc 52.39\n",
      "Ep 3 \titer 348  \tloss 0.89005, train acc 75.52, train corr acc 56.88, val acc 75.70, val corr acc 51.89\n",
      "Ep 3 \titer 349  \tloss 0.90040, train acc 76.56, train corr acc 54.55, val acc 75.70, val corr acc 51.89\n",
      "Ep 3 \titer 350  \tloss 0.89644, train acc 76.56, train corr acc 53.61, val acc 76.02, val corr acc 52.52\n",
      "Ep 3 \titer 351  \tloss 0.84172, train acc 74.48, train corr acc 51.96, val acc 75.76, val corr acc 52.02\n",
      "Ep 3 \titer 352  \tloss 1.03378, train acc 70.31, train corr acc 47.22, val acc 76.40, val corr acc 53.27\n",
      "Ep 3 \titer 353  \tloss 0.86972, train acc 75.00, train corr acc 53.40, val acc 75.38, val corr acc 51.26\n",
      "Ep 3 \titer 354  \tloss 0.79273, train acc 78.12, train corr acc 55.32, val acc 75.70, val corr acc 51.89\n",
      "Ep 3 \titer 355  \tloss 0.77349, train acc 79.17, train corr acc 55.56, val acc 75.95, val corr acc 52.39\n",
      "Ep 3 \titer 356  \tloss 0.82897, train acc 77.08, train corr acc 54.17, val acc 76.15, val corr acc 52.77\n",
      "Ep 3 \titer 357  \tloss 0.93396, train acc 77.08, train corr acc 60.00, val acc 75.70, val corr acc 51.89\n",
      "Ep 3 \titer 358  \tloss 0.77566, train acc 79.17, train corr acc 57.45, val acc 75.89, val corr acc 52.27\n",
      "Ep 3 \titer 359  \tloss 0.84247, train acc 73.96, train corr acc 51.46, val acc 75.51, val corr acc 51.51\n",
      "Ep 3 \titer 360  \tloss 0.82190, train acc 77.60, train corr acc 58.65, val acc 75.38, val corr acc 51.26\n",
      "Ep 3 \titer 361  \tloss 0.92275, train acc 76.04, train corr acc 52.08, val acc 75.89, val corr acc 52.27\n",
      "Ep 3 \titer 362  \tloss 0.78257, train acc 77.60, train corr acc 55.21, val acc 75.70, val corr acc 51.89\n",
      "Ep 3 \titer 363  \tloss 0.68718, train acc 80.21, train corr acc 55.81, val acc 75.51, val corr acc 51.51\n",
      "Ep 3 \titer 364  \tloss 0.87487, train acc 78.12, train corr acc 59.62, val acc 76.02, val corr acc 52.52\n",
      "Ep 3 \titer 365  \tloss 0.72719, train acc 79.17, train corr acc 52.94, val acc 75.45, val corr acc 51.39\n",
      "Ep 3 \titer 366  \tloss 0.82262, train acc 78.12, train corr acc 58.42, val acc 75.76, val corr acc 52.02\n",
      "Ep 3 \titer 367  \tloss 0.78354, train acc 79.69, train corr acc 59.79, val acc 75.95, val corr acc 52.39\n",
      "Ep 3 \titer 368  \tloss 0.79072, train acc 77.60, train corr acc 56.12, val acc 75.38, val corr acc 51.26\n",
      "Ep 3 \titer 369  \tloss 0.88046, train acc 74.48, train corr acc 52.43, val acc 75.32, val corr acc 51.13\n",
      "Ep 3 \titer 370  \tloss 0.86100, train acc 76.56, train corr acc 54.55, val acc 75.25, val corr acc 51.01\n",
      "Ep 3 \titer 371  \tloss 0.82682, train acc 76.04, train corr acc 53.54, val acc 75.64, val corr acc 51.76\n",
      "Ep 3 \titer 372  \tloss 0.84484, train acc 76.56, train corr acc 55.88, val acc 75.64, val corr acc 51.76\n",
      "Ep 3 \titer 373  \tloss 0.84731, train acc 75.52, train corr acc 51.04, val acc 75.32, val corr acc 51.13\n",
      "Ep 3 \titer 374  \tloss 0.70359, train acc 80.21, train corr acc 59.14, val acc 75.83, val corr acc 52.14\n",
      "Ep 3 \titer 375  \tloss 0.72221, train acc 79.17, train corr acc 56.52, val acc 75.25, val corr acc 51.01\n",
      "Ep 3 \titer 376  \tloss 0.71645, train acc 78.12, train corr acc 57.14, val acc 75.32, val corr acc 51.13\n",
      "Ep 3 \titer 377  \tloss 0.87420, train acc 78.12, train corr acc 60.75, val acc 75.32, val corr acc 51.13\n",
      "Ep 3 \titer 378  \tloss 0.90297, train acc 76.04, train corr acc 55.34, val acc 75.57, val corr acc 51.64\n",
      "Ep 3 \titer 379  \tloss 0.91227, train acc 78.65, train corr acc 60.19, val acc 75.57, val corr acc 51.64\n",
      "Ep 3 \titer 380  \tloss 0.90715, train acc 76.56, train corr acc 55.88, val acc 75.57, val corr acc 51.64\n",
      "Ep 3 \titer 381  \tloss 0.75609, train acc 79.69, train corr acc 56.18, val acc 75.95, val corr acc 52.39\n",
      "Ep 3 \titer 382  \tloss 0.84319, train acc 75.00, train corr acc 52.00, val acc 75.25, val corr acc 51.01\n",
      "Ep 3 \titer 383  \tloss 0.80940, train acc 75.52, train corr acc 53.92, val acc 75.32, val corr acc 51.13\n",
      "Ep 3 \titer 384  \tloss 0.92201, train acc 74.48, train corr acc 53.77, val acc 75.76, val corr acc 52.02\n",
      "Ep 3 \titer 385  \tloss 0.79927, train acc 79.17, train corr acc 58.76, val acc 75.45, val corr acc 51.39\n",
      "Ep 3 \titer 386  \tloss 0.78163, train acc 80.21, train corr acc 62.38, val acc 75.95, val corr acc 52.39\n",
      "Ep 3 \titer 387  \tloss 0.83298, train acc 76.56, train corr acc 56.31, val acc 75.13, val corr acc 50.76\n",
      "Ep 3 \titer 388  \tloss 0.85876, train acc 74.48, train corr acc 52.43, val acc 75.76, val corr acc 52.02\n",
      "Ep 3 \titer 389  \tloss 0.73707, train acc 80.21, train corr acc 60.42, val acc 75.76, val corr acc 52.02\n",
      "Ep 3 \titer 390  \tloss 0.85650, train acc 76.56, train corr acc 56.73, val acc 75.70, val corr acc 51.89\n",
      "Ep 3 \titer 391  \tloss 0.88969, train acc 73.44, train corr acc 47.42, val acc 75.70, val corr acc 51.89\n",
      "Ep 3 \titer 392  \tloss 0.74829, train acc 80.73, train corr acc 62.63, val acc 75.76, val corr acc 52.02\n",
      "Ep 3 \titer 393  \tloss 0.86746, train acc 79.17, train corr acc 61.54, val acc 75.51, val corr acc 51.51\n",
      "Ep 3 \titer 394  \tloss 0.89914, train acc 75.00, train corr acc 56.36, val acc 75.83, val corr acc 52.14\n",
      "Ep 3 \titer 395  \tloss 0.85435, train acc 77.08, train corr acc 54.64, val acc 76.21, val corr acc 52.90\n",
      "Ep 3 \titer 396  \tloss 0.65075, train acc 81.77, train corr acc 61.96, val acc 75.89, val corr acc 52.27\n",
      "Ep 3 \titer 397  \tloss 0.78427, train acc 78.12, train corr acc 57.58, val acc 75.57, val corr acc 51.64\n",
      "Ep 3 \titer 398  \tloss 0.82959, train acc 79.17, train corr acc 57.45, val acc 76.65, val corr acc 53.78\n",
      "Ep 3 \titer 399  \tloss 0.86196, train acc 76.56, train corr acc 52.63, val acc 76.08, val corr acc 52.64\n",
      "Ep 3 \titer 400  \tloss 0.86296, train acc 76.04, train corr acc 53.54, val acc 75.51, val corr acc 51.51\n",
      "Ep 3 \titer 401  \tloss 0.69509, train acc 80.21, train corr acc 58.24, val acc 75.51, val corr acc 51.51\n",
      "Ep 3 \titer 402  \tloss 0.75614, train acc 80.21, train corr acc 56.32, val acc 76.27, val corr acc 53.02\n",
      "Ep 3 \titer 403  \tloss 0.75676, train acc 80.21, train corr acc 57.30, val acc 76.21, val corr acc 52.90\n",
      "Ep 3 \titer 404  \tloss 0.80836, train acc 78.12, train corr acc 58.42, val acc 75.83, val corr acc 52.14\n",
      "Ep 3 \titer 405  \tloss 0.81319, train acc 78.12, train corr acc 59.62, val acc 75.57, val corr acc 51.64\n",
      "Ep 3 \titer 406  \tloss 0.67438, train acc 83.33, train corr acc 68.63, val acc 75.64, val corr acc 51.76\n",
      "Ep 3 \titer 407  \tloss 0.76968, train acc 78.65, train corr acc 58.59, val acc 75.95, val corr acc 52.39\n",
      "Ep 3 \titer 408  \tloss 0.66738, train acc 79.17, train corr acc 57.45, val acc 75.83, val corr acc 52.14\n",
      "Ep 3 \titer 409  \tloss 0.81393, train acc 79.69, train corr acc 59.38, val acc 75.25, val corr acc 51.01\n",
      "Ep 3 \titer 410  \tloss 0.85497, train acc 76.04, train corr acc 52.58, val acc 75.25, val corr acc 51.01\n",
      "Ep 3 \titer 411  \tloss 0.83980, train acc 76.56, train corr acc 52.13, val acc 75.19, val corr acc 50.88\n",
      "Ep 3 \titer 412  \tloss 0.78441, train acc 77.08, train corr acc 58.88, val acc 75.25, val corr acc 51.01\n",
      "Ep 3 \titer 413  \tloss 0.81928, train acc 77.08, train corr acc 53.19, val acc 75.25, val corr acc 51.01\n",
      "Ep 3 \titer 414  \tloss 0.89346, train acc 73.96, train corr acc 51.46, val acc 75.70, val corr acc 51.89\n",
      "Ep 3 \titer 415  \tloss 0.83652, train acc 78.12, train corr acc 57.14, val acc 75.70, val corr acc 51.89\n",
      "Ep 3 \titer 416  \tloss 0.78714, train acc 79.17, train corr acc 56.52, val acc 75.45, val corr acc 51.39\n",
      "Ep 3 \titer 417  \tloss 0.92618, train acc 73.96, train corr acc 51.46, val acc 75.83, val corr acc 52.14\n",
      "Ep 3 \titer 418  \tloss 0.83351, train acc 78.12, train corr acc 58.82, val acc 75.38, val corr acc 51.26\n",
      "Ep 3 \titer 419  \tloss 0.83885, train acc 76.56, train corr acc 57.94, val acc 75.57, val corr acc 51.64\n",
      "Ep 3 \titer 420  \tloss 0.76857, train acc 78.65, train corr acc 58.59, val acc 75.38, val corr acc 51.26\n",
      "Ep 3 \titer 421  \tloss 0.79854, train acc 78.12, train corr acc 55.79, val acc 75.70, val corr acc 51.89\n",
      "Ep 3 \titer 422  \tloss 0.80768, train acc 81.25, train corr acc 61.70, val acc 75.38, val corr acc 51.26\n",
      "Ep 3 \titer 423  \tloss 0.90353, train acc 74.48, train corr acc 57.39, val acc 76.02, val corr acc 52.52\n",
      "Ep 3 \titer 424  \tloss 0.87381, train acc 75.00, train corr acc 51.52, val acc 75.83, val corr acc 52.14\n",
      "Ep 3 \titer 425  \tloss 0.87947, train acc 76.56, train corr acc 56.31, val acc 75.13, val corr acc 50.76\n",
      "Ep 3 \titer 426  \tloss 0.87866, train acc 75.52, train corr acc 52.04, val acc 75.00, val corr acc 50.50\n",
      "Ep 3 \titer 427  \tloss 0.78502, train acc 76.56, train corr acc 53.61, val acc 75.38, val corr acc 51.26\n",
      "Ep 3 \titer 428  \tloss 0.85463, train acc 75.52, train corr acc 53.00, val acc 75.38, val corr acc 51.26\n",
      "Ep 3 \titer 429  \tloss 0.79432, train acc 78.12, train corr acc 59.22, val acc 76.21, val corr acc 52.90\n",
      "Ep 3 \titer 430  \tloss 0.78815, train acc 79.17, train corr acc 57.45, val acc 76.02, val corr acc 52.52\n",
      "Ep 3 \titer 431  \tloss 0.83818, train acc 77.08, train corr acc 56.44, val acc 75.64, val corr acc 51.76\n",
      "Ep 3 \titer 432  \tloss 0.83573, train acc 77.60, train corr acc 59.43, val acc 75.38, val corr acc 51.26\n",
      "Ep 3 \titer 433  \tloss 0.87645, train acc 76.56, train corr acc 53.61, val acc 75.76, val corr acc 52.02\n",
      "Ep 3 \titer 434  \tloss 0.88341, train acc 76.04, train corr acc 53.54, val acc 76.27, val corr acc 53.02\n",
      "Ep 3 \titer 435  \tloss 0.79945, train acc 78.65, train corr acc 61.68, val acc 76.21, val corr acc 52.90\n",
      "Ep 3 \titer 436  \tloss 0.72922, train acc 78.65, train corr acc 57.73, val acc 75.70, val corr acc 51.89\n",
      "Ep 3 \titer 437  \tloss 0.77581, train acc 77.60, train corr acc 54.26, val acc 75.76, val corr acc 52.02\n",
      "Ep 3 \titer 438  \tloss 0.88488, train acc 75.00, train corr acc 53.40, val acc 75.57, val corr acc 51.64\n",
      "Ep 3 \titer 439  \tloss 0.74608, train acc 81.25, train corr acc 60.00, val acc 75.83, val corr acc 52.14\n",
      "Ep 3 \titer 440  \tloss 0.69855, train acc 79.69, train corr acc 59.38, val acc 75.70, val corr acc 51.89\n",
      "Ep 3 \titer 441  \tloss 0.87858, train acc 76.04, train corr acc 54.00, val acc 75.95, val corr acc 52.39\n",
      "Ep 3 \titer 442  \tloss 0.77166, train acc 78.65, train corr acc 57.73, val acc 75.76, val corr acc 52.02\n",
      "Ep 3 \titer 443  \tloss 0.80651, train acc 78.65, train corr acc 58.16, val acc 75.13, val corr acc 50.76\n",
      "Ep 3 \titer 444  \tloss 0.89636, train acc 73.96, train corr acc 54.13, val acc 75.51, val corr acc 51.51\n",
      "Ep 3 \titer 445  \tloss 0.75060, train acc 79.69, train corr acc 55.17, val acc 75.83, val corr acc 52.14\n",
      "Ep 3 \titer 446  \tloss 0.72113, train acc 78.65, train corr acc 53.93, val acc 76.02, val corr acc 52.52\n",
      "Ep 3 \titer 447  \tloss 0.77777, train acc 78.65, train corr acc 58.16, val acc 75.51, val corr acc 51.51\n",
      "Ep 3 \titer 448  \tloss 0.86954, train acc 77.08, train corr acc 56.44, val acc 75.45, val corr acc 51.39\n",
      "Ep 3 \titer 449  \tloss 0.68282, train acc 82.29, train corr acc 60.47, val acc 75.64, val corr acc 51.76\n",
      "Ep 3 \titer 450  \tloss 0.85269, train acc 79.69, train corr acc 59.79, val acc 75.51, val corr acc 51.51\n",
      "Ep 3 \titer 451  \tloss 0.70947, train acc 80.21, train corr acc 60.00, val acc 75.38, val corr acc 51.26\n",
      "Ep 3 \titer 452  \tloss 0.83129, train acc 78.65, train corr acc 54.44, val acc 75.13, val corr acc 50.76\n",
      "Ep 3 \titer 453  \tloss 0.78378, train acc 79.17, train corr acc 58.33, val acc 74.87, val corr acc 50.25\n",
      "Ep 3 \titer 454  \tloss 0.72412, train acc 79.69, train corr acc 60.20, val acc 75.19, val corr acc 50.88\n",
      "Ep 3 \titer 455  \tloss 0.98999, train acc 69.79, train corr acc 45.79, val acc 75.32, val corr acc 51.13\n",
      "Ep 3 \titer 456  \tloss 0.74779, train acc 79.17, train corr acc 57.45, val acc 75.13, val corr acc 50.76\n",
      "\n",
      "Epoch 4 of 4 took 68.249s\n",
      "  training loss:\t\t0.837618\n",
      "  training raw accuracy:\t\t76.73 %\n",
      "  training corrected acc:\t\t54.67 %\n",
      "  validation loss:\t\t1.084696\n",
      "  validation raw accuracy:\t\t75.13 %\n",
      "  validation corrected acc:\t\t50.76 % \n",
      "\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Training!\n",
    "train_losses, train_accs, train_corrected_accs, val_losses, val_accs, val_corrected_accs = model.train(train_data, val_data, train_loss_acc, compute_loss_acc, num_epochs=num_epochs, batchsize=batchsize, record_per_iter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
